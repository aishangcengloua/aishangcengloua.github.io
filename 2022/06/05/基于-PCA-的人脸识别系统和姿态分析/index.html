<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/%E5%AE%9D%E5%84%BF%E5%A7%90.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/%E5%AE%9D%E5%84%BF%E5%A7%90.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/%E5%AE%9D%E5%84%BF%E5%A7%90.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"aishangcengloua.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1    PCA&amp;emsp;&amp;emsp;在解决实际问题的时候，多变量问题是经常会遇到的，变量太多，无疑会增加分析问题的难度与复杂性。同时，在许多实际问题中，多个变量之间是具有一定的相关关系的。因此，能否在各个变量之间相关关系研究的基础上， 用较少的新变量代替原来较多的变量，而且使这些较少的新变量尽可能多地保留原来较多的变量所反映的信息？事实上，这种想法是可以实现的。">
<meta property="og:type" content="article">
<meta property="og:title" content="基于 PCA 的人脸识别系统和姿态分析">
<meta property="og:url" content="https://aishangcengloua.github.io/2022/06/05/%E5%9F%BA%E4%BA%8E-PCA-%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%A7%BF%E6%80%81%E5%88%86%E6%9E%90/index.html">
<meta property="og:site_name" content="Z.H.Chen&#39;s Blog">
<meta property="og:description" content="1    PCA&amp;emsp;&amp;emsp;在解决实际问题的时候，多变量问题是经常会遇到的，变量太多，无疑会增加分析问题的难度与复杂性。同时，在许多实际问题中，多个变量之间是具有一定的相关关系的。因此，能否在各个变量之间相关关系研究的基础上， 用较少的新变量代替原来较多的变量，而且使这些较少的新变量尽可能多地保留原来较多的变量所反映的信息？事实上，这种想法是可以实现的。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://th.bing.com/th/id/OIP.2LuHxwMc-MzJ1dVcPILd8gHaFj?w=232&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.25&amp;pid=1.7">
<meta property="og:image" content="https://www.biaodianfu.com/wp-content/uploads/2020/09/pca-1.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/a0f6f5a31b3c4ed5b0cb7c22181a7b36.gif#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/20141118160519755">
<meta property="og:image" content="https://s2.loli.net/2022/05/19/pC3x96HrBuUeXVE.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/19/6zfl5CbSkRD9tIU.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/19/qDipj3KYxOENIdr.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/19/gmIs7vV8OjkhFcY.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/19/ztsfYqZ4EBxbmAH.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/19/3vGMJNwdRm7VqFk.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/19/eAz9hIPBoxL3SsM.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/20/s9gKJwOAuvIlXNa.gif">
<meta property="og:image" content="https://s2.loli.net/2022/05/20/uXFliTn684xyjbt.gif">
<meta property="og:image" content="https://s2.loli.net/2022/05/20/QfqCo8hGndFTKsY.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/b9f891364dce4b34b7c5cc92eeddb91e.png#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/5c69273a82b9498fa2ee5e5687e83144.png#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/fe51821134814cc5996538ab3fd303c8.png#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/b2ff281d361544b8ac5eefa6f2efe04b.png#pic_center">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/KhdyRUGOxXbQT4I.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/ZKIA3FSzvopPYyE.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/YknZ5BqiUgu9emH.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/mXRtE9GuBdiFbHf.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/a7FzbHgidoVXJqc.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/WvjkfipygLDnwsx.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/rqFL1VSwfOvTsUh.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/TOR9sYqIkmcPtnp.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/7SAPQtwZ1HJDdWq.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/21/hsgao7wQbFTD6f2.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/20/U2avBNKTs9LjDe3.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/20/G4bIoi1AmtPzdDW.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/20/4LkADSqtzQr9eRx.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/20/OJMPFlqrbmC6W9Y.png">
<meta property="og:image" content="https://s2.loli.net/2022/05/20/rDhmiMLb4V5A3Z7.png">
<meta property="article:published_time" content="2022-06-05T14:50:23.000Z">
<meta property="article:modified_time" content="2022-06-05T14:53:39.628Z">
<meta property="article:author" content="Z.H.Chen">
<meta property="article:tag" content="主成分分析">
<meta property="article:tag" content="人脸识别">
<meta property="article:tag" content="姿态分析">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://th.bing.com/th/id/OIP.2LuHxwMc-MzJ1dVcPILd8gHaFj?w=232&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.25&amp;pid=1.7">

<link rel="canonical" href="https://aishangcengloua.github.io/2022/06/05/%E5%9F%BA%E4%BA%8E-PCA-%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%A7%BF%E6%80%81%E5%88%86%E6%9E%90/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>基于 PCA 的人脸识别系统和姿态分析 | Z.H.Chen's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Z.H.Chen's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Z.H.Chen's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">59</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">8</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">60</span></a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/atom.xml" rel="section"><i class="fa fa-rss fa-fw"></i>RSS</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/aishangcengloua" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aishangcengloua.github.io/2022/06/05/%E5%9F%BA%E4%BA%8E-PCA-%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%A7%BF%E6%80%81%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/%E5%AE%9D%E5%84%BF%E5%A7%90.jpg">
      <meta itemprop="name" content="Z.H.Chen">
      <meta itemprop="description" content="你好啊！欢迎来到我的博客世界！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Z.H.Chen's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于 PCA 的人脸识别系统和姿态分析
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-06-05 22:50:23 / 修改时间：22:53:39" itemprop="dateCreated datePublished" datetime="2022-06-05T22:50:23+08:00">2022-06-05</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BC%A0%E7%BB%9F%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">传统算法</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2022/06/05/%E5%9F%BA%E4%BA%8E-PCA-%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%A7%BF%E6%80%81%E5%88%86%E6%9E%90/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2022/06/05/%E5%9F%BA%E4%BA%8E-PCA-%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%A7%BF%E6%80%81%E5%88%86%E6%9E%90/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>12k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>20 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1-PCA"><a href="#1-PCA" class="headerlink" title="1    PCA"></a>1    PCA</h1><p>&emsp;&emsp;在解决实际问题的时候，多变量问题是经常会遇到的，变量太多，无疑会增加分析问题的难度与复杂性。同时，在许多实际问题中，多个变量之间是具有一定的相关关系的。因此，能否在各个变量之间相关关系研究的基础上， 用较少的新变量代替原来较多的变量，而且使这些较少的新变量尽可能多地保留原来较多的变量所反映的信息？事实上，这种想法是可以实现的。</p>
<h2 id="1-1-原理"><a href="#1-1-原理" class="headerlink" title="1.1    原理"></a>1.1    原理</h2><p>&emsp;&emsp;<strong>PCA</strong>(Principal Components Analysis,，主成分分析)是将原来多个变量化为少数几个综合指标的一种统计分析方法，从数学角度来看，这是一种降维处理技术。  下面举例说明其原理，加入有以下数据：</p>
<p><img src="https://th.bing.com/th/id/OIP.2LuHxwMc-MzJ1dVcPILd8gHaFj?w=232&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.25&amp;pid=1.7" alt="img"></p>
<p>可以将上述数据看成一个椭圆形，椭圆有一个长轴和一个短轴。 在短轴方向上， 数据变化很少；在极端的情况，短轴如果退化成一点， 那只有在长轴的方向才能够解释这些点的变化了。这样，由二维到一维的降维就自然完成了。 从数据波动上来看，在短轴上数据的方差较小，因此在该轴上的信息属于次信息；而在长轴上数据的方差较大，因此在该轴上的信息属于主信息。了解 PCA 的基本原理之后，我们还要思考一个问题，PCA 优化的目标是什么？请看下图：</p>
<p><img src="https://www.biaodianfu.com/wp-content/uploads/2020/09/pca-1.png" alt="img" style="zoom: 50%;" /></p>
<p>我们将上图中的点往两个超平面上投影，分别得到不同超平面的方差分别为：0.045，0.206，因此将所有样本点投影到方差为 0.206 的超平面能在实现降维的目标且保留更多的信息。因此 PCA 要做得是使所有样本的投影尽可能分开，也即找到一个样本投影后的方差最大的超平面来实现降维。我们将上述降维准则称作 <strong>最大可分性</strong>；同时样本点到这个超平面的距离都足够近，即下图中所有红线(即投影造成的损失)加起来最小，也就是保留了更多的信息，我们将此准则称作 <strong>最近重构性</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/a0f6f5a31b3c4ed5b0cb7c22181a7b36.gif#pic_center" alt="在这里插入图片描述" style="zoom: 80%;" /></p>
<h2 id="1-2-算法流程"><a href="#1-2-算法流程" class="headerlink" title="1.2    算法流程"></a>1.2    算法流程</h2><p>&emsp;&emsp;PCA 整体的算法流程描述如下：</p>
<hr>
<p><strong>输入：样本集 $\boldsymbol{D = {x_1,x_2, \cdots,x_m}}$； 低维空间维数 $\boldsymbol{k}$;</strong></p>
<p><strong>过程：</strong></p>
<p><strong>1：对所有样本进行零均值化：$\boldsymbol{x_i\leftarrow x_i - \frac{1}{m}\sum_{i=1}^{m}x_i}$;</strong></p>
<p><strong>2：计算样本的协方差矩阵 $\boldsymbol{XX^T}$;</strong></p>
<p><strong>3：对协方差矩阵 $\boldsymbol{XX^T}$ 做特征值分解；</strong></p>
<p><strong>4：取最大的 $\boldsymbol{k}$ 个的特征值所对应的特征向量 $\boldsymbol{w_1, w_2, \cdots, w_{k}}$;</strong></p>
<p><strong>输出：投影矩阵 $\boldsymbol{W = (w_1, w_2, \cdots, w_{k})}$。</strong></p>
<hr>
<p>下面对每个步骤进行详细分析。</p>
<h3 id="1-2-1-零均值化"><a href="#1-2-1-零均值化" class="headerlink" title="1.2.1    零均值化"></a>1.2.1    零均值化</h3><p>&emsp;&emsp;此步骤的目的是标准化输入数据集，使数据成比例缩小。更确切地说，在使用 PCA 之前必须标准化数据的原因是 PCA 方法对初始变量的方差非常敏感。也就是说，如果初始变量的范围之间存在较大差异，那么范围较大的变量占的比重较大，和较小的变量相比(例如，范围介于 0 和 100 之间的变量较 0 到 1 之间的变量会占较大比重)，这将导致主成分的偏差。通过将数据转换为同样的比例可以防止这个问题。在实现过程中，我们的操作区别于标准的标准化，我们只将每个样本减去它们的均值。</p>
<h3 id="1-2-2-计算协方差矩阵"><a href="#1-2-2-计算协方差矩阵" class="headerlink" title="1.2.2    计算协方差矩阵"></a>1.2.2    计算协方差矩阵</h3><p>&emsp;&emsp;此步骤的目的是了解输入数据集的变量相对于彼此平均值变化，换句话说，查看它们是否存在关系。因为有时候变量由于高度相关，这样就会包含冗余信息。因此，为了识别变量的相关性，我们计算协方差矩阵。下面以二维矩阵为例：</p>
<script type="math/tex; mode=display">
C= 
\begin{bmatrix}
Cov(x,x)&Cov(x,y)&Cov(x, z)\\
Cov(y,x)&Cov(y, y)&Cov(y,z)\\
Cov(z,x)&Cov(z, y)&Cov(z,z)
\end{bmatrix}</script><p>上述矩阵中，对角线上分别是特征 $x, y,z$ 的方差，非对角线上是协方差。由于协方差是可交换的 $Cov(a, b) = Cov(b,a)$，协方差矩阵关于主对角线是对称的，这意味着上三角部分和下三角部分相等。协方差矩阵可以告诉我们变量之间的关系，总结有如下三点：</p>
<ul>
<li>如果协方差为正则：两个变量一起增加或减少(正相关)；</li>
<li>如果协方差为负则：两个变量其中一个增加，另一个减少(负相关)；</li>
<li>协方差绝对值越大，两者对彼此的影响越大，反之越小。</li>
</ul>
<h3 id="1-2-3-特征值和特征向量"><a href="#1-2-3-特征值和特征向量" class="headerlink" title="1.2.3    特征值和特征向量"></a>1.2.3    特征值和特征向量</h3><p>&emsp;&emsp;求协方差矩阵 $C$ 的特征值 $\lambda$ 和相对应的特征向量 $u$ (每一个特征值对应一个特征向量)：</p>
<script type="math/tex; mode=display">
Cu = \lambda u</script><p>特征值 $\lambda$ 会有 $N$ 个，每一个 $\lambda$ 对应一个特征向量 $u$，将特征值 $\lambda$ 按照从大到小的顺序排序，选择最大的前 $K$ 个，并将其相对应的 $K$ 个特征向量拿出来，我们会得到一组 $\{(\lambda_1,u_1),(\lambda_2,u_2),\cdots,(\lambda_k, u_k)\}$。为什么只取特征值较大的特征向量，因为较大特征值对应的特征向量保留了原始数据的大部分信息吗，也即方差较大，可作为数据的主成分。</p>
<h3 id="1-2-4-降维得到-K-维特征"><a href="#1-2-4-降维得到-K-维特征" class="headerlink" title="1.2.4    降维得到 K 维特征"></a>1.2.4    降维得到 K 维特征</h3><p>&emsp;&emsp;选取最大的前 $K$ 个特征值和相对应的特征向量，并进行投影的过程，就是降维的过程。对于每个样本 $X_i$，原始的特征是 $(x_1, x_2, \cdots,x_m)$，投影之后的新特征是 $(y_1,y_2,\cdots,y_k)$，计算过程如下：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
y_1^i\\
y_2^i\\
\vdots \\
y_k^i\\
\end{bmatrix} = 
\begin{bmatrix}
u^T_1\cdot(x_1^i, x_2^i, \cdots,x_m^i)^T\\
u^T_2\cdot(x_1^i, x_2^i, \cdots,x_m^i)^T\\
\vdots\\
u^T_k\cdot(x_1^i, x_2^i, \cdots,x_m^i)^T
\end{bmatrix}</script><h3 id="1-2-5-PCA-的优缺点"><a href="#1-2-5-PCA-的优缺点" class="headerlink" title="1.2.5    PCA 的优缺点"></a>1.2.5    PCA 的优缺点</h3><p>优点：</p>
<ul>
<li>只需以方差衡量信息量，不受数据集以外的因素影响；</li>
<li>各主成分之间正交，可消除原始数据成分间的相互影响；</li>
<li>计算方法简单，主要运算是特征值分解且易于实现。</li>
</ul>
<p>缺点：</p>
<ul>
<li>主成分各特征维度的含义具有模糊性，不如原始样本特征的解释性强；</li>
<li>方差小的成分可能含有影响样本差异的重要信息，降维丢弃可能对后续数据处理有影响。</li>
</ul>
<h1 id="2-Python-实现-PCA"><a href="#2-Python-实现-PCA" class="headerlink" title="2    Python 实现 PCA"></a>2    Python 实现 PCA</h1><p>&emsp;&emsp;本次实现的流程完全依据于 <a href="# 1.2    算法流程"><strong>1.2    算法流程</strong></a>，代码中有详细注释，便不在另做解释：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PCA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_components</span>):</span><br><span class="line">        <span class="comment"># 决定降到多少维</span></span><br><span class="line">        self.n_components = n_components</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 均值</span></span><br><span class="line">        X_mean = np.mean(X, axis = <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 去均值化</span></span><br><span class="line">        X_norm = X - X_mean</span><br><span class="line">        <span class="comment"># 计算协方差矩阵，将每行也即每一个样本看作一个变量，每列作为观测值</span></span><br><span class="line">        X_conv = np.cov(X_norm, rowvar = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 计算特征值何特征向量</span></span><br><span class="line">        eigenvalues, featurevectors = np.linalg.eig(X_conv)</span><br><span class="line">        <span class="comment"># 特征值从小到大的下标</span></span><br><span class="line">        index = np.argsort(eigenvalues)</span><br><span class="line">        <span class="comment"># 取最大的 n_components 个特征值</span></span><br><span class="line">        n_index = index[ -self.n_components : ]</span><br><span class="line">        <span class="comment"># 降维，训练样本的特征脸空间</span></span><br><span class="line">        self.w = featurevectors[ : , n_index]</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 计算训练样本和测试样本在特征脸空间的投影</span></span><br><span class="line">        <span class="comment"># 映射到图像空间</span></span><br><span class="line">        eigenfaces = np.dot(X, self.w)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> eigenfaces</span><br></pre></td></tr></table></figure>
<h1 id="3-基于-PCA-的人脸识别"><a href="#3-基于-PCA-的人脸识别" class="headerlink" title="3    基于 PCA 的人脸识别"></a>3    基于 PCA 的人脸识别</h1><p>&emsp;&emsp;在前面中，我们从原理开始分析 PCA 算法，最终并使用 Python 实现了 PCA 算法，那这部分主要是使用 PCA 来对不同的人脸识别数据集进行提取特征，并且实现人脸识别。</p>
<h2 id="3-1-ORL-数据集"><a href="#3-1-ORL-数据集" class="headerlink" title="3.1    ORL 数据集"></a>3.1    ORL 数据集</h2><p>&emsp;&emsp;ORL 人脸数据集共包含 40 个不同人的 400 张图像，是在 1992 年 4 月至 1994 年 4 月期间由英国剑桥的 Olivetti 研究实验室创建。 此数据集下包含 40 个目录，每个目录下有 10 张图像，每个目录表示一个不同的人。所有的图像是以 PGM 格式存储，灰度图，图像大小宽度为 92，高度为 112。对每一个目录下的图像，这些图像是在不同的时间、不同的光照、不同的面部表情 (睁眼 / 闭眼，微笑 / 不微笑) 和面部细节 (戴眼镜 / 不戴眼镜) 环境下采集的。所有的图像是在较暗的均匀背景下拍摄的，拍摄的是正脸 (有些带有略微的侧偏)。下载地址为：<a target="_blank" rel="noopener" href="https://github.com/yasminemedhat/Face-Recognition"><strong>https://github.com/yasminemedhat/Face-Recognition</strong></a></p>
<p><img src="https://img-blog.csdn.net/20141118160519755" alt="img" style="zoom:67%;" /></p>
<p>人脸识别的流程如下：</p>
<ul>
<li>数据读取与数据处理；</li>
<li>数据分组；</li>
<li>使用 PCA 进行特征提取；</li>
<li>人脸识别；</li>
<li>人脸识别的 GUI 界面。</li>
</ul>
<h3 id="3-1-1-数据读取与数据处理"><a href="#3-1-1-数据读取与数据处理" class="headerlink" title="3.1.1    数据读取与数据处理"></a>3.1.1    数据读取与数据处理</h3><p>&emsp;&emsp;因为 ORL 数据集的图片格式是 <strong>.pgm</strong>，我使用了 <strong>pillow</strong> 库中的 <strong>Image</strong> 类来进行读取。对于每张照片将其拉直，因为 ORL 中图片大小是 (112，92)，拉直之后则变成 (10304，)，然后将所有照片进行拼接，最终得到大小为 (400，10304) 的二维矩阵。再者就是标签的构造，从上到下的 <strong>人</strong> 的标签分别是 0，1，2，…，39，要注意每一张图片都要有一个标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img).ravel()</span><br><span class="line">            X.append(img)</span><br><span class="line">        y.extend([idx] * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<h3 id="3-1-2-数据分组"><a href="#3-1-2-数据分组" class="headerlink" title="3.1.2    数据分组"></a>3.1.2    数据分组</h3><p>&emsp;&emsp;本次数据的分割依据于下面的两种方式：</p>
<ul>
<li>每个人的前面 8 张照片作为训练并作为测试样本库，后面 2 张作为测试待识别图片；</li>
<li>前 38 个人作为训练，后 12 个人作为测试，其中测试库中每个人的前面 8 张照片为测试样本库，后面 2 张照片作为待识别图片。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y, flag</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    test_set = []</span><br><span class="line">    test_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line">    <span class="comment"># 分组一：每个人的任意 8 张照片作为训练并作为测试样本库</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="number">1</span> :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>) :</span><br><span class="line">            train_set.append(X[i * <span class="number">10</span> : i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            train_target.extend(y[i * <span class="number">10</span> : i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            face_unrecognized_set.append(X[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">            face_unrecognized_target.extend(y[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">        test_set = train_set.copy()</span><br><span class="line">        test_target = train_target.copy()</span><br><span class="line">    <span class="comment"># 分组二：前 38 个人作为训练，后 2 个人作为测试</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        train_set = X[: <span class="number">380</span>, :]</span><br><span class="line">        train_target = y[: <span class="number">380</span>]</span><br><span class="line">        X_temp = X[<span class="number">380</span>:, :]</span><br><span class="line">        y_temp = y[<span class="number">380</span>:]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>) :</span><br><span class="line">            test_set.extend(X_temp[i * <span class="number">10</span>: i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            test_target.extend(y_temp[i * <span class="number">10</span>: i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            face_unrecognized_set.extend(X_temp[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">            face_unrecognized_target.extend(y_temp[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    test_set = np.array(test_set)</span><br><span class="line">    test_target = np.array(test_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           test_set, test_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br></pre></td></tr></table></figure>
<h3 id="3-1-3-使用-PCA-进行特征提取"><a href="#3-1-3-使用-PCA-进行特征提取" class="headerlink" title="3.1.3    使用 PCA 进行特征提取"></a>3.1.3    使用 PCA 进行特征提取</h3><p>&emsp;&emsp;本过程对人脸特征进行提取，主要难度在于编写 PCA，我们在前面已经完成。但是我们还有一个非常重要的参数要确定，就是 $\boldsymbol{k}$ 值，如果 $\boldsymbol{k}$ 过大，那 PCA 降维之后数据信息中仍然保留大量的冗余信息；如果 $\boldsymbol{k}$ 过小，则 PCA 降维过程中损失了过多信息，不利于后续的识别工作。为此，我借用 <strong>sklearn</strong> 来探究在保留 95% 的原始数据应该降到多少纬合适。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components = <span class="number">0.95</span>)</span><br><span class="line">pca.fit(train_set)</span><br><span class="line"><span class="built_in">print</span>(pca.n_components_)</span><br></pre></td></tr></table></figure>
<p>最终的测试结果是对于 <strong>分组一</strong> 和 <strong>分组二</strong> 的 $\boldsymbol{k}$ 值分别是 161，184。知道 $\boldsymbol{k}$ 值之后，我们就可以进行特征提取，要注意我们只能对训练集进行训练，也即要使用训练集的特征向量对测试集和待识别图片进行 PCA 降维。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">161</span>) <span class="comment"># or pca = PCA(n_components = 184)</span></span><br><span class="line">pca.fit(train_set)</span><br><span class="line">train_reduction = pca.transform(train_set)</span><br><span class="line">test_reduction = pca.transform(test_set)</span><br><span class="line">face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br></pre></td></tr></table></figure>
<h3 id="3-1-4-人脸识别"><a href="#3-1-4-人脸识别" class="headerlink" title="3.1.4    人脸识别"></a>3.1.4    人脸识别</h3><p>&emsp;&emsp;经过上述步骤之后，我们可以得到降维后的训练集、测试集和待识别人脸，在这部分我们就可以进行人脸匹配。首先要说明：对于人脸识别而言，如果计算机先前没有看到过关于这个人的照片，那对这个人进行人脸识别是没有意义的，大家可以细细探究一下 <strong>分组一</strong> 和 <strong>分组二</strong>。本次人脸识别我使用的准则是 <strong>二范数</strong>，下面分别对 <strong>分组一</strong> 和 <strong>分组二</strong> 进行讲解。</p>
<p>&emsp;&emsp;首先是 <strong>分组一</strong>，因为训练集和测试集一样，都包含了全部人的人脸，也就是说计算机 <strong>“看过”</strong> 待识别人脸，因此我们可以用训练集或者测试集来进行人脸识别：计算待识别的人脸特征向量与训练集中每一张图片的特征向量的二范数，其中二范数最小的那张图片就是我们在训练集中匹配到的人脸。在此过程我设置了两个返回值分别是 <strong>pred</strong> 和 <strong>labels</strong>，前者为匹配到的人脸图片在训练集中的下标，方便后面的 GUI 设计，后者是匹配到的人脸图片的标签，用于后续的识别准确率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, Y</span>) :</span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)) :</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis = <span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        labels.append(label // <span class="number">8</span>)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;其次是 <strong>分组二</strong>，训练集是前 38 个人的人脸照片，测试集是后两个人的前 8 张图片，待识别图片是后两个人的后两张人脸图片。如果我们使用训练集去匹配待识别图片，这时计算原先没有 <strong>“看过”</strong> 该人人脸，此时识别是无意义的，因此我们要使用测试集去识别待识别图片。返回值同样是 <strong>pred</strong> 和 <strong>labels</strong>，要注意标签的计算方式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, Y</span>) :</span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)) :</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis = <span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        labels.append(label // <span class="number">8</span> + <span class="number">38</span>)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred) </span><br></pre></td></tr></table></figure>
<h3 id="3-1-5-人脸识别的-GUI-界面"><a href="#3-1-5-人脸识别的-GUI-界面" class="headerlink" title="3.1.5    人脸识别的 GUI 界面"></a>3.1.5    人脸识别的 GUI 界面</h3><p>&emsp;&emsp;为了体现人脸识别系统的完整性，我设计了人脸识别系统的 GUI，在 GUI 页面的左边展示的是待识别人脸图片，在点击按键 <strong>“开始识别”</strong> 之后，GUI 页面右边会展示识别效果。代码与效果会在下面展示。</p>
<h3 id="3-1-6-实验结果"><a href="#3-1-6-实验结果" class="headerlink" title="3.1.6    实验结果"></a>3.1.6    实验结果</h3><p>&emsp;&emsp;对于分组一：一共有采集了 80 张待识别人脸图片，最终识别正确率是 0.95，显示别效果如下：</p>
<p><img src="https://s2.loli.net/2022/05/19/pC3x96HrBuUeXVE.png" alt="1652942593728.png" style="zoom:50%;" /></p>
<p>如上图，前面三张识别是成功的，而第四张是识别错误的。</p>
<p>&emsp;&emsp;对于分组二：一共有采集了 4 张待识别人脸图片，最终识别正确率是 1.0，显示别效果如下：</p>
<p><img src="https://s2.loli.net/2022/05/19/6zfl5CbSkRD9tIU.png" alt="1652942964367.png" style="zoom:50%;" /></p>
<p>如上图，四张待识别图片全部识别正确。</p>
<h3 id="3-1-7-全部代码"><a href="#3-1-7-全部代码" class="headerlink" title="3.1.7    全部代码"></a>3.1.7    全部代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageTk</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> font</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_components</span>):</span><br><span class="line">        <span class="comment"># 决定降到多少维</span></span><br><span class="line">        self.n_components = n_components</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 均值</span></span><br><span class="line">        X_mean = np.mean(X, axis = <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 去均值化</span></span><br><span class="line">        X_norm = X - X_mean</span><br><span class="line">        <span class="comment"># 计算协方差矩阵，将每行也即每一个样本看作一个变量，每列作为观测值</span></span><br><span class="line">        X_conv = np.cov(X_norm, rowvar = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 计算特征值何特征向量</span></span><br><span class="line">        eigenvalues, featurevectors = np.linalg.eig(X_conv)</span><br><span class="line">        <span class="comment"># 特征值从小到大的下标</span></span><br><span class="line">        index = np.argsort(eigenvalues)</span><br><span class="line">        <span class="comment"># 取最大的 n_components 个特征值</span></span><br><span class="line">        n_index = index[ -self.n_components : ]</span><br><span class="line">        <span class="comment"># 降维，训练样本的特征脸空间</span></span><br><span class="line">        self.w = featurevectors[ : , n_index]</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 计算训练样本和测试样本在特征脸空间的投影</span></span><br><span class="line">        <span class="comment"># 映射到图像空间</span></span><br><span class="line">        eigenfaces = np.dot(X, self.w)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> eigenfaces</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img).ravel()</span><br><span class="line">            X.append(img)</span><br><span class="line">        y.extend([idx] * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y, flag</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    test_set = []</span><br><span class="line">    test_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line">    <span class="comment"># 分组一：每个人的任意 8 张照片作为训练并作为测试样本库</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="number">1</span> :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>) :</span><br><span class="line">            train_set.append(X[i * <span class="number">10</span> : i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            train_target.extend(y[i * <span class="number">10</span> : i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            face_unrecognized_set.append(X[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">            face_unrecognized_target.extend(y[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">        test_set = train_set.copy()</span><br><span class="line">        test_target = train_target.copy()</span><br><span class="line">    <span class="comment"># 分组二：前 38 个人作为训练，后 2 个人作为测试</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        train_set = X[: <span class="number">380</span>, :]</span><br><span class="line">        train_target = y[: <span class="number">380</span>]</span><br><span class="line">        X_temp = X[<span class="number">380</span>:, :]</span><br><span class="line">        y_temp = y[<span class="number">380</span>:]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>) :</span><br><span class="line">            test_set.extend(X_temp[i * <span class="number">10</span>: i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            test_target.extend(y_temp[i * <span class="number">10</span>: i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            face_unrecognized_set.extend(X_temp[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">            face_unrecognized_target.extend(y_temp[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    test_set = np.array(test_set)</span><br><span class="line">    test_target = np.array(test_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           test_set, test_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, Y</span>) :</span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)) :</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis = <span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        labels.append(label // <span class="number">8</span>)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Face_GUI</span>(<span class="params">unrecognized, result</span>) :</span><br><span class="line">    img = unrecognized.reshape(<span class="number">112</span>, <span class="number">92</span>)</span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    photo = ImageTk.PhotoImage(img)</span><br><span class="line"></span><br><span class="line">    label = Label(root, text = <span class="string">&quot;图片识别&quot;</span>, fg = <span class="string">&#x27;red&#x27;</span>, font = (<span class="string">&quot;华文行楷&quot;</span>, <span class="number">25</span>, font.BOLD))</span><br><span class="line">    label.place(relx = <span class="number">0.35</span>, rely = <span class="number">0.01</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    lb1 = Label(root, image = photo)</span><br><span class="line">    lb1.place(relx = <span class="number">0.1</span>, rely = <span class="number">0.25</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    label_context1 = Label(root, text = <span class="string">&quot;待识别图片:&quot;</span>, fg = <span class="string">&#x27;blue&#x27;</span>, </span><br><span class="line">                           							font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    label_context1.place(relx = <span class="number">0.1</span>, rely = <span class="number">0.15</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    btn = Button(root, text = <span class="string">&quot;开始识别&quot;</span>, command = <span class="keyword">lambda</span> : Match(result), </span><br><span class="line">                 									font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    btn.place(relx = <span class="number">0.35</span>, rely = <span class="number">0.65</span>, relwidth = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Match</span>(<span class="params">result</span>) :</span><br><span class="line">    img = result.reshape(<span class="number">112</span>, <span class="number">92</span>)</span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    photo = ImageTk.PhotoImage(img)</span><br><span class="line"></span><br><span class="line">    lb2 = Label(root, image = photo)</span><br><span class="line">    lb2.place(relx = <span class="number">0.6</span>, rely = <span class="number">0.25</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    label_context2 = Label(root, text = <span class="string">&quot;识别结果:&quot;</span>, fg = <span class="string">&#x27;blue&#x27;</span>, </span><br><span class="line">                           							font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    label_context2.place(relx = <span class="number">0.6</span>, rely = <span class="number">0.15</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.1</span>)</span><br><span class="line">    root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    X, y = Data_Processing(<span class="string">&#x27;ORL&#x27;</span>)</span><br><span class="line">    train_set, train_target, test_set, test_target, face_unrecognized_set,\</span><br><span class="line">    					face_unrecognized_target = Data_Split(X, y, flag = <span class="number">1</span>)</span><br><span class="line">    pca = PCA(n_components = <span class="number">161</span>)</span><br><span class="line">    pca.fit(train_set)</span><br><span class="line">    train_reduction = pca.transform(train_set)</span><br><span class="line">    test_reduction = pca.transform(test_set)</span><br><span class="line">    face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br><span class="line">    labels, pred = Predict(train_reduction, face_unrecognized_reduction)</span><br><span class="line">    accuracy = (labels == face_unrecognized_target).<span class="built_in">sum</span>() / <span class="built_in">len</span>(face_unrecognized_target)</span><br><span class="line">    <span class="built_in">print</span>(accuracy)</span><br><span class="line">    <span class="built_in">print</span>(pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pred)):</span><br><span class="line">        root = Tk()</span><br><span class="line">        root.geometry(<span class="string">&#x27;480x480&#x27;</span>)</span><br><span class="line">        root.title(<span class="string">&#x27;基于 PCA 的人脸识别系统&#x27;</span>)</span><br><span class="line">        unrecognized = face_unrecognized_set[i]</span><br><span class="line">        result = train_set[pred[i]]</span><br><span class="line">        Face_GUI(unrecognized, result)</span><br></pre></td></tr></table></figure>
<h2 id="3-2-Yale-数据集"><a href="#3-2-Yale-数据集" class="headerlink" title="3.2    Yale 数据集"></a>3.2    Yale 数据集</h2><p>&emsp;&emsp;Yale 人脸数据库是一个人脸数据集，主要用于身份鉴定，包含 15 个人，其中每个人有 11 张图像共计 165 个 GIF 格式的灰度图像，每个主题包含不同的面部表情：中心光、带眼镜、快乐、左光、没有眼镜、正常、右光、悲伤、困、惊讶和眨眼。图像大小宽度为 320，高度为 243。下载地址为：<a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/olgabelitskaya/yale-face-database"><strong>https://www.kaggle.com/datasets/olgabelitskaya/yale-face-database</strong></a></p>
<p><img src="https://s2.loli.net/2022/05/19/qDipj3KYxOENIdr.png" alt="0.png"></p>
<p>使用 PCA 对 Yale数据集进行人脸识别的流程和对 ORL 数据集的流程一样，但是许多细节需要调整。</p>
<h3 id="3-2-1-数据读取和数据处理"><a href="#3-2-1-数据读取和数据处理" class="headerlink" title="3.2.1    数据读取和数据处理"></a>3.2.1    数据读取和数据处理</h3><p>&emsp;&emsp;Yale 数据集的文件形式不是我们常见的图片编码格式，因此我使用了 <strong>skimage</strong> 包中的 <strong>io</strong> 模块对图片进行读取。</p>
<p><img src="https://s2.loli.net/2022/05/19/gmIs7vV8OjkhFcY.png" alt="捕获.PNG" style="zoom:67%;" /></p>
<p>在读取完之后，我们发现原始的人脸图片很大，其大小为我们前面所讲的 (243，320)，一张图中，背景占比很高，如果直接对原图进行展平得到 (77760，) 大小的向量，这对于计算资源的要求很高，而且因为背景的存在会影响人脸特征的提取，并最终影响人脸识别性能。因此，一般的人脸识别系统在特征提取之前会首先做一件事：<strong>人脸检测</strong>。不能此实验我使用热人脸检测模型是 <strong>MTCNN</strong> 这是一个深度学习模型，可以达到实施效果，且准确率非常高。可以在命令行通过以下命令进行安装：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mtcnn</span><br></pre></td></tr></table></figure>
<p>MTCNN 的使用模板如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mtcnn.mtcnn <span class="keyword">import</span> MTCNN</span><br><span class="line"><span class="comment"># 要注意输出的图像要是三通道的</span></span><br><span class="line">detector = MTCNN()</span><br><span class="line">result = detector.detect_faces(img)</span><br></pre></td></tr></table></figure>
<p>返回值为：要注意的是返回的结果可能有多个人脸。</p>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="symbol">&#x27;box</span><span class="symbol">&#x27;:</span> [<span class="name">121</span>, <span class="number">69</span>, <span class="number">122</span>, <span class="number">154</span>],</span><br><span class="line">  <span class="symbol">&#x27;confidence</span><span class="symbol">&#x27;:</span> <span class="number">0.9999041557312012</span>,</span><br><span class="line">  <span class="symbol">&#x27;keypoints</span><span class="symbol">&#x27;:</span> &#123;<span class="symbol">&#x27;left_eye</span><span class="symbol">&#x27;:</span> (<span class="name">160</span>, <span class="number">122</span>),</span><br><span class="line">   <span class="symbol">&#x27;right_eye</span><span class="symbol">&#x27;:</span> (<span class="name">214</span>, <span class="number">123</span>),</span><br><span class="line">   <span class="symbol">&#x27;nose</span><span class="symbol">&#x27;:</span> (<span class="name">189</span>, <span class="number">152</span>),</span><br><span class="line">   <span class="symbol">&#x27;mouth_left</span><span class="symbol">&#x27;:</span> (<span class="name">163</span>, <span class="number">182</span>),</span><br><span class="line">   <span class="symbol">&#x27;mouth_right</span><span class="symbol">&#x27;:</span> (<span class="name">210</span>, <span class="number">184</span>)&#125;&#125;]</span><br></pre></td></tr></table></figure>
<p>关于 MTCNN 可以参考：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1604.02878"><strong>https://arxiv.org/abs/1604.02878</strong></a>，这里不做更多说明。下面看一下人脸检测的效果：</p>
<p><img src="https://s2.loli.net/2022/05/19/ztsfYqZ4EBxbmAH.png" alt="Figure_1.png" style="zoom: 50%;" /></p>
<p>在人脸检测之后，就可以根据结果中的人脸框信息对原图的人脸区域进行裁剪，同时为保证最后提取特征的图片向量维度一致，将裁取图片进行 <strong>resize</strong> 到 (100，100)。</p>
<p><img src="https://s2.loli.net/2022/05/19/3vGMJNwdRm7VqFk.png" alt="Figure_1.png" style="zoom:25%;" /></p>
<p>得到人脸区域之后，我们将该区域展平成向量，以便后续操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Draw_image_with_boxes</span>(<span class="params">data, result_list</span>):</span><br><span class="line">    plt.imshow(data)</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> result_list:</span><br><span class="line">        <span class="built_in">print</span>(result)</span><br><span class="line">        <span class="comment"># 得到人脸框的起始点坐标和宽高</span></span><br><span class="line">        x, y, width, height = result[<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">        rect = Rectangle((x, y), width, height, fill = <span class="literal">False</span>, color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        <span class="comment"># 画出人脸框</span></span><br><span class="line">        ax.add_patch(rect)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    Yale_path = []</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    faces = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> os.listdir(root) :</span><br><span class="line">        <span class="keyword">if</span> element != <span class="string">&#x27;Readme.txt&#x27;</span>:</span><br><span class="line">            Yale_path.append(os.path.join(root, element))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> Yale_path :</span><br><span class="line">        image = io.imread(path, as_gray = <span class="literal">True</span>)</span><br><span class="line">        X.append(image)</span><br><span class="line">        label = <span class="built_in">int</span>(os.path.split(path)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&quot;subject&quot;</span>, <span class="string">&quot;&quot;</span>)) - <span class="number">1</span></span><br><span class="line">        y.append(label)</span><br><span class="line"></span><br><span class="line">    detector = MTCNN()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img_src <span class="keyword">in</span> X :</span><br><span class="line">        <span class="comment"># 因为 mtcnn 输入的图片要求是 3 通道，而原始图是灰度图，因此对图像进行拓展</span></span><br><span class="line">        img = np.stack((img_src, img_src, img_src), axis = <span class="number">2</span>)</span><br><span class="line">        result = detector.detect_faces(img)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Draw_image_with_boxes(img, result)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 依据检测结果中的人脸框信息对原图进行裁取，并 resize 到(100, 100)</span></span><br><span class="line">        <span class="comment"># 因为 mtcnn 是同时检测多个人脸，所以返回是一个列表，</span></span><br><span class="line">        <span class="comment"># 但因我们提供的图片只有一个人脸，则取巧</span></span><br><span class="line">        box = result[<span class="number">0</span>][<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">        <span class="comment"># 对原图进行裁取</span></span><br><span class="line">        img1 = img_src[box[<span class="number">1</span>] : box[<span class="number">1</span>] + box[<span class="number">3</span>], box[<span class="number">0</span>] : box[<span class="number">0</span>] + box[<span class="number">2</span>]]</span><br><span class="line">        image = Image.fromarray(img1)</span><br><span class="line">        image = image.resize((<span class="number">100</span>, <span class="number">100</span>))</span><br><span class="line">        face_array = np.asarray(image)</span><br><span class="line">        <span class="comment"># plt.imshow(face_array, vmax = 255, vmin = 0, cmap = &#x27;gray&#x27;)</span></span><br><span class="line">        <span class="comment"># plt.show()</span></span><br><span class="line">        faces.append(face_array.ravel())</span><br><span class="line"></span><br><span class="line">    faces = np.array(faces)</span><br><span class="line">    y = np.array(y)</span><br><span class="line">    <span class="built_in">print</span>(faces.shape)</span><br><span class="line">    <span class="keyword">return</span> faces, y</span><br></pre></td></tr></table></figure>
<h3 id="3-2-2-数据分组"><a href="#3-2-2-数据分组" class="headerlink" title="3.2.2    数据分组"></a>3.2.2    数据分组</h3><p>&emsp;&emsp;对于 Yale 数据集，我没有像 ORL 数据集那样分组，我直接取每个人的前 8 张图片作为预测集，取每个人的后 3 张图片作为待识别图片，也即训练集维度为 (120，10000)，待识别图片为 (45，10000)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line">    <span class="comment"># 取每个人的前 8 张图片作为预测集，取每个人的后 3 张图片作为待识别图片</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>) :</span><br><span class="line">        train_set.extend(X[i * <span class="number">11</span> : i * <span class="number">11</span> + <span class="number">8</span>])</span><br><span class="line">        train_target.extend(y[i * <span class="number">11</span> : i * <span class="number">11</span> + <span class="number">8</span>])</span><br><span class="line">        face_unrecognized_set.extend(X[i * <span class="number">11</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">11</span>])</span><br><span class="line">        face_unrecognized_target.extend(y[i * <span class="number">11</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">11</span>])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br></pre></td></tr></table></figure>
<h3 id="3-2-3-使用-PCA-进行特征提取"><a href="#3-2-3-使用-PCA-进行特征提取" class="headerlink" title="3.2.3    使用 PCA 进行特征提取"></a>3.2.3    使用 PCA 进行特征提取</h3><p>&emsp;&emsp;我们在 <a href="# 3.1.3    使用 PCA 进行特征提取"><strong>3.1.3    使用 PCA 进行特征提取</strong></a> 中通过保留原始数据的 95% 来探究合适的 $\boldsymbol{k}$ 值，对 Yale 数据集采用相同的方法得到保留原始数据的 95% 的 $\boldsymbol{k}$ 值为 46。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">46</span>)</span><br><span class="line">pca.fit(train_set)</span><br><span class="line">train_reduction = pca.transform(train_set)</span><br><span class="line">face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br></pre></td></tr></table></figure>
<h3 id="3-2-4-人脸识别及可视化"><a href="#3-2-4-人脸识别及可视化" class="headerlink" title="3.2.4    人脸识别及可视化"></a>3.2.4    人脸识别及可视化</h3><p>&emsp;&emsp;Yale 数据集的标签预测过程与 ORL 数据集的分组一一样，且人脸识别的 GUI 界面也与前面一样。<a href="# 3.1.4    人脸识别"><strong>3.1.4    人脸识别</strong></a>，<a href="# 3.1.5    人脸识别的 GUI 界面"><strong>3.1.5    人脸识别的 GUI 界面</strong></a>。要修改的代码只有一处。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = result.reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-2-5-实验结果"><a href="#3-2-5-实验结果" class="headerlink" title="3.2.5    实验结果"></a>3.2.5    实验结果</h3><p>&emsp;&emsp;基于 PCA 算法构建的人脸识别系统对 Yale 数据集的识别正确率有 0.933，这是一个非常不错的正确率，因为 Yale 数据集的外界扰动十分大。识别效果如下：</p>
<p><img src="https://s2.loli.net/2022/05/19/eAz9hIPBoxL3SsM.png" alt="1652968049305.png" style="zoom: 50%;" /></p>
<p>如上图，一些光照变换很大、戴眼镜的人脸都能识别成，在右下角是一张识别错误的人脸，跟 ORL 数据集相比，PCA 对 Yale 数据集的鲁棒性会稍差一点。</p>
<h3 id="3-2-6-全部代码"><a href="#3-2-6-全部代码" class="headerlink" title="3.2.6    全部代码"></a>3.2.6    全部代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PCA <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageTk</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> font</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> mtcnn.mtcnn <span class="keyword">import</span> MTCNN</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> Rectangle</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Draw_image_with_boxes</span>(<span class="params">data, result_list</span>):</span><br><span class="line">    plt.imshow(data)</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> result_list:</span><br><span class="line">        <span class="built_in">print</span>(result)</span><br><span class="line">        <span class="comment"># 得到人脸框的起始点坐标和宽高</span></span><br><span class="line">        x, y, width, height = result[<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">        rect = Rectangle((x, y), width, height, fill = <span class="literal">False</span>, color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        <span class="comment"># 画出人脸框</span></span><br><span class="line">        ax.add_patch(rect)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    Yale_path = []</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    faces = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> os.listdir(root) :</span><br><span class="line">        <span class="keyword">if</span> element != <span class="string">&#x27;Readme.txt&#x27;</span>:</span><br><span class="line">            Yale_path.append(os.path.join(root, element))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> Yale_path :</span><br><span class="line">        image = io.imread(path, as_gray = <span class="literal">True</span>)</span><br><span class="line">        X.append(image)</span><br><span class="line">        label = <span class="built_in">int</span>(os.path.split(path)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&quot;subject&quot;</span>, <span class="string">&quot;&quot;</span>)) - <span class="number">1</span></span><br><span class="line">        y.append(label)</span><br><span class="line"></span><br><span class="line">    detector = MTCNN()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img_src <span class="keyword">in</span> X :</span><br><span class="line">        <span class="comment"># 因为 mtcnn 输入的图片要求是 3 通道，而原始图是灰度图，因此对图像进行拓展</span></span><br><span class="line">        img = np.stack((img_src, img_src, img_src), axis = <span class="number">2</span>)</span><br><span class="line">        result = detector.detect_faces(img)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw_image_with_boxes(img, result)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 依据检测结果中的人脸框信息对原图进行裁取，并 resize 到(100, 100)</span></span><br><span class="line">        <span class="comment"># 因为 mtcnn 是同时检测多个人脸，所以返回是一个列表，</span></span><br><span class="line">        <span class="comment"># 但因我们提供的图片只有一个人脸，则取巧</span></span><br><span class="line">        box = result[<span class="number">0</span>][<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">        <span class="comment"># 对原图进行裁取</span></span><br><span class="line">        img1 = img_src[box[<span class="number">1</span>] : box[<span class="number">1</span>] + box[<span class="number">3</span>], box[<span class="number">0</span>] : box[<span class="number">0</span>] + box[<span class="number">2</span>]]</span><br><span class="line">        image = Image.fromarray(img1)</span><br><span class="line">        image = image.resize((<span class="number">100</span>, <span class="number">100</span>))</span><br><span class="line">        face_array = np.asarray(image)</span><br><span class="line">        <span class="comment"># plt.imshow(face_array, vmax = 255, vmin = 0, cmap = &#x27;gray&#x27;)</span></span><br><span class="line">        <span class="comment"># plt.show()</span></span><br><span class="line">        faces.append(face_array.ravel())</span><br><span class="line"></span><br><span class="line">    faces = np.array(faces)</span><br><span class="line">    y = np.array(y)</span><br><span class="line">    <span class="built_in">print</span>(faces.shape)</span><br><span class="line">    <span class="keyword">return</span> faces, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line">    <span class="comment"># 取每个人的前 8 张图片作为预测集，取每个人的后 3 张图片作为待识别图片</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>) :</span><br><span class="line">        train_set.extend(X[i * <span class="number">11</span> : i * <span class="number">11</span> + <span class="number">8</span>])</span><br><span class="line">        train_target.extend(y[i * <span class="number">11</span> : i * <span class="number">11</span> + <span class="number">8</span>])</span><br><span class="line">        face_unrecognized_set.extend(X[i * <span class="number">11</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">11</span>])</span><br><span class="line">        face_unrecognized_target.extend(y[i * <span class="number">11</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">11</span>])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, Y</span>) :</span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)) :</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis = <span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        labels.append(label // <span class="number">8</span>)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Face_GUI</span>(<span class="params">unrecognized, result</span>) :</span><br><span class="line">    img = unrecognized.reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    photo = ImageTk.PhotoImage(img)</span><br><span class="line"></span><br><span class="line">    label = Label(root, text = <span class="string">&quot;图片识别&quot;</span>, fg = <span class="string">&#x27;red&#x27;</span>, font = (<span class="string">&quot;华文行楷&quot;</span>, <span class="number">25</span>, font.BOLD))</span><br><span class="line">    label.place(relx = <span class="number">0.35</span>, rely = <span class="number">0.01</span>, relwidth = <span class="number">0.3</span>, relheight=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    lb1 = Label(root, image = photo)</span><br><span class="line">    lb1.place(relx = <span class="number">0.1</span>, rely = <span class="number">0.25</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    label_context1 = Label(root, text = <span class="string">&quot;待识别图片:&quot;</span>, fg = <span class="string">&#x27;blue&#x27;</span>, </span><br><span class="line">                           						font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    label_context1.place(relx = <span class="number">0.1</span>, rely = <span class="number">0.15</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    btn = Button(root, text = <span class="string">&quot;开始识别&quot;</span>, command = <span class="keyword">lambda</span> : Match(result), </span><br><span class="line">                 								font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    btn.place(relx = <span class="number">0.35</span>, rely = <span class="number">0.65</span>, relwidth = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Match</span>(<span class="params">result</span>) :</span><br><span class="line">    img = result.reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    photo = ImageTk.PhotoImage(img)</span><br><span class="line"></span><br><span class="line">    lb2 = Label(root, image = photo)</span><br><span class="line">    lb2.place(relx = <span class="number">0.6</span>, rely = <span class="number">0.25</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    label_context2 = Label(root, text = <span class="string">&quot;识别结果:&quot;</span>, fg = <span class="string">&#x27;blue&#x27;</span>, </span><br><span class="line">                           						font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    label_context2.place(relx = <span class="number">0.6</span>, rely = <span class="number">0.15</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.1</span>)</span><br><span class="line">    root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    X, y = Data_Processing(<span class="string">&#x27;Yale&#x27;</span>)</span><br><span class="line">    train_set, train_target, face_unrecognized_set, \</span><br><span class="line">    				face_unrecognized_target = Data_Split(X, y)</span><br><span class="line">    <span class="comment"># print(train_set.shape, train_target.shape, face_unrecognized_set.shape, 															face_unrecognized_target.shape)</span></span><br><span class="line">    pca = PCA(n_components = <span class="number">46</span>)</span><br><span class="line">    pca.fit(train_set)</span><br><span class="line">    train_reduction = pca.transform(train_set)</span><br><span class="line">    face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br><span class="line">    labels, pred = Predict(train_reduction, face_unrecognized_reduction)</span><br><span class="line">    accuracy = (labels == face_unrecognized_target).<span class="built_in">sum</span>() / <span class="built_in">len</span>(face_unrecognized_target)</span><br><span class="line">    <span class="built_in">print</span>(accuracy)</span><br><span class="line">    <span class="built_in">print</span>(pred)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pred)):</span><br><span class="line">        root = Tk()</span><br><span class="line">        root.geometry(<span class="string">&#x27;480x480&#x27;</span>)</span><br><span class="line">        root.title(<span class="string">&#x27;基于 PCA 的人脸识别系统&#x27;</span>)</span><br><span class="line">        unrecognized = face_unrecognized_set[i]</span><br><span class="line">        result = train_set[pred[i]]</span><br><span class="line">        Face_GUI(unrecognized, result)</span><br></pre></td></tr></table></figure>
<h2 id="3-3-UMIST-数据集"><a href="#3-3-UMIST-数据集" class="headerlink" title="3.3    UMIST 数据集"></a>3.3    UMIST 数据集</h2><p>&emsp;&emsp; 我这里的数据集是 Sheffield 数据集，是 UMIST 数据集的 <strong>“升级版”</strong>(也就是加了几张图片)，后面均以 UMIST 数据集代称。UMIST 人脸数据库由 20 个人(混合种族 / 性别 / 外貌)的 564 张图像组成(Sheffield 数据集为 575)。 每个人都显示在从侧面到正面视图的一系列姿势，每个人都在一个单独的目录中，标记为 1a、1b、…… 1t，并且图像在拍摄时连续编号。 这些文件都是 PGM 格式，大约 220 x 220 像素，256 位灰度。UMIST 数据集有两个版本，一个是原始图片，一个裁剪掉了一些背景区域，裁剪后地图片大小为 (112，92)，与 ORL 数据集一样大小。为实验方便，我所用的版本是裁剪过后的版本。下载地址为：<a target="_blank" rel="noopener" href="http://eprints.lincoln.ac.uk/id/eprint/16081/"><strong>http://eprints.lincoln.ac.uk/id/eprint/16081/</strong></a></p>
<p>未裁剪的图像示例：</p>
<p><img src="https://s2.loli.net/2022/05/20/s9gKJwOAuvIlXNa.gif" alt="face2.gif" style="zoom: 50%;" /></p>
<p>裁剪图像示例：</p>
<p><img src="https://s2.loli.net/2022/05/20/uXFliTn684xyjbt.gif" alt="face1.gif"></p>
<p>说一个小插曲：我原本也就是想找 UMIST 数据集来做实验的，但我从前一天的晚上找到第二天早上都没找到，找到的都是一些处理好的文本数据，便放弃不找了。于是想着找 Bern 数据集来替代，却在找 Bern 数据集过程中阴差阳错地找到了 UMIST 数据集。果真我与你有缘！</p>
<h3 id="3-3-1-数据读取与数据处理"><a href="#3-3-1-数据读取与数据处理" class="headerlink" title="3.3.1    数据读取与数据处理"></a>3.3.1    数据读取与数据处理</h3><p>&emsp;&emsp;对 UMIST 数据集的读取方式与 ORL 数据集有些许差别，但是处理过程与其一样，返回 <a href="#3.1.1    数据读取与数据处理"><strong>3.1.1    数据读取与数据处理</strong></a>。最终得到的数据的二维矩阵大小为 (575, 10304)，标签为 (575，)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    path_files = os.listdir(root)</span><br><span class="line">    <span class="keyword">for</span> idx, path_file <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_files) :</span><br><span class="line">        path_images = os.listdir(os.path.join(root, path_file, <span class="string">&#x27;face&#x27;</span>))</span><br><span class="line">        <span class="keyword">for</span> path_image <span class="keyword">in</span> path_images :</span><br><span class="line">            path = os.path.join(root, path_file, <span class="string">&#x27;face&#x27;</span>, path_image)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img)</span><br><span class="line">            X.append(img.ravel())</span><br><span class="line">            y.append(idx)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<h3 id="3-3-2-数据分组"><a href="#3-3-2-数据分组" class="headerlink" title="3.3.2    数据分组"></a>3.3.2    数据分组</h3><p>&emsp;&emsp;对于 UMIST 数据集，我取每个人的前 5 张图片作为待识别图片，每个人的其余图片为作为训练集。UMIST 数据集与 ORL、Yale 数据集都不一样，因为它每个的图片数量不一样，意味着不能按照常规方法去分割数据。这里我维护了一个 <strong>index</strong> 列表，里面存的是每个人的第一张图片的下标，index 列表从第二个元素开始每一个元素减 1 即可得到前面那个人的最后一张图片的下标。然后依据 index 列表对数据进行裁剪，最终得到的待识别图片的维度是 (100，10304)，训练集图片为 (475，10304)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line"></span><br><span class="line">    index = []</span><br><span class="line">    index.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(y)) :</span><br><span class="line">        <span class="keyword">if</span> y[idx] != y[idx - <span class="number">1</span>] :</span><br><span class="line">            index.append(idx)</span><br><span class="line">    index.append(<span class="built_in">len</span>(y))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取每个人的后 5 张图片作为待识别图片，其余图片作为训练集</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(index) - <span class="number">1</span>) :</span><br><span class="line">        face_unrecognized_set.extend(X[index[i] : index[i] + <span class="number">5</span>])</span><br><span class="line">        face_unrecognized_target.extend(y[index[i]: index[i] + <span class="number">5</span>])</span><br><span class="line">        train_set.extend(X[index[i] + <span class="number">5</span> : index[i + <span class="number">1</span>]])</span><br><span class="line">        train_target.extend(y[index[i] + <span class="number">5</span> : index[i + <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br></pre></td></tr></table></figure>
<h3 id="3-3-3-使用-PCA-进行特征提取"><a href="#3-3-3-使用-PCA-进行特征提取" class="headerlink" title="3.3.3    使用 PCA 进行特征提取"></a>3.3.3    使用 PCA 进行特征提取</h3><p>&emsp;&emsp;同样，我采取与前面相同的方法确定了保留原始数据 95% 信息的 $\boldsymbol{k}$ 值为 97。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">97</span>)</span><br><span class="line">pca.fit(train_set)</span><br><span class="line">train_reduction = pca.transform(train_set)</span><br><span class="line">face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br><span class="line">labels, pred = Predict(train_reduction, face_unrecognized_reduction)</span><br></pre></td></tr></table></figure>
<h3 id="3-3-4-人脸识别及可视化"><a href="#3-3-4-人脸识别及可视化" class="headerlink" title="3.3.4    人脸识别及可视化"></a>3.3.4    人脸识别及可视化</h3><p>&emsp;&emsp;对于 UMIST 数据集，人脸识别和数据分组一样，都有一个问题就是每个人的照片数量不一样，因此在预测标签时不能简单地进行整除等操作。借鉴数据分组时的思想，我同样维护了一个 <strong>index</strong> 列表，里面存的是训练集中的每个人的第一张图片的下标，index 列表从第二个元素开始每一个元素减 1 即可得到前面那个人的最后一张图片的下标。在得到预测下标之后，用其与 index 中的元素相比较便可确定标签，更详细地比较方法参考代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, y, Y</span>):</span><br><span class="line">    <span class="comment"># y 表示训练集的标签</span></span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line"></span><br><span class="line">    index = []</span><br><span class="line">    index.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(y)):</span><br><span class="line">        <span class="keyword">if</span> y[idx] != y[idx - <span class="number">1</span>]:</span><br><span class="line">            index.append(idx)</span><br><span class="line">    index.append(<span class="built_in">len</span>(y))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)):</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis=<span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(index) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> label &gt;= index[j] <span class="keyword">and</span> label &lt; index[j + <span class="number">1</span>]:</span><br><span class="line">                labels.append(j)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred)</span><br></pre></td></tr></table></figure>
<p>其次就是人脸识别的 GUI 页面，UMIST 数据集的 GUI 过程与 ORL 数据集一模一样，请参考前面的代码。</p>
<h3 id="3-3-5-实验结果"><a href="#3-3-5-实验结果" class="headerlink" title="3.3.5    实验结果"></a>3.3.5    实验结果</h3><p>&emsp;&emsp;基于 PCA 算法构建的人脸识别系统对 UMIST 数据集的识别正确率只有 0.88，在三个数据集中最差，其原因可能是 UMIST 数据集中的人的姿态变化幅度较大，如每个人的照片都是从侧面到正面进行拍摄的；其次可能是我对数据的分组不够好，因为前 5 张图片的侧脸角度是最大的。识别效果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/QfqCo8hGndFTKsY.png" alt="1653017304521.png" style="zoom:50%;" /></p>
<p>如上图，可以看到前 3 张待识别图片的侧面的角度非常大，但是该系统还是能够正确识别出来，如果从这个角度来看 0.88 的正确率也不算很差。而在右下角的这张待识别图片就识别错误了。</p>
<h3 id="3-3-6-全部代码"><a href="#3-3-6-全部代码" class="headerlink" title="3.3.6    全部代码"></a>3.3.6    全部代码</h3><p>&emsp;&emsp;限于篇幅原因，这里不张贴全部代码了，可以参考前面 ORL 和 Yale 数据集的代码，且关于一些需要改动的地方在前面几点也已解释清楚。</p>
<p>&emsp;&emsp;至此，我们从 0 开始构建 PCA 算法，到构建基于 PCA 的人脸识别系统对三种不同的数据集进行人脸识别的的工作全部完成。当然，对于 PCA 算法我们依然有许多值得探究的地方，如 $\boldsymbol{k}$ 值的选取，如若以后有时间，也可多花时间进行研究。</p>
<h1 id="4-基于-MediaPipe-的姿态分析"><a href="#4-基于-MediaPipe-的姿态分析" class="headerlink" title="4    基于 MediaPipe 的姿态分析"></a>4    基于 MediaPipe 的姿态分析</h1><p>&emsp;&emsp;<a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/"><strong>MediaPipe</strong></a> 是一个用于构建机器学习管道的框架，用于处理视频、音频等时间序列数据。这个跨平台框架适用于桌面 / 服务器、Android、iOS 和嵌入式设备，如 Raspberry Pi 和 Jetson Nano，由谷歌公司开发。自 2012 年起，谷歌在内部的多个产品和服务中使用了它。它最初是为了实时分析 YouTube 上的视频和音频而开发的。渐渐地，它被整合到更多的产品中，比如谷歌镜头的目标检测、增强现实广告等。</p>
<h2 id="4-1-MediaPipe-Solutions"><a href="#4-1-MediaPipe-Solutions" class="headerlink" title="4.1    MediaPipe Solutions"></a>4.1    MediaPipe Solutions</h2><p>&emsp;&emsp;Solutions 是基于特定的预训练 TensorFlow 或 TFLite 模型的开源预构建示例。MediaPipe Solutions 构建在框架之上。目前，它提供了 16 个 Solutions，如下所示：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/face_detection">人脸检测</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/face_mesh">Face Mesh</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/iris">虹膜</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/hands">手</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/pose">姿态</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/holistic">人体</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/selfie_segmentation">人物分割</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/hair_segmentation">头发分割</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/object_detection">目标检测</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/box_tracking">Box Tracking</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/instant_motion_tracking">Instant Motion Tracking</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/objectron">3D 目标检测</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/knift">特征匹配</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/autoflip">AutoFlip</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/media_sequence">MediaSequence</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/youtube_8m">YouTube-8M</a></li>
</ul>
<p>我将使用其中的姿态检测对前面三种数据集进行进行简单姿态检测。下面是 Pose Solutions 的简单的介绍。</p>
<h3 id="4-1-1-ML-管道"><a href="#4-1-1-ML-管道" class="headerlink" title="4.1.1    ML 管道"></a>4.1.1    ML 管道</h3><p>&emsp;&emsp;Pose Solutions 利用两步检测器 - 跟踪器 ML 管道。使用检测器，管道首先在帧内定位人 / 姿势感兴趣区域 (ROI)。跟踪器随后裁剪帧 ROI 作为输入来预测 ROI 内的姿势标志和分割掩码。请注意，对于视频用例，仅在需要时调用检测器，即在第一帧以及当跟踪器无法再识别前一帧中存在的身体姿势时。对于其他帧，管道只是从前一帧的姿势地标中导出 ROI。</p>
<h3 id="4-1-2-姿态估计质量"><a href="#4-1-2-姿态估计质量" class="headerlink" title="4.1.2    姿态估计质量"></a>4.1.2    姿态估计质量</h3><p>&emsp;&emsp;使用了三个不同的验证数据集，代表不同的垂直领域：瑜伽、舞蹈。每张图像仅包含距离摄像机 2-4 米的一个人。对 COCO 拓扑中的 17 个关键点进行评估。</p>
<p><img src="https://img-blog.csdnimg.cn/b9f891364dce4b34b7c5cc92eeddb91e.png#pic_center" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/5c69273a82b9498fa2ee5e5687e83144.png#pic_center" alt="img" style="zoom:67%;" /></p>
<p>Pose Solutions 的模型的设计基于实时感知用例，所以它们都能在大多数现代设备上实时工作。</p>
<h3 id="4-1-3-人-姿势检测模型-BlazePose-检测器"><a href="#4-1-3-人-姿势检测模型-BlazePose-检测器" class="headerlink" title="4.1.3    人 / 姿势检测模型 (BlazePose 检测器)"></a>4.1.3    人 / 姿势检测模型 (BlazePose 检测器)</h3><p>&emsp;&emsp;该检测器的设计思想来自于轻量级 BlazeFace 模型，在 MediaPipe 人脸检测中用作人员检测器的代理。它明确地预测了两个额外的虚拟关键点，这些虚拟关键点将人体中心、旋转和比例牢牢地描述为一个圆圈。受列奥纳多的维特鲁威人的启发，我们预测了一个人臀部的中点、外接整个人的圆的半径以及连接肩部和臀部中点的线的倾斜角。</p>
<p><img src="https://img-blog.csdnimg.cn/fe51821134814cc5996538ab3fd303c8.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="4-1-4-Pose-Landmark-模型-BlazePose-GHUM-3D"><a href="#4-1-4-Pose-Landmark-模型-BlazePose-GHUM-3D" class="headerlink" title="4.1.4    Pose Landmark 模型 (BlazePose GHUM 3D)"></a>4.1.4    Pose Landmark 模型 (BlazePose GHUM 3D)</h3><p>&emsp;&emsp;Pose Solutions 中的地标模型预测了 33 个地标的位置，如下：</p>
<p><img src="https://img-blog.csdnimg.cn/b2ff281d361544b8ac5eefa6f2efe04b.png#pic_center" alt="img"></p>
<h3 id="4-1-5-API"><a href="#4-1-5-API" class="headerlink" title="4.1.5    API"></a>4.1.5    API</h3><p>输入参数：</p>
<ul>
<li>STATIC_IMAGE_MODE：如果设置为 false，该解决方案会将输入图像视为视频流。它将尝试在第一张图像中检测最突出的人，并在成功检测后进一步定位姿势地标。在随后的图像中，它只是简单地跟踪那些地标，而不会调用另一个检测，直到它失去跟踪，以减少计算和延迟。如果设置为 true，则人员检测会运行每个输入图像，非常适合处理一批静态的、可能不相关的图像。默认为 false；</li>
<li>MODEL_COMPLEXITY：姿势地标模型的复杂度：0、1 或 2。地标准确度和推理延迟通常随着模型复杂度的增加而增加。默认为 1；</li>
<li>SMOOTH_LANDMARKS：如果设置为 true，解决方案过滤不同的输入图像上的姿势地标以减少抖动，但如果 static_image_mode 也设置为 true 则忽略。默认为 true；</li>
<li>UPPER_BODY_ONLY：是要追踪 33 个地标的全部姿势地标还是只有 25 个上半身的姿势地标；</li>
<li>ENABLE_SEGMENTATION：如果设置为 true，除了姿势地标之外，该解决方案还会生成分割掩码。默认为 false；</li>
<li>SMOOTH_SEGMENTATION：如果设置为 true，解决方案过滤不同的输入图像上的分割掩码以减少抖动，但如果 enable_segmentation 设置为 false 或者 static_image_mode 设置为 true 则忽略。默认为 true；</li>
<li>MIN_DETECTION_CONFIDENCE：来自人员检测模型的最小置信值 ([0.0, 1.0])，用于将检测视为成功。默认为 0.5；</li>
<li>MIN_TRACKING_CONFIDENCE：来自地标跟踪模型的最小置信值 ([0.0, 1.0])，用于将被视为成功跟踪的姿势地标，否则将在下一个输入图像上自动调用人物检测。将其设置为更高的值可以提高解决方案的稳健性，但代价是更高的延迟。如果 static_image_mode 为 true，则忽略，人员检测在每个图像上运行。默认为 0.5。</li>
</ul>
<p>输出：</p>
<ul>
<li>具有 “pose_landmarks” 字段的 NamedTuple 对象，其中包含检测到的最突出人物的姿势标志。</li>
</ul>
<p>参考：<a target="_blank" rel="noopener" href="https://google.github.io/mediapipe/solutions/pose"><strong>https://google.github.io/mediapipe/solutions/pose</strong></a></p>
<h3 id="4-1-6-示例"><a href="#4-1-6-示例" class="headerlink" title="4.1.6    示例"></a>4.1.6    示例</h3><p>原图：</p>
<p><img src="https://s2.loli.net/2022/05/21/KhdyRUGOxXbQT4I.png" alt="girl.png" style="zoom:50%;" /></p>
<p>检测后：</p>
<p><img src="https://s2.loli.net/2022/05/21/ZKIA3FSzvopPYyE.png" alt="girl_pose.png" style="zoom: 50%;" /></p>
<p>注意为了显示自拍的效果，我将图片进行了水平翻转。</p>
<h2 id="4-2-ORL-数据集"><a href="#4-2-ORL-数据集" class="headerlink" title="4.2    ORL 数据集"></a>4.2    ORL 数据集</h2><p>&emsp;&emsp;因为本次的姿态估计模型我是直接调用已经训练好的模型，因此只需要将 ORL 数据集当作测试集进行预测即可。</p>
<h3 id="4-2-1-数据读取与处理"><a href="#4-2-1-数据读取与处理" class="headerlink" title="4.2.1    数据读取与处理"></a>4.2.1    数据读取与处理</h3><p>&emsp;&emsp;因为我们只需要数据集，因此不需要数据的标签与分割，同时因模型要求输入要是图片，则不需要对图片进行展平。此外，MediaPipe Pose 模型要求输入的图片是 <strong>RGB</strong> 类型，但是我们前面三个数据集的所有图片都是灰度图，则在检测前我们要将灰度图转成 RGB 图，同时不能改变图片的性质。怎么改呢？其实很简单：只需将该灰度图在通道维度拼接 3 次即可。此时，红色、绿色和蓝色的分量是相同的，因此图像仍然是 “灰度图”。</p>
<ul>
<li><strong>shape：(671, 600)</strong></li>
</ul>
<p><img src="https://s2.loli.net/2022/05/21/YknZ5BqiUgu9emH.png" alt="girl2.png" style="zoom:50%;" /></p>
<ul>
<li><strong>shape：(671, 600, 3)</strong></li>
</ul>
<p><img src="https://s2.loli.net/2022/05/21/mXRtE9GuBdiFbHf.png" alt="girl3.png" style="zoom:50%;" /></p>
<p>其实在技巧在前面使用 <strong>mtcnn</strong> 进行人脸检测时就使用过这个技巧，只是当时没有具体说明。我们在后续对 Yale 和 UMIST 数据集的姿态预测前会进行同样的处理，在此说明。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Get_imgList</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img)</span><br><span class="line">            <span class="comment"># 将灰度图转成 RGB 图</span></span><br><span class="line">            image = np.stack((img, img, img), axis=<span class="number">2</span>)</span><br><span class="line">            X.append(image)</span><br><span class="line">            <span class="built_in">print</span>(image.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>
<h3 id="4-2-2-姿态估计"><a href="#4-2-2-姿态估计" class="headerlink" title="4.2.2    姿态估计"></a>4.2.2    姿态估计</h3><p>&emsp;将第一和第二个人的姿态估计结果由如下代码进行拼接。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img_path = [<span class="string">&#x27;ORL_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">                                <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>)]</span><br><span class="line">img = []</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> img_path :</span><br><span class="line">    image = cv2.imread(path)</span><br><span class="line">    img.append(image)</span><br><span class="line">img_1 = np.concatenate((img[<span class="number">0</span> : <span class="number">5</span>]), axis = <span class="number">1</span>)</span><br><span class="line">img_2 = np.concatenate((img[<span class="number">5</span> : <span class="number">10</span>]), axis = <span class="number">1</span>)</span><br><span class="line">img_3 = np.concatenate((img[<span class="number">10</span> : <span class="number">15</span>]), axis = <span class="number">1</span>)</span><br><span class="line">img_4 = np.concatenate((img[<span class="number">15</span> : <span class="number">20</span>]), axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">img_5 = np.concatenate((img_1, img_2), axis = <span class="number">0</span>)</span><br><span class="line">img_6 = np.concatenate((img_3, img_4), axis = <span class="number">0</span>)</span><br><span class="line">cv2.imwrite(<span class="string">&#x27;people_1.png&#x27;</span>, img_5)</span><br><span class="line">cv2.imwrite(<span class="string">&#x27;people_2.png&#x27;</span>, img_6)</span><br></pre></td></tr></table></figure>
<p>所得结果如下：</p>
<p>第一个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/a7FzbHgidoVXJqc.png" alt="people_1.png"></p>
<p>第二个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/WvjkfipygLDnwsx.png" alt="people_2.png"></p>
<h3 id="4-2-3-全部代码"><a href="#4-2-3-全部代码" class="headerlink" title="4.2.3    全部代码"></a>4.2.3    全部代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">mp_drawing = mp.solutions.drawing_utils</span><br><span class="line">mp_drawing_styles = mp.solutions.drawing_styles</span><br><span class="line">mp_pose = mp.solutions.pose</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Get_imgList</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img)</span><br><span class="line">            <span class="comment"># 将灰度图转成 RGB 图</span></span><br><span class="line">            image = np.stack((img, img, img), axis=<span class="number">2</span>)</span><br><span class="line">            X.append(image)</span><br><span class="line">            <span class="built_in">print</span>(image.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Pose</span>(<span class="params">imgList</span>):</span><br><span class="line">    <span class="keyword">with</span> mp_pose.Pose(</span><br><span class="line">            min_detection_confidence = <span class="number">0.5</span>,</span><br><span class="line">            min_tracking_confidence = <span class="number">0.5</span>) <span class="keyword">as</span> pose:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgList) :</span><br><span class="line">            <span class="comment"># 为了提高性能，不需要图像标记</span></span><br><span class="line">            image.flags.writeable = <span class="literal">False</span></span><br><span class="line">            results = pose.process(image)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在图上绘制姿态点</span></span><br><span class="line">            image.flags.writeable = <span class="literal">True</span></span><br><span class="line">            mp_drawing.draw_landmarks(</span><br><span class="line">                image,</span><br><span class="line">                results.pose_landmarks,</span><br><span class="line">                mp_pose.POSE_CONNECTIONS,</span><br><span class="line">                landmark_drawing_spec = \</span><br><span class="line">                mp_drawing_styles.get_default_pose_landmarks_style())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 水平翻转图片可达到显示自拍效果</span></span><br><span class="line">            cv2.imshow(<span class="string">&#x27;MediaPipe Pose&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> idx &lt; <span class="number">20</span>:</span><br><span class="line">                cv2.imwrite(<span class="string">&#x27;ORL_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span>,</span><br><span class="line">                            cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">imgList = Get_imgList(<span class="string">&#x27;ORL&#x27;</span>)</span><br><span class="line">Pose(imgList)</span><br></pre></td></tr></table></figure>
<h2 id="4-3-Yale-数据集"><a href="#4-3-Yale-数据集" class="headerlink" title="4.3    Yale 数据集"></a>4.3    Yale 数据集</h2><p>&emsp;&emsp;对 Yale 数据集的姿态估计流程和 ORL 数据集一样，同时不用对 Yale 数据集进行人脸检测。对前面两个人的姿态估计效果如下：</p>
<p>第一个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/rqFL1VSwfOvTsUh.png" alt="people_3.png" style="zoom: 50%;" /></p>
<p>第二个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/TOR9sYqIkmcPtnp.png" alt="people_4.png" style="zoom:50%;" /></p>
<p>全部代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">mp_drawing = mp.solutions.drawing_utils</span><br><span class="line">mp_drawing_styles = mp.solutions.drawing_styles</span><br><span class="line">mp_pose = mp.solutions.pose</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Image_concatenate</span>() :</span><br><span class="line">    img_path = [<span class="string">&#x27;Yale_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">                <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">22</span>)]</span><br><span class="line">    img = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, path <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_path):</span><br><span class="line">        image = cv2.imread(path)</span><br><span class="line">        img.append(image)</span><br><span class="line">        <span class="keyword">if</span> idx == <span class="number">10</span> <span class="keyword">or</span> idx == <span class="number">21</span>:</span><br><span class="line">            noise = np.full(image.shape, <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">            <span class="built_in">print</span>(noise.shape, noise.dtype)</span><br><span class="line">            img.append(noise)</span><br><span class="line"></span><br><span class="line">    img_1 = np.concatenate((img[<span class="number">0</span>: <span class="number">6</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_2 = np.concatenate((img[<span class="number">6</span>: <span class="number">12</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_3 = np.concatenate((img[<span class="number">12</span>: <span class="number">18</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_4 = np.concatenate((img[<span class="number">18</span>: <span class="number">24</span>]), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    img_5 = np.concatenate((img_1, img_2), axis=<span class="number">0</span>)</span><br><span class="line">    img_6 = np.concatenate((img_3, img_4), axis=<span class="number">0</span>)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;people_1.png&#x27;</span>, img_5)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;people_1.png&#x27;</span>, img_6)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Get_imgList</span>(<span class="params">root</span>) :</span><br><span class="line">    Yale_path = []</span><br><span class="line">    X = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> os.listdir(root):</span><br><span class="line">        <span class="keyword">if</span> element != <span class="string">&#x27;Readme.txt&#x27;</span>:</span><br><span class="line">            Yale_path.append(os.path.join(root, element))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> Yale_path:</span><br><span class="line">        img = io.imread(path, as_gray=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(img.shape)</span><br><span class="line">        image = np.stack((img, img, img), axis=<span class="number">2</span>)</span><br><span class="line">        X.append(image)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Pose</span>(<span class="params">imgList</span>):</span><br><span class="line">    <span class="keyword">with</span> mp_pose.Pose(</span><br><span class="line">            min_detection_confidence = <span class="number">0.5</span>,</span><br><span class="line">            min_tracking_confidence = <span class="number">0.5</span>) <span class="keyword">as</span> pose:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgList) :</span><br><span class="line">            <span class="comment"># 为了提高性能，不需要图像标记</span></span><br><span class="line">            image.flags.writeable = <span class="literal">False</span></span><br><span class="line">            results = pose.process(image)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在图上绘制姿态点</span></span><br><span class="line">            image.flags.writeable = <span class="literal">True</span></span><br><span class="line">            mp_drawing.draw_landmarks(</span><br><span class="line">                image,</span><br><span class="line">                results.pose_landmarks,</span><br><span class="line">                mp_pose.POSE_CONNECTIONS,</span><br><span class="line">                landmark_drawing_spec = \</span><br><span class="line">                mp_drawing_styles.get_default_pose_landmarks_style())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 水平翻转图片可达到显示自拍效果</span></span><br><span class="line">            cv2.imshow(<span class="string">&#x27;MediaPipe Pose&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> idx &lt; <span class="number">22</span>:</span><br><span class="line">                cv2.imwrite(<span class="string">&#x27;Yale_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span>,</span><br><span class="line">                            cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">imgList = Get_imgList(<span class="string">&#x27;Yale&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(imgList))</span><br><span class="line">Pose(imgList)</span><br></pre></td></tr></table></figure>
<h2 id="4-4-UMIST-数据集"><a href="#4-4-UMIST-数据集" class="headerlink" title="4.4    UMIST 数据集"></a>4.4    UMIST 数据集</h2><p>&emsp;&emsp;因为 UMIST 中的图像是由人的侧面到正面进行拍摄的，因此我截取了第一和第二个人中间的二十张图片进行姿态估计的结果展示如下：</p>
<p>第一个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/7SAPQtwZ1HJDdWq.png" alt="people_5.png" style="zoom: 80%;" /></p>
<p>第二个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/hsgao7wQbFTD6f2.png" alt="people_6.png" style="zoom:80%;" /></p>
<p>全部代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">mp_drawing = mp.solutions.drawing_utils</span><br><span class="line">mp_drawing_styles = mp.solutions.drawing_styles</span><br><span class="line">mp_pose = mp.solutions.pose</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Image_concatenate</span>() :</span><br><span class="line">    img_path = [<span class="string">&#x27;UMIST_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">                <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>)]</span><br><span class="line">    img = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, path <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_path):</span><br><span class="line">        image = cv2.imread(path)</span><br><span class="line">        img.append(image)</span><br><span class="line"></span><br><span class="line">    img_1 = np.concatenate((img[<span class="number">0</span>: <span class="number">5</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_2 = np.concatenate((img[<span class="number">5</span>: <span class="number">10</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_3 = np.concatenate((img[<span class="number">10</span>: <span class="number">15</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_4 = np.concatenate((img[<span class="number">15</span>: <span class="number">20</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_5 = np.concatenate((img[<span class="number">20</span>: <span class="number">25</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_6 = np.concatenate((img[<span class="number">25</span>: <span class="number">30</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_7 = np.concatenate((img[<span class="number">30</span>: <span class="number">35</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_8 = np.concatenate((img[<span class="number">35</span>: <span class="number">40</span>]), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    img_9 = np.concatenate((img_1, img_2, img_3, img_4), axis=<span class="number">0</span>)</span><br><span class="line">    img_10 = np.concatenate((img_5, img_6, img_7, img_8), axis=<span class="number">0</span>)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;people_5.png&#x27;</span>, img_9)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;people_6.png&#x27;</span>, img_10)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Get_imgList</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    path_files = os.listdir(root)</span><br><span class="line">    <span class="keyword">for</span> idx, path_file <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_files):</span><br><span class="line">        path_images = os.listdir(os.path.join(root, path_file, <span class="string">&#x27;face&#x27;</span>))</span><br><span class="line">        <span class="keyword">for</span> path_image <span class="keyword">in</span> path_images:</span><br><span class="line">            path = os.path.join(root, path_file, <span class="string">&#x27;face&#x27;</span>, path_image)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img)</span><br><span class="line">            <span class="comment"># 将灰度图转成 RGB 图</span></span><br><span class="line">            image = np.stack((img, img, img), axis=<span class="number">2</span>)</span><br><span class="line">            X.append(image)</span><br><span class="line">    X = np.array(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Pose</span>(<span class="params">imgList</span>):</span><br><span class="line">    <span class="keyword">with</span> mp_pose.Pose(</span><br><span class="line">            min_detection_confidence = <span class="number">0.5</span>,</span><br><span class="line">            min_tracking_confidence = <span class="number">0.5</span>) <span class="keyword">as</span> pose:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgList) :</span><br><span class="line">            <span class="comment"># 为了提高性能，不需要图像标记</span></span><br><span class="line">            image.flags.writeable = <span class="literal">False</span></span><br><span class="line">            results = pose.process(image)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在图上绘制姿态点</span></span><br><span class="line">            image.flags.writeable = <span class="literal">True</span></span><br><span class="line">            mp_drawing.draw_landmarks(</span><br><span class="line">                image,</span><br><span class="line">                results.pose_landmarks,</span><br><span class="line">                mp_pose.POSE_CONNECTIONS,</span><br><span class="line">                landmark_drawing_spec = \</span><br><span class="line">                mp_drawing_styles.get_default_pose_landmarks_style())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 水平翻转图片可达到显示自拍效果</span></span><br><span class="line">            cv2.imshow(<span class="string">&#x27;MediaPipe Pose&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="number">10</span> &lt;= idx &lt; <span class="number">30</span> :</span><br><span class="line">                cv2.imwrite(<span class="string">&#x27;UMIST_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span> - <span class="number">10</span>) + <span class="string">&#x27;.png&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="number">48</span> &lt;= idx &lt; <span class="number">68</span> :</span><br><span class="line">                cv2.imwrite(<span class="string">&#x27;UMIST_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span> - <span class="number">28</span>) + <span class="string">&#x27;.png&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">imgList = Get_imgList(<span class="string">&#x27;UMIST&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(imgList))</span><br><span class="line">Pose(imgList)</span><br></pre></td></tr></table></figure>
<h2 id="4-5-结果分析"><a href="#4-5-结果分析" class="headerlink" title="4.5    结果分析"></a>4.5    结果分析</h2><p>&emsp;&emsp;经过对三个数据集的中人的姿态估计，我们能够得到人脸关键部位点的位置，如左右眼角，左右嘴角，鼻子等，而根据这些关键特征点的分布我们可以对该人的形态或者神态进行进一步的预测。比如说，当眼睛那一排特征点的分布是水平的，说明这个人正处于一种较为平和、中立的状态，如果分布波动很大，则说明这个人此时正处于一种较为亢奋的状态，表现出愤怒、开心等表情；当特征点之间的距离很近，则对于摄像机而言这个人表现为侧脸；再者，当两个嘴角点之间的距离较大，即这个人的的嘴巴张的很大，我们可以觉得这个人是在开心大笑……等等。</p>
<p>&emsp;&emsp;综上，姿态分析对于视觉领域来说十分重要，我们可以利用姿态进行运动追踪、表情分析、医学诊断等等。</p>
<h1 id="5-基于-KNN-的人脸识别"><a href="#5-基于-KNN-的人脸识别" class="headerlink" title="5    基于 KNN 的人脸识别"></a>5    基于 KNN 的人脸识别</h1><p>&emsp;&emsp;前面我们通过构建 PCA 降维算法分别对 ORL、Yale 和 UMIST 三种不同的数据集进行了人脸识别，且识别精度分别在 0.95、0.93 和 0.88。而在下面中，我使用了另一种传统机器学习算法——KNN 再次对上述三种数据集进行人脸识别。</p>
<h2 id="5-1-KNN"><a href="#5-1-KNN" class="headerlink" title="5.1    KNN"></a>5.1    KNN</h2><p>&emsp;&emsp;<strong>KNN</strong> (K-Nearest Neighbor，K邻近算法)的基本思想是：给定一个训练数据集，对新输入的样本，在训练数据集中找到与该样本最邻近的 k 个实例(也就是所谓的 k 个邻居)，这 k 个实例中的多数属于某个类别，就把输入样本划分到该类别中。k 近邻算法通常又可以分为分类算法和回归算法：</p>
<ul>
<li>分类算法中采用多数表决法，就是选择 k 个样本中出现最多的类别标记作为预测结果；</li>
</ul>
<p><img src="https://s2.loli.net/2022/05/20/U2avBNKTs9LjDe3.png" alt="捕获.PNG"></p>
<ul>
<li>回归算法中采用平均法，将 k 个样本实际输出标记的平均值或加权平均值作为预测结果。</li>
</ul>
<p>而人脸识别本质上也是一个多分类问题，因此可以使用 KNN 来进行人脸识别。</p>
<h2 id="5-2-ORL-数据集"><a href="#5-2-ORL-数据集" class="headerlink" title="5.2    ORL 数据集"></a>5.2    ORL 数据集</h2><p>&emsp;&emsp;首先是数据的读取与处理，KNN 接受的数据输入与 PCA 算法是一样的，即二维矩阵 (m，n)，m 为样本数，n 为特征向量，因此数据处理与前面完全一样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img).ravel()</span><br><span class="line">            X.append(img)</span><br><span class="line">        y.extend([idx] * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<p>对于数据分组，我使用了 <strong>sklearn</strong> 库中的 <strong>train_test_split</strong> 函数，将数据划分成 <strong>2 : 8</strong>，其中训练集为 8，测试集为 2，同时将数据打乱。我还探究了不同 k 值对模型性能的影响。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Draw_precision</span>(<span class="params">scores</span>) :</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>), scores, <span class="string">&#x27;o--&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;$n\_neighbors$&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;$precision$&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>), scores):</span><br><span class="line">        plt.text(x - <span class="number">0.18</span>, y - <span class="number">0.1</span>, <span class="string">f&#x27;$<span class="subst">&#123;y&#125;</span>$&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.title(<span class="string">f&#x27;$precision\ of\ different\ neighors$&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.xticks(np.arange(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">    plt.yticks(np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line">    plt.show()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;KNN_ORL_Database.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    X, y = Data_Processing(<span class="string">&#x27;ORL&#x27;</span>)</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, \</span><br><span class="line">                                train_size=<span class="number">0.8</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    scores = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用不同的邻居数进行训练测试</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">        knn = KNeighborsClassifier(n_neighbors=n)</span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        knn.fit(X_train, y_train)</span><br><span class="line">        <span class="comment"># 预测</span></span><br><span class="line">        pred = knn.predict(X_test)</span><br><span class="line">        <span class="comment"># 准确率并保留3位小数</span></span><br><span class="line">        score = <span class="built_in">round</span>(knn.score(X_test, y_test), <span class="number">3</span>)</span><br><span class="line">        scores.append(score)</span><br><span class="line"></span><br><span class="line">    Draw_precision(scores)</span><br></pre></td></tr></table></figure>
<p>所得结果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/G4bIoi1AmtPzdDW.png" alt="KNN_ORL_Database.png" style="zoom: 67%;" /></p>
<p>如上图所示，k 等于 1 时人脸识别的效果最好，识别正确率达到 0.975，比 PCA 算法的 0.95 要高。</p>
<h2 id="5-3-Yale-数据集"><a href="#5-3-Yale-数据集" class="headerlink" title="5.3    Yale 数据集"></a>5.3    Yale 数据集</h2><p>&emsp;&emsp;同理，参考 <a href="# 3.2.1    数据读取和数据处理"><strong>3.2.1    数据读取和数据处理</strong></a> 的方法，KNN 的参数设置与前面处理 ORL 数据集的一致。所得结果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/4LkADSqtzQr9eRx.png" alt="KNN_Yale_Database.png" style="zoom:67%;" /></p>
<p>如上图所示，使用 KNN 对 Yale 进行识别的效果很不好，不同的 k 值中最高的识别正确率也只有 0.879。原因可能是数据过少，因为在训练之前进行了人脸检测并且裁剪。因此，我采取了下面的数据处理方式，即不进行人脸检测和裁剪等操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    Yale_path = []</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> os.listdir(root) :</span><br><span class="line">        <span class="keyword">if</span> element != <span class="string">&#x27;Readme.txt&#x27;</span>:</span><br><span class="line">            Yale_path.append(os.path.join(root, element))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> Yale_path :</span><br><span class="line">        image = io.imread(path, as_gray = <span class="literal">True</span>)</span><br><span class="line">        X.append(image.ravel())</span><br><span class="line">        label = <span class="built_in">int</span>(os.path.split(path)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&quot;subject&quot;</span>, <span class="string">&quot;&quot;</span>)) - <span class="number">1</span></span><br><span class="line">        y.append(label)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line">    <span class="built_in">print</span>(X.shape)</span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<p>所得结果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/OJMPFlqrbmC6W9Y.png" alt="KNN_Yale_Database.png" style="zoom:67%;" /></p>
<p>如上图所示，当 k 值为 1 时，模型的性能最好，即识别正确率达到 0.939，此结果与 PCA 算法相当。</p>
<h2 id="5-4-UMIST-数据集"><a href="#5-4-UMIST-数据集" class="headerlink" title="5.4    UMIST 数据集"></a>5.4    UMIST 数据集</h2><p>&emsp;&emsp;UMIST 数据集的读取与处理参照 <a href="# 3.3.1    数据读取与数据处理"><strong>3.3.1    数据读取与数据处理</strong></a>，KNN 的参数的设置与前面相同。所得结果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/rDhmiMLb4V5A3Z7.png" alt="KNN_UMIST_Database.png" style="zoom:67%;" /></p>
<p>如上图所示，KNN 对于 UMIST 的鲁棒性非常强，识别性能特别好，在 k 等于 1、2 和 3 时的识别正确率有 0.974、0.965 和 0.957，远超 PCA 算法的 0.88 的正确率。</p>
<h2 id="5-5-KNN-的优缺点"><a href="#5-5-KNN-的优缺点" class="headerlink" title="5.5    KNN 的优缺点"></a>5.5    KNN 的优缺点</h2><p>优点：</p>
<ul>
<li>理论成熟，思想简单，既可以用来做分类又可以做回归；</li>
<li>可以用于非线性分类；</li>
<li>训练时间复杂度低，相比于 PCA，KNN 花费的时间很少；</li>
<li>和朴素贝叶斯之类的算法比，对数据没有假设，准确度高，对异常点不敏感；</li>
<li>由于 KNN 方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属的类别，因此对于类域的交叉或重叠较多的待分类样本集来说，KNN 方法较其他方法更为适合。</li>
</ul>
<p>缺点：</p>
<ul>
<li>计算量大，尤其是特征数非常多的时候；</li>
<li>样本不平衡的时候，对稀有类别的预测准确率低；</li>
<li>是惰性学习方法，基本上不学习，导致预测时速度比起逻辑回归之类的算法慢；</li>
<li>KNN 模型的可解释性不强。</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/" rel="tag"><i class="fa fa-tag"></i> 主成分分析</a>
              <a href="/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/" rel="tag"><i class="fa fa-tag"></i> 人脸识别</a>
              <a href="/tags/%E5%A7%BF%E6%80%81%E5%88%86%E6%9E%90/" rel="tag"><i class="fa fa-tag"></i> 姿态分析</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/06/05/PyTorch%E2%80%94%E2%80%94%E5%AE%9E%E7%8E%B0%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88self-attention%EF%BC%89/" rel="prev" title="PyTorch——实现自注意力机制（self-attention）">
      <i class="fa fa-chevron-left"></i> PyTorch——实现自注意力机制（self-attention）
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/06/07/Bayesian-based-text-classification/" rel="next" title="Text Classification Based On Bayes">
      Text Classification Based On Bayes <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-PCA"><span class="nav-text">1    PCA</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E5%8E%9F%E7%90%86"><span class="nav-text">1.1    原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-text">1.2    算法流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-1-%E9%9B%B6%E5%9D%87%E5%80%BC%E5%8C%96"><span class="nav-text">1.2.1    零均值化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-2-%E8%AE%A1%E7%AE%97%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5"><span class="nav-text">1.2.2    计算协方差矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-3-%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="nav-text">1.2.3    特征值和特征向量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-4-%E9%99%8D%E7%BB%B4%E5%BE%97%E5%88%B0-K-%E7%BB%B4%E7%89%B9%E5%BE%81"><span class="nav-text">1.2.4    降维得到 K 维特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-5-PCA-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-text">1.2.5    PCA 的优缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Python-%E5%AE%9E%E7%8E%B0-PCA"><span class="nav-text">2    Python 实现 PCA</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E5%9F%BA%E4%BA%8E-PCA-%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB"><span class="nav-text">3    基于 PCA 的人脸识别</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-ORL-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">3.1    ORL 数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-1-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-text">3.1.1    数据读取与数据处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-2-%E6%95%B0%E6%8D%AE%E5%88%86%E7%BB%84"><span class="nav-text">3.1.2    数据分组</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-3-%E4%BD%BF%E7%94%A8-PCA-%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">3.1.3    使用 PCA 进行特征提取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-4-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB"><span class="nav-text">3.1.4    人脸识别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-5-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%9A%84-GUI-%E7%95%8C%E9%9D%A2"><span class="nav-text">3.1.5    人脸识别的 GUI 界面</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-6-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-text">3.1.6    实验结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-7-%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81"><span class="nav-text">3.1.7    全部代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Yale-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">3.2    Yale 数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E5%92%8C%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-text">3.2.1    数据读取和数据处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-%E6%95%B0%E6%8D%AE%E5%88%86%E7%BB%84"><span class="nav-text">3.2.2    数据分组</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-3-%E4%BD%BF%E7%94%A8-PCA-%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">3.2.3    使用 PCA 进行特征提取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-4-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-text">3.2.4    人脸识别及可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-5-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-text">3.2.5    实验结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-6-%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81"><span class="nav-text">3.2.6    全部代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-UMIST-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">3.3    UMIST 数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-1-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-text">3.3.1    数据读取与数据处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-2-%E6%95%B0%E6%8D%AE%E5%88%86%E7%BB%84"><span class="nav-text">3.3.2    数据分组</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-3-%E4%BD%BF%E7%94%A8-PCA-%E8%BF%9B%E8%A1%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="nav-text">3.3.3    使用 PCA 进行特征提取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-4-%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E5%8F%8A%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-text">3.3.4    人脸识别及可视化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-5-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-text">3.3.5    实验结果</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-6-%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81"><span class="nav-text">3.3.6    全部代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-%E5%9F%BA%E4%BA%8E-MediaPipe-%E7%9A%84%E5%A7%BF%E6%80%81%E5%88%86%E6%9E%90"><span class="nav-text">4    基于 MediaPipe 的姿态分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-MediaPipe-Solutions"><span class="nav-text">4.1    MediaPipe Solutions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1-ML-%E7%AE%A1%E9%81%93"><span class="nav-text">4.1.1    ML 管道</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2-%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E8%B4%A8%E9%87%8F"><span class="nav-text">4.1.2    姿态估计质量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-3-%E4%BA%BA-%E5%A7%BF%E5%8A%BF%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B-BlazePose-%E6%A3%80%E6%B5%8B%E5%99%A8"><span class="nav-text">4.1.3    人 &#x2F; 姿势检测模型 (BlazePose 检测器)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-4-Pose-Landmark-%E6%A8%A1%E5%9E%8B-BlazePose-GHUM-3D"><span class="nav-text">4.1.4    Pose Landmark 模型 (BlazePose GHUM 3D)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-5-API"><span class="nav-text">4.1.5    API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-6-%E7%A4%BA%E4%BE%8B"><span class="nav-text">4.1.6    示例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-ORL-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">4.2    ORL 数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E4%B8%8E%E5%A4%84%E7%90%86"><span class="nav-text">4.2.1    数据读取与处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1"><span class="nav-text">4.2.2    姿态估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81"><span class="nav-text">4.2.3    全部代码</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-Yale-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">4.3    Yale 数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-UMIST-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">4.4    UMIST 数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-5-%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="nav-text">4.5    结果分析</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E5%9F%BA%E4%BA%8E-KNN-%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB"><span class="nav-text">5    基于 KNN 的人脸识别</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-KNN"><span class="nav-text">5.1    KNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-ORL-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">5.2    ORL 数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-Yale-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">5.3    Yale 数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-4-UMIST-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-text">5.4    UMIST 数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-5-KNN-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="nav-text">5.5    KNN 的优缺点</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Z.H.Chen"
      src="/images/%E5%AE%9D%E5%84%BF%E5%A7%90.jpg">
  <p class="site-author-name" itemprop="name">Z.H.Chen</p>
  <div class="site-description" itemprop="description">你好啊！欢迎来到我的博客世界！</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">59</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/aishangcengloua" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;aishangcengloua" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhihonghaha@outlook.com" title="E-Mail → mailto:zhihonghaha@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/San%20Zhang" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;San Zhang" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/weixin_53598445" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;weixin_53598445" rel="noopener" target="_blank"><i class="fa custom csdn fa-fw"></i>CSDN</a>
      </span>
  </div>



      </div>
	  <div>
		<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=29567192&auto=1&height=66"></iframe>
	  </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Z.H.Chen</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">158k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">4:24</span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>-->



<!--添加运行时间-->
<span id="sitetime"></span>
<script language=javascript>
	function siteTime(){
		window.setTimeout("siteTime()", 1000);
		var seconds = 1000;
		var minutes = seconds * 60;
		var hours = minutes * 60;
		var days = hours * 24;
		var years = days * 365;
		var today = new Date();
		var todayYear = today.getFullYear();
		var todayMonth = today.getMonth()+1;
		var todayDate = today.getDate();
		var todayHour = today.getHours();
		var todayMinute = today.getMinutes();
		var todaySecond = today.getSeconds();
		/* 
      Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
      year - 作为date对象的年份，为4位年份值
      month - 0-11之间的整数，做为date对象的月份
      day - 1-31之间的整数，做为date对象的天数
      hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
      minutes - 0-59之间的整数，做为date对象的分钟数
      seconds - 0-59之间的整数，做为date对象的秒数
      microseconds - 0-999之间的整数，做为date对象的毫秒数
     */
		var t1 = Date.UTC(2022,06,03,21,44,16); //北京时间2018-2-13 00:00:00
		var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
		var diff = t2-t1;
		var diffYears = Math.floor(diff/years);
		var diffDays = Math.floor((diff/days)-diffYears*365);
		var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
		var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
		var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
		document.getElementById("sitetime").innerHTML=" 本站已运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
	}
	siteTime();
</script>
<!--// 添加运行时间-->
        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script color='' opacity='' zIndex='' count='' src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>


  <script defer src="/lib/three/three.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    // window.MathJax = {
    //   loader: {
    //
    //     source: {
    //       '[tex]/amsCd': '[tex]/amscd',
    //       '[tex]/AMScd': '[tex]/amscd'
    //     }
    //   },
    //   tex: {
    //     inlineMath: {'[+]': [['$', '$']]},
    //
    //     tags: 'ams'
    //   },
    //   options: {
    //     renderActions: {
    //       findScript: [10, doc => {
    //         document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
    //           const display = !!node.type.match(/; *mode=display/);
    //           const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
    //           const text = document.createTextNode('');
    //           node.parentNode.replaceChild(text, node);
    //           math.start = {node: text, delim: '', n: 0};
    //           math.end = {node: text, delim: '', n: 0};
    //           doc.math.push(math);
    //         });
    //       }, '', false],
    //       insertedScript: [200, () => {
    //         document.querySelectorAll('mjx-container').forEach(node => {
    //           let target = node.parentNode;
    //           if (target.nodeName.toLowerCase() === 'li') {
    //             target.parentNode.classList.add('has-jax');
    //           }
    //         });
    //       }, '', false]
    //     }
    //   }
    // };
    window.MathJax = {
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax@2.7.8/unpacked/MathJax.js?config=TeX-MML-AM_CHTML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'uK0vMHBYaRUKqNipxEo7b3Xu-gzGzoHsz',
      appKey     : 'GP3Y93YOxdDSB61tVmKVt3AW',
      placeholder: "有任何问题欢迎随时讨论！",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

    </div>
</body>
</html>
