<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Text Classification Based On Bayes</title>
    <url>/2022/06/07/Bayesian-based-text-classification/</url>
    <content><![CDATA[<p>
    <font size="6"><font color=red><strong>Statement:</strong></font></font>
</p>

<p>
    <font size="5"><strong>Here are some very important announcements: The content of this blog is from the Python experiment of probability theory and mathematical statistics at the School of Electronic and Information Engineering, Shenzhen University. If you happen to be completing this experiment, please only use this blog as a reference, please do not copy it directly. If this blog violates your rights, please contact me to delete it.</strong></font></font>
</p>

<p><strong>DataSet：</strong><a href="https://www2.aueb.gr/users/ion/data/enron-spam/"><strong>https://www2.aueb.gr/users/ion/data/enron-spam/</strong></a></p>
<h2 id="1-Experimental-Purposes"><a href="#1-Experimental-Purposes" class="headerlink" title="1. Experimental Purposes"></a>1. Experimental Purposes</h2><ul>
<li>Familiar with the Bayes theorem.</li>
<li>Understand the implementation of the Bayes theorem in python.</li>
<li>Know how to use Naive Bayes for a practical task, e.g., text classification.</li>
</ul>
<h2 id="2-Background-Information"><a href="#2-Background-Information" class="headerlink" title="2. Background Information"></a>2. Background Information</h2><p>The challenge of text classification is to attach labels to bodies of text, e.g., tax document, medical form, etc. based on the text itself. For example, think of your spam folder in your email. How does your email provider know that a particular message is spam or “ham” (not spam)? We’ll take a look at one natural language processing technique for text classification called Naive Bayes. </p>
<h3 id="2-1-Samples-and-the-Sampling-Distribution"><a href="#2-1-Samples-and-the-Sampling-Distribution" class="headerlink" title="2.1 Samples and the Sampling Distribution"></a>2.1 Samples and the Sampling Distribution</h3><p>Before we derive the algorithm, we need to discuss the fundamental rule that Naive Bayes uses: Bayes Theorem:</p>
<script type="math/tex; mode=display">p(A|B) = \displaystyle\frac{p(B|A)p(A)}{p(B)}</script><p>where $A$ and $B$ are events and $p(\cdot)$ is a probability.</p>
<p>Let’s take a second to break this down. On the left, we have the probability of an event $A$ happening given that event $B$ happens. We say this is equal to the probability of event $B$ happening given event $A$ times the probability that event $A$ happens overall. All of that is divided by the probability that event $B$ happens overall. An example of this might help shed some light on why this is an ingenious theorem.</p>
<p>The classic example used to illustrate Bayes Theorem involves medical testing. Let’s suppose that we were getting tested for the flu. When we get a medical test, there are really 4 cases to consider when we get the results back:</p>
<ul>
<li><strong>True Positive</strong>: The test says we have the flu and we actually have the flu</li>
<li><strong>True Negative</strong>: The test says we don’t have the flu and we actually don’t have the flu</li>
<li><strong>False Positive</strong>: The test says we have the flu and we actually don’t have the flu</li>
<li><strong>False Negative</strong>: The test says we don’t have the flu and we actually do have the flu</li>
</ul>
<p>Suppose we also know some information about the flu and our testing methodology: we know our test can correctly detect that a person has the flu 99.5% of the time (i.e., $p(\text{tested+}|\text{Flu})=0.995$)  and correctly detect that a person does not have the flu 99.5% of the time (i.e., $p(\text{tested-}|\text{No Flu})=0.995$). These correspond to the <strong>true positive rate</strong> and <strong>true negative rate</strong>. We also know that this specific type of flu is rare and only affects 1% of people. Given this information, we can compute the probability that any randomly selected person will have this specific type of the flu. Specifically, we want to compute the probability that the person has the specific type of flu, given that the person tested positive for it, i.e., event $A=\text{Flu}$ and $B=\text{tested+}$.</p>
<p>Let’s just substitute the problem specifics into Bayes Theorem.</p>
<script type="math/tex; mode=display">p(\text{Flu}|\text{tested+}) = \displaystyle\frac{p(\text{tested+}|\text{Flu})p(\text{Flu})}{p(\text{tested+})}</script><p>Now let’s try to figure out specific values for the quantities on the right-hand side. The first quantity is $p(\text{tested+}|\text{Flu})$. This is the probability that someone tests positive given that they have the flu. In other words, this is the true positive rate: the probability that our test can correctly detect that a person has the flu! This number is 99.5% or 0.995 The next quantity in the numerator is $p(\text{Flu})$. This is called the <strong>prior probability</strong>. In other words, it is the probability that any random person has the flu. We know from our problem that this number is 1%, or 0.01. Let’s substitute in those values in the numerator.</p>
<script type="math/tex; mode=display">
p(\text{Flu}|\text{tested+}) = \displaystyle\frac{0.995 \cdot 0.01}{p(\text{tested+})}</script><p>Now we have to deal with the denominator: $p(\text{tested+})$. This is the probability that our test returns positive overall. We can’t quite use the information given in the problem as directly as before however. But first, why do we even need $p(\text{tested+})$? Recall that probabilities have to be between 0 and 1. Based on the above equation, if we left out the denominator, then we wouldn’t have a valid probability!</p>
<p>Anyways, when can our test return positive? Well there are two cases: either our test returns positive and the person actually has the flu (true positive) or our test returns positive and our person does not have the flu (false positive). We can’t quite simply sum both of these cases to be the denominator. We have to weight them by their respective probabilities, i.e., the probability that any person has the flu overall and the probability that any person does not have the flu overall. Let’s expand the denominator.</p>
<script type="math/tex; mode=display">p(\text{Flu}|\text{tested+}) = \displaystyle\frac{0.995 \cdot 0.01}{p(\text{tested+}|\text{Flu})p(\text{Flu})+p(\text{tested+}|\text{No Flu})p(\text{No Flu})}</script><p>Now let’s reason about these values. $p(\text{+}|\text{Flu})p(\text{Flu})$ is something we’ve seen before: it’s the numerator! Now let’s look at the next quantity: $p(\text{+}|\text{No Flu})p(\text{No Flu})$. We can compute the first term by taking the complement of the true negative: $p(\text{+}|\text{No Flu})=1-p(\text{-}|\text{No Flu})=0.005$. And $p(\text{No Flu})=1-p(\text{Flu})=0.99$ since they are complimentary events. So now we can plug in all of our values and get a result.</p>
<script type="math/tex; mode=display">p(\text{Flu}|\text{tested+}) = \displaystyle\frac{0.995 \cdot 0.01}{0.995 \cdot 0.01+0.005 \cdot 0.99}= 0.6678</script><p>This result is a little surprising! This is saying, despite our test’s accuracy, knowing someone tested positive means that there’s only a 67% chance that they actually have the flu! Hopefully, this example illustrated how to use Bayes Theorem.</p>
<h3 id="2-2-Deriving-Naive-Bayes"><a href="#2-2-Deriving-Naive-Bayes" class="headerlink" title="2.2 Deriving Naive Bayes"></a>2.2 Deriving Naive Bayes</h3><p>Now let’s convert the Bayes Theorem notation into something slightly more machine learning-oriented.</p>
<script type="math/tex; mode=display">p(H|E) = \displaystyle\frac{p(E|H)p(H)}{p(E)}</script><p>where $H$ is the hypothesis and $E$ is the evidence. Now this might make more sense in the context of text classification: the probability that our hypothesis is correct given the evidence to support it is equal to the probability of observing that evidence given our hypothesis times the prior probability of the hypothesis divided by the probability of observing that evidence overall.</p>
<p>Let’s break this down again like we did for the original Bayes Theorem, except we’ll use the context of the text classification problem we’re trying to solve: spam detection. Our hypothesis $H$ is something like “this text is spam” and the evidence $E$ is the text of the email. So to restate, we’re trying to find the probability that our email is spam given the text in the email. The numerator is then the probability that that we find these words in a spam email times the probability that any email is spam. The denominator is a bit tricky: it’s the probability that we observe those words overall.</p>
<p>There’s something a bit off with this formulation though: the evidence needs to be represented as multiple pieces of evidence: the words $w_1,\dots,w_n$. No problem! We can do that and Bayes Theorem still holds. We can also change hypothesis $H$ to a class $\text{Spam}$.</p>
<script type="math/tex; mode=display">p(\text{Spam}|w_1,\dots,w_n) = \displaystyle\frac{p(w_1,\dots,w_n|\text{Spam})p(\text{Spam})}{p(w_1,\dots,w_n)}</script><p>We can use a conditional probability formula to expand out the numerator.</p>
<script type="math/tex; mode=display">p(\text{Spam}|w_1,\dots,w_n) = \displaystyle\frac{p(w_1|w_2,\dots,w_n,\text{Spam})p(w_2|w_3,\dots,w_n,\text{Spam})\dots p(w_{n-1}|w_n,\text{Spam})p(\text{Spam})}{p(w_1,\dots,w_n)}</script><p>Not only does this look messy, it’s also quite messy to compute! Let’s think about the first term: $p(w_1|w_2,\dots,w_n,\text{Spam})$. This is the probability of finding the first word, given all of the other words and given that the email is spam. This is really difficult to compute if we have a lot of words!</p>
<h3 id="2-3-Naive-Bayes-Assumption"><a href="#2-3-Naive-Bayes-Assumption" class="headerlink" title="2.3 Naive Bayes Assumption"></a>2.3 Naive Bayes Assumption</h3><p>To help us with that equation, we can make an assumption called the <strong>Naive Bayes assumption</strong> to help us with the math, and eventually the code. <strong>The assumption is that each word is independent of all other words.</strong> <em>In reality</em>, this is not always true! Knowing what words come before/after do influence the next/previous word! However, making this assumption greatly simplifies the math and, in practice, works well! This assumption is why this technique is called Naive Bayes. So after making that assumption, we can break down the numerator into the following.</p>
<script type="math/tex; mode=display">p(\text{Spam}|w_1,\dots,w_n) = \displaystyle\frac{p(w_1|\text{Spam})p(w_2|\text{Spam})\dots p(w_n|\text{Spam})p(\text{Spam})}{p(w_1,\dots,w_n)}</script><p>This looks better! Now we can interpret a term $p(w_1|\text{Spam})$ to mean the probability of finding word $w_1$ in a spam email. We can use a notational shorthand to symbolize product $(\Pi)$.</p>
<script type="math/tex; mode=display">p(\text{Spam}|w_1,\dots,w_n) = \displaystyle\frac{p(\text{Spam})\displaystyle\prod_{i=1}^np(w_i|\text{Spam})}{p(w_1,\dots,w_n)}</script><p>This is the Naive Bayes formulation! This returns the probability that an email message is spam given the words in that email. For text classification, however, we need an actually label, not a probability, so we may simply say that an email is spam if $p(\text{Spam}|w_1,\dots,w_n)$ is greater than 50%. If not, then it is not spam. In other words, we choose “spam” or “ham” based on which one of these two classes has the higher probability! Actually, we don’t need probabilities at all. We can forget about the denominator since its only purpose is to scale the numerator.</p>
<script type="math/tex; mode=display">p(\text{Spam}|w_1,\dots,w_n) \propto p(\text{Spam})\displaystyle\prod_{i=1}^np(w_i|\text{Spam})</script><p>(where $\propto$ signifies proportional to) That’s one extra thing we don’t have to compute! In this instance, we pick whichever class has the higher score since this is not a true probability anymore.</p>
<h3 id="2-4-Numerical-Stability"><a href="#2-4-Numerical-Stability" class="headerlink" title="2.4 Numerical Stability"></a>2.4 Numerical Stability</h3><p>There’s one extra thing we’re going to do to help us with <strong>numerical stability</strong>. If we look at the numerator, we see we’re multiplying many probabilities together. If we do that, we could end up with <em>really</em> small numbers, and our computer might round down to zero! To prevent this, we’re going to look at the <strong>log probability</strong> by taking the log of each side. Using some properties of logarithms, we can manipulate our Naive Bayes formulation.</p>
<script type="math/tex; mode=display">\begin{align*} \log p(\text{Spam}|w_1,\dots,w_n) &\propto \log p(\text{Spam})\displaystyle\prod_{i=1}^np(w_i|\text{Spam})\tag{1}\\ \log p(\text{Spam}|w_1,\dots,w_n) &\propto \log p(\text{Spam}) + \log \displaystyle\prod_{i=1}^np(w_i|\text{Spam})\tag{2}\\ \log p(\text{Spam}|w_1,\dots,w_n) &\propto \log p(\text{Spam}) + \displaystyle\sum_{i=1}^n \log p(w_i|\text{Spam}) \tag{3} \end{align*}</script><p>Now we’re dealing with additions of log probabilities instead of <em>multiplying</em> many probabilities together! Since log has really nice properties (monotonicity being the key one), we can still take the highest score to be our prediction, i.e., we don’t have to “undo” the log!</p>
<h2 id="3-Experimental-Requirements"><a href="#3-Experimental-Requirements" class="headerlink" title="3. Experimental Requirements"></a>3. Experimental Requirements</h2><h3 id="3-1-Dataset"><a href="#3-1-Dataset" class="headerlink" title="3.1 Dataset"></a>3.1 Dataset</h3><p>We’ll be using the Enron email dataset for our training data. This is real email data from the Enron Corporation after the company collapsed. We have downloaded the dataset for you. Put this enron folder in the same directory as your source code so we can find the dataset!</p>
<font size=4><strong><font color=red>A WORD OF WARNING!</font>: Since this dataset is a real dataset of emails, it contains real spam messages. Your anti-virus may prune some these emails because they are spam. You may need to turn off these protection temporarily.</strong></font>

<h3 id="3-2-Naive-Bayes-for-Text-Classification"><a href="#3-2-Naive-Bayes-for-Text-Classification" class="headerlink" title="3.2 Naive Bayes for Text Classification"></a>3.2 Naive Bayes for Text Classification</h3><p>Here is the dataset-loading code:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">DATA_DIR = <span class="string">&#x27;enron&#x27;</span></span><br><span class="line">target_names = [<span class="string">&#x27;ham&#x27;</span>, <span class="string">&#x27;spam&#x27;</span>]</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_data</span>(<span class="params">DATA_DIR</span>):</span><br><span class="line">    subfolders = [<span class="string">&#x27;enron%d&#x27;</span> % i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">7</span>)]</span><br><span class="line">    data = []</span><br><span class="line">    target = []</span><br><span class="line">    <span class="keyword">for</span> subfolder <span class="keyword">in</span> subfolders:</span><br><span class="line">        <span class="comment"># spam</span></span><br><span class="line">        spam_files = os.listdir(os.path.join(DATA_DIR, subfolder, <span class="string">&#x27;spam&#x27;</span>))</span><br><span class="line">        <span class="keyword">for</span> spam_file <span class="keyword">in</span> spam_files:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(DATA_DIR, subfolder, <span class="string">&#x27;spam&#x27;</span>, spam_file), encoding=<span class="string">&quot;latin-1&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                data.append(f.read())</span><br><span class="line">                target.append(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># ham</span></span><br><span class="line">        ham_files = os.listdir(os.path.join(DATA_DIR, subfolder, <span class="string">&#x27;ham&#x27;</span>))</span><br><span class="line">        <span class="keyword">for</span> ham_file <span class="keyword">in</span> ham_files:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(DATA_DIR, subfolder, <span class="string">&#x27;ham&#x27;</span>, ham_file), encoding=<span class="string">&quot;latin-1&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                data.append(f.read())</span><br><span class="line">                target.append(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> data, target</span><br><span class="line"><span class="comment"># get_data(DATA_DIR)</span></span><br></pre></td></tr></table></figure>
<p>You can verify that the data has been successfully loaded with the following code.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X, y = get_data(DATA_DIR)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(X) == <span class="number">33716</span>, <span class="string">&quot;Please check for missing files.&quot;</span></span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(y) == <span class="number">33716</span>, <span class="string">&quot;Please check for missing files.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the first data and target.</span></span><br><span class="line"><span class="built_in">print</span>(X[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(y[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<pre><code>Subject: dobmeos with hgh my energy level has gone up ! stukm
introducing
doctor - formulated
hgh
human growth hormone - also called hgh
is referred to in medical science as the master hormone . it is very plentiful
when we are young , but near the age of twenty - one our bodies begin to produce
less of it . by the time we are forty nearly everyone is deficient in hgh ,
and at eighty our production has normally diminished at least 90 - 95 % .
advantages of hgh :
- increased muscle strength
- loss in body fat
- increased bone density
- lower blood pressure
- quickens wound healing
- reduces cellulite
- improved vision
- wrinkle disappearance
- increased skin thickness texture
- increased energy levels
- improved sleep and emotional stability
- improved memory and mental alertness
- increased sexual potency
- resistance to common illness
- strengthened heart muscle
- controlled cholesterol
- controlled mood swings
- new hair growth and color restore
read
more at this website
unsubscribe

1
</code></pre><p>This will produce two lists: the data list, where each element is the text of an email, and the target list, which is simply binary (1 meaning spam and 0 meaning ham). Now let’s create a class and add some helper functions for string manipulation.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SpamDetector_1</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Implementation of Naive Bayes for binary classification&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clean</span>(<span class="params">self, s</span>):</span><br><span class="line">        translator = <span class="built_in">str</span>.maketrans(<span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, string.punctuation) <span class="comment">#Collect all punctuation in English string and turning them to None</span></span><br><span class="line">        <span class="keyword">return</span> s.translate(translator)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">self, text</span>):</span><br><span class="line">        text = self.clean(text).lower()</span><br><span class="line">        <span class="keyword">return</span> re.split(<span class="string">&quot;\W+&quot;</span>, text) <span class="comment"># &quot;\W+&quot; matches infinite non-word characters</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_word_counts</span>(<span class="params">self, words</span>):</span><br><span class="line">        word_counts = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            word_counts[word] = word_counts.get(word, <span class="number">0.0</span>) + <span class="number">1.0</span></span><br><span class="line">        <span class="keyword">return</span> word_counts</span><br></pre></td></tr></table></figure>
<p>We have a function to clean up our string by removing punctuation, one to tokenize our string into words, and another to count up how many of each word appears in a list of words.</p>
<p>Before we start the actual algorithm, let’s first understand the algorithm. For training,  we need three things: the (log) class priors, i.e., the probability that any given message is spam/ham; a vocabulary of words; and words frequency for spam and ham separately, i.e., the number of times a given word appears in a spam and ham message. Given a list of input documents, we can write this algorithm.</p>
<ol>
<li>Compute log class priors by counting how many messages are spam/ham, dividing by the total number of messages, and taking the log.</li>
<li>For each (document, label) pair, tokenize the document into words.</li>
<li>For each word, either add it to the vocabulary for spam/ham, if it isn’t already there, and update the number of counts. Also add that word to the global vocabulary.</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># modify this cell</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpamDetector_2</span>(<span class="title class_ inherited__">SpamDetector_1</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, Y</span>):</span><br><span class="line">        self.num_messages = &#123;&#125;</span><br><span class="line">        self.log_class_priors = &#123;&#125;</span><br><span class="line">        self.word_counts = &#123;&#125;</span><br><span class="line">        self.vocab = <span class="built_in">set</span>()</span><br><span class="line">        n = <span class="built_in">len</span>(X)</span><br><span class="line">        self.num_messages[<span class="string">&#x27;spam&#x27;</span>] = <span class="built_in">sum</span>(<span class="number">1</span> <span class="keyword">for</span> label <span class="keyword">in</span> Y <span class="keyword">if</span> label == <span class="number">1</span>)</span><br><span class="line">        self.num_messages[<span class="string">&#x27;ham&#x27;</span>] = <span class="built_in">sum</span>(<span class="number">1</span> <span class="keyword">for</span> label <span class="keyword">in</span> Y <span class="keyword">if</span> label == <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute the log prior probability of spam/ham.</span></span><br><span class="line">        <span class="comment"># Hint: compute the log class priors by counting up how many spam/ham messages </span></span><br><span class="line">        <span class="comment"># are in our dataset and dividing by the total number, and take the log.</span></span><br><span class="line">        <span class="comment"># Please perform the calculation for self.log_class_priors[&#x27;spam&#x27;] and self.log_class_priors[&#x27;ham&#x27;] separately.</span></span><br><span class="line"></span><br><span class="line">        self.log_class_priors[<span class="string">&#x27;spam&#x27;</span>] = math.log(self.num_messages[<span class="string">&#x27;spam&#x27;</span>] / n) </span><br><span class="line">        self.log_class_priors[<span class="string">&#x27;ham&#x27;</span>] = math.log(self.num_messages[<span class="string">&#x27;ham&#x27;</span>] / n) </span><br><span class="line"></span><br><span class="line">        self.word_counts[<span class="string">&#x27;spam&#x27;</span>] = &#123;&#125;</span><br><span class="line">        self.word_counts[<span class="string">&#x27;ham&#x27;</span>] = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(X, Y):</span><br><span class="line">            c = <span class="string">&#x27;spam&#x27;</span> <span class="keyword">if</span> y == <span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;ham&#x27;</span></span><br><span class="line">            counts = self.get_word_counts(self.tokenize(x))</span><br><span class="line">            <span class="keyword">for</span> word, count <span class="keyword">in</span> counts.items():</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.vocab:</span><br><span class="line">                    self.vocab.add(word)</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.word_counts[c]:</span><br><span class="line">                    self.word_counts[c][word] = <span class="number">0.0</span></span><br><span class="line">                self.word_counts[c][word] += count</span><br></pre></td></tr></table></figure>
<p>First, we can compute the log class priors by counting up how many spam/ham messages are in our dataset and dividing by the total number. Finally, we take the log.</p>
<p><strong>You may apply the following code to see if the log prior probability of spam/ham is computed successfully.</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">MNB = SpamDetector_2()</span><br><span class="line">MNB.fit(X[<span class="number">100</span>:], y[<span class="number">100</span>:])</span><br><span class="line"></span><br><span class="line"><span class="comment"># If an assert error occurs, you can print and debug it.</span></span><br><span class="line"><span class="comment"># print(&quot;log_class_priors of spam&quot;, MNB.log_class_priors[&#x27;spam&#x27;])</span></span><br><span class="line"><span class="comment"># print(&quot;log_class_priors of ham&quot;, MNB.log_class_priors[&#x27;ham&#x27;])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">round</span>(MNB.log_class_priors[<span class="string">&#x27;spam&#x27;</span>], <span class="number">4</span>) == -<span class="number">0.6776</span>, <span class="string">&quot;The prior probability of spam is calculated incorrectly, please try again.&quot;</span></span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">round</span>(MNB.log_class_priors[<span class="string">&#x27;ham&#x27;</span>], <span class="number">4</span>) == -<span class="number">0.7089</span>, <span class="string">&quot;The prior probability of ham is calculated incorrectly, please try again.&quot;</span></span><br></pre></td></tr></table></figure>
<p>Then we can iterate through our dataset. For each input, we get the word counts and iterate through each (word, frequency) pair. If the word isn’t in our global vocabulary, we add it. If it isn’t in the vocabulary for that particular class label, we also add it along with the frequency.</p>
<p>For example, suppose we had a “spam” message. We count up how many times each unique word appears in that spam message and add that count to the “spam” vocabulary. Suppose the word “free” appears 4 times. Then we add the word “free” to our global vocabulary and add it to the “spam” vocabulary with a count of 4.</p>
<p>We’re keeping track of the frequency of each word as it appears in either a spam or ham message. For example, we expect the word “free” to appear in both messages, but we expect it to be more frequent in the “spam” vocabulary than the “ham” vocabulary.</p>
<p>Now that we’ve extracted all of the data we need from the training data, we can write another function to actually output the class label for new data. To do this classification, we apply Naive Bayes directly. For example, given a document, we need to iterate each of the words and compute $\log p(w_i|\text{Spam})$ and sum them all up, and we also compute $\log p(w_i|\text{Ham})$ and sum them all up. Then we add the log class priors and check to see which score is bigger for that document. Whichever is larger, that is  the predicted label!</p>
<p>To compute $\log p(w_i|\text{Spam})$, the numerator is how many times we’ve seen $w_i$ in a “spam” message, and the denominator is sum of all word counts in all “spam” messages.</p>
<p>On additional note: remember that the log of 0 is undefined! What if we encounter a word that is in the “spam” vocabulary, but not the “ham” vocabulary? Then $p(w_i|\text{Ham})$ will be 0! One way around this is to use <strong>Laplace Smoothing</strong>. We simply add 1 to the numerator, but we also have to add the size of the vocabulary to the denominator to balance it.</p>
<p><strong>Laplace Smoothing</strong>：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{\hat{p}(w_i|c)} &= \displaystyle{\boldsymbol{\frac{count(w_i, c) + 1}{\sum_{w∈V}(count(w, c) + 1)}}}\\
                   &= \displaystyle{\boldsymbol{\frac{count(w_i, c) + 1}{[\sum_{w∈V}(count(w, c)] + |V|}}}
\end{aligned}\tag{4}</script><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># modify this cell</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpamDetector</span>(<span class="title class_ inherited__">SpamDetector_2</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        result = []</span><br><span class="line">        flag_1 = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> X:</span><br><span class="line">            counts = self.get_word_counts(self.tokenize(x))</span><br><span class="line">            spam_score = <span class="number">0</span></span><br><span class="line">            ham_score = <span class="number">0</span></span><br><span class="line">            flag_2 = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> word, _ <span class="keyword">in</span> counts.items():</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.vocab: <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># According to Equation 3，compute the conditional probability of spam/ham and add Laplace</span></span><br><span class="line">                <span class="comment"># smoothing (add 1 to the numerator and add the size of the vocabulary to the denominator).</span></span><br><span class="line">                <span class="comment"># Please define the variable name as log_w_given_spam and log_w_given_ham.</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Perform Laplace Smoothing on the data, using the formula (4) defined in the previous cell;</span></span><br><span class="line">                <span class="comment"># It should be noted that if formula (4) is used, it will be divided into two cases to calculate the conditional probability;</span></span><br><span class="line">                <span class="comment"># The first case is that the current word only appears in one type of email, and the other is in both types of emails; &#x27;</span></span><br><span class="line">                <span class="comment"># Otherwise self.word_counts[class][word] will report an error.</span></span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">in</span> self.word_counts[<span class="string">&#x27;spam&#x27;</span>] :</span><br><span class="line">                    numerator = self.word_counts[<span class="string">&#x27;spam&#x27;</span>][word] + <span class="number">1</span></span><br><span class="line">                    denominator = <span class="built_in">sum</span>([self.word_counts[<span class="string">&#x27;spam&#x27;</span>][key] <span class="keyword">for</span> key <span class="keyword">in</span> self.word_counts[<span class="string">&#x27;spam&#x27;</span>]]) + <span class="built_in">len</span>(self.vocab)</span><br><span class="line">                    log_w_given_spam = math.log(numerator / denominator)</span><br><span class="line">                <span class="keyword">else</span> :</span><br><span class="line">                    numerator = <span class="number">1</span></span><br><span class="line">                    denominator = <span class="built_in">sum</span>([self.word_counts[<span class="string">&#x27;spam&#x27;</span>][key] <span class="keyword">for</span> key <span class="keyword">in</span> self.word_counts[<span class="string">&#x27;spam&#x27;</span>]]) + <span class="built_in">len</span>(self.vocab)</span><br><span class="line">                    log_w_given_spam = math.log(numerator / denominator)</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">in</span> self.word_counts[<span class="string">&#x27;ham&#x27;</span>] :</span><br><span class="line">                    numerator = self.word_counts[<span class="string">&#x27;ham&#x27;</span>][word] + <span class="number">1</span></span><br><span class="line">                    denominator = <span class="built_in">sum</span>([self.word_counts[<span class="string">&#x27;ham&#x27;</span>][key] <span class="keyword">for</span> key <span class="keyword">in</span> self.word_counts[<span class="string">&#x27;ham&#x27;</span>]]) + <span class="built_in">len</span>(self.vocab)</span><br><span class="line">                    log_w_given_ham = math.log(numerator / denominator)</span><br><span class="line">                <span class="keyword">else</span> :</span><br><span class="line">                    numerator = <span class="number">1</span></span><br><span class="line">                    denominator = <span class="built_in">sum</span>([self.word_counts[<span class="string">&#x27;ham&#x27;</span>][key] <span class="keyword">for</span> key <span class="keyword">in</span> self.word_counts[<span class="string">&#x27;ham&#x27;</span>]]) + <span class="built_in">len</span>(self.vocab)</span><br><span class="line">                    log_w_given_ham = math.log(numerator / denominator)</span><br><span class="line">                <span class="comment">#</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># Testing your results. Do not remove.</span></span><br><span class="line">                <span class="keyword">if</span> (flag_1 == <span class="number">0</span>) <span class="keyword">and</span> (flag_2 == <span class="number">0</span>):</span><br><span class="line">                    <span class="comment"># If an assert error occurs, you can print and debug it.</span></span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;log_w_given_spam&quot;</span>, log_w_given_spam)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;log_w_given_ham&quot;</span>, log_w_given_ham)</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">assert</span> <span class="built_in">round</span>(log_w_given_spam, <span class="number">4</span>) == -<span class="number">5.2759</span>, <span class="string">&quot;The conditional probability of spam is calculated incorrectly, please try again.&quot;</span></span><br><span class="line">                    <span class="keyword">assert</span> <span class="built_in">round</span>(log_w_given_ham, <span class="number">4</span>) == -<span class="number">5.1075</span>, <span class="string">&quot;The conditional probability of ham is calculated incorrectly, please try again.&quot;</span></span><br><span class="line">                <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Calculate the sum of the conditional probabilities of spam/ham and define them as spam_score and ham_score.</span></span><br><span class="line"></span><br><span class="line">                spam_score += log_w_given_spam</span><br><span class="line">                ham_score += log_w_given_ham</span><br><span class="line"></span><br><span class="line">                flag_2 += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># Testing your results. Do not remove.</span></span><br><span class="line">            <span class="keyword">if</span> flag_1 == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># If an assert error occurs, you can print and debug it.</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;spam_score&quot;</span>, spam_score)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;ham_score&quot;</span>, ham_score)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">round</span>(spam_score, <span class="number">2</span>) == -<span class="number">1015.11</span>, <span class="string">&quot;The sum of the conditional probabilities of spam is calculated incorrectly, please try again.&quot;</span></span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">round</span>(ham_score, <span class="number">2</span>) == -<span class="number">1102.46</span>, <span class="string">&quot;The sum of the conditional probabilities of ham is calculated incorrectly, please try again.&quot;</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Finally, remember to add the prior probability to the spam_score and spam_score.</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Your Code</span></span><br><span class="line">            <span class="comment"># 要加上类别的先验概率。</span></span><br><span class="line">            spam_score += self.log_class_priors[<span class="string">&#x27;spam&#x27;</span>]</span><br><span class="line">            ham_score += self.log_class_priors[<span class="string">&#x27;ham&#x27;</span>]</span><br><span class="line">            <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Testing your results. Do not remove.</span></span><br><span class="line">            <span class="keyword">if</span> flag_1 == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># If an assert error occurs, you can print and debug it.</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;spam_score plus prior_probability&quot;</span>, spam_score)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;ham_score plus prior_probability&quot;</span>, ham_score)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">round</span>(spam_score, <span class="number">2</span>) == -<span class="number">1015.79</span>, <span class="string">&quot;You forget to add its prior probability to the spam_score, please try again.&quot;</span></span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">round</span>(ham_score, <span class="number">2</span>) == -<span class="number">1103.17</span>, <span class="string">&quot;You forget to add its prior probability to the ham_score, please try again.&quot;</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Please count the prediction results according to the rules </span></span><br><span class="line">            <span class="comment"># (Check to see which score is bigger for that document. Whichever is larger, that is the predicted label!), </span></span><br><span class="line">            <span class="comment"># and add the labels to the list result (1 for spam and 0 for ham).</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Calculate the Bayesian probability according to formula (3);</span></span><br><span class="line">            <span class="comment"># If the score of garbage text is larger, the predicted label is 1, otherwise the predicted label is 0.</span></span><br><span class="line">            <span class="keyword">if</span> spam_score &gt; ham_score :</span><br><span class="line">                result.append(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                result.append(<span class="number">0</span>)</span><br><span class="line">            <span class="comment">#</span></span><br><span class="line"></span><br><span class="line">            flag_1 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<p>In our case, the input can be a list of document texts; we return a list of predictions. Finally, we can use the class like this.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># modify this cell</span></span><br><span class="line"></span><br><span class="line">MNB = SpamDetector()</span><br><span class="line">MNB.fit(X[<span class="number">100</span>:], y[<span class="number">100</span>:])</span><br><span class="line">pred = MNB.predict(X[:<span class="number">100</span>])</span><br><span class="line">true = y[:<span class="number">100</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the accuracy rate and print it (results are retained to 4 decimal places).</span></span><br><span class="line"><span class="comment"># Please define the variable name as accuracy.</span></span><br><span class="line"></span><br><span class="line">accuracy = <span class="built_in">sum</span>(pred) / <span class="built_in">sum</span>(true)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(accuracy)</span><br><span class="line"><span class="keyword">assert</span> accuracy == <span class="number">0.9800</span></span><br></pre></td></tr></table></figure>
<pre><code>log_w_given_spam -5.275940294514414
log_w_given_ham -5.107477914537173
spam_score -1015.1113024344844
ham_score -1102.456441377472
spam_score plus prior_probability -1015.7889234611885
ham_score plus prior_probability -1103.165359580201
0.98
</code></pre><p>We’re reserving the first 100 for the testing set, “train” our Naive Bayes classifier, then compute the accuracy.</p>
<p>To recap, we reviewed Bayes Theorem and demonstrated how to use it with an example. Then we re-worked it using hypotheses and evidence instead of just events A and B to make it more specific to our task of spam detection. From there, we derived Naive Bayes by making the Naive Bayes Assumption that each word appears independently of all other words. Then we formulated a prediction equation/rule. Using the Enron dataset, we created a binary Naive Bayes classifier for detecting spam emails.</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>传统算法</category>
      </categories>
      <tags>
        <tag>Bayes</tag>
        <tag>text classification</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 PCA 的人脸识别系统和姿态分析</title>
    <url>/2022/06/05/%E5%9F%BA%E4%BA%8E-PCA-%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E5%92%8C%E5%A7%BF%E6%80%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<h1 id="1-PCA"><a href="#1-PCA" class="headerlink" title="1    PCA"></a>1    PCA</h1><p>&emsp;&emsp;在解决实际问题的时候，多变量问题是经常会遇到的，变量太多，无疑会增加分析问题的难度与复杂性。同时，在许多实际问题中，多个变量之间是具有一定的相关关系的。因此，能否在各个变量之间相关关系研究的基础上， 用较少的新变量代替原来较多的变量，而且使这些较少的新变量尽可能多地保留原来较多的变量所反映的信息？事实上，这种想法是可以实现的。</p>
<h2 id="1-1-原理"><a href="#1-1-原理" class="headerlink" title="1.1    原理"></a>1.1    原理</h2><p>&emsp;&emsp;<strong>PCA</strong>(Principal Components Analysis,，主成分分析)是将原来多个变量化为少数几个综合指标的一种统计分析方法，从数学角度来看，这是一种降维处理技术。  下面举例说明其原理，加入有以下数据：</p>
<p><img src="https://th.bing.com/th/id/OIP.2LuHxwMc-MzJ1dVcPILd8gHaFj?w=232&amp;h=180&amp;c=7&amp;r=0&amp;o=5&amp;dpr=1.25&amp;pid=1.7" alt="img"></p>
<p>可以将上述数据看成一个椭圆形，椭圆有一个长轴和一个短轴。 在短轴方向上， 数据变化很少；在极端的情况，短轴如果退化成一点， 那只有在长轴的方向才能够解释这些点的变化了。这样，由二维到一维的降维就自然完成了。 从数据波动上来看，在短轴上数据的方差较小，因此在该轴上的信息属于次信息；而在长轴上数据的方差较大，因此在该轴上的信息属于主信息。了解 PCA 的基本原理之后，我们还要思考一个问题，PCA 优化的目标是什么？请看下图：</p>
<p><img src="https://www.biaodianfu.com/wp-content/uploads/2020/09/pca-1.png" alt="img" style="zoom: 50%;" /></p>
<p>我们将上图中的点往两个超平面上投影，分别得到不同超平面的方差分别为：0.045，0.206，因此将所有样本点投影到方差为 0.206 的超平面能在实现降维的目标且保留更多的信息。因此 PCA 要做得是使所有样本的投影尽可能分开，也即找到一个样本投影后的方差最大的超平面来实现降维。我们将上述降维准则称作 <strong>最大可分性</strong>；同时样本点到这个超平面的距离都足够近，即下图中所有红线(即投影造成的损失)加起来最小，也就是保留了更多的信息，我们将此准则称作 <strong>最近重构性</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/a0f6f5a31b3c4ed5b0cb7c22181a7b36.gif#pic_center" alt="在这里插入图片描述" style="zoom: 80%;" /></p>
<h2 id="1-2-算法流程"><a href="#1-2-算法流程" class="headerlink" title="1.2    算法流程"></a>1.2    算法流程</h2><p>&emsp;&emsp;PCA 整体的算法流程描述如下：</p>
<hr>
<p><strong>输入：样本集 $\boldsymbol{D = {x_1,x_2, \cdots,x_m}}$； 低维空间维数 $\boldsymbol{k}$;</strong></p>
<p><strong>过程：</strong></p>
<p><strong>1：对所有样本进行零均值化：$\boldsymbol{x_i\leftarrow x_i - \frac{1}{m}\sum_{i=1}^{m}x_i}$;</strong></p>
<p><strong>2：计算样本的协方差矩阵 $\boldsymbol{XX^T}$;</strong></p>
<p><strong>3：对协方差矩阵 $\boldsymbol{XX^T}$ 做特征值分解；</strong></p>
<p><strong>4：取最大的 $\boldsymbol{k}$ 个的特征值所对应的特征向量 $\boldsymbol{w_1, w_2, \cdots, w_{k}}$;</strong></p>
<p><strong>输出：投影矩阵 $\boldsymbol{W = (w_1, w_2, \cdots, w_{k})}$。</strong></p>
<hr>
<p>下面对每个步骤进行详细分析。</p>
<h3 id="1-2-1-零均值化"><a href="#1-2-1-零均值化" class="headerlink" title="1.2.1    零均值化"></a>1.2.1    零均值化</h3><p>&emsp;&emsp;此步骤的目的是标准化输入数据集，使数据成比例缩小。更确切地说，在使用 PCA 之前必须标准化数据的原因是 PCA 方法对初始变量的方差非常敏感。也就是说，如果初始变量的范围之间存在较大差异，那么范围较大的变量占的比重较大，和较小的变量相比(例如，范围介于 0 和 100 之间的变量较 0 到 1 之间的变量会占较大比重)，这将导致主成分的偏差。通过将数据转换为同样的比例可以防止这个问题。在实现过程中，我们的操作区别于标准的标准化，我们只将每个样本减去它们的均值。</p>
<h3 id="1-2-2-计算协方差矩阵"><a href="#1-2-2-计算协方差矩阵" class="headerlink" title="1.2.2    计算协方差矩阵"></a>1.2.2    计算协方差矩阵</h3><p>&emsp;&emsp;此步骤的目的是了解输入数据集的变量相对于彼此平均值变化，换句话说，查看它们是否存在关系。因为有时候变量由于高度相关，这样就会包含冗余信息。因此，为了识别变量的相关性，我们计算协方差矩阵。下面以二维矩阵为例：</p>
<script type="math/tex; mode=display">
C= 
\begin{bmatrix}
Cov(x,x)&Cov(x,y)&Cov(x, z)\\
Cov(y,x)&Cov(y, y)&Cov(y,z)\\
Cov(z,x)&Cov(z, y)&Cov(z,z)
\end{bmatrix}</script><p>上述矩阵中，对角线上分别是特征 $x, y,z$ 的方差，非对角线上是协方差。由于协方差是可交换的 $Cov(a, b) = Cov(b,a)$，协方差矩阵关于主对角线是对称的，这意味着上三角部分和下三角部分相等。协方差矩阵可以告诉我们变量之间的关系，总结有如下三点：</p>
<ul>
<li>如果协方差为正则：两个变量一起增加或减少(正相关)；</li>
<li>如果协方差为负则：两个变量其中一个增加，另一个减少(负相关)；</li>
<li>协方差绝对值越大，两者对彼此的影响越大，反之越小。</li>
</ul>
<h3 id="1-2-3-特征值和特征向量"><a href="#1-2-3-特征值和特征向量" class="headerlink" title="1.2.3    特征值和特征向量"></a>1.2.3    特征值和特征向量</h3><p>&emsp;&emsp;求协方差矩阵 $C$ 的特征值 $\lambda$ 和相对应的特征向量 $u$ (每一个特征值对应一个特征向量)：</p>
<script type="math/tex; mode=display">
Cu = \lambda u</script><p>特征值 $\lambda$ 会有 $N$ 个，每一个 $\lambda$ 对应一个特征向量 $u$，将特征值 $\lambda$ 按照从大到小的顺序排序，选择最大的前 $K$ 个，并将其相对应的 $K$ 个特征向量拿出来，我们会得到一组 $\{(\lambda_1,u_1),(\lambda_2,u_2),\cdots,(\lambda_k, u_k)\}$。为什么只取特征值较大的特征向量，因为较大特征值对应的特征向量保留了原始数据的大部分信息吗，也即方差较大，可作为数据的主成分。</p>
<h3 id="1-2-4-降维得到-K-维特征"><a href="#1-2-4-降维得到-K-维特征" class="headerlink" title="1.2.4    降维得到 K 维特征"></a>1.2.4    降维得到 K 维特征</h3><p>&emsp;&emsp;选取最大的前 $K$ 个特征值和相对应的特征向量，并进行投影的过程，就是降维的过程。对于每个样本 $X_i$，原始的特征是 $(x_1, x_2, \cdots,x_m)$，投影之后的新特征是 $(y_1,y_2,\cdots,y_k)$，计算过程如下：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
y_1^i\\
y_2^i\\
\vdots \\
y_k^i\\
\end{bmatrix} = 
\begin{bmatrix}
u^T_1\cdot(x_1^i, x_2^i, \cdots,x_m^i)^T\\
u^T_2\cdot(x_1^i, x_2^i, \cdots,x_m^i)^T\\
\vdots\\
u^T_k\cdot(x_1^i, x_2^i, \cdots,x_m^i)^T
\end{bmatrix}</script><h3 id="1-2-5-PCA-的优缺点"><a href="#1-2-5-PCA-的优缺点" class="headerlink" title="1.2.5    PCA 的优缺点"></a>1.2.5    PCA 的优缺点</h3><p>优点：</p>
<ul>
<li>只需以方差衡量信息量，不受数据集以外的因素影响；</li>
<li>各主成分之间正交，可消除原始数据成分间的相互影响；</li>
<li>计算方法简单，主要运算是特征值分解且易于实现。</li>
</ul>
<p>缺点：</p>
<ul>
<li>主成分各特征维度的含义具有模糊性，不如原始样本特征的解释性强；</li>
<li>方差小的成分可能含有影响样本差异的重要信息，降维丢弃可能对后续数据处理有影响。</li>
</ul>
<h1 id="2-Python-实现-PCA"><a href="#2-Python-实现-PCA" class="headerlink" title="2    Python 实现 PCA"></a>2    Python 实现 PCA</h1><p>&emsp;&emsp;本次实现的流程完全依据于 <a href="# 1.2    算法流程"><strong>1.2    算法流程</strong></a>，代码中有详细注释，便不在另做解释：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PCA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_components</span>):</span><br><span class="line">        <span class="comment"># 决定降到多少维</span></span><br><span class="line">        self.n_components = n_components</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 均值</span></span><br><span class="line">        X_mean = np.mean(X, axis = <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 去均值化</span></span><br><span class="line">        X_norm = X - X_mean</span><br><span class="line">        <span class="comment"># 计算协方差矩阵，将每行也即每一个样本看作一个变量，每列作为观测值</span></span><br><span class="line">        X_conv = np.cov(X_norm, rowvar = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 计算特征值何特征向量</span></span><br><span class="line">        eigenvalues, featurevectors = np.linalg.eig(X_conv)</span><br><span class="line">        <span class="comment"># 特征值从小到大的下标</span></span><br><span class="line">        index = np.argsort(eigenvalues)</span><br><span class="line">        <span class="comment"># 取最大的 n_components 个特征值</span></span><br><span class="line">        n_index = index[ -self.n_components : ]</span><br><span class="line">        <span class="comment"># 降维，训练样本的特征脸空间</span></span><br><span class="line">        self.w = featurevectors[ : , n_index]</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 计算训练样本和测试样本在特征脸空间的投影</span></span><br><span class="line">        <span class="comment"># 映射到图像空间</span></span><br><span class="line">        eigenfaces = np.dot(X, self.w)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> eigenfaces</span><br></pre></td></tr></table></figure>
<h1 id="3-基于-PCA-的人脸识别"><a href="#3-基于-PCA-的人脸识别" class="headerlink" title="3    基于 PCA 的人脸识别"></a>3    基于 PCA 的人脸识别</h1><p>&emsp;&emsp;在前面中，我们从原理开始分析 PCA 算法，最终并使用 Python 实现了 PCA 算法，那这部分主要是使用 PCA 来对不同的人脸识别数据集进行提取特征，并且实现人脸识别。</p>
<h2 id="3-1-ORL-数据集"><a href="#3-1-ORL-数据集" class="headerlink" title="3.1    ORL 数据集"></a>3.1    ORL 数据集</h2><p>&emsp;&emsp;ORL 人脸数据集共包含 40 个不同人的 400 张图像，是在 1992 年 4 月至 1994 年 4 月期间由英国剑桥的 Olivetti 研究实验室创建。 此数据集下包含 40 个目录，每个目录下有 10 张图像，每个目录表示一个不同的人。所有的图像是以 PGM 格式存储，灰度图，图像大小宽度为 92，高度为 112。对每一个目录下的图像，这些图像是在不同的时间、不同的光照、不同的面部表情 (睁眼 / 闭眼，微笑 / 不微笑) 和面部细节 (戴眼镜 / 不戴眼镜) 环境下采集的。所有的图像是在较暗的均匀背景下拍摄的，拍摄的是正脸 (有些带有略微的侧偏)。下载地址为：<a href="https://github.com/yasminemedhat/Face-Recognition"><strong>https://github.com/yasminemedhat/Face-Recognition</strong></a></p>
<p><img src="https://img-blog.csdn.net/20141118160519755" alt="img" style="zoom:67%;" /></p>
<p>人脸识别的流程如下：</p>
<ul>
<li>数据读取与数据处理；</li>
<li>数据分组；</li>
<li>使用 PCA 进行特征提取；</li>
<li>人脸识别；</li>
<li>人脸识别的 GUI 界面。</li>
</ul>
<h3 id="3-1-1-数据读取与数据处理"><a href="#3-1-1-数据读取与数据处理" class="headerlink" title="3.1.1    数据读取与数据处理"></a>3.1.1    数据读取与数据处理</h3><p>&emsp;&emsp;因为 ORL 数据集的图片格式是 <strong>.pgm</strong>，我使用了 <strong>pillow</strong> 库中的 <strong>Image</strong> 类来进行读取。对于每张照片将其拉直，因为 ORL 中图片大小是 (112，92)，拉直之后则变成 (10304，)，然后将所有照片进行拼接，最终得到大小为 (400，10304) 的二维矩阵。再者就是标签的构造，从上到下的 <strong>人</strong> 的标签分别是 0，1，2，…，39，要注意每一张图片都要有一个标签。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img).ravel()</span><br><span class="line">            X.append(img)</span><br><span class="line">        y.extend([idx] * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<h3 id="3-1-2-数据分组"><a href="#3-1-2-数据分组" class="headerlink" title="3.1.2    数据分组"></a>3.1.2    数据分组</h3><p>&emsp;&emsp;本次数据的分割依据于下面的两种方式：</p>
<ul>
<li>每个人的前面 8 张照片作为训练并作为测试样本库，后面 2 张作为测试待识别图片；</li>
<li>前 38 个人作为训练，后 12 个人作为测试，其中测试库中每个人的前面 8 张照片为测试样本库，后面 2 张照片作为待识别图片。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y, flag</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    test_set = []</span><br><span class="line">    test_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line">    <span class="comment"># 分组一：每个人的任意 8 张照片作为训练并作为测试样本库</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="number">1</span> :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>) :</span><br><span class="line">            train_set.append(X[i * <span class="number">10</span> : i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            train_target.extend(y[i * <span class="number">10</span> : i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            face_unrecognized_set.append(X[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">            face_unrecognized_target.extend(y[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">        test_set = train_set.copy()</span><br><span class="line">        test_target = train_target.copy()</span><br><span class="line">    <span class="comment"># 分组二：前 38 个人作为训练，后 2 个人作为测试</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        train_set = X[: <span class="number">380</span>, :]</span><br><span class="line">        train_target = y[: <span class="number">380</span>]</span><br><span class="line">        X_temp = X[<span class="number">380</span>:, :]</span><br><span class="line">        y_temp = y[<span class="number">380</span>:]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>) :</span><br><span class="line">            test_set.extend(X_temp[i * <span class="number">10</span>: i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            test_target.extend(y_temp[i * <span class="number">10</span>: i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            face_unrecognized_set.extend(X_temp[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">            face_unrecognized_target.extend(y_temp[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    test_set = np.array(test_set)</span><br><span class="line">    test_target = np.array(test_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           test_set, test_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br></pre></td></tr></table></figure>
<h3 id="3-1-3-使用-PCA-进行特征提取"><a href="#3-1-3-使用-PCA-进行特征提取" class="headerlink" title="3.1.3    使用 PCA 进行特征提取"></a>3.1.3    使用 PCA 进行特征提取</h3><p>&emsp;&emsp;本过程对人脸特征进行提取，主要难度在于编写 PCA，我们在前面已经完成。但是我们还有一个非常重要的参数要确定，就是 $\boldsymbol{k}$ 值，如果 $\boldsymbol{k}$ 过大，那 PCA 降维之后数据信息中仍然保留大量的冗余信息；如果 $\boldsymbol{k}$ 过小，则 PCA 降维过程中损失了过多信息，不利于后续的识别工作。为此，我借用 <strong>sklearn</strong> 来探究在保留 95% 的原始数据应该降到多少纬合适。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components = <span class="number">0.95</span>)</span><br><span class="line">pca.fit(train_set)</span><br><span class="line"><span class="built_in">print</span>(pca.n_components_)</span><br></pre></td></tr></table></figure>
<p>最终的测试结果是对于 <strong>分组一</strong> 和 <strong>分组二</strong> 的 $\boldsymbol{k}$ 值分别是 161，184。知道 $\boldsymbol{k}$ 值之后，我们就可以进行特征提取，要注意我们只能对训练集进行训练，也即要使用训练集的特征向量对测试集和待识别图片进行 PCA 降维。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">161</span>) <span class="comment"># or pca = PCA(n_components = 184)</span></span><br><span class="line">pca.fit(train_set)</span><br><span class="line">train_reduction = pca.transform(train_set)</span><br><span class="line">test_reduction = pca.transform(test_set)</span><br><span class="line">face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br></pre></td></tr></table></figure>
<h3 id="3-1-4-人脸识别"><a href="#3-1-4-人脸识别" class="headerlink" title="3.1.4    人脸识别"></a>3.1.4    人脸识别</h3><p>&emsp;&emsp;经过上述步骤之后，我们可以得到降维后的训练集、测试集和待识别人脸，在这部分我们就可以进行人脸匹配。首先要说明：对于人脸识别而言，如果计算机先前没有看到过关于这个人的照片，那对这个人进行人脸识别是没有意义的，大家可以细细探究一下 <strong>分组一</strong> 和 <strong>分组二</strong>。本次人脸识别我使用的准则是 <strong>二范数</strong>，下面分别对 <strong>分组一</strong> 和 <strong>分组二</strong> 进行讲解。</p>
<p>&emsp;&emsp;首先是 <strong>分组一</strong>，因为训练集和测试集一样，都包含了全部人的人脸，也就是说计算机 <strong>“看过”</strong> 待识别人脸，因此我们可以用训练集或者测试集来进行人脸识别：计算待识别的人脸特征向量与训练集中每一张图片的特征向量的二范数，其中二范数最小的那张图片就是我们在训练集中匹配到的人脸。在此过程我设置了两个返回值分别是 <strong>pred</strong> 和 <strong>labels</strong>，前者为匹配到的人脸图片在训练集中的下标，方便后面的 GUI 设计，后者是匹配到的人脸图片的标签，用于后续的识别准确率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, Y</span>) :</span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)) :</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis = <span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        labels.append(label // <span class="number">8</span>)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;其次是 <strong>分组二</strong>，训练集是前 38 个人的人脸照片，测试集是后两个人的前 8 张图片，待识别图片是后两个人的后两张人脸图片。如果我们使用训练集去匹配待识别图片，这时计算原先没有 <strong>“看过”</strong> 该人人脸，此时识别是无意义的，因此我们要使用测试集去识别待识别图片。返回值同样是 <strong>pred</strong> 和 <strong>labels</strong>，要注意标签的计算方式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, Y</span>) :</span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)) :</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis = <span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        labels.append(label // <span class="number">8</span> + <span class="number">38</span>)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred) </span><br></pre></td></tr></table></figure>
<h3 id="3-1-5-人脸识别的-GUI-界面"><a href="#3-1-5-人脸识别的-GUI-界面" class="headerlink" title="3.1.5    人脸识别的 GUI 界面"></a>3.1.5    人脸识别的 GUI 界面</h3><p>&emsp;&emsp;为了体现人脸识别系统的完整性，我设计了人脸识别系统的 GUI，在 GUI 页面的左边展示的是待识别人脸图片，在点击按键 <strong>“开始识别”</strong> 之后，GUI 页面右边会展示识别效果。代码与效果会在下面展示。</p>
<h3 id="3-1-6-实验结果"><a href="#3-1-6-实验结果" class="headerlink" title="3.1.6    实验结果"></a>3.1.6    实验结果</h3><p>&emsp;&emsp;对于分组一：一共有采集了 80 张待识别人脸图片，最终识别正确率是 0.95，显示别效果如下：</p>
<p><img src="https://s2.loli.net/2022/05/19/pC3x96HrBuUeXVE.png" alt="1652942593728.png" style="zoom:50%;" /></p>
<p>如上图，前面三张识别是成功的，而第四张是识别错误的。</p>
<p>&emsp;&emsp;对于分组二：一共有采集了 4 张待识别人脸图片，最终识别正确率是 1.0，显示别效果如下：</p>
<p><img src="https://s2.loli.net/2022/05/19/6zfl5CbSkRD9tIU.png" alt="1652942964367.png" style="zoom:50%;" /></p>
<p>如上图，四张待识别图片全部识别正确。</p>
<h3 id="3-1-7-全部代码"><a href="#3-1-7-全部代码" class="headerlink" title="3.1.7    全部代码"></a>3.1.7    全部代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageTk</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> font</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCA</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_components</span>):</span><br><span class="line">        <span class="comment"># 决定降到多少维</span></span><br><span class="line">        self.n_components = n_components</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 均值</span></span><br><span class="line">        X_mean = np.mean(X, axis = <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 去均值化</span></span><br><span class="line">        X_norm = X - X_mean</span><br><span class="line">        <span class="comment"># 计算协方差矩阵，将每行也即每一个样本看作一个变量，每列作为观测值</span></span><br><span class="line">        X_conv = np.cov(X_norm, rowvar = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 计算特征值何特征向量</span></span><br><span class="line">        eigenvalues, featurevectors = np.linalg.eig(X_conv)</span><br><span class="line">        <span class="comment"># 特征值从小到大的下标</span></span><br><span class="line">        index = np.argsort(eigenvalues)</span><br><span class="line">        <span class="comment"># 取最大的 n_components 个特征值</span></span><br><span class="line">        n_index = index[ -self.n_components : ]</span><br><span class="line">        <span class="comment"># 降维，训练样本的特征脸空间</span></span><br><span class="line">        self.w = featurevectors[ : , n_index]</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 计算训练样本和测试样本在特征脸空间的投影</span></span><br><span class="line">        <span class="comment"># 映射到图像空间</span></span><br><span class="line">        eigenfaces = np.dot(X, self.w)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> eigenfaces</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img).ravel()</span><br><span class="line">            X.append(img)</span><br><span class="line">        y.extend([idx] * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y, flag</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    test_set = []</span><br><span class="line">    test_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line">    <span class="comment"># 分组一：每个人的任意 8 张照片作为训练并作为测试样本库</span></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="number">1</span> :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>) :</span><br><span class="line">            train_set.append(X[i * <span class="number">10</span> : i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            train_target.extend(y[i * <span class="number">10</span> : i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            face_unrecognized_set.append(X[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">            face_unrecognized_target.extend(y[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">        test_set = train_set.copy()</span><br><span class="line">        test_target = train_target.copy()</span><br><span class="line">    <span class="comment"># 分组二：前 38 个人作为训练，后 2 个人作为测试</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        train_set = X[: <span class="number">380</span>, :]</span><br><span class="line">        train_target = y[: <span class="number">380</span>]</span><br><span class="line">        X_temp = X[<span class="number">380</span>:, :]</span><br><span class="line">        y_temp = y[<span class="number">380</span>:]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>) :</span><br><span class="line">            test_set.extend(X_temp[i * <span class="number">10</span>: i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            test_target.extend(y_temp[i * <span class="number">10</span>: i * <span class="number">10</span> + <span class="number">8</span>])</span><br><span class="line">            face_unrecognized_set.extend(X_temp[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line">            face_unrecognized_target.extend(y_temp[i * <span class="number">10</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    test_set = np.array(test_set)</span><br><span class="line">    test_target = np.array(test_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           test_set, test_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, Y</span>) :</span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)) :</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis = <span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        labels.append(label // <span class="number">8</span>)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Face_GUI</span>(<span class="params">unrecognized, result</span>) :</span><br><span class="line">    img = unrecognized.reshape(<span class="number">112</span>, <span class="number">92</span>)</span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    photo = ImageTk.PhotoImage(img)</span><br><span class="line"></span><br><span class="line">    label = Label(root, text = <span class="string">&quot;图片识别&quot;</span>, fg = <span class="string">&#x27;red&#x27;</span>, font = (<span class="string">&quot;华文行楷&quot;</span>, <span class="number">25</span>, font.BOLD))</span><br><span class="line">    label.place(relx = <span class="number">0.35</span>, rely = <span class="number">0.01</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    lb1 = Label(root, image = photo)</span><br><span class="line">    lb1.place(relx = <span class="number">0.1</span>, rely = <span class="number">0.25</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    label_context1 = Label(root, text = <span class="string">&quot;待识别图片:&quot;</span>, fg = <span class="string">&#x27;blue&#x27;</span>, </span><br><span class="line">                           							font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    label_context1.place(relx = <span class="number">0.1</span>, rely = <span class="number">0.15</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    btn = Button(root, text = <span class="string">&quot;开始识别&quot;</span>, command = <span class="keyword">lambda</span> : Match(result), </span><br><span class="line">                 									font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    btn.place(relx = <span class="number">0.35</span>, rely = <span class="number">0.65</span>, relwidth = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Match</span>(<span class="params">result</span>) :</span><br><span class="line">    img = result.reshape(<span class="number">112</span>, <span class="number">92</span>)</span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    photo = ImageTk.PhotoImage(img)</span><br><span class="line"></span><br><span class="line">    lb2 = Label(root, image = photo)</span><br><span class="line">    lb2.place(relx = <span class="number">0.6</span>, rely = <span class="number">0.25</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    label_context2 = Label(root, text = <span class="string">&quot;识别结果:&quot;</span>, fg = <span class="string">&#x27;blue&#x27;</span>, </span><br><span class="line">                           							font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    label_context2.place(relx = <span class="number">0.6</span>, rely = <span class="number">0.15</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.1</span>)</span><br><span class="line">    root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    X, y = Data_Processing(<span class="string">&#x27;ORL&#x27;</span>)</span><br><span class="line">    train_set, train_target, test_set, test_target, face_unrecognized_set,\</span><br><span class="line">    					face_unrecognized_target = Data_Split(X, y, flag = <span class="number">1</span>)</span><br><span class="line">    pca = PCA(n_components = <span class="number">161</span>)</span><br><span class="line">    pca.fit(train_set)</span><br><span class="line">    train_reduction = pca.transform(train_set)</span><br><span class="line">    test_reduction = pca.transform(test_set)</span><br><span class="line">    face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br><span class="line">    labels, pred = Predict(train_reduction, face_unrecognized_reduction)</span><br><span class="line">    accuracy = (labels == face_unrecognized_target).<span class="built_in">sum</span>() / <span class="built_in">len</span>(face_unrecognized_target)</span><br><span class="line">    <span class="built_in">print</span>(accuracy)</span><br><span class="line">    <span class="built_in">print</span>(pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pred)):</span><br><span class="line">        root = Tk()</span><br><span class="line">        root.geometry(<span class="string">&#x27;480x480&#x27;</span>)</span><br><span class="line">        root.title(<span class="string">&#x27;基于 PCA 的人脸识别系统&#x27;</span>)</span><br><span class="line">        unrecognized = face_unrecognized_set[i]</span><br><span class="line">        result = train_set[pred[i]]</span><br><span class="line">        Face_GUI(unrecognized, result)</span><br></pre></td></tr></table></figure>
<h2 id="3-2-Yale-数据集"><a href="#3-2-Yale-数据集" class="headerlink" title="3.2    Yale 数据集"></a>3.2    Yale 数据集</h2><p>&emsp;&emsp;Yale 人脸数据库是一个人脸数据集，主要用于身份鉴定，包含 15 个人，其中每个人有 11 张图像共计 165 个 GIF 格式的灰度图像，每个主题包含不同的面部表情：中心光、带眼镜、快乐、左光、没有眼镜、正常、右光、悲伤、困、惊讶和眨眼。图像大小宽度为 320，高度为 243。下载地址为：<a href="https://www.kaggle.com/datasets/olgabelitskaya/yale-face-database"><strong>https://www.kaggle.com/datasets/olgabelitskaya/yale-face-database</strong></a></p>
<p><img src="https://s2.loli.net/2022/05/19/qDipj3KYxOENIdr.png" alt="0.png"></p>
<p>使用 PCA 对 Yale数据集进行人脸识别的流程和对 ORL 数据集的流程一样，但是许多细节需要调整。</p>
<h3 id="3-2-1-数据读取和数据处理"><a href="#3-2-1-数据读取和数据处理" class="headerlink" title="3.2.1    数据读取和数据处理"></a>3.2.1    数据读取和数据处理</h3><p>&emsp;&emsp;Yale 数据集的文件形式不是我们常见的图片编码格式，因此我使用了 <strong>skimage</strong> 包中的 <strong>io</strong> 模块对图片进行读取。</p>
<p><img src="https://s2.loli.net/2022/05/19/gmIs7vV8OjkhFcY.png" alt="捕获.PNG" style="zoom:67%;" /></p>
<p>在读取完之后，我们发现原始的人脸图片很大，其大小为我们前面所讲的 (243，320)，一张图中，背景占比很高，如果直接对原图进行展平得到 (77760，) 大小的向量，这对于计算资源的要求很高，而且因为背景的存在会影响人脸特征的提取，并最终影响人脸识别性能。因此，一般的人脸识别系统在特征提取之前会首先做一件事：<strong>人脸检测</strong>。不能此实验我使用热人脸检测模型是 <strong>MTCNN</strong> 这是一个深度学习模型，可以达到实施效果，且准确率非常高。可以在命令行通过以下命令进行安装：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install mtcnn</span><br></pre></td></tr></table></figure>
<p>MTCNN 的使用模板如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> mtcnn.mtcnn <span class="keyword">import</span> MTCNN</span><br><span class="line"><span class="comment"># 要注意输出的图像要是三通道的</span></span><br><span class="line">detector = MTCNN()</span><br><span class="line">result = detector.detect_faces(img)</span><br></pre></td></tr></table></figure>
<p>返回值为：要注意的是返回的结果可能有多个人脸。</p>
<figure class="highlight scheme"><table><tr><td class="code"><pre><span class="line">[&#123;<span class="symbol">&#x27;box</span><span class="symbol">&#x27;:</span> [<span class="name">121</span>, <span class="number">69</span>, <span class="number">122</span>, <span class="number">154</span>],</span><br><span class="line">  <span class="symbol">&#x27;confidence</span><span class="symbol">&#x27;:</span> <span class="number">0.9999041557312012</span>,</span><br><span class="line">  <span class="symbol">&#x27;keypoints</span><span class="symbol">&#x27;:</span> &#123;<span class="symbol">&#x27;left_eye</span><span class="symbol">&#x27;:</span> (<span class="name">160</span>, <span class="number">122</span>),</span><br><span class="line">   <span class="symbol">&#x27;right_eye</span><span class="symbol">&#x27;:</span> (<span class="name">214</span>, <span class="number">123</span>),</span><br><span class="line">   <span class="symbol">&#x27;nose</span><span class="symbol">&#x27;:</span> (<span class="name">189</span>, <span class="number">152</span>),</span><br><span class="line">   <span class="symbol">&#x27;mouth_left</span><span class="symbol">&#x27;:</span> (<span class="name">163</span>, <span class="number">182</span>),</span><br><span class="line">   <span class="symbol">&#x27;mouth_right</span><span class="symbol">&#x27;:</span> (<span class="name">210</span>, <span class="number">184</span>)&#125;&#125;]</span><br></pre></td></tr></table></figure>
<p>关于 MTCNN 可以参考：<a href="https://arxiv.org/abs/1604.02878"><strong>https://arxiv.org/abs/1604.02878</strong></a>，这里不做更多说明。下面看一下人脸检测的效果：</p>
<p><img src="https://s2.loli.net/2022/05/19/ztsfYqZ4EBxbmAH.png" alt="Figure_1.png" style="zoom: 50%;" /></p>
<p>在人脸检测之后，就可以根据结果中的人脸框信息对原图的人脸区域进行裁剪，同时为保证最后提取特征的图片向量维度一致，将裁取图片进行 <strong>resize</strong> 到 (100，100)。</p>
<p><img src="https://s2.loli.net/2022/05/19/3vGMJNwdRm7VqFk.png" alt="Figure_1.png" style="zoom:25%;" /></p>
<p>得到人脸区域之后，我们将该区域展平成向量，以便后续操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Draw_image_with_boxes</span>(<span class="params">data, result_list</span>):</span><br><span class="line">    plt.imshow(data)</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> result_list:</span><br><span class="line">        <span class="built_in">print</span>(result)</span><br><span class="line">        <span class="comment"># 得到人脸框的起始点坐标和宽高</span></span><br><span class="line">        x, y, width, height = result[<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">        rect = Rectangle((x, y), width, height, fill = <span class="literal">False</span>, color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        <span class="comment"># 画出人脸框</span></span><br><span class="line">        ax.add_patch(rect)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    Yale_path = []</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    faces = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> os.listdir(root) :</span><br><span class="line">        <span class="keyword">if</span> element != <span class="string">&#x27;Readme.txt&#x27;</span>:</span><br><span class="line">            Yale_path.append(os.path.join(root, element))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> Yale_path :</span><br><span class="line">        image = io.imread(path, as_gray = <span class="literal">True</span>)</span><br><span class="line">        X.append(image)</span><br><span class="line">        label = <span class="built_in">int</span>(os.path.split(path)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&quot;subject&quot;</span>, <span class="string">&quot;&quot;</span>)) - <span class="number">1</span></span><br><span class="line">        y.append(label)</span><br><span class="line"></span><br><span class="line">    detector = MTCNN()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img_src <span class="keyword">in</span> X :</span><br><span class="line">        <span class="comment"># 因为 mtcnn 输入的图片要求是 3 通道，而原始图是灰度图，因此对图像进行拓展</span></span><br><span class="line">        img = np.stack((img_src, img_src, img_src), axis = <span class="number">2</span>)</span><br><span class="line">        result = detector.detect_faces(img)</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># Draw_image_with_boxes(img, result)</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 依据检测结果中的人脸框信息对原图进行裁取，并 resize 到(100, 100)</span></span><br><span class="line">        <span class="comment"># 因为 mtcnn 是同时检测多个人脸，所以返回是一个列表，</span></span><br><span class="line">        <span class="comment"># 但因我们提供的图片只有一个人脸，则取巧</span></span><br><span class="line">        box = result[<span class="number">0</span>][<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">        <span class="comment"># 对原图进行裁取</span></span><br><span class="line">        img1 = img_src[box[<span class="number">1</span>] : box[<span class="number">1</span>] + box[<span class="number">3</span>], box[<span class="number">0</span>] : box[<span class="number">0</span>] + box[<span class="number">2</span>]]</span><br><span class="line">        image = Image.fromarray(img1)</span><br><span class="line">        image = image.resize((<span class="number">100</span>, <span class="number">100</span>))</span><br><span class="line">        face_array = np.asarray(image)</span><br><span class="line">        <span class="comment"># plt.imshow(face_array, vmax = 255, vmin = 0, cmap = &#x27;gray&#x27;)</span></span><br><span class="line">        <span class="comment"># plt.show()</span></span><br><span class="line">        faces.append(face_array.ravel())</span><br><span class="line"></span><br><span class="line">    faces = np.array(faces)</span><br><span class="line">    y = np.array(y)</span><br><span class="line">    <span class="built_in">print</span>(faces.shape)</span><br><span class="line">    <span class="keyword">return</span> faces, y</span><br></pre></td></tr></table></figure>
<h3 id="3-2-2-数据分组"><a href="#3-2-2-数据分组" class="headerlink" title="3.2.2    数据分组"></a>3.2.2    数据分组</h3><p>&emsp;&emsp;对于 Yale 数据集，我没有像 ORL 数据集那样分组，我直接取每个人的前 8 张图片作为预测集，取每个人的后 3 张图片作为待识别图片，也即训练集维度为 (120，10000)，待识别图片为 (45，10000)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line">    <span class="comment"># 取每个人的前 8 张图片作为预测集，取每个人的后 3 张图片作为待识别图片</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>) :</span><br><span class="line">        train_set.extend(X[i * <span class="number">11</span> : i * <span class="number">11</span> + <span class="number">8</span>])</span><br><span class="line">        train_target.extend(y[i * <span class="number">11</span> : i * <span class="number">11</span> + <span class="number">8</span>])</span><br><span class="line">        face_unrecognized_set.extend(X[i * <span class="number">11</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">11</span>])</span><br><span class="line">        face_unrecognized_target.extend(y[i * <span class="number">11</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">11</span>])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br></pre></td></tr></table></figure>
<h3 id="3-2-3-使用-PCA-进行特征提取"><a href="#3-2-3-使用-PCA-进行特征提取" class="headerlink" title="3.2.3    使用 PCA 进行特征提取"></a>3.2.3    使用 PCA 进行特征提取</h3><p>&emsp;&emsp;我们在 <a href="# 3.1.3    使用 PCA 进行特征提取"><strong>3.1.3    使用 PCA 进行特征提取</strong></a> 中通过保留原始数据的 95% 来探究合适的 $\boldsymbol{k}$ 值，对 Yale 数据集采用相同的方法得到保留原始数据的 95% 的 $\boldsymbol{k}$ 值为 46。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">46</span>)</span><br><span class="line">pca.fit(train_set)</span><br><span class="line">train_reduction = pca.transform(train_set)</span><br><span class="line">face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br></pre></td></tr></table></figure>
<h3 id="3-2-4-人脸识别及可视化"><a href="#3-2-4-人脸识别及可视化" class="headerlink" title="3.2.4    人脸识别及可视化"></a>3.2.4    人脸识别及可视化</h3><p>&emsp;&emsp;Yale 数据集的标签预测过程与 ORL 数据集的分组一一样，且人脸识别的 GUI 界面也与前面一样。<a href="# 3.1.4    人脸识别"><strong>3.1.4    人脸识别</strong></a>，<a href="# 3.1.5    人脸识别的 GUI 界面"><strong>3.1.5    人脸识别的 GUI 界面</strong></a>。要修改的代码只有一处。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = result.reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<h3 id="3-2-5-实验结果"><a href="#3-2-5-实验结果" class="headerlink" title="3.2.5    实验结果"></a>3.2.5    实验结果</h3><p>&emsp;&emsp;基于 PCA 算法构建的人脸识别系统对 Yale 数据集的识别正确率有 0.933，这是一个非常不错的正确率，因为 Yale 数据集的外界扰动十分大。识别效果如下：</p>
<p><img src="https://s2.loli.net/2022/05/19/eAz9hIPBoxL3SsM.png" alt="1652968049305.png" style="zoom: 50%;" /></p>
<p>如上图，一些光照变换很大、戴眼镜的人脸都能识别成，在右下角是一张识别错误的人脸，跟 ORL 数据集相比，PCA 对 Yale 数据集的鲁棒性会稍差一点。</p>
<h3 id="3-2-6-全部代码"><a href="#3-2-6-全部代码" class="headerlink" title="3.2.6    全部代码"></a>3.2.6    全部代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PCA <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageTk</span><br><span class="line"><span class="keyword">from</span> tkinter <span class="keyword">import</span> font</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> mtcnn.mtcnn <span class="keyword">import</span> MTCNN</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> Rectangle</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Draw_image_with_boxes</span>(<span class="params">data, result_list</span>):</span><br><span class="line">    plt.imshow(data)</span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> result_list:</span><br><span class="line">        <span class="built_in">print</span>(result)</span><br><span class="line">        <span class="comment"># 得到人脸框的起始点坐标和宽高</span></span><br><span class="line">        x, y, width, height = result[<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">        rect = Rectangle((x, y), width, height, fill = <span class="literal">False</span>, color = <span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">        <span class="comment"># 画出人脸框</span></span><br><span class="line">        ax.add_patch(rect)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    Yale_path = []</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    faces = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> os.listdir(root) :</span><br><span class="line">        <span class="keyword">if</span> element != <span class="string">&#x27;Readme.txt&#x27;</span>:</span><br><span class="line">            Yale_path.append(os.path.join(root, element))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> Yale_path :</span><br><span class="line">        image = io.imread(path, as_gray = <span class="literal">True</span>)</span><br><span class="line">        X.append(image)</span><br><span class="line">        label = <span class="built_in">int</span>(os.path.split(path)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&quot;subject&quot;</span>, <span class="string">&quot;&quot;</span>)) - <span class="number">1</span></span><br><span class="line">        y.append(label)</span><br><span class="line"></span><br><span class="line">    detector = MTCNN()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> img_src <span class="keyword">in</span> X :</span><br><span class="line">        <span class="comment"># 因为 mtcnn 输入的图片要求是 3 通道，而原始图是灰度图，因此对图像进行拓展</span></span><br><span class="line">        img = np.stack((img_src, img_src, img_src), axis = <span class="number">2</span>)</span><br><span class="line">        result = detector.detect_faces(img)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Draw_image_with_boxes(img, result)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 依据检测结果中的人脸框信息对原图进行裁取，并 resize 到(100, 100)</span></span><br><span class="line">        <span class="comment"># 因为 mtcnn 是同时检测多个人脸，所以返回是一个列表，</span></span><br><span class="line">        <span class="comment"># 但因我们提供的图片只有一个人脸，则取巧</span></span><br><span class="line">        box = result[<span class="number">0</span>][<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">        <span class="comment"># 对原图进行裁取</span></span><br><span class="line">        img1 = img_src[box[<span class="number">1</span>] : box[<span class="number">1</span>] + box[<span class="number">3</span>], box[<span class="number">0</span>] : box[<span class="number">0</span>] + box[<span class="number">2</span>]]</span><br><span class="line">        image = Image.fromarray(img1)</span><br><span class="line">        image = image.resize((<span class="number">100</span>, <span class="number">100</span>))</span><br><span class="line">        face_array = np.asarray(image)</span><br><span class="line">        <span class="comment"># plt.imshow(face_array, vmax = 255, vmin = 0, cmap = &#x27;gray&#x27;)</span></span><br><span class="line">        <span class="comment"># plt.show()</span></span><br><span class="line">        faces.append(face_array.ravel())</span><br><span class="line"></span><br><span class="line">    faces = np.array(faces)</span><br><span class="line">    y = np.array(y)</span><br><span class="line">    <span class="built_in">print</span>(faces.shape)</span><br><span class="line">    <span class="keyword">return</span> faces, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line">    <span class="comment"># 取每个人的前 8 张图片作为预测集，取每个人的后 3 张图片作为待识别图片</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">15</span>) :</span><br><span class="line">        train_set.extend(X[i * <span class="number">11</span> : i * <span class="number">11</span> + <span class="number">8</span>])</span><br><span class="line">        train_target.extend(y[i * <span class="number">11</span> : i * <span class="number">11</span> + <span class="number">8</span>])</span><br><span class="line">        face_unrecognized_set.extend(X[i * <span class="number">11</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">11</span>])</span><br><span class="line">        face_unrecognized_target.extend(y[i * <span class="number">11</span> + <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">11</span>])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, Y</span>) :</span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)) :</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis = <span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        labels.append(label // <span class="number">8</span>)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Face_GUI</span>(<span class="params">unrecognized, result</span>) :</span><br><span class="line">    img = unrecognized.reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    photo = ImageTk.PhotoImage(img)</span><br><span class="line"></span><br><span class="line">    label = Label(root, text = <span class="string">&quot;图片识别&quot;</span>, fg = <span class="string">&#x27;red&#x27;</span>, font = (<span class="string">&quot;华文行楷&quot;</span>, <span class="number">25</span>, font.BOLD))</span><br><span class="line">    label.place(relx = <span class="number">0.35</span>, rely = <span class="number">0.01</span>, relwidth = <span class="number">0.3</span>, relheight=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">    lb1 = Label(root, image = photo)</span><br><span class="line">    lb1.place(relx = <span class="number">0.1</span>, rely = <span class="number">0.25</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    label_context1 = Label(root, text = <span class="string">&quot;待识别图片:&quot;</span>, fg = <span class="string">&#x27;blue&#x27;</span>, </span><br><span class="line">                           						font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    label_context1.place(relx = <span class="number">0.1</span>, rely = <span class="number">0.15</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    btn = Button(root, text = <span class="string">&quot;开始识别&quot;</span>, command = <span class="keyword">lambda</span> : Match(result), </span><br><span class="line">                 								font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    btn.place(relx = <span class="number">0.35</span>, rely = <span class="number">0.65</span>, relwidth = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Match</span>(<span class="params">result</span>) :</span><br><span class="line">    img = result.reshape(<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    photo = ImageTk.PhotoImage(img)</span><br><span class="line"></span><br><span class="line">    lb2 = Label(root, image = photo)</span><br><span class="line">    lb2.place(relx = <span class="number">0.6</span>, rely = <span class="number">0.25</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">    label_context2 = Label(root, text = <span class="string">&quot;识别结果:&quot;</span>, fg = <span class="string">&#x27;blue&#x27;</span>, </span><br><span class="line">                           						font = (<span class="string">&quot;华文新魏&quot;</span>, <span class="number">15</span>, font.BOLD))</span><br><span class="line">    label_context2.place(relx = <span class="number">0.6</span>, rely = <span class="number">0.15</span>, relwidth = <span class="number">0.3</span>, relheight = <span class="number">0.1</span>)</span><br><span class="line">    root.mainloop()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    X, y = Data_Processing(<span class="string">&#x27;Yale&#x27;</span>)</span><br><span class="line">    train_set, train_target, face_unrecognized_set, \</span><br><span class="line">    				face_unrecognized_target = Data_Split(X, y)</span><br><span class="line">    <span class="comment"># print(train_set.shape, train_target.shape, face_unrecognized_set.shape, 															face_unrecognized_target.shape)</span></span><br><span class="line">    pca = PCA(n_components = <span class="number">46</span>)</span><br><span class="line">    pca.fit(train_set)</span><br><span class="line">    train_reduction = pca.transform(train_set)</span><br><span class="line">    face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br><span class="line">    labels, pred = Predict(train_reduction, face_unrecognized_reduction)</span><br><span class="line">    accuracy = (labels == face_unrecognized_target).<span class="built_in">sum</span>() / <span class="built_in">len</span>(face_unrecognized_target)</span><br><span class="line">    <span class="built_in">print</span>(accuracy)</span><br><span class="line">    <span class="built_in">print</span>(pred)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(pred)):</span><br><span class="line">        root = Tk()</span><br><span class="line">        root.geometry(<span class="string">&#x27;480x480&#x27;</span>)</span><br><span class="line">        root.title(<span class="string">&#x27;基于 PCA 的人脸识别系统&#x27;</span>)</span><br><span class="line">        unrecognized = face_unrecognized_set[i]</span><br><span class="line">        result = train_set[pred[i]]</span><br><span class="line">        Face_GUI(unrecognized, result)</span><br></pre></td></tr></table></figure>
<h2 id="3-3-UMIST-数据集"><a href="#3-3-UMIST-数据集" class="headerlink" title="3.3    UMIST 数据集"></a>3.3    UMIST 数据集</h2><p>&emsp;&emsp; 我这里的数据集是 Sheffield 数据集，是 UMIST 数据集的 <strong>“升级版”</strong>(也就是加了几张图片)，后面均以 UMIST 数据集代称。UMIST 人脸数据库由 20 个人(混合种族 / 性别 / 外貌)的 564 张图像组成(Sheffield 数据集为 575)。 每个人都显示在从侧面到正面视图的一系列姿势，每个人都在一个单独的目录中，标记为 1a、1b、…… 1t，并且图像在拍摄时连续编号。 这些文件都是 PGM 格式，大约 220 x 220 像素，256 位灰度。UMIST 数据集有两个版本，一个是原始图片，一个裁剪掉了一些背景区域，裁剪后地图片大小为 (112，92)，与 ORL 数据集一样大小。为实验方便，我所用的版本是裁剪过后的版本。下载地址为：<a href="http://eprints.lincoln.ac.uk/id/eprint/16081/"><strong>http://eprints.lincoln.ac.uk/id/eprint/16081/</strong></a></p>
<p>未裁剪的图像示例：</p>
<p><img src="https://s2.loli.net/2022/05/20/s9gKJwOAuvIlXNa.gif" alt="face2.gif" style="zoom: 50%;" /></p>
<p>裁剪图像示例：</p>
<p><img src="https://s2.loli.net/2022/05/20/uXFliTn684xyjbt.gif" alt="face1.gif"></p>
<p>说一个小插曲：我原本也就是想找 UMIST 数据集来做实验的，但我从前一天的晚上找到第二天早上都没找到，找到的都是一些处理好的文本数据，便放弃不找了。于是想着找 Bern 数据集来替代，却在找 Bern 数据集过程中阴差阳错地找到了 UMIST 数据集。果真我与你有缘！</p>
<h3 id="3-3-1-数据读取与数据处理"><a href="#3-3-1-数据读取与数据处理" class="headerlink" title="3.3.1    数据读取与数据处理"></a>3.3.1    数据读取与数据处理</h3><p>&emsp;&emsp;对 UMIST 数据集的读取方式与 ORL 数据集有些许差别，但是处理过程与其一样，返回 <a href="#3.1.1    数据读取与数据处理"><strong>3.1.1    数据读取与数据处理</strong></a>。最终得到的数据的二维矩阵大小为 (575, 10304)，标签为 (575，)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    path_files = os.listdir(root)</span><br><span class="line">    <span class="keyword">for</span> idx, path_file <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_files) :</span><br><span class="line">        path_images = os.listdir(os.path.join(root, path_file, <span class="string">&#x27;face&#x27;</span>))</span><br><span class="line">        <span class="keyword">for</span> path_image <span class="keyword">in</span> path_images :</span><br><span class="line">            path = os.path.join(root, path_file, <span class="string">&#x27;face&#x27;</span>, path_image)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img)</span><br><span class="line">            X.append(img.ravel())</span><br><span class="line">            y.append(idx)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<h3 id="3-3-2-数据分组"><a href="#3-3-2-数据分组" class="headerlink" title="3.3.2    数据分组"></a>3.3.2    数据分组</h3><p>&emsp;&emsp;对于 UMIST 数据集，我取每个人的前 5 张图片作为待识别图片，每个人的其余图片为作为训练集。UMIST 数据集与 ORL、Yale 数据集都不一样，因为它每个的图片数量不一样，意味着不能按照常规方法去分割数据。这里我维护了一个 <strong>index</strong> 列表，里面存的是每个人的第一张图片的下标，index 列表从第二个元素开始每一个元素减 1 即可得到前面那个人的最后一张图片的下标。然后依据 index 列表对数据进行裁剪，最终得到的待识别图片的维度是 (100，10304)，训练集图片为 (475，10304)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Split</span>(<span class="params">X, y</span>) :</span><br><span class="line">    train_set = []</span><br><span class="line">    train_target = []</span><br><span class="line">    face_unrecognized_set = []</span><br><span class="line">    face_unrecognized_target = []</span><br><span class="line"></span><br><span class="line">    index = []</span><br><span class="line">    index.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(y)) :</span><br><span class="line">        <span class="keyword">if</span> y[idx] != y[idx - <span class="number">1</span>] :</span><br><span class="line">            index.append(idx)</span><br><span class="line">    index.append(<span class="built_in">len</span>(y))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取每个人的后 5 张图片作为待识别图片，其余图片作为训练集</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(index) - <span class="number">1</span>) :</span><br><span class="line">        face_unrecognized_set.extend(X[index[i] : index[i] + <span class="number">5</span>])</span><br><span class="line">        face_unrecognized_target.extend(y[index[i]: index[i] + <span class="number">5</span>])</span><br><span class="line">        train_set.extend(X[index[i] + <span class="number">5</span> : index[i + <span class="number">1</span>]])</span><br><span class="line">        train_target.extend(y[index[i] + <span class="number">5</span> : index[i + <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    train_set = np.array(train_set)</span><br><span class="line">    train_target = np.array(train_target)</span><br><span class="line">    face_unrecognized_set = np.array(face_unrecognized_set)</span><br><span class="line">    face_unrecognized_target = np.array(face_unrecognized_target)</span><br><span class="line">    <span class="keyword">return</span> train_set, train_target, \</span><br><span class="line">           face_unrecognized_set, face_unrecognized_target</span><br></pre></td></tr></table></figure>
<h3 id="3-3-3-使用-PCA-进行特征提取"><a href="#3-3-3-使用-PCA-进行特征提取" class="headerlink" title="3.3.3    使用 PCA 进行特征提取"></a>3.3.3    使用 PCA 进行特征提取</h3><p>&emsp;&emsp;同样，我采取与前面相同的方法确定了保留原始数据 95% 信息的 $\boldsymbol{k}$ 值为 97。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pca = PCA(n_components = <span class="number">97</span>)</span><br><span class="line">pca.fit(train_set)</span><br><span class="line">train_reduction = pca.transform(train_set)</span><br><span class="line">face_unrecognized_reduction = pca.transform(face_unrecognized_set)</span><br><span class="line">labels, pred = Predict(train_reduction, face_unrecognized_reduction)</span><br></pre></td></tr></table></figure>
<h3 id="3-3-4-人脸识别及可视化"><a href="#3-3-4-人脸识别及可视化" class="headerlink" title="3.3.4    人脸识别及可视化"></a>3.3.4    人脸识别及可视化</h3><p>&emsp;&emsp;对于 UMIST 数据集，人脸识别和数据分组一样，都有一个问题就是每个人的照片数量不一样，因此在预测标签时不能简单地进行整除等操作。借鉴数据分组时的思想，我同样维护了一个 <strong>index</strong> 列表，里面存的是训练集中的每个人的第一张图片的下标，index 列表从第二个元素开始每一个元素减 1 即可得到前面那个人的最后一张图片的下标。在得到预测下标之后，用其与 index 中的元素相比较便可确定标签，更详细地比较方法参考代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Predict</span>(<span class="params">X, y, Y</span>):</span><br><span class="line">    <span class="comment"># y 表示训练集的标签</span></span><br><span class="line">    labels = []</span><br><span class="line">    pred = []</span><br><span class="line"></span><br><span class="line">    index = []</span><br><span class="line">    index.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(y)):</span><br><span class="line">        <span class="keyword">if</span> y[idx] != y[idx - <span class="number">1</span>]:</span><br><span class="line">            index.append(idx)</span><br><span class="line">    index.append(<span class="built_in">len</span>(y))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(Y)):</span><br><span class="line">        distance = np.linalg.norm(X - Y[i], axis=<span class="number">1</span>)</span><br><span class="line">        label = np.argmin(distance)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(index) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> label &gt;= index[j] <span class="keyword">and</span> label &lt; index[j + <span class="number">1</span>]:</span><br><span class="line">                labels.append(j)</span><br><span class="line">        pred.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(labels), np.array(pred)</span><br></pre></td></tr></table></figure>
<p>其次就是人脸识别的 GUI 页面，UMIST 数据集的 GUI 过程与 ORL 数据集一模一样，请参考前面的代码。</p>
<h3 id="3-3-5-实验结果"><a href="#3-3-5-实验结果" class="headerlink" title="3.3.5    实验结果"></a>3.3.5    实验结果</h3><p>&emsp;&emsp;基于 PCA 算法构建的人脸识别系统对 UMIST 数据集的识别正确率只有 0.88，在三个数据集中最差，其原因可能是 UMIST 数据集中的人的姿态变化幅度较大，如每个人的照片都是从侧面到正面进行拍摄的；其次可能是我对数据的分组不够好，因为前 5 张图片的侧脸角度是最大的。识别效果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/QfqCo8hGndFTKsY.png" alt="1653017304521.png" style="zoom:50%;" /></p>
<p>如上图，可以看到前 3 张待识别图片的侧面的角度非常大，但是该系统还是能够正确识别出来，如果从这个角度来看 0.88 的正确率也不算很差。而在右下角的这张待识别图片就识别错误了。</p>
<h3 id="3-3-6-全部代码"><a href="#3-3-6-全部代码" class="headerlink" title="3.3.6    全部代码"></a>3.3.6    全部代码</h3><p>&emsp;&emsp;限于篇幅原因，这里不张贴全部代码了，可以参考前面 ORL 和 Yale 数据集的代码，且关于一些需要改动的地方在前面几点也已解释清楚。</p>
<p>&emsp;&emsp;至此，我们从 0 开始构建 PCA 算法，到构建基于 PCA 的人脸识别系统对三种不同的数据集进行人脸识别的的工作全部完成。当然，对于 PCA 算法我们依然有许多值得探究的地方，如 $\boldsymbol{k}$ 值的选取，如若以后有时间，也可多花时间进行研究。</p>
<h1 id="4-基于-MediaPipe-的姿态分析"><a href="#4-基于-MediaPipe-的姿态分析" class="headerlink" title="4    基于 MediaPipe 的姿态分析"></a>4    基于 MediaPipe 的姿态分析</h1><p>&emsp;&emsp;<a href="https://google.github.io/mediapipe/"><strong>MediaPipe</strong></a> 是一个用于构建机器学习管道的框架，用于处理视频、音频等时间序列数据。这个跨平台框架适用于桌面 / 服务器、Android、iOS 和嵌入式设备，如 Raspberry Pi 和 Jetson Nano，由谷歌公司开发。自 2012 年起，谷歌在内部的多个产品和服务中使用了它。它最初是为了实时分析 YouTube 上的视频和音频而开发的。渐渐地，它被整合到更多的产品中，比如谷歌镜头的目标检测、增强现实广告等。</p>
<h2 id="4-1-MediaPipe-Solutions"><a href="#4-1-MediaPipe-Solutions" class="headerlink" title="4.1    MediaPipe Solutions"></a>4.1    MediaPipe Solutions</h2><p>&emsp;&emsp;Solutions 是基于特定的预训练 TensorFlow 或 TFLite 模型的开源预构建示例。MediaPipe Solutions 构建在框架之上。目前，它提供了 16 个 Solutions，如下所示：</p>
<ul>
<li><a href="https://google.github.io/mediapipe/solutions/face_detection">人脸检测</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/face_mesh">Face Mesh</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/iris">虹膜</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/hands">手</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/pose">姿态</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/holistic">人体</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/selfie_segmentation">人物分割</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/hair_segmentation">头发分割</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/object_detection">目标检测</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/box_tracking">Box Tracking</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/instant_motion_tracking">Instant Motion Tracking</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/objectron">3D 目标检测</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/knift">特征匹配</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/autoflip">AutoFlip</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/media_sequence">MediaSequence</a></li>
<li><a href="https://google.github.io/mediapipe/solutions/youtube_8m">YouTube-8M</a></li>
</ul>
<p>我将使用其中的姿态检测对前面三种数据集进行进行简单姿态检测。下面是 Pose Solutions 的简单的介绍。</p>
<h3 id="4-1-1-ML-管道"><a href="#4-1-1-ML-管道" class="headerlink" title="4.1.1    ML 管道"></a>4.1.1    ML 管道</h3><p>&emsp;&emsp;Pose Solutions 利用两步检测器 - 跟踪器 ML 管道。使用检测器，管道首先在帧内定位人 / 姿势感兴趣区域 (ROI)。跟踪器随后裁剪帧 ROI 作为输入来预测 ROI 内的姿势标志和分割掩码。请注意，对于视频用例，仅在需要时调用检测器，即在第一帧以及当跟踪器无法再识别前一帧中存在的身体姿势时。对于其他帧，管道只是从前一帧的姿势地标中导出 ROI。</p>
<h3 id="4-1-2-姿态估计质量"><a href="#4-1-2-姿态估计质量" class="headerlink" title="4.1.2    姿态估计质量"></a>4.1.2    姿态估计质量</h3><p>&emsp;&emsp;使用了三个不同的验证数据集，代表不同的垂直领域：瑜伽、舞蹈。每张图像仅包含距离摄像机 2-4 米的一个人。对 COCO 拓扑中的 17 个关键点进行评估。</p>
<p><img src="https://img-blog.csdnimg.cn/b9f891364dce4b34b7c5cc92eeddb91e.png#pic_center" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/5c69273a82b9498fa2ee5e5687e83144.png#pic_center" alt="img" style="zoom:67%;" /></p>
<p>Pose Solutions 的模型的设计基于实时感知用例，所以它们都能在大多数现代设备上实时工作。</p>
<h3 id="4-1-3-人-姿势检测模型-BlazePose-检测器"><a href="#4-1-3-人-姿势检测模型-BlazePose-检测器" class="headerlink" title="4.1.3    人 / 姿势检测模型 (BlazePose 检测器)"></a>4.1.3    人 / 姿势检测模型 (BlazePose 检测器)</h3><p>&emsp;&emsp;该检测器的设计思想来自于轻量级 BlazeFace 模型，在 MediaPipe 人脸检测中用作人员检测器的代理。它明确地预测了两个额外的虚拟关键点，这些虚拟关键点将人体中心、旋转和比例牢牢地描述为一个圆圈。受列奥纳多的维特鲁威人的启发，我们预测了一个人臀部的中点、外接整个人的圆的半径以及连接肩部和臀部中点的线的倾斜角。</p>
<p><img src="https://img-blog.csdnimg.cn/fe51821134814cc5996538ab3fd303c8.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="4-1-4-Pose-Landmark-模型-BlazePose-GHUM-3D"><a href="#4-1-4-Pose-Landmark-模型-BlazePose-GHUM-3D" class="headerlink" title="4.1.4    Pose Landmark 模型 (BlazePose GHUM 3D)"></a>4.1.4    Pose Landmark 模型 (BlazePose GHUM 3D)</h3><p>&emsp;&emsp;Pose Solutions 中的地标模型预测了 33 个地标的位置，如下：</p>
<p><img src="https://img-blog.csdnimg.cn/b2ff281d361544b8ac5eefa6f2efe04b.png#pic_center" alt="img"></p>
<h3 id="4-1-5-API"><a href="#4-1-5-API" class="headerlink" title="4.1.5    API"></a>4.1.5    API</h3><p>输入参数：</p>
<ul>
<li>STATIC_IMAGE_MODE：如果设置为 false，该解决方案会将输入图像视为视频流。它将尝试在第一张图像中检测最突出的人，并在成功检测后进一步定位姿势地标。在随后的图像中，它只是简单地跟踪那些地标，而不会调用另一个检测，直到它失去跟踪，以减少计算和延迟。如果设置为 true，则人员检测会运行每个输入图像，非常适合处理一批静态的、可能不相关的图像。默认为 false；</li>
<li>MODEL_COMPLEXITY：姿势地标模型的复杂度：0、1 或 2。地标准确度和推理延迟通常随着模型复杂度的增加而增加。默认为 1；</li>
<li>SMOOTH_LANDMARKS：如果设置为 true，解决方案过滤不同的输入图像上的姿势地标以减少抖动，但如果 static_image_mode 也设置为 true 则忽略。默认为 true；</li>
<li>UPPER_BODY_ONLY：是要追踪 33 个地标的全部姿势地标还是只有 25 个上半身的姿势地标；</li>
<li>ENABLE_SEGMENTATION：如果设置为 true，除了姿势地标之外，该解决方案还会生成分割掩码。默认为 false；</li>
<li>SMOOTH_SEGMENTATION：如果设置为 true，解决方案过滤不同的输入图像上的分割掩码以减少抖动，但如果 enable_segmentation 设置为 false 或者 static_image_mode 设置为 true 则忽略。默认为 true；</li>
<li>MIN_DETECTION_CONFIDENCE：来自人员检测模型的最小置信值 ([0.0, 1.0])，用于将检测视为成功。默认为 0.5；</li>
<li>MIN_TRACKING_CONFIDENCE：来自地标跟踪模型的最小置信值 ([0.0, 1.0])，用于将被视为成功跟踪的姿势地标，否则将在下一个输入图像上自动调用人物检测。将其设置为更高的值可以提高解决方案的稳健性，但代价是更高的延迟。如果 static_image_mode 为 true，则忽略，人员检测在每个图像上运行。默认为 0.5。</li>
</ul>
<p>输出：</p>
<ul>
<li>具有 “pose_landmarks” 字段的 NamedTuple 对象，其中包含检测到的最突出人物的姿势标志。</li>
</ul>
<p>参考：<a href="https://google.github.io/mediapipe/solutions/pose"><strong>https://google.github.io/mediapipe/solutions/pose</strong></a></p>
<h3 id="4-1-6-示例"><a href="#4-1-6-示例" class="headerlink" title="4.1.6    示例"></a>4.1.6    示例</h3><p>原图：</p>
<p><img src="https://s2.loli.net/2022/05/21/KhdyRUGOxXbQT4I.png" alt="girl.png" style="zoom:50%;" /></p>
<p>检测后：</p>
<p><img src="https://s2.loli.net/2022/05/21/ZKIA3FSzvopPYyE.png" alt="girl_pose.png" style="zoom: 50%;" /></p>
<p>注意为了显示自拍的效果，我将图片进行了水平翻转。</p>
<h2 id="4-2-ORL-数据集"><a href="#4-2-ORL-数据集" class="headerlink" title="4.2    ORL 数据集"></a>4.2    ORL 数据集</h2><p>&emsp;&emsp;因为本次的姿态估计模型我是直接调用已经训练好的模型，因此只需要将 ORL 数据集当作测试集进行预测即可。</p>
<h3 id="4-2-1-数据读取与处理"><a href="#4-2-1-数据读取与处理" class="headerlink" title="4.2.1    数据读取与处理"></a>4.2.1    数据读取与处理</h3><p>&emsp;&emsp;因为我们只需要数据集，因此不需要数据的标签与分割，同时因模型要求输入要是图片，则不需要对图片进行展平。此外，MediaPipe Pose 模型要求输入的图片是 <strong>RGB</strong> 类型，但是我们前面三个数据集的所有图片都是灰度图，则在检测前我们要将灰度图转成 RGB 图，同时不能改变图片的性质。怎么改呢？其实很简单：只需将该灰度图在通道维度拼接 3 次即可。此时，红色、绿色和蓝色的分量是相同的，因此图像仍然是 “灰度图”。</p>
<ul>
<li><strong>shape：(671, 600)</strong></li>
</ul>
<p><img src="https://s2.loli.net/2022/05/21/YknZ5BqiUgu9emH.png" alt="girl2.png" style="zoom:50%;" /></p>
<ul>
<li><strong>shape：(671, 600, 3)</strong></li>
</ul>
<p><img src="https://s2.loli.net/2022/05/21/mXRtE9GuBdiFbHf.png" alt="girl3.png" style="zoom:50%;" /></p>
<p>其实在技巧在前面使用 <strong>mtcnn</strong> 进行人脸检测时就使用过这个技巧，只是当时没有具体说明。我们在后续对 Yale 和 UMIST 数据集的姿态预测前会进行同样的处理，在此说明。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Get_imgList</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img)</span><br><span class="line">            <span class="comment"># 将灰度图转成 RGB 图</span></span><br><span class="line">            image = np.stack((img, img, img), axis=<span class="number">2</span>)</span><br><span class="line">            X.append(image)</span><br><span class="line">            <span class="built_in">print</span>(image.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure>
<h3 id="4-2-2-姿态估计"><a href="#4-2-2-姿态估计" class="headerlink" title="4.2.2    姿态估计"></a>4.2.2    姿态估计</h3><p>&emsp;将第一和第二个人的姿态估计结果由如下代码进行拼接。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">img_path = [<span class="string">&#x27;ORL_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">                                <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>)]</span><br><span class="line">img = []</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> img_path :</span><br><span class="line">    image = cv2.imread(path)</span><br><span class="line">    img.append(image)</span><br><span class="line">img_1 = np.concatenate((img[<span class="number">0</span> : <span class="number">5</span>]), axis = <span class="number">1</span>)</span><br><span class="line">img_2 = np.concatenate((img[<span class="number">5</span> : <span class="number">10</span>]), axis = <span class="number">1</span>)</span><br><span class="line">img_3 = np.concatenate((img[<span class="number">10</span> : <span class="number">15</span>]), axis = <span class="number">1</span>)</span><br><span class="line">img_4 = np.concatenate((img[<span class="number">15</span> : <span class="number">20</span>]), axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">img_5 = np.concatenate((img_1, img_2), axis = <span class="number">0</span>)</span><br><span class="line">img_6 = np.concatenate((img_3, img_4), axis = <span class="number">0</span>)</span><br><span class="line">cv2.imwrite(<span class="string">&#x27;people_1.png&#x27;</span>, img_5)</span><br><span class="line">cv2.imwrite(<span class="string">&#x27;people_2.png&#x27;</span>, img_6)</span><br></pre></td></tr></table></figure>
<p>所得结果如下：</p>
<p>第一个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/a7FzbHgidoVXJqc.png" alt="people_1.png"></p>
<p>第二个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/WvjkfipygLDnwsx.png" alt="people_2.png"></p>
<h3 id="4-2-3-全部代码"><a href="#4-2-3-全部代码" class="headerlink" title="4.2.3    全部代码"></a>4.2.3    全部代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">mp_drawing = mp.solutions.drawing_utils</span><br><span class="line">mp_drawing_styles = mp.solutions.drawing_styles</span><br><span class="line">mp_pose = mp.solutions.pose</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Get_imgList</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img)</span><br><span class="line">            <span class="comment"># 将灰度图转成 RGB 图</span></span><br><span class="line">            image = np.stack((img, img, img), axis=<span class="number">2</span>)</span><br><span class="line">            X.append(image)</span><br><span class="line">            <span class="built_in">print</span>(image.shape)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Pose</span>(<span class="params">imgList</span>):</span><br><span class="line">    <span class="keyword">with</span> mp_pose.Pose(</span><br><span class="line">            min_detection_confidence = <span class="number">0.5</span>,</span><br><span class="line">            min_tracking_confidence = <span class="number">0.5</span>) <span class="keyword">as</span> pose:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgList) :</span><br><span class="line">            <span class="comment"># 为了提高性能，不需要图像标记</span></span><br><span class="line">            image.flags.writeable = <span class="literal">False</span></span><br><span class="line">            results = pose.process(image)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在图上绘制姿态点</span></span><br><span class="line">            image.flags.writeable = <span class="literal">True</span></span><br><span class="line">            mp_drawing.draw_landmarks(</span><br><span class="line">                image,</span><br><span class="line">                results.pose_landmarks,</span><br><span class="line">                mp_pose.POSE_CONNECTIONS,</span><br><span class="line">                landmark_drawing_spec = \</span><br><span class="line">                mp_drawing_styles.get_default_pose_landmarks_style())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 水平翻转图片可达到显示自拍效果</span></span><br><span class="line">            cv2.imshow(<span class="string">&#x27;MediaPipe Pose&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> idx &lt; <span class="number">20</span>:</span><br><span class="line">                cv2.imwrite(<span class="string">&#x27;ORL_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span>,</span><br><span class="line">                            cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">imgList = Get_imgList(<span class="string">&#x27;ORL&#x27;</span>)</span><br><span class="line">Pose(imgList)</span><br></pre></td></tr></table></figure>
<h2 id="4-3-Yale-数据集"><a href="#4-3-Yale-数据集" class="headerlink" title="4.3    Yale 数据集"></a>4.3    Yale 数据集</h2><p>&emsp;&emsp;对 Yale 数据集的姿态估计流程和 ORL 数据集一样，同时不用对 Yale 数据集进行人脸检测。对前面两个人的姿态估计效果如下：</p>
<p>第一个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/rqFL1VSwfOvTsUh.png" alt="people_3.png" style="zoom: 50%;" /></p>
<p>第二个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/TOR9sYqIkmcPtnp.png" alt="people_4.png" style="zoom:50%;" /></p>
<p>全部代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line">mp_drawing = mp.solutions.drawing_utils</span><br><span class="line">mp_drawing_styles = mp.solutions.drawing_styles</span><br><span class="line">mp_pose = mp.solutions.pose</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Image_concatenate</span>() :</span><br><span class="line">    img_path = [<span class="string">&#x27;Yale_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">                <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">22</span>)]</span><br><span class="line">    img = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, path <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_path):</span><br><span class="line">        image = cv2.imread(path)</span><br><span class="line">        img.append(image)</span><br><span class="line">        <span class="keyword">if</span> idx == <span class="number">10</span> <span class="keyword">or</span> idx == <span class="number">21</span>:</span><br><span class="line">            noise = np.full(image.shape, <span class="number">255</span>).astype(np.uint8)</span><br><span class="line">            <span class="built_in">print</span>(noise.shape, noise.dtype)</span><br><span class="line">            img.append(noise)</span><br><span class="line"></span><br><span class="line">    img_1 = np.concatenate((img[<span class="number">0</span>: <span class="number">6</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_2 = np.concatenate((img[<span class="number">6</span>: <span class="number">12</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_3 = np.concatenate((img[<span class="number">12</span>: <span class="number">18</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_4 = np.concatenate((img[<span class="number">18</span>: <span class="number">24</span>]), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    img_5 = np.concatenate((img_1, img_2), axis=<span class="number">0</span>)</span><br><span class="line">    img_6 = np.concatenate((img_3, img_4), axis=<span class="number">0</span>)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;people_1.png&#x27;</span>, img_5)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;people_1.png&#x27;</span>, img_6)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Get_imgList</span>(<span class="params">root</span>) :</span><br><span class="line">    Yale_path = []</span><br><span class="line">    X = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> os.listdir(root):</span><br><span class="line">        <span class="keyword">if</span> element != <span class="string">&#x27;Readme.txt&#x27;</span>:</span><br><span class="line">            Yale_path.append(os.path.join(root, element))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> Yale_path:</span><br><span class="line">        img = io.imread(path, as_gray=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(img.shape)</span><br><span class="line">        image = np.stack((img, img, img), axis=<span class="number">2</span>)</span><br><span class="line">        X.append(image)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Pose</span>(<span class="params">imgList</span>):</span><br><span class="line">    <span class="keyword">with</span> mp_pose.Pose(</span><br><span class="line">            min_detection_confidence = <span class="number">0.5</span>,</span><br><span class="line">            min_tracking_confidence = <span class="number">0.5</span>) <span class="keyword">as</span> pose:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgList) :</span><br><span class="line">            <span class="comment"># 为了提高性能，不需要图像标记</span></span><br><span class="line">            image.flags.writeable = <span class="literal">False</span></span><br><span class="line">            results = pose.process(image)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在图上绘制姿态点</span></span><br><span class="line">            image.flags.writeable = <span class="literal">True</span></span><br><span class="line">            mp_drawing.draw_landmarks(</span><br><span class="line">                image,</span><br><span class="line">                results.pose_landmarks,</span><br><span class="line">                mp_pose.POSE_CONNECTIONS,</span><br><span class="line">                landmark_drawing_spec = \</span><br><span class="line">                mp_drawing_styles.get_default_pose_landmarks_style())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 水平翻转图片可达到显示自拍效果</span></span><br><span class="line">            cv2.imshow(<span class="string">&#x27;MediaPipe Pose&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> idx &lt; <span class="number">22</span>:</span><br><span class="line">                cv2.imwrite(<span class="string">&#x27;Yale_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span>,</span><br><span class="line">                            cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">imgList = Get_imgList(<span class="string">&#x27;Yale&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(imgList))</span><br><span class="line">Pose(imgList)</span><br></pre></td></tr></table></figure>
<h2 id="4-4-UMIST-数据集"><a href="#4-4-UMIST-数据集" class="headerlink" title="4.4    UMIST 数据集"></a>4.4    UMIST 数据集</h2><p>&emsp;&emsp;因为 UMIST 中的图像是由人的侧面到正面进行拍摄的，因此我截取了第一和第二个人中间的二十张图片进行姿态估计的结果展示如下：</p>
<p>第一个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/7SAPQtwZ1HJDdWq.png" alt="people_5.png" style="zoom: 80%;" /></p>
<p>第二个人：</p>
<p><img src="https://s2.loli.net/2022/05/21/hsgao7wQbFTD6f2.png" alt="people_6.png" style="zoom:80%;" /></p>
<p>全部代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">mp_drawing = mp.solutions.drawing_utils</span><br><span class="line">mp_drawing_styles = mp.solutions.drawing_styles</span><br><span class="line">mp_pose = mp.solutions.pose</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Image_concatenate</span>() :</span><br><span class="line">    img_path = [<span class="string">&#x27;UMIST_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span>) + <span class="string">&#x27;.png&#x27;</span></span><br><span class="line">                <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>)]</span><br><span class="line">    img = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> idx, path <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_path):</span><br><span class="line">        image = cv2.imread(path)</span><br><span class="line">        img.append(image)</span><br><span class="line"></span><br><span class="line">    img_1 = np.concatenate((img[<span class="number">0</span>: <span class="number">5</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_2 = np.concatenate((img[<span class="number">5</span>: <span class="number">10</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_3 = np.concatenate((img[<span class="number">10</span>: <span class="number">15</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_4 = np.concatenate((img[<span class="number">15</span>: <span class="number">20</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_5 = np.concatenate((img[<span class="number">20</span>: <span class="number">25</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_6 = np.concatenate((img[<span class="number">25</span>: <span class="number">30</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_7 = np.concatenate((img[<span class="number">30</span>: <span class="number">35</span>]), axis=<span class="number">1</span>)</span><br><span class="line">    img_8 = np.concatenate((img[<span class="number">35</span>: <span class="number">40</span>]), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    img_9 = np.concatenate((img_1, img_2, img_3, img_4), axis=<span class="number">0</span>)</span><br><span class="line">    img_10 = np.concatenate((img_5, img_6, img_7, img_8), axis=<span class="number">0</span>)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;people_5.png&#x27;</span>, img_9)</span><br><span class="line">    cv2.imwrite(<span class="string">&#x27;people_6.png&#x27;</span>, img_10)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Get_imgList</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    path_files = os.listdir(root)</span><br><span class="line">    <span class="keyword">for</span> idx, path_file <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_files):</span><br><span class="line">        path_images = os.listdir(os.path.join(root, path_file, <span class="string">&#x27;face&#x27;</span>))</span><br><span class="line">        <span class="keyword">for</span> path_image <span class="keyword">in</span> path_images:</span><br><span class="line">            path = os.path.join(root, path_file, <span class="string">&#x27;face&#x27;</span>, path_image)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img)</span><br><span class="line">            <span class="comment"># 将灰度图转成 RGB 图</span></span><br><span class="line">            image = np.stack((img, img, img), axis=<span class="number">2</span>)</span><br><span class="line">            X.append(image)</span><br><span class="line">    X = np.array(X)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Pose</span>(<span class="params">imgList</span>):</span><br><span class="line">    <span class="keyword">with</span> mp_pose.Pose(</span><br><span class="line">            min_detection_confidence = <span class="number">0.5</span>,</span><br><span class="line">            min_tracking_confidence = <span class="number">0.5</span>) <span class="keyword">as</span> pose:</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgList) :</span><br><span class="line">            <span class="comment"># 为了提高性能，不需要图像标记</span></span><br><span class="line">            image.flags.writeable = <span class="literal">False</span></span><br><span class="line">            results = pose.process(image)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在图上绘制姿态点</span></span><br><span class="line">            image.flags.writeable = <span class="literal">True</span></span><br><span class="line">            mp_drawing.draw_landmarks(</span><br><span class="line">                image,</span><br><span class="line">                results.pose_landmarks,</span><br><span class="line">                mp_pose.POSE_CONNECTIONS,</span><br><span class="line">                landmark_drawing_spec = \</span><br><span class="line">                mp_drawing_styles.get_default_pose_landmarks_style())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 水平翻转图片可达到显示自拍效果</span></span><br><span class="line">            cv2.imshow(<span class="string">&#x27;MediaPipe Pose&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="number">10</span> &lt;= idx &lt; <span class="number">30</span> :</span><br><span class="line">                cv2.imwrite(<span class="string">&#x27;UMIST_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span> - <span class="number">10</span>) + <span class="string">&#x27;.png&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="number">48</span> &lt;= idx &lt; <span class="number">68</span> :</span><br><span class="line">                cv2.imwrite(<span class="string">&#x27;UMIST_Poses/pose_&#x27;</span> + <span class="built_in">str</span>(idx + <span class="number">1</span> - <span class="number">28</span>) + <span class="string">&#x27;.png&#x27;</span>, cv2.flip(image, <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="number">27</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line">imgList = Get_imgList(<span class="string">&#x27;UMIST&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(imgList))</span><br><span class="line">Pose(imgList)</span><br></pre></td></tr></table></figure>
<h2 id="4-5-结果分析"><a href="#4-5-结果分析" class="headerlink" title="4.5    结果分析"></a>4.5    结果分析</h2><p>&emsp;&emsp;经过对三个数据集的中人的姿态估计，我们能够得到人脸关键部位点的位置，如左右眼角，左右嘴角，鼻子等，而根据这些关键特征点的分布我们可以对该人的形态或者神态进行进一步的预测。比如说，当眼睛那一排特征点的分布是水平的，说明这个人正处于一种较为平和、中立的状态，如果分布波动很大，则说明这个人此时正处于一种较为亢奋的状态，表现出愤怒、开心等表情；当特征点之间的距离很近，则对于摄像机而言这个人表现为侧脸；再者，当两个嘴角点之间的距离较大，即这个人的的嘴巴张的很大，我们可以觉得这个人是在开心大笑……等等。</p>
<p>&emsp;&emsp;综上，姿态分析对于视觉领域来说十分重要，我们可以利用姿态进行运动追踪、表情分析、医学诊断等等。</p>
<h1 id="5-基于-KNN-的人脸识别"><a href="#5-基于-KNN-的人脸识别" class="headerlink" title="5    基于 KNN 的人脸识别"></a>5    基于 KNN 的人脸识别</h1><p>&emsp;&emsp;前面我们通过构建 PCA 降维算法分别对 ORL、Yale 和 UMIST 三种不同的数据集进行了人脸识别，且识别精度分别在 0.95、0.93 和 0.88。而在下面中，我使用了另一种传统机器学习算法——KNN 再次对上述三种数据集进行人脸识别。</p>
<h2 id="5-1-KNN"><a href="#5-1-KNN" class="headerlink" title="5.1    KNN"></a>5.1    KNN</h2><p>&emsp;&emsp;<strong>KNN</strong> (K-Nearest Neighbor，K邻近算法)的基本思想是：给定一个训练数据集，对新输入的样本，在训练数据集中找到与该样本最邻近的 k 个实例(也就是所谓的 k 个邻居)，这 k 个实例中的多数属于某个类别，就把输入样本划分到该类别中。k 近邻算法通常又可以分为分类算法和回归算法：</p>
<ul>
<li>分类算法中采用多数表决法，就是选择 k 个样本中出现最多的类别标记作为预测结果；</li>
</ul>
<p><img src="https://s2.loli.net/2022/05/20/U2avBNKTs9LjDe3.png" alt="捕获.PNG"></p>
<ul>
<li>回归算法中采用平均法，将 k 个样本实际输出标记的平均值或加权平均值作为预测结果。</li>
</ul>
<p>而人脸识别本质上也是一个多分类问题，因此可以使用 KNN 来进行人脸识别。</p>
<h2 id="5-2-ORL-数据集"><a href="#5-2-ORL-数据集" class="headerlink" title="5.2    ORL 数据集"></a>5.2    ORL 数据集</h2><p>&emsp;&emsp;首先是数据的读取与处理，KNN 接受的数据输入与 PCA 算法是一样的，即二维矩阵 (m，n)，m 为样本数，n 为特征向量，因此数据处理与前面完全一样。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    path_list = [<span class="string">&#x27;s&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">41</span>)]</span><br><span class="line">    <span class="keyword">for</span> idx, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(path_list) :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>) :</span><br><span class="line">            path = os.path.join(root, s, <span class="built_in">str</span>(i) + <span class="string">&#x27;.pgm&#x27;</span>)</span><br><span class="line">            img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">            img = np.array(img).ravel()</span><br><span class="line">            X.append(img)</span><br><span class="line">        y.extend([idx] * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<p>对于数据分组，我使用了 <strong>sklearn</strong> 库中的 <strong>train_test_split</strong> 函数，将数据划分成 <strong>2 : 8</strong>，其中训练集为 8，测试集为 2，同时将数据打乱。我还探究了不同 k 值对模型性能的影响。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Draw_precision</span>(<span class="params">scores</span>) :</span><br><span class="line">    plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>), scores, <span class="string">&#x27;o--&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;$n\_neighbors$&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;$precision$&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>), scores):</span><br><span class="line">        plt.text(x - <span class="number">0.18</span>, y - <span class="number">0.1</span>, <span class="string">f&#x27;$<span class="subst">&#123;y&#125;</span>$&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.title(<span class="string">f&#x27;$precision\ of\ different\ neighors$&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.xticks(np.arange(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">    plt.yticks(np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line">    plt.show()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;KNN_ORL_Database.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    X, y = Data_Processing(<span class="string">&#x27;ORL&#x27;</span>)</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, \</span><br><span class="line">                                train_size=<span class="number">0.8</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    scores = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用不同的邻居数进行训练测试</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>):</span><br><span class="line">        knn = KNeighborsClassifier(n_neighbors=n)</span><br><span class="line">        <span class="comment"># 训练</span></span><br><span class="line">        knn.fit(X_train, y_train)</span><br><span class="line">        <span class="comment"># 预测</span></span><br><span class="line">        pred = knn.predict(X_test)</span><br><span class="line">        <span class="comment"># 准确率并保留3位小数</span></span><br><span class="line">        score = <span class="built_in">round</span>(knn.score(X_test, y_test), <span class="number">3</span>)</span><br><span class="line">        scores.append(score)</span><br><span class="line"></span><br><span class="line">    Draw_precision(scores)</span><br></pre></td></tr></table></figure>
<p>所得结果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/G4bIoi1AmtPzdDW.png" alt="KNN_ORL_Database.png" style="zoom: 67%;" /></p>
<p>如上图所示，k 等于 1 时人脸识别的效果最好，识别正确率达到 0.975，比 PCA 算法的 0.95 要高。</p>
<h2 id="5-3-Yale-数据集"><a href="#5-3-Yale-数据集" class="headerlink" title="5.3    Yale 数据集"></a>5.3    Yale 数据集</h2><p>&emsp;&emsp;同理，参考 <a href="# 3.2.1    数据读取和数据处理"><strong>3.2.1    数据读取和数据处理</strong></a> 的方法，KNN 的参数设置与前面处理 ORL 数据集的一致。所得结果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/4LkADSqtzQr9eRx.png" alt="KNN_Yale_Database.png" style="zoom:67%;" /></p>
<p>如上图所示，使用 KNN 对 Yale 进行识别的效果很不好，不同的 k 值中最高的识别正确率也只有 0.879。原因可能是数据过少，因为在训练之前进行了人脸检测并且裁剪。因此，我采取了下面的数据处理方式，即不进行人脸检测和裁剪等操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Data_Processing</span>(<span class="params">root</span>) :</span><br><span class="line">    Yale_path = []</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    <span class="keyword">for</span> element <span class="keyword">in</span> os.listdir(root) :</span><br><span class="line">        <span class="keyword">if</span> element != <span class="string">&#x27;Readme.txt&#x27;</span>:</span><br><span class="line">            Yale_path.append(os.path.join(root, element))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> Yale_path :</span><br><span class="line">        image = io.imread(path, as_gray = <span class="literal">True</span>)</span><br><span class="line">        X.append(image.ravel())</span><br><span class="line">        label = <span class="built_in">int</span>(os.path.split(path)[-<span class="number">1</span>].split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>].replace(<span class="string">&quot;subject&quot;</span>, <span class="string">&quot;&quot;</span>)) - <span class="number">1</span></span><br><span class="line">        y.append(label)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line">    <span class="built_in">print</span>(X.shape)</span><br><span class="line">    <span class="keyword">return</span> X, y</span><br></pre></td></tr></table></figure>
<p>所得结果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/OJMPFlqrbmC6W9Y.png" alt="KNN_Yale_Database.png" style="zoom:67%;" /></p>
<p>如上图所示，当 k 值为 1 时，模型的性能最好，即识别正确率达到 0.939，此结果与 PCA 算法相当。</p>
<h2 id="5-4-UMIST-数据集"><a href="#5-4-UMIST-数据集" class="headerlink" title="5.4    UMIST 数据集"></a>5.4    UMIST 数据集</h2><p>&emsp;&emsp;UMIST 数据集的读取与处理参照 <a href="# 3.3.1    数据读取与数据处理"><strong>3.3.1    数据读取与数据处理</strong></a>，KNN 的参数的设置与前面相同。所得结果如下：</p>
<p><img src="https://s2.loli.net/2022/05/20/rDhmiMLb4V5A3Z7.png" alt="KNN_UMIST_Database.png" style="zoom:67%;" /></p>
<p>如上图所示，KNN 对于 UMIST 的鲁棒性非常强，识别性能特别好，在 k 等于 1、2 和 3 时的识别正确率有 0.974、0.965 和 0.957，远超 PCA 算法的 0.88 的正确率。</p>
<h2 id="5-5-KNN-的优缺点"><a href="#5-5-KNN-的优缺点" class="headerlink" title="5.5    KNN 的优缺点"></a>5.5    KNN 的优缺点</h2><p>优点：</p>
<ul>
<li>理论成熟，思想简单，既可以用来做分类又可以做回归；</li>
<li>可以用于非线性分类；</li>
<li>训练时间复杂度低，相比于 PCA，KNN 花费的时间很少；</li>
<li>和朴素贝叶斯之类的算法比，对数据没有假设，准确度高，对异常点不敏感；</li>
<li>由于 KNN 方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属的类别，因此对于类域的交叉或重叠较多的待分类样本集来说，KNN 方法较其他方法更为适合。</li>
</ul>
<p>缺点：</p>
<ul>
<li>计算量大，尤其是特征数非常多的时候；</li>
<li>样本不平衡的时候，对稀有类别的预测准确率低；</li>
<li>是惰性学习方法，基本上不学习，导致预测时速度比起逻辑回归之类的算法慢；</li>
<li>KNN 模型的可解释性不强。</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>传统算法</category>
      </categories>
      <tags>
        <tag>主成分分析</tag>
        <tag>人脸识别</tag>
        <tag>姿态分析</tag>
      </tags>
  </entry>
  <entry>
    <title>PyTorch——实现自注意力机制（self-attention）</title>
    <url>/2022/06/05/PyTorch%E2%80%94%E2%80%94%E5%AE%9E%E7%8E%B0%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%EF%BC%88self-attention%EF%BC%89/</url>
    <content><![CDATA[<h1 id="1-原理简述"><a href="#1-原理简述" class="headerlink" title="1    原理简述"></a>1    原理简述</h1><p>&emsp;&emsp;Self-Attention Layer 一次检查同一句子中的所有单词的注意力，这使得它成为一个简单的矩阵计算，并且能够在计算单元上并行计算。 此外，Self-Attention Layer 可以使用下面提到的 Multi-Head 架构来拓宽视野，也就是多头注意力机制。Self-Attention Layer 基本结构如下：<br><img src="https://img-blog.csdnimg.cn/fc65b9f0024549318aad9019931c293a.png" alt="在这里插入图片描述"></p>
<p>对于每个输入 $\boldsymbol{x}$，首先经过 <strong>Embedding</strong> 层对每个输入进行编码得到 $\boldsymbol{a_1,a_2,a_3,a_4}$，后将输入特征经过三个全连接层分别得到 <strong>Query，Key，Value</strong>：</p>
<ul>
<li>$\boldsymbol{q^i(Query) = W^q a^i}$；</li>
<li>$\boldsymbol{k^i(Key) = W^k a^i}$；</li>
<li>$\boldsymbol{v^i(Value) = W^v a^i}$。</li>
</ul>
<p>$\boldsymbol{W^q, W^k,W^v}$ 由网络训练而来。注意力矩阵是由 Query 和 Key 计算得到，方式由许多种，如点积、缩放点积等。Value 可以看作是信息提取器，将根据单词的注意力提取一个唯一的值，也即某个特征有多少成分被提取出来。下面计算一种注意力矩阵的方式：缩放点积。<br><img src="https://img-blog.csdnimg.cn/6385301128964680b30be08f2ac35638.gif#pic_center" alt="在这里插入图片描述"><br>注意力矩阵 $\boldsymbol{A}$ 定义为 Query (giver) 和 Key (receiver) 的内积除以其维度的平方根。 每个单词通过提供 Query 来匹配作为注意力的目标单词的 Key，从而对所有单词产生注意力。为防止注意力分数随维度增大而增大，让注意力矩阵除以向量的维度的开方。 然后对得到的注意力矩阵 $\boldsymbol{A}$ 进行 <strong>Softmax</strong> 归一化得到 $\boldsymbol{\hat{A}}$，最后将  $\boldsymbol{\hat{A}}$ 乘以 Value 矩阵并相加得到最终的特征 $\boldsymbol{b}$。<br><img src="https://img-blog.csdnimg.cn/9c375b3ad70240f1b2014231cbdd5e14.gif#pic_center" alt="在这里插入图片描述"></p>
<p>矩阵化如下：<br><img src="https://img-blog.csdnimg.cn/8b635a6a21ef402e8702d8f191da661a.png" alt="在这里插入图片描述"></p>
<p>在上述的 self-attention 中，我们最终只得到一个注意力矩阵，也就是说这个注意力矩阵所关注的信息只偏句子之间的一种关系，但是在时序序列中，往往特征之间不止一种关系，所以我们要提取多个注意力矩阵，这样可以捕获更多的信息，这种注意力机制也就是 <strong>多头注意力机制(Multi-Heads)</strong>。在实现过程中，我们只需要将原始的 $\boldsymbol{q^i,k^i,v^i}$ 分裂为 $\boldsymbol{n}$ 个就得到 $\boldsymbol{n}$ 头自注意力机制了。<br><img src="https://img-blog.csdnimg.cn/6ba45518a73649e9818594897369ff57.gif#pic_center" alt="在这里插入图片描述"></p>
<h1 id="2-PyTorch-实现"><a href="#2-PyTorch-实现" class="headerlink" title="2    PyTorch 实现"></a>2    PyTorch 实现</h1><p>定义 num_attention_heads 为注意力机制的头数，input_size 为输入特征维度，hidden_size 为 $\boldsymbol{q^i,k^i,v^i}$ 的总维度，这样每个头的维度也可以求出，定义为 attention_head_size：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.num_attention_heads = num_attention_heads</span><br><span class="line">self.attention_head_size = <span class="built_in">int</span>(hidden_size / num_attention_heads)</span><br><span class="line">self.all_head_size = hidden_size</span><br></pre></td></tr></table></figure>
<p>定义 $\boldsymbol{W^q, W^k,W^v}$，通过全连接网络生成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.key_layer = nn.Linear(input_size, hidden_size)</span><br><span class="line">self.query_layer = nn.Linear(input_size, hidden_size)</span><br><span class="line">self.value_layer = nn.Linear(input_size, hidden_size)</span><br></pre></td></tr></table></figure>
<p>使用输入特征乘 $\boldsymbol{W^q, W^k,W^v}$ 得到 <strong>Query，Key，Value</strong> 矩阵，维度为 $(batch\_size,seq\_len, hidden\_size)$：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">key = self.key_layer(x)</span><br><span class="line">query = self.query_layer(x)</span><br><span class="line">value = self.value_layer(x)</span><br></pre></td></tr></table></figure>
<p>求多头注意力机制的 $\boldsymbol{W^q, W^k,W^v}$，头数为 num_attention_heads，并要调换维度，即将 $seq\_len$ 维度与 $num\_attention\_heads$ 维度对换，最终 $\boldsymbol{W^q, W^k,W^v}$ 维度为 $(batch\_size,num\_attention\_heads,seq\_len,attention\_head\_size)$：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">trans_to_multiple_heads</span>(<span class="params">self, x</span>):</span><br><span class="line">    new_size = x.size()[ : -<span class="number">1</span>] + (self.num_attention_heads, self.attention_head_size)</span><br><span class="line">    x = x.view(new_size)</span><br><span class="line">    <span class="keyword">return</span> x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">key_heads = self.trans_to_multiple_heads(key)</span><br><span class="line">query_heads = self.trans_to_multiple_heads(query)</span><br><span class="line">value_heads = self.trans_to_multiple_heads(value)</span><br></pre></td></tr></table></figure>
<p>将 $\boldsymbol{Q}$ 和 $\boldsymbol{K}$ 矩阵做点积运算，并进行缩放，得到注意力矩阵的维度为 $(batch\_size,num\_attention\_heads,seq\_len,seq\_len)$：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">attention_scores = torch.matmul(query_heads, key_heads.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line">attention_scores = attention_scores / math.sqrt(self.attention_head_size)</span><br></pre></td></tr></table></figure>
<p>对注意力矩阵进行归一化，归一化的维度为 3，矩阵的维度不发生变化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">attention_probs = F.softmax(attention_scores, dim = -<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>将注意力矩阵乘以矩阵 $\boldsymbol{V}$，得到输出特征，维度为 $(batch\_size,num\_attention\_heads,seq\_len,attention\_head\_size)$：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">context = torch.matmul(attention_probs, value_heads)</span><br></pre></td></tr></table></figure>
<p>将各头的注意力矩阵进行拼接，contiguous() 是将 tensor 的内存变成连续的，否则进行 view 操作时会报错，至于原因可参考：<a href="https://blog.csdn.net/kdongyi/article/details/108180250"><strong>https://blog.csdn.net/kdongyi/article/details/108180250</strong></a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">context = context.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).contiguous()</span><br><span class="line">new_size = context.size()[ : -<span class="number">2</span>] + (self.all_head_size , )</span><br><span class="line">context = context.view(*new_size)</span><br></pre></td></tr></table></figure>
<p>全部代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">selfAttention</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_attention_heads, input_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(selfAttention, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> hidden_size % num_attention_heads != <span class="number">0</span> :</span><br><span class="line">            <span class="keyword">raise</span> ValueError(</span><br><span class="line">                <span class="string">&quot;the hidden size %d is not a multiple of the number of attention heads&quot;</span></span><br><span class="line">                <span class="string">&quot;%d&quot;</span> % (hidden_size, num_attention_heads)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        self.num_attention_heads = num_attention_heads</span><br><span class="line">        self.attention_head_size = <span class="built_in">int</span>(hidden_size / num_attention_heads)</span><br><span class="line">        self.all_head_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.key_layer = nn.Linear(input_size, hidden_size)</span><br><span class="line">        self.query_layer = nn.Linear(input_size, hidden_size)</span><br><span class="line">        self.value_layer = nn.Linear(input_size, hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">trans_to_multiple_heads</span>(<span class="params">self, x</span>):</span><br><span class="line">        new_size = x.size()[ : -<span class="number">1</span>] + (self.num_attention_heads, self.attention_head_size)</span><br><span class="line">        x = x.view(new_size)</span><br><span class="line">        <span class="keyword">return</span> x.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        key = self.key_layer(x)</span><br><span class="line">        query = self.query_layer(x)</span><br><span class="line">        value = self.value_layer(x)</span><br><span class="line"></span><br><span class="line">        key_heads = self.trans_to_multiple_heads(key)</span><br><span class="line">        query_heads = self.trans_to_multiple_heads(query)</span><br><span class="line">        value_heads = self.trans_to_multiple_heads(value)</span><br><span class="line"></span><br><span class="line">        attention_scores = torch.matmul(query_heads, key_heads.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line">        attention_scores = attention_scores / math.sqrt(self.attention_head_size)</span><br><span class="line"></span><br><span class="line">        attention_probs = F.softmax(attention_scores, dim = -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        context = torch.matmul(attention_probs, value_heads)</span><br><span class="line">        context = context.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).contiguous()</span><br><span class="line">        new_size = context.size()[ : -<span class="number">2</span>] + (self.all_head_size , )</span><br><span class="line">        context = context.view(*new_size)</span><br><span class="line">        <span class="keyword">return</span> context</span><br></pre></td></tr></table></figure>
<p>测试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features = torch.rand((<span class="number">32</span>, <span class="number">20</span>, <span class="number">10</span>))</span><br><span class="line">attention = selfAttention(<span class="number">2</span>, <span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">result = attention.forward(features)</span><br><span class="line"><span class="built_in">print</span>(result.shape)</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.Size([<span class="number">32</span>, <span class="number">20</span>, <span class="number">20</span>])</span><br></pre></td></tr></table></figure>
<p>参考：<br><a href="https://blog.csdn.net/beilizhang/article/details/115282604"><strong><em>https://blog.csdn.net/beilizhang/article/details/115282604</em></strong></a></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
        <tag>self-attention</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读：Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Network</title>
    <url>/2022/06/05/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9APseudo-Label-The-Simple-and-Efficient-Semi-Supervised-Learning-Method-for-Deep-Neural-Network/</url>
    <content><![CDATA[<center><font size=6><font color=red>论文阅读：Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks</font></font></center>

<h1 id="1-文章简述"><a href="#1-文章简述" class="headerlink" title="1    文章简述"></a>1    文章简述</h1><p>&emsp;&emsp;该文章的主要思想是将预测概率最大的标记作为无标记数据的伪标签，然后给未标记数据设一个权重，在训练过程中慢慢增加未标记数据的权重来进行训练，在手写体数据集上有了较好的性能。算法流程如下：</p>
<hr>
<p><strong>输入：样本集 $\boldsymbol{D1 = \{(x_1, y_1),(x_2,y_2),\cdots,(x_n, y_n)\}, D2 = \{x_1,x_2,,\cdots,x_n\}}$，其中 $\boldsymbol{D_1}$ 为已标注数据，$\boldsymbol{D_2}$ 为未标注数据；</strong></p>
<p><strong>过程：</strong></p>
<p><strong>1：用 $\boldsymbol{D_1}$ 来训练得到一个初始分类器；</strong></p>
<p><strong>2：用初始分类器对 $\boldsymbol{D_2}$ 进行分类，将预测的最大预测概率的类对 $\boldsymbol{D_2}$ 进行标注，得到伪标签(Pseudo-Label)；</strong></p>
<p><strong>3：使用 $\boldsymbol{D_1}$ 和得到伪标签的样本进行训练，再对 $\boldsymbol{D_2}$ 进行分类、标注，直至所有的样本均被标注；</strong></p>
<p><strong>4：使用最终网络对 MNIST 数据集进行分类；</strong></p>
<p><strong>输出：MNIST 测试集上的分类错误率。</strong></p>
<hr>
<h1 id="2-伪标签-Pseudo-Label"><a href="#2-伪标签-Pseudo-Label" class="headerlink" title="2    伪标签(Pseudo-Label)"></a>2    伪标签(Pseudo-Label)</h1><p>&emsp;&emsp;伪标签是未标注样本的的标签，是对当前未标注样本的预测的最大概率对应的类别，在文章中表示如下：</p>
<script type="math/tex; mode=display">
y'_i= \begin{cases} 1& if\ i = argmax_{i'}\ f_{i'}(x) \\ 0& \text{otherwise} \end{cases} \tag{1}</script><p><strong>Pseudo-Label</strong> 用于 Dropout 的微调阶段。预训练网络以监督方式同时使用标记和未标记数据进行训练，整体的损失函数表示为：</p>
<script type="math/tex; mode=display">
L = \frac{1}{n}\sum_{m = 1}^n\sum_{i=1}^CL(y_i^m,f_i^m) + \alpha(t)\frac{1}{n'}\sum_{m = 1}^{n'}\sum_{i = 1}^{C}L(y_i^{'m},f_i^{'m})\tag{2}</script><p>其中：</p>
<ul>
<li>$n$ 是已标注样本一个 <strong>batch_size</strong> 的样本数，$n’$ 是未标注样本的一个 <strong>batch_size</strong> 的样本数，$C$ 是类别数；</li>
<li>$f_i^m$ 是已标注样本的输出，$y_i^m$ 是已标注样本的真实标签；</li>
<li>$f_i^{‘m}$ 是未标注样本的输出，$y_i^{‘m}$ 是未标注样本的伪标签；</li>
<li>$\alpha(t)$ 是平衡已标注样本损失和未标注样本损失的系数，对模型的性能有着至关重要的影响。如果 $\alpha(t)$ 太大，会对训练产生很大成都的干扰；而如果 $\alpha(t)$ 太小，则不能利用未标注数据。</li>
</ul>
<p>在原文中，作者 $\alpha(t)$ 缓慢增加，以帮助优化过程避免较差的局部最优点：</p>
<script type="math/tex; mode=display">
\alpha(t) = \begin{cases}0 & {t<T_1} \\
\frac{t-T_1}{T_2 - T_1}\alpha_f & {T_1 < t < T_2} \\
\alpha_f&{T_2\leq t}
\end{cases}\tag{3}</script><p>其中：</p>
<ul>
<li>$\alpha(t) = 3,T_1 = 100,T_2 = 600$；</li>
<li>即在 100 个 epoch 之前，$\alpha(t)$ 为0，此时只在有标签的数据上进行训练；</li>
<li>在100-600 个 epoch 之间时，$\alpha(t)$ 设置为(epoch_current - 100) / 500 * 3；</li>
<li>当大于 600 个 epoch 的时候，$\alpha(t)$ 为 3。</li>
</ul>
<h1 id="3-熵正则化"><a href="#3-熵正则化" class="headerlink" title="3    熵正则化"></a>3    熵正则化</h1><p>&emsp;&emsp;文章在公式(2)中计算模型损失大小使用的方法是交叉熵，熵可用来衡量一个系统混乱程度，在概率论中，某中情况的概率越大，代表熵越小。在文章中，作者使用了熵正则化，主要思想是用熵来衡量分类的重叠程度(class overlap)，熵高的时候，重叠率也是高的，熵小的时候，重叠率是低的。论文中体现的主要的半监督方法是熵正则化，熵正则化依据于低密度假设：假设数据非黑即白，在两个类别之间的数据分布之间存在比较大的差距，即在两个类别之间的边界处数据的密度很低，用熵可以来表示，作为一个正则化项。所以通过最小化未标记数据的条件熵可以减少重叠率，从而得到一个通过低密度区域的决策边界，也就是让分类的边界更加的明显。熵正则化表达式如下：</p>
<script type="math/tex; mode=display">
H(y|x') = -\frac{1}{n'}\sum_{m = 1}^{n'}\sum_{i = 1}^CP(y_i^m = 1|x^{'m})logP(y_i^m = 1|x^{'m})\tag4</script><p>结合公式(2)和公式(4)得到最大后验估计为：</p>
<script type="math/tex; mode=display">
C(\theta, \lambda) = \sum_{m = 1}^{n} logP(y^m|x^m;\theta) - \lambda H(y|x';\theta)\tag5</script><p>其中：</p>
<ul>
<li>公式的第一部分是已标注数据的条件似然函数，对应已标注数据的损失；</li>
<li>公式的第二部分是未标注数据的条件熵，对应未标注数据的损失，可以用来减少类别的重叠率；</li>
<li>$\lambda$ 对应 $\alpha(t)$。</li>
</ul>
<p>经上述分析，可得到通过对未标注数据建立的伪标签可以达到和熵正则化一样的效果。</p>
<h1 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4    实验结果"></a>4    实验结果</h1><p>神经网络使用 600 个已标注样本和有或没有 60000 个未标注样本和 Pseudo-Labels 进行训练的效果分别如下：</p>
<p><img src="https://img-blog.csdnimg.cn/941d6f3ff0304abb91fccb3c993b8a45.png#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li><strong>dropNN</strong> 表示没有使用未标注数据；</li>
<li><strong>+PL</strong> 表示使用了未标注数据。</li>
</ul>
<p>在上图中，使用已标注数据和未标注数据进行训练的模型，测试数据的网络输出的每一类会更加接近，聚类效果更好。</p>
<p>不同模型使用具有 100、600、1000 和 3000 个已标注训练样本在 MNIST 测试集上的分类错误率如下：</p>
<p><img src="https://img-blog.csdnimg.cn/e4049d510d0e4e8bb0753cb889b17d3f.png#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>已标注训练样本集的大小减少到 100、600、1000 和 3000。对于验证集，分别选取 1000 个已标注样本；</li>
<li>使用相同的网络和参数进行了 10 次随机分割实验。在 100 个已标注训练样本的情况下，结果在很大程度上取决于数据分割，因此进行了30个实验。</li>
</ul>
<p>通过上图的性能比较，尽管原文中的方法简单，但对于小型已标注数据集，其性能优于传统方法。该训练方案没有流形切线分类器复杂，并且不使用在半监督嵌入中使用的样本之间计算代价高昂的相似度矩阵。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>自监督学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>MTCNN 测试时的一些 tips</title>
    <url>/2022/06/05/MTCNN-%E6%B5%8B%E8%AF%95%E6%97%B6%E7%9A%84%E4%B8%80%E4%BA%9B-tips/</url>
    <content><![CDATA[<h1 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1    网络结构"></a>1    网络结构</h1><p>&emsp;&emsp;MTCNN 是多任务级联 CNN 的人脸检测深度学习模型，该模型不仅考虑了人脸检测概率，还综合训练了人脸边框回归和面部关键点检测，多任务同时建立 loss function 并训练，因此为 MTCNN。级联 CNN 主要由三个子网络组成：P-Net、R-Net 和 O-Net。<br>&emsp;&emsp;P-Net 的结构如下：<br><img src="https://img-blog.csdnimg.cn/52bf5bf680944505ad1a4f52c5a94644.png#pic_center" alt="在这里插入图片描述\](https://img-blog.csdnimg.cn/a37a2812f2914fd48ae0c9f7ed16cb35.png"></p>
<p>从网络结构上看，P-Net 接受大小为 (12，12，3) 的图片的输入，输出三种特征图，大小为 (1，1，C)，也就是说最终得到的特征图每一点都对应着一个大小为 12×12 的感受野。三种输出如下：</p>
<ul>
<li><strong>cls</strong>：图像是否包含人脸，输出向量大小为 (1，1，2)，也就是两个值，即图像不是人脸的概率和图像是人脸的概率。这两个值加起来严格等于 1，之所以使用两个值来表示，是为了方便定义交叉熵损失函数；</li>
<li><strong>bounding_box</strong>：当前框位置相对完美的人脸框位置的偏移。这个偏移大小为 (1，1，4)，即表示框左上角和右下角的坐标的偏移量。网络结构中的输出叫做 <strong>bounding_boxes</strong>，如果按代码来说应该是 <strong>offsets</strong>；</li>
<li><strong>landmark</strong>：5 个关键点相对于人脸框的偏移量。分别对应着左眼的位置、右眼的位置、鼻子的位置、左嘴巴的位置、右嘴巴的位置。每个关键点需要两维来表示，因此输出是向量大小为 (1，1，10)。</li>
</ul>
<p><strong>Tips：</strong></p>
<ul>
<li>(12，12，3) 的输入大小指的是人脸框的大小，并不是真正图片的大小。在测试的时候大家会发现我们会输入各种缩放比例的图片，为什么可以这样？这是因为 P-Net 的输出是 <strong>特征图</strong>，没有 <strong>全连接层</strong>，这意味着网络对输出图片大小没有限制；</li>
<li>训练时是 (12，12，3) 的输入，(1，1，32) 的输出，但是这里的 (12，12) 输入只是一个示意，实际测试的时候由于 P-Net 的输出特征图的感受野是 (12, 12)，输入任意尺寸的图片矩阵经过 P-Net 后可以看做经历了一个完整的卷积(kernel = 12，stride = 2)，输出是 (H’，W’，32)。例如如果输入是 (48，48，3) 的图片矩阵，经过 P-Net 后输出为 (19，19，32) 了，并且 (19，19) 中每个二维点对应到原图中都是一个 (12，12) 的视野区域，可以理解为对原图进行了卷积的滑动并分别计算每个 (12，12) 窗口的人脸概率以及框回归；</li>
<li>P-Net 实际上对输出特征图的 <strong>每一个像素格子</strong> 都进行人脸概率、边框、地标预测，因此开始时的预测框数量非常多，要根据人脸概率的阈值先进行初步筛选，在进行边界框的 <strong>非极大值抑制</strong>。那这里就有疑问了，为什么可以对每一个像素方格进行预测？这里可以在后面的 <strong>图像金字塔</strong> 中再做解释；</li>
<li>在实际测试中，P-Net 的输出中不包括 <strong>landmark</strong>。</li>
</ul>
<p>&emsp;&emsp;R-Net 的网络结构如下：<br><img src="https://img-blog.csdnimg.cn/aa3f543d4b314a8ba20c7abc68ddee07.png#pic_center" alt="在这里插入图片描述"></p>
<p>由于 P-Net 是对输出特征图的每一个像素进行预测，因此结果十分冗杂，所以接下来使用 R-Net 进一步优化。R-Net 和 P-Net 类似，不过这一步的输入是前面 P-Net 生成的边界框，不管实际边界框的大小，在输入 R-Net 之前，都需要缩放到 (24，24，3)。网络的输出和 P-Net 是一样的。这一步的目的主要是为了去除大量的非人脸框。<br>&emsp;&emsp;O-Net 的网络结构如下：<br><img src="https://img-blog.csdnimg.cn/2131139030b344a4bae24798437e26f9.png#pic_center" alt="在这里插入图片描述"></p>
<p>进一步将 R-Net 的所得到的区域缩放到 (48，48，3)，输入到最后的 O-Net，O-Net 的结构与 P-Net 类似，只不过在测试输出的时候多了关键点位置的输出。输入大小为 (48，48，3) 的图像，输出包含 n 个人脸概率、边界框的偏移量和关键点的偏移量。三个字网络流程如下：</p>
<p><img src="https://img-blog.csdnimg.cn/aec976c698d544e9afc28839fcd037d1.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="2-图像金字塔"><a href="#2-图像金字塔" class="headerlink" title="2    图像金字塔"></a>2    图像金字塔</h1><p>&emsp;&emsp;MTCNN基于卷积神经网络，通常只适用于检测一定尺寸范围内的人脸，比如其中的 P-Net，用于判断 12 × 12 大小范围内是否含有人脸，但是输入图像中人脸的尺寸未知，需要构建图像金字塔获得不同尺寸的图像，缩放图像是为了将图像中的人脸缩放到网络能检测的适宜尺寸，只要某个人脸被放缩到 12 × 12 左右，就可以被检测出来，下图为MTCNN人脸检测流程。</p>
<p><img src="https://img-blog.csdnimg.cn/b3ac3293462a4dd9ad6ed7a5ac9e6076.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;在人脸检测中，通常要设置要原图中要检测的最小人脸尺寸，原图中小于这个尺寸的人脸不必关心，MTCNN 代码中为 <code>minsize = 20</code>，MTCNN P-Net 用于检测 12 × 12 大小的人脸，这需要我们将不同的人脸大小都要缩放到 12 × 12。在 P-Net 中我们为什么可以对输出特征图中的每一个像素方格进行预测，正是因为原图中的人脸都被缩放到 12 × 12，而且输出特征图的感受野正是 12 × 12。</p>
<p><strong>Tips：</strong></p>
<p>人脸检测中的图像金字塔构建，涉及如下数据：</p>
<ul>
<li>输入图像尺寸：<code>(h, w)</code>；</li>
<li>最小人脸尺寸：<code>min_face_size</code>；</li>
<li>最大人脸尺寸：<code>max_face_size</code>，如果不设置，为图像高宽中较短的那个；</li>
<li>网络/方法能检测的人脸尺寸：<code>net_face_size</code>；</li>
<li>金字塔层间缩放比率：<code>factor</code>；</li>
</ul>
<p>缩放图像是为了将图像中的人脸缩放到网络能检测的适宜尺寸，图像金字塔中：</p>
<ul>
<li>最大缩放尺度(最小缩小比例)：<code>max_scale = net_face_size / min_face_size</code>；</li>
<li>最小缩放尺度(最大缩小比例)：<code>min_scale = net_face_size / max_face_size</code>；</li>
<li>中间的尺度：<code>scale_n = max_scale * (factor ^ n)</code>；</li>
<li>对应的图像尺寸为：<code>(h_n, w_n) = (h * scale_n, w_n * scale_n)</code>；</li>
<li>保证 <code>min(h_n, w_n) &gt;net_face_size</code>。</li>
</ul>
<p><strong>注：</strong> 缩小比例为缩放尺寸的倒数。<br>&emsp;&emsp;在 MTCNN 的实际测试中，如果输入图像为 (100，120)，其中人脸最小为 (20，20)，最大为 (20，20)——对应图像较短边长，为了将人脸放缩到 (12，12)，同时保证相邻层间缩放比率 <code>factor = 0.709</code>，依据上述公式则最大缩放尺度为 12 / 20，最小缩放尺度为 12 / 20，金字塔中图像尺寸依次为 (60，72)、(52，61)、(36，43)、(26，31)、(18，22)、(13，16)，其中 (60，72) 对应把 (20，20) 的人脸缩放到 (12，12)，(13，16)对应把 (100，100) 的人脸缩放到 (12，12)，在保证缩放比率一致的情况下近似。<br>&emsp;&emsp;综上，构建图像金字塔有两个步骤：</p>
<ul>
<li>给定输入图像，根据设置的最小人脸尺寸以及网络能检测的人脸尺寸，确定最大缩放图像和最小缩放图像；</li>
<li>根据设置的金字塔层间缩放比率，确定每层图像的尺寸。</li>
</ul>
<h1 id="3-其他"><a href="#3-其他" class="headerlink" title="3    其他"></a>3    其他</h1><p><strong>Tips：</strong></p>
<ul>
<li>测试时只使用 onet.eval()，这是因为只有 O-Net 中有 Dropout 层。如果模型中有 BN 层和 Dropout，在测试时添加 model.eval()。model.eval() 是保证 BN 层能够用全部训练数据的均值和方差，即测试过程中要保证 BN 层的均值和方差不变。对于 Dropout，model.eval() 是利用到了所有网络连接，即不进行随机舍弃神经元；</li>
<li>将 255 的 RGB 图像归一化到了 [-1，1] 的区间，归一化操作，加快收敛速度。由于图片每个像素点上是 [0，255] 的数，都是非负数，对每个像素点做 (x – 127.5) / 128，可以把 [0，255] 映射为 (-1，1)。有正有负的输入，损失函数收敛速度更快。因为 MTCNN 的训练中有次操作，因此测试时也要做。</li>
</ul>
<h1 id="4-效果"><a href="#4-效果" class="headerlink" title="4    效果"></a>4    效果</h1><p>&emsp;本次代码实现了两种检测方式：静态图像检测和摄像头实时检测。<a href="https://github.com/aishangcengloua/mtcnn-PyTorch"><strong>GitHub：https://github.com/aishangcengloua/mtcnn-PyTorch</strong></a></p>
<ul>
<li>静态图像检测</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> src <span class="keyword">import</span> FaceDetector</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 人脸检测对象。优先使用GPU进行计算</span></span><br><span class="line">detector = FaceDetector()</span><br><span class="line"></span><br><span class="line">image = Image.<span class="built_in">open</span>(<span class="string">&quot;./images/face_1.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检测人脸，返回人脸位置坐标</span></span><br><span class="line">bboxes, landmarks = detector.detect(image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制并保存标注图</span></span><br><span class="line">drawed_image = detector.draw_bboxes(image)</span><br><span class="line">drawed_image.save(<span class="string">&quot;./images/drawed_image.jpg&quot;</span>)</span><br><span class="line">drawed_image.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 裁剪人脸图片并保存</span></span><br><span class="line"><span class="comment"># face_img_list = detector.crop_faces(image, size=64)</span></span><br><span class="line"><span class="comment"># for i in range(len(face_img_list)):</span></span><br><span class="line"><span class="comment">#     face_img_list[i].save(&quot;./images/face_&quot; + str(i + 1) + &quot;.jpg&quot;)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/ffc8e21ea6b6496dba70f8d5bebc5d02.jpeg" alt="在这里插入图片描述"></p>
<ul>
<li>摄像头实时检测</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> src <span class="keyword">import</span> FaceDetector</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">detector = FaceDetector()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">camera_detect</span>():</span><br><span class="line">    video = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        ret, frame = video.read()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将 OpenCV 格式的图片转换为 PIL.Image，注意 PIL 图片是 (width, height)</span></span><br><span class="line">        pil_im = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))</span><br><span class="line">        <span class="comment"># 绘制带人脸框的标注图</span></span><br><span class="line">        drawed_pil_im = detector.draw_bboxes(pil_im)</span><br><span class="line">        <span class="comment"># 再转回 OpenCV 格式用于视频显示</span></span><br><span class="line">        frame = cv2.cvtColor(np.asarray(drawed_pil_im), cv2.COLOR_RGB2BGR)</span><br><span class="line"></span><br><span class="line">        cv2.imshow(<span class="string">&quot;Face Detection&quot;</span>, frame)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&quot;q&quot;</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    video.release()</span><br><span class="line">    cv2.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    camera_detect()</span><br></pre></td></tr></table></figure>
<h1 id="5-参考"><a href="#5-参考" class="headerlink" title="5    参考"></a>5    参考</h1><ul>
<li><a href="https://its301.com/article/weixin_41721222/88084549"><strong>https://its301.com/article/weixin_41721222/88084549</strong></a></li>
<li><a href="https://www.i4k.xyz/article/yanxueotft/99696057"><strong>https://www.i4k.xyz/article/yanxueotft/99696057</strong></a></li>
<li><a href="https://www.twblogs.net/a/5eef9bb51f92b2f1a17d09ef/?lang=zh-cn"><strong>https://www.twblogs.net/a/5eef9bb51f92b2f1a17d09ef/?lang=zh-cn</strong></a></li>
<li><a href="https://github.com/inkuang/MTCNN-PyTorch"><strong>https://github.com/inkuang/MTCNN-PyTorch</strong></a></li>
<li><a href="https://github.com/TropComplique/mtcnn-pytorch"><strong>https://github.com/TropComplique/mtcnn-pytorch</strong></a></li>
<li><a href="https://github.com/kpzhang93/MTCNN_face_detection_alignment"><strong>https://github.com/kpzhang93/MTCNN_face_detection_alignment</strong></a></li>
<li><a href="https://arxiv.org/abs/1604.02878"><strong>Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks</strong></a></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>PyTorch</tag>
        <tag>人脸检测</tag>
        <tag>MTCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 中的图：A* 算法</title>
    <url>/2022/06/05/Python-%E4%B8%AD%E7%9A%84%E5%9B%BE%EF%BC%9AA-%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="1-什么是A-算法"><a href="#1-什么是A-算法" class="headerlink" title="1    什么是A*算法"></a>1    什么是A*算法</h1><p>&emsp;&emsp;假设一个走迷宫游戏，我将 <strong>A</strong> 点定义成起点也就是开始状态，定义 <strong>B</strong> 为终点也就是结束状态。我们的目标就是找到从 A 走到 B 地最佳路径，如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/b034a9f77f034966a81f547473c07042.png#pic_center" alt="在这里插入图片描述"></p>
<p>我们可以将上述的迷宫看做一张图，在简单的情况下（比如这个），生成的图由少量节点和边组成，BFS、DFS 和 Dijkstra 就足够了。然而，在现实生活中，因为我们通常要处理组合复杂性非常大的问题，我们将不得不处理大量的节点和边，而 BFS、DFS 和 Dijkstra 要不可避免地遍历整张图，搜索代价十分巨大。因此，我们必须使用某种意义上的引导算法（启发式算法）。A<em> 算法就是一种启发式算法。与其他图遍历算法不同，A</em> 仅根据其功能在看起来有希望且合理的情况下执行一个步骤。它朝着目标前进，不考虑任何非最佳步骤，所以 A<em> 所搜索出来的路径一定是最优路径。这使得 A</em> 对于人工智能系统非常有用——尤其是在机器学习和游戏开发中，因为这些系统复制了现实世界的场景。</p>
<h2 id="1-1-A-的基本概念"><a href="#1-1-A-的基本概念" class="headerlink" title="1.1    A* 的基本概念"></a>1.1    A* 的基本概念</h2><p>&emsp;&emsp;A<em> 基于使用 <strong>启发式</strong> 方法来实现最优性和完整性，是最佳优先算法的一种变体。当搜索算法具有最优性时，这意味着它可以保证找到可能的最佳解决方案。当搜索算法具有完备性时，这意味着如果给定问题的解决方案存在，则该算法保证找到它。<br>&emsp;&emsp;每次 A</em> 进入一个状态即图中的一个节点，它计算从当前节点移动到所有相邻节点的成本 <code>f(n)</code> ，然后进入具有最低   <code>f(n)</code> 的节点，注意 <code>n</code> 指的是当前节点的邻居节点。计算公式如下：</p>
<script type="math/tex; mode=display">
f(n) = g(n) + h(n)</script><p>其中：</p>
<ul>
<li><code>f(n)</code>：从初始状态经由状态 <code>n</code> 到目标状态的代价估计；</li>
<li><code>g(n)</code>：在状态空间中从初始状态到当前状态 <code>n</code> 的实际代价；</li>
<li><code>h(n)</code>：从当前状态 <code>n</code> 到目标状态的最佳路径的估计代价。</li>
</ul>
<p>为了能够重建任何路径，我们需要用具有最佳 <code>f(n)</code> 值的相对标记每个节点。这也意味着如果我们重新访问某些节点，我们也必须更新它们的最佳邻居。A* 的效率高度依赖于启发式值<code>h(n)</code>，并且根据问题的类型，我们可能需要使用不同的启发式函数来找到最佳解决方案。。</p>
<h2 id="1-2-启发函数的可接受性和一致性"><a href="#1-2-启发函数的可接受性和一致性" class="headerlink" title="1.2    启发函数的可接受性和一致性"></a>1.2    启发函数的可接受性和一致性</h2><p>&emsp;&emsp;如果一个给定的启发式函数从不高估 <code>n</code> 和目标节点之间的实际距离，则 <code>h(n)</code> 是可接受的。因此，对于每个节点 <code>n</code>，适用以下公式：</p>
<script type="math/tex; mode=display">
h(n) \leq h^*(n)</script><p><code>h*(n)</code> 是 <code>n</code> 和目标节点之间的实际距离。但是，如果函数确实高估了实际距离，但从不超过 <code>d</code>，我们可以肯定地说，该函数产生的解的精度为 <code>d</code>（即它不会高估从开始到结束的最短路径超过 <code>d</code>)。<br>&emsp;&emsp;如果估计总是小于或等于目标节点 <code>n</code> 和其任何邻居之间的估计距离，加上到达该邻居的估计成本，则给定启发式函数<code>h(n)</code> 是一致的：</p>
<script type="math/tex; mode=display">
c(n, m) + h(m) \geq h(n)</script><p>如果 <code>h(n)</code> 是一致的，那么我们就知道到任何已经检查过的节点的最佳路径。这意味着这个函数是最优的。</p>
<h1 id="2-Python-实现-A-算法"><a href="#2-Python-实现-A-算法" class="headerlink" title="2    Python 实现 A* 算法"></a>2    Python 实现 A* 算法</h1><p>&emsp;&emsp;本次实现从零开始，也即先构建一个加权有向图，其次利用 A* 算法寻找图中的某一节点到达另一节点的的最佳路径，其中：</p>
<ul>
<li>图的存储结构是邻接列表，可参考：<a href="https://blog.csdn.net/weixin_53598445/article/details/124190900"><strong><em>Python 中的图：图的存储结构</em></strong></a>；</li>
<li>为了方便，本次定义的启发函数 <code>h(n) = 1</code>，即任何的当前节点到目标节点的最佳路径的估计代价均为1。</li>
</ul>
<p>图的构建如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">adjacency_list = &#123;<span class="string">&#x27;A&#x27;</span> : [(<span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">7</span>)],</span><br><span class="line">                  <span class="string">&#x27;B&#x27;</span> : [(<span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>)],</span><br><span class="line">                  <span class="string">&#x27;C&#x27;</span> : [(<span class="string">&#x27;D&#x27;</span>, <span class="number">12</span>)]&#125;</span><br></pre></td></tr></table></figure>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">adjacency_list = &#123;<span class="string">&#x27;A&#x27;</span> : [(<span class="string">&#x27;B&#x27;</span>, <span class="number">1</span>), (<span class="string">&#x27;C&#x27;</span>, <span class="number">3</span>), (<span class="string">&#x27;D&#x27;</span>, <span class="number">7</span>)],</span><br><span class="line">                  <span class="string">&#x27;B&#x27;</span> : [(<span class="string">&#x27;D&#x27;</span>, <span class="number">5</span>)],</span><br><span class="line">                  <span class="string">&#x27;C&#x27;</span> : [(<span class="string">&#x27;D&#x27;</span>, <span class="number">12</span>)]&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>() :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, adjacency</span>):</span><br><span class="line">        self.adjacency = adjacency</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_neighbors</span>(<span class="params">self, v</span>):</span><br><span class="line">        <span class="keyword">return</span> self.adjacency[v]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">h</span>(<span class="params">self, n</span>):</span><br><span class="line">        H = &#123;<span class="string">&#x27;A&#x27;</span> : <span class="number">1</span>,</span><br><span class="line">             <span class="string">&#x27;B&#x27;</span> : <span class="number">1</span>,</span><br><span class="line">             <span class="string">&#x27;C&#x27;</span> : <span class="number">1</span>,</span><br><span class="line">             <span class="string">&#x27;D&#x27;</span> : <span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> H[n]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">A_star</span>(<span class="params">self, start, target</span>):</span><br><span class="line">        <span class="comment"># 首先说明：下面注释中邻居节点和子节点指的是同一个意思</span></span><br><span class="line">        <span class="comment"># open_list 存的是已访问，但该节点的邻居节点仍未被访问的节点，从 start 节点开始</span></span><br><span class="line">        <span class="comment"># close_list 存的是已访问，且该节点的邻居节点已被访问的节点</span></span><br><span class="line">        open_list = <span class="built_in">set</span>(start)</span><br><span class="line">        close_list = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># g 存的是</span></span><br><span class="line">        g = &#123;&#125;</span><br><span class="line">        g[start] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录所有节点的父节点</span></span><br><span class="line">        parents = &#123;&#125;</span><br><span class="line">        parents[start] = start</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(open_list) &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 当前节点</span></span><br><span class="line">            n = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 在当前节点的邻居节点中找到 f() 值最低的节点，更新当前节点</span></span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> open_list :</span><br><span class="line">                <span class="keyword">if</span> n == <span class="literal">None</span> <span class="keyword">or</span> g[v] + self.h(v) &lt; g[n] + self.h(n) :</span><br><span class="line">                    n = v</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> n == <span class="literal">None</span> :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;path does not exists!&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果当前节点是目标节点，回溯求得最佳路径。利用 parents</span></span><br><span class="line">            <span class="keyword">if</span> n == target :</span><br><span class="line">                path = []</span><br><span class="line">                <span class="keyword">while</span> parents[n] != n :</span><br><span class="line">                    path.append(n)</span><br><span class="line">                    n = parents[n]</span><br><span class="line"></span><br><span class="line">                path.append(start)</span><br><span class="line">                path.reverse()</span><br><span class="line">                best_path = <span class="string">&#x27;-&gt;&#x27;</span>.join(path)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&#x27;the best path of the node <span class="subst">&#123;start&#125;</span> to <span class="subst">&#123;target&#125;</span> is: <span class="subst">&#123;best_path&#125;</span>&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span> path</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 当前节点的所有邻居节点</span></span><br><span class="line">            <span class="keyword">for</span> (m, weight) <span class="keyword">in</span> self.get_neighbors(n) :</span><br><span class="line">                <span class="comment"># 如果没被访问过，添加至 open_list</span></span><br><span class="line">                <span class="keyword">if</span> m <span class="keyword">not</span> <span class="keyword">in</span> open_list <span class="keyword">and</span> m <span class="keyword">not</span> <span class="keyword">in</span> close_list :</span><br><span class="line">                    open_list.add(m)</span><br><span class="line">                    parents[m] = n</span><br><span class="line">                    <span class="comment"># 开始节点到当前节点的邻居节点的代价，为求下一个最佳节点做准备</span></span><br><span class="line">                    g[m] = g[n] + weight</span><br><span class="line">                <span class="comment"># 否则说明 m 节点的父节点是 n 节点的子节点，也是最佳路径中的上一个节点的子节点</span></span><br><span class="line">                <span class="keyword">else</span> :</span><br><span class="line">                    <span class="comment"># 如果从上一个节点先访问 n 再访问 m 比直接访问 m 更快，则更新父节点和相应的代价</span></span><br><span class="line">                    <span class="keyword">if</span> g[m] &gt; g[n] + weight :</span><br><span class="line">                        g[m] = g[n] + weight</span><br><span class="line">                        parents[m] = n</span><br><span class="line">                        <span class="comment"># 如果 m 节点位于 closed_list 中，将其移至 open_list</span></span><br><span class="line">                        <span class="keyword">if</span> m <span class="keyword">in</span> close_list :</span><br><span class="line">                            close_list.remove(m)</span><br><span class="line">                            open_list.add(m)</span><br><span class="line"></span><br><span class="line">            open_list.remove(n)</span><br><span class="line">            close_list.add(n)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;path does not exists!&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">graph = Graph(adjacency_list)</span><br><span class="line">graph.A_star(<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;D&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>代码中有详细注释，便不再讲解。效果如下：<br><img src="https://img-blog.csdnimg.cn/789dbe327af1410daec07446cf011add.png" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>Python</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>A*</tag>
        <tag>启发式函数</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode刷题——字符串</title>
    <url>/2022/06/05/LeetCode%E5%88%B7%E9%A2%98%E2%80%94%E2%80%94%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<h2 id="344-反转字符串"><a href="#344-反转字符串" class="headerlink" title="344. 反转字符串"></a>344. 反转字符串</h2><p>&emsp;&emsp;编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 <code>s</code> 的形式给出。不要给另外的数组分配额外的空间，你必须<strong>原地修改输入数组</strong>、使用 <code>O(1)</code> 的额外空间解决这一问题。</p>
<p>示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：s = [<span class="string">&quot;h&quot;</span>,<span class="string">&quot;e&quot;</span>,<span class="string">&quot;l&quot;</span>,<span class="string">&quot;l&quot;</span>,<span class="string">&quot;o&quot;</span>]</span><br><span class="line">输出：[<span class="string">&quot;o&quot;</span>,<span class="string">&quot;l&quot;</span>,<span class="string">&quot;l&quot;</span>,<span class="string">&quot;e&quot;</span>,<span class="string">&quot;h&quot;</span>]</span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：s = [<span class="string">&quot;H&quot;</span>,<span class="string">&quot;a&quot;</span>,<span class="string">&quot;n&quot;</span>,<span class="string">&quot;n&quot;</span>,<span class="string">&quot;a&quot;</span>,<span class="string">&quot;h&quot;</span>]</span><br><span class="line">输出：[<span class="string">&quot;h&quot;</span>,<span class="string">&quot;a&quot;</span>,<span class="string">&quot;n&quot;</span>,<span class="string">&quot;n&quot;</span>,<span class="string">&quot;a&quot;</span>,<span class="string">&quot;H&quot;</span>]</span><br></pre></td></tr></table></figure>
<p>思路：双指针。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseString</span>(<span class="params">self, s: <span class="type">List</span>[<span class="built_in">str</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Do not return anything, modify s in-place instead.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="built_in">len</span>(s) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; j :</span><br><span class="line">            s[i], s[j] = s[j], s[i]</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            j -= <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="541-反转字符串-II"><a href="#541-反转字符串-II" class="headerlink" title="541. 反转字符串 II"></a>541. 反转字符串 II</h2><p>&emsp;&emsp;给定一个字符串 <code>s</code> 和一个整数 <code>k</code>，从字符串开头算起，每计数至 <code>2k</code> 个字符，就反转这 <code>2k</code> 字符中的前 <code>k</code> 个字符。</p>
<ul>
<li>如果剩余字符少于 <code>k</code> 个，则将剩余字符全部反转。</li>
<li>如果剩余字符小于 <code>2k</code> 但大于或等于 <code>k</code> 个，则反转前 <code>k</code> 个字符，其余字符保持原样。</li>
</ul>
<p>示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：s = <span class="string">&quot;abcdefg&quot;</span>, k = <span class="number">2</span></span><br><span class="line">输出：<span class="string">&quot;bacdfeg&quot;</span></span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：s = <span class="string">&quot;abcd&quot;</span>, k = <span class="number">2</span></span><br><span class="line">输出：<span class="string">&quot;bacd&quot;</span></span><br></pre></td></tr></table></figure>
<p>思路：我们直接按题意进行模拟：反转每个下标从 <code>2k</code> 的倍数开始的，长度为 <code>k</code> 的子串。若该子串长度不足 <code>k</code>，则反转整个子串。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseStr</span>(<span class="params">self, s: <span class="built_in">str</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        s = <span class="built_in">list</span>(s)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(s), <span class="number">2</span> * k) :</span><br><span class="line">            s[i : i + k] = s[i : i + k][ : : -<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(s)</span><br></pre></td></tr></table></figure>
<h2 id="剑指-Offer-05-替换空格"><a href="#剑指-Offer-05-替换空格" class="headerlink" title="剑指 Offer 05. 替换空格"></a>剑指 Offer 05. 替换空格</h2><p>&emsp;&emsp;请实现一个函数，把字符串 s 中的每个空格替换成 <code>&quot;%20&quot;</code>。</p>
<p>示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：s = <span class="string">&quot;We are happy.&quot;</span></span><br><span class="line">输出：<span class="string">&quot;We%20are%20happy.&quot;</span></span><br></pre></td></tr></table></figure>
<p>思路：一次遍历直接替换。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">replaceSpace</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        s = <span class="built_in">list</span>(s)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)) :</span><br><span class="line">            <span class="keyword">if</span> s[i] == <span class="string">&#x27; &#x27;</span> :</span><br><span class="line">                s[i] = <span class="string">&#x27;%20&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(s)</span><br></pre></td></tr></table></figure>
<h2 id="151-颠倒字符串中的单词"><a href="#151-颠倒字符串中的单词" class="headerlink" title="151. 颠倒字符串中的单词"></a>151. 颠倒字符串中的单词</h2><p>&emsp;&emsp;给你一个字符串 <code>s</code> ，颠倒字符串中 单词 的顺序。<code>单词</code> 是由非空格字符组成的字符串。<code>s</code> 中使用至少一个空格将字符串中的 <code>单词</code> 分隔开。返回 <code>单词</code> 顺序颠倒且 <code>单词</code> 之间用单个空格连接的结果字符串。<strong>注意</strong>：输入字符串 <code>s</code> 中可能会存在前导空格、尾随空格或者单词间的多个空格。返回的结果字符串中，单词间应当仅用单个空格分隔，且不包含任何额外的空格。</p>
<p> 示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：s = <span class="string">&quot;the sky is blue&quot;</span></span><br><span class="line">输出：<span class="string">&quot;blue is sky the&quot;</span></span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：s = <span class="string">&quot;  hello world  &quot;</span></span><br><span class="line">输出：<span class="string">&quot;world hello&quot;</span></span><br><span class="line">解释：颠倒后的字符串中不能存在前导空格和尾随空格。</span><br></pre></td></tr></table></figure>
<p>示例三：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：s = <span class="string">&quot;a good   example&quot;</span></span><br><span class="line">输出：<span class="string">&quot;example good a&quot;</span></span><br><span class="line">解释：如果两个单词间有多余的空格，颠倒后的字符串需要将单词间的空格减少到仅有一个。</span><br></pre></td></tr></table></figure>
<p>思路：双指针+反向遍历。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reverseWords</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># 1、当快指针和慢指针同时指向空格时 fast 和 slow 都减一</span></span><br><span class="line">        <span class="comment"># 2、当慢指针遇到一个单词的额末尾字母时，停下</span></span><br><span class="line">        <span class="comment"># 3、当快指针遇到空格且慢指针不为空格的话，添加单词，这里要注意当 fast==0 时要另外处理</span></span><br><span class="line"></span><br><span class="line">        words = []</span><br><span class="line">        slow = <span class="built_in">len</span>(s) - <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> fast <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s) - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>) :</span><br><span class="line">            <span class="keyword">if</span> s[fast] != <span class="string">&#x27; &#x27;</span> :</span><br><span class="line">                <span class="keyword">if</span> fast == <span class="number">0</span> :</span><br><span class="line">                    words.append(s[fast : slow + <span class="number">1</span>])</span><br><span class="line">                <span class="keyword">else</span> :</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                <span class="keyword">if</span> s[slow] != <span class="string">&#x27; &#x27;</span> :</span><br><span class="line">                    words.append(s[fast + <span class="number">1</span> : slow + <span class="number">1</span>])</span><br><span class="line">                    slow = fast</span><br><span class="line">            slow -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot; &quot;</span>.join(words)</span><br></pre></td></tr></table></figure>
<h2 id="459-重复的子字符串"><a href="#459-重复的子字符串" class="headerlink" title="459. 重复的子字符串"></a>459. 重复的子字符串</h2><p>&emsp;&emsp;给定一个非空的字符串 <code>s</code> ，检查是否可以通过由它的一个子串重复多次构成。</p>
<p>示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入: s = <span class="string">&quot;abab&quot;</span></span><br><span class="line">输出: true</span><br><span class="line">解释: 可由子串 <span class="string">&quot;ab&quot;</span> 重复两次构成。</span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入: s = <span class="string">&quot;aba&quot;</span></span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure>
<p>示例三：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入: s = <span class="string">&quot;abcabcabcabc&quot;</span></span><br><span class="line">输出: true</span><br><span class="line">解释: 可由子串 <span class="string">&quot;abc&quot;</span> 重复四次构成。 (或子串 <span class="string">&quot;abcabc&quot;</span> 重复两次构成。)</span><br></pre></td></tr></table></figure>
<p>思路：这道题有很多钟方法，这里介绍字符串匹配。假设 <code>s</code>  由 <code>n</code> 个重复的子字符串 <code>s&#39;</code> 构成，若 <code>n == 1</code> 则不满足要求，若 <code>n &gt;= 2</code>，则满足题目要求。然后我们将第一个 <code>s&#39;</code> 移到最后面，此时的字符串还是跟原始的 <code>s</code> 一样。然后我们将 <code>s</code> 扩展成 <code>s + s</code>，并且去除 <code>s + s</code> 的第一个字符和最后一个字符，相当于损坏了第一个 <code>s</code> 的第一个子字符串和第二个 <code>s</code> 的最后一个子字符串，如果在去除字符之后的字符串中我们还能找到原始的字符串 <code>s</code>，说明 <code>s</code> 满足条件。其实这里就相当于 <code>n &gt;= 2</code>，然后第二个 <code>s</code> 的第一个子字符串填补了第一个 <code>s</code> 的最后一子字符串。这两个是充要条件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">repeatedSubstringPattern</span>(<span class="params">self, s: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">return</span> s <span class="keyword">in</span> (s + s)[<span class="number">1</span> : <span class="built_in">len</span>(s) * <span class="number">2</span> - <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 中的图：图的存储结构</title>
    <url>/2022/06/05/Python-%E4%B8%AD%E7%9A%84%E5%9B%BE%EF%BC%9A%E5%9B%BE%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<h1 id="1-什么是图"><a href="#1-什么是图" class="headerlink" title="1    什么是图"></a>1    什么是图</h1><p>&emsp;&emsp;图是一种数据结构，可用于对对象之间的层次结构和关系进行建模。它由<strong>一组节点</strong>和<strong>一组边</strong>组成。节点表示单个对象，而边表示这些对象之间的关系。<strong>注意</strong>：可能在不同的文献中节点也被称作<strong>顶点</strong>，它们指同一个意思。<br>&emsp;&emsp;如果图中的边可以通过双向遍历，则是<strong>无向图(undirected)</strong>，如果只能通过一个方向进行遍历，则是<strong>有向图(undirected)</strong>。<br><img src="https://img-blog.csdnimg.cn/2b04ebe1cbfb4c40b1634dde5bbcbb67.png" alt="在这里插入图片描述"><br>并非图的所有节点都需要与其他节点连接。如果可以从图中的每个节点 访问其他任何的节点，我们称该图为<strong>连接图(connected)</strong>，但有时你通过一些几点无法访问其他节点，那这个图就是<strong>未连接图(disconnected)</strong>。常见的误解是图的节点之间都必须连接，事实上，图可以不包含边，只有节点：<br><img src="https://img-blog.csdnimg.cn/1924b974e53047c992477123b99185a0.png" alt="在这里插入图片描述"><br>从实现的角度来看，在定义好节点之后，我们需要定义是<strong>边缘的权重(weights)</strong>。它是分配给边缘的数值，描述了遍历该边缘的成本。边的权重越小，遍历它的成本就越低。基于此，将权重分配给边缘的图称为<strong>加权图</strong>：<br><img src="https://img-blog.csdnimg.cn/15925167fb9c48648c311f39b2eebc80.png" alt="在这里插入图片描述"></p>
<h1 id="2-图的三种存储方式"><a href="#2-图的三种存储方式" class="headerlink" title="2    图的三种存储方式"></a>2    图的三种存储方式</h1><p>&emsp;&emsp;一般来说，为了更简单的实现，任何给定图的节点都用数字(从零开始)标记，如果需要字符的方式进行定义节点名称，可用字典的方式进行转换。我将使用以下加权有向图作为后面部分中的示例：</p>
<p><img src="https://img-blog.csdnimg.cn/de223cb8122a4d11a8d7d57818a9e96a.png" alt="在这里插入图片描述"><br>之所以选择加权有向图作为示例，因为它说明了大多数实现的细微差别。一般来说，加权图和未加权图之间的切换非常简单。在有向图和无向图之间切换也是一件非常容易的事情。如果需要，我们将在以下部分中介绍这些主题中的每一个。</p>
<h2 id="2-1-边列表-List-of-Edges"><a href="#2-1-边列表-List-of-Edges" class="headerlink" title="2.1    边列表(List of Edges)"></a>2.1    边列表(List of Edges)</h2><h3 id="2-1-1-原理"><a href="#2-1-1-原理" class="headerlink" title="2.1.1    原理"></a>2.1.1    原理</h3><p>&emsp;&emsp;边列表是表示图的最简单方法，但由于它缺乏适当的结构，因此通常仅用于说明目的。我们将使用它来解释一些图算法，因为它几乎没有开销，并且允许我们专注于算法实现，而不是图本身的实现。每条边连接两个节点，并且可能分配给它一个权重。因此，每条边都由一个列表以下列方式表示：<code>[node1, node2, weight]</code>，其中 <code>weight</code> 是一个可选属性(如果是未加权的图，则不需要)。顾名思义，边列表将图形存储为以所述方式表示的边列表。<img src="https://img-blog.csdnimg.cn/557d6137624f447cb89c53b66f75f746.png" alt="在这里插入图片描述"><br>边列表实际上是一张表格。该表的每一行代表一个边，它的两个节点和该边的权重。由于这是一个加权图，边表示中的节点顺序说明了边的方向，即只能从 <code>node1</code> 到 <code>node2</code> 遍历边。在使用边列表处理无向图时，与有向图不同的地方就是权重的定义，有向图定义一个方向，无向图定义两个方向。在下面实现时会详细注释。<br><strong>优点：</strong></p>
<ul>
<li>便于实现和理解</li>
<li>非常适合说明目的</li>
<li>按定义表示图(一组节点和一组边)</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>不适合在实际程序中应用</li>
<li>没有使用任何的数据结构进行构造</li>
<li>效率低</li>
<li>不够通用，不能互换地表示有向图和无向图</li>
</ul>
<h3 id="2-1-2-Python-实现"><a href="#2-1-2-Python-实现" class="headerlink" title="2.1.2    Python 实现"></a>2.1.2    Python 实现</h3><p>首先根据边列表的定义编写一个 <code>Graph</code> 类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>() :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_nodes, directed = <span class="literal">True</span></span>):</span><br><span class="line">        self.num_of_nodes = num_of_nodes</span><br><span class="line">        self.directed = directed</span><br><span class="line">        self.list_of_edges = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_edge</span>(<span class="params">self, node1, node2, weight</span>):</span><br><span class="line">        <span class="comment">#从 node1 到 node2 添加权重</span></span><br><span class="line">        self.list_of_edges.append([node1, node2, weight])</span><br><span class="line"></span><br><span class="line">        <span class="comment">#如果是无向图，则需要定义 node2 到 node1 的权重</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.directed :</span><br><span class="line">            self.list_of_edges.append([node2, node1, weight])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#打印边和节点</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_edge_list</span>(<span class="params">self</span>):</span><br><span class="line">        num_of_edges = <span class="built_in">len</span>(self.list_of_edges)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_of_edges) :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;Edges : <span class="subst">&#123;i + <span class="number">1</span>&#125;</span> : <span class="subst">&#123;self.list_of_edges[i]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>此实现非常简单，一个图被表示为一个边列表，其中每条边都由一个列表以下列方式表示：<code>[node1, node2, weight]</code>。因此，图实际上是一个矩阵，其中每一行代表一条边。测试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    graph = Graph(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">0</span>, <span class="number">25</span>)</span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    graph.add_edge(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    graph.add_edge(<span class="number">1</span>, <span class="number">4</span>, <span class="number">15</span>)</span><br><span class="line">    graph.add_edge(<span class="number">4</span>, <span class="number">2</span>, <span class="number">7</span>)</span><br><span class="line">    graph.add_edge(<span class="number">4</span>, <span class="number">3</span>, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">    graph.print_edge_list()</span><br></pre></td></tr></table></figure>
<p>首先，示例图有 <code>5</code> 个节点，因此可以使用构造函数创建一个包含 <code>5</code> 个节点的图。然后将所有边添加到创建的图形并打印图形。这将输出以下内容：<br><img src="https://img-blog.csdnimg.cn/83ae74de1db041538e3b09cfde3da2fc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>此输出与我们在前几节中显示的边示例列表一致：<br><img src="https://img-blog.csdnimg.cn/64c18f2e5114438180bf233fd7119fd0.png" alt="在这里插入图片描述"><br>如果想定义无向图，使用 <code>graph = Graph(5, directed = False)</code> 即可。</p>
<h2 id="2-2-邻接矩阵-Adjacency-Matrix"><a href="#2-2-邻接矩阵-Adjacency-Matrix" class="headerlink" title="2.2    邻接矩阵(Adjacency Matrix)"></a>2.2    邻接矩阵(Adjacency Matrix)</h2><h3 id="2-2-1-原理"><a href="#2-2-1-原理" class="headerlink" title="2.2.1    原理"></a>2.2.1    原理</h3><p>&emsp;&emsp;邻接矩阵是表示图的最流行的方法之一，因为它是最容易理解和实现的方法，并且适用于许多应用程序。它使用 <code>nxn</code> 矩阵来表示图( <code>n</code> 是图中的节点数)。换句话说，行数和列数等于图中的节点数。最初，矩阵的每个字段都设置为特殊值 <code>- inf</code>、<code>0</code>、<code>-1</code>、<code>False</code> 等，这表明图中不存在节点。在初始阶段之后，您可以通过填充适当的字段 <code>1</code>(对于未加权图)或边权重(对于加权图)来添加图的每条边。<br>&emsp;&emsp;提到的矩阵本质上是一个表格，每一行和每一列都代表图形的一个节点。例如，下标为 <code>3</code> 的行指的是节点 <code>3</code>，因此可以使用邻接矩阵来仅表示带有编号标记节点的图。第 <code>i</code> 行和第 <code>j</code> 列的值不是初始值则说明节点 <code>i</code> 和 <code>j</code> 之间的边或者权重的存在。邻接图展示如下：<br><img src="https://img-blog.csdnimg.cn/d2e1867db35e409ea4c516e99b2d0d99.png" alt="在这里插入图片描述"><br>此图中有 <code>n</code> 节点。因此，我们创建了一个包含 <code>n</code> 行和列的表，并将所有单元格初始化为 <code>0</code>，表示任何两个节点之间没有边的特殊值。由于示例图是加权和定向的，因此需要：</p>
<ul>
<li>遍历图中的每条边</li>
<li>确定该边的开始和结束节点</li>
<li>确定该边的权重</li>
<li>用权重值填充矩阵的适当字段</li>
</ul>
<p>以边<code>3-4</code>为例。起始节点是 <code>3</code>，结束节点是 <code>4</code>，所以需要填写下标为 <code>[3, 4]</code> 的值。从图像中，可以读取边缘的权重为 <code>11</code>，因此使用填充 <code>11</code>。现在已经标记了边缘的存在 <code>3-4</code>。重复该过程，直到标记了图中的每条边。<br><strong>优点：</strong></p>
<ul>
<li>低查找时间，可以在 <code>O(1)</code> 的时间内确定是否存在边</li>
<li>添加/删除边需要 <code>O(1)</code> 时间</li>
<li>便于实现和理解</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>花费更多的空间 <code>O(num_of_nodes²)</code></li>
<li>添加节点需要 <code>O(num_of_nodes²)</code> 时间</li>
<li>查找所选节点的相邻节点的成本很高 <code>O(num_of_nodes)</code></li>
<li>遍历图的成本很高 <code>O(num_of_nodes²)</code></li>
<li>标记/枚举边的成本很高 <code>O(num_of_nodes²)</code></li>
</ul>
<h3 id="2-2-2-Python-实现"><a href="#2-2-2-Python-实现" class="headerlink" title="2.2.2    Python 实现"></a>2.2.2    Python 实现</h3><p>&emsp;&emsp;邻接矩阵本质上是一个简单的 <code>nxn</code> 矩阵，其中 <code>n</code> 是图中的节点数。因此，我们将其实现为具有 <code>num_of_nodes</code> 行和列的矩阵。我们将使用列表推导来构造它并将所有字段初始化为 <code>0</code>。在这种情况下，<code>0</code> 是一个特殊值，指的是图中最初没有边，添加边非常简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_nodes, directed = <span class="literal">True</span></span>):</span><br><span class="line">        self.num_of_nodes = num_of_nodes</span><br><span class="line">        self.directed = directed</span><br><span class="line">        self.edge_matrix = [[<span class="number">0</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_of_nodes)] <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_of_nodes)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_edge</span>(<span class="params">self, node1, node2, weight</span>):</span><br><span class="line">        self.edge_matrix[node1][node2] = weight</span><br><span class="line"></span><br><span class="line">        <span class="comment">#无向图</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.directed :</span><br><span class="line">            self.edge_matrix[node2][node1] = weight</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_edge_matrix</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_of_nodes) :</span><br><span class="line">            <span class="built_in">print</span>(self.edge_matrix[i])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>测试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    graph = Graph(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">0</span>, <span class="number">25</span>)</span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    graph.add_edge(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    graph.add_edge(<span class="number">1</span>, <span class="number">4</span>, <span class="number">15</span>)</span><br><span class="line">    graph.add_edge(<span class="number">4</span>, <span class="number">2</span>, <span class="number">7</span>)</span><br><span class="line">    graph.add_edge(<span class="number">4</span>, <span class="number">3</span>, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">    graph.print_edge_matrix()</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="https://img-blog.csdnimg.cn/6defea9fc5ec46d1b6e0301ce1bc1671.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>正如预期的那样，输出与我们在前面展示的矩阵相同：<br><img src="https://img-blog.csdnimg.cn/88f9d95bf2f94e448017db2d024319a5.png" alt="在这里插入图片描述"><br>如果想构造无向图，使用以下方式构造函数：<code>graph = Graph(5, directed = False)</code>。</p>
<h2 id="2-3-邻接表-Adjacency-List"><a href="#2-3-邻接表-Adjacency-List" class="headerlink" title="2.3    邻接表(Adjacency List)"></a>2.3    邻接表(Adjacency List)</h2><h3 id="2-3-1-原理"><a href="#2-3-1-原理" class="headerlink" title="2.3.1    原理"></a>2.3.1    原理</h3><p>&emsp;&emsp;邻接表是存储图的最有效方式。它仅存储图中存在的边，这与邻接矩阵相反，邻接矩阵显式存储所有可能的边，包括存在的和不存在的。邻接矩阵最初被开发为仅表示未加权的图，但以最有效的方式是仅使用一个数组来存储一个图。<br>&emsp;&emsp;我们可以仅使用 12 个整数值的数组来表示示例图。将其与邻接矩阵进行比较，邻接矩阵由 <code>n²</code> 元素组成(<code>n</code> 是图中的节点数)，其中邻接列表仅包含 <code>n+e</code> 个元素，其中 <code>n</code> 表示节点数，<code>e</code> 表示图的边的数量。<br><img src="https://img-blog.csdnimg.cn/84b84235bdef40e785a54061f3255ba5.png" alt="在这里插入图片描述"><br>构建邻接表首先需要知道的是图中节点的数量，在示例图中，有 <code>5</code> 个节点，因此列表中的前 <code>5</code> 个位置代表这些节点，比如下标 <code>1</code> 代表第 <code>1</code> 个节点。索引 <code>i</code> 上的值是指列表中的索引，可以在其中找到节点 <code>i</code> 的相邻节点的索引。例如，索引 <code>0</code> 上的值是 <code>5</code>，这意味着应该查看邻接列表中的索引 <code>5</code> 以查找哪些节点连接到节点 <code>0</code>，即节点 <code>0</code>、<code>1</code> 和 <code>2</code>，索引 <code>5</code> 表示邻接节点的开始索引，但是我们怎么知道什么时候应该停止寻找相邻节点？这很简单，查看列表中 <code>0</code> 节点旁边的索引上的值。下一个索引是 <code>1</code>，它代表节点 <code>1</code>，它的值是 <code>8</code>，意思是你可以在邻接表中从索引 <code>8</code> 开始找到与节点 <code>1</code> 相邻的节点。因此，与节点 <code>0</code> 相邻的节点作为索引 <code>5</code> 和 <code>8</code> 之间列表的值。<br>&emsp;&emsp;为了更容易理解这种结构，可以以更结构化的方式重新排列邻接列表的元素。如果这样做，就会看到生成的结构看起来很像一个链表：</p>
<p><img src="https://img-blog.csdnimg.cn/d81218dd751242b2a0993574290418fd.png#pic_center" alt="在这里插入图片描述"><br>此外，链表的结构与字典非常相似。它有一组键(<strong>节点</strong>)，以及每个键的一组值(<strong>一组与键节点相邻的节点</strong>)。如果要表示加权图，则必须找到一种在相邻节点之外存储权重的方法（如下图所示）。下图显示了示例图的邻接列表包括有和没有权重：<br><img src="https://img-blog.csdnimg.cn/9d0573742ea44431866bd61d6a723813.png" alt="在这里插入图片描述"><br>当查看加权相邻列表时，可以轻松构建示例图的边集。节点 <code>0</code> 具有三个相邻节点：<code>0</code>、<code>1</code>、<code>2</code>，这意味着图具有边 <code>0-0</code>、<code>0-1</code> 和 <code>0-2</code>。这些边的权重也可以从邻接表中读取，边 <code>0-0</code> 的权重为 <code>25</code>，边 <code>0-1</code> 的权重为 5，依此类推。<br><strong>优点：</strong></p>
<ul>
<li>快速地找到所选节点的相邻节点 <code>O(1)</code></li>
<li>对密度较低的图有效(与节点数相比，边数较少)</li>
<li>可以将它用于字母和数字标记的节点</li>
<li>遍历图的成本低 <code>O(length_of_list)</code>，<code>length_of_list</code> 长度等于图中节点数和边数之和</li>
<li>标记/枚举边的成本低 <code>O(length_of_list)</code></li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>查找花费时间多 <code>O(length_of_list)</code></li>
<li>移除边的成本高 <code>O(length_of_list)</code></li>
</ul>
<h3 id="2-3-2-Python-实现"><a href="#2-3-2-Python-实现" class="headerlink" title="2.3.2    Python 实现"></a>2.3.2    Python 实现</h3><p>&emsp;&emsp;正如我们在前面所解释的，在 Python 中表示邻接列表的最佳方式是使用<strong>字典</strong>——它具有一组键和对应的值。我们将为每个节点创建一个键，并为每个键创建一组相邻节点。这样，我们将有效地为图中的每个节点创建一组相邻节点。本质上，相邻节点代表关键节点和相邻节点之间的边，因此我们需要为每条边分配权重。因此要将每个相邻节点表示为一个元组：一对相邻节点的名称和该边的权重：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>() :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_nodes, directed = <span class="literal">True</span></span>):</span><br><span class="line">        self.num_of_nodes = num_of_nodes</span><br><span class="line">        self.directed = directed</span><br><span class="line">        self.adjacency_list = &#123;node : <span class="built_in">set</span>() <span class="keyword">for</span> node <span class="keyword">in</span> <span class="built_in">range</span>(num_of_nodes)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_edge</span>(<span class="params">self, node1, node2, weight</span>):</span><br><span class="line">        self.adjacency_list[node1].add((node2, weight))</span><br><span class="line"></span><br><span class="line">        <span class="comment">#无向图</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.directed :</span><br><span class="line">            self.adjacency_list[node2].add((node1, weight))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_adj_list</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> self.adjacency_list.keys() :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;node <span class="subst">&#123;key&#125;</span> : <span class="subst">&#123;self.adjacency_list[key]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>测试：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    graph = Graph(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">0</span>, <span class="number">25</span>)</span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">    graph.add_edge(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    graph.add_edge(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    graph.add_edge(<span class="number">1</span>, <span class="number">4</span>, <span class="number">15</span>)</span><br><span class="line">    graph.add_edge(<span class="number">4</span>, <span class="number">2</span>, <span class="number">7</span>)</span><br><span class="line">    graph.add_edge(<span class="number">4</span>, <span class="number">3</span>, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">    graph.print_adj_list()</span><br></pre></td></tr></table></figure>
<p>输出：<img src="https://img-blog.csdnimg.cn/4b01e0bd88f94695a351ca604bd25fb4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>输出与前面描述的链表和字典相同：<br><img src="https://img-blog.csdnimg.cn/64fb5caa454346f9b19d40f06e514a04.png" alt="在这里插入图片描述"><br>如果想构造无向图，使用以下方式构造函数：<code>graph = Graph(5, directed = False)</code>。</p>
]]></content>
      <categories>
        <category>Python</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>图</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode——哈希表经典例题</title>
    <url>/2022/06/05/LeetCode%E2%80%94%E2%80%94%E5%93%88%E5%B8%8C%E8%A1%A8%E7%BB%8F%E5%85%B8%E4%BE%8B%E9%A2%98/</url>
    <content><![CDATA[<h2 id="242-有效的字母异位词"><a href="#242-有效的字母异位词" class="headerlink" title="242. 有效的字母异位词"></a>242. 有效的字母异位词</h2><p>&emsp;&emsp;给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。注意：若 s 和 t 中每个字符出现的次数都相同，则称 s 和 t 互为字母异位词。<br>示例 1:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入: s = <span class="string">&quot;anagram&quot;</span>, t = <span class="string">&quot;nagaram&quot;</span></span><br><span class="line">输出: true</span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入: s = <span class="string">&quot;rat&quot;</span>, t = <span class="string">&quot;car&quot;</span></span><br><span class="line">输出: false</span><br></pre></td></tr></table></figure>
<p>思路：定义一个数组叫做 <code>record</code>，大小为 26就可以了，初始化为0，因为题目规定两个字符串的的字符均是小写字母。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isAnagram</span>(<span class="params">self, s: <span class="built_in">str</span>, t: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        record = [<span class="number">0</span>] * <span class="number">26</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#记录 s 中的个字母出现的次数</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(s)) :</span><br><span class="line">            record[<span class="built_in">ord</span>(s[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#记录 t 中的个字母出现的次数</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(t)) :</span><br><span class="line">            record[<span class="built_in">ord</span>(t[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)] -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#record数组如果有的元素不为零0，说明字符串s和t 一定是谁多了字符或者谁少了字符。</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(record)) :</span><br><span class="line">            <span class="keyword">if</span> record[i] != <span class="number">0</span> :</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h2 id="349-两个数组的交集"><a href="#349-两个数组的交集" class="headerlink" title="349. 两个数组的交集"></a>349. 两个数组的交集</h2><p>&emsp;&emsp;给定两个数组 <code>nums1</code> 和 <code>nums2</code> ，返回 它们的交集 。输出结果中的每个元素一定是 唯一 的。我们可以 不考虑输出结果的顺序 。</p>
<p>示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums1 = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], nums2 = [<span class="number">2</span>,<span class="number">2</span>]</span><br><span class="line">输出：[<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p>示例 2：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums1 = [<span class="number">4</span>,<span class="number">9</span>,<span class="number">5</span>], nums2 = [<span class="number">9</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">8</span>,<span class="number">4</span>]</span><br><span class="line">输出：[<span class="number">9</span>,<span class="number">4</span>]</span><br><span class="line">解释：[<span class="number">4</span>,<span class="number">9</span>] 也是可通过的</span><br></pre></td></tr></table></figure>
<p>思路：使用 <code>set</code> 对两个数组进行去重，然后求交集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">intersection</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        lst = <span class="built_in">list</span>(<span class="built_in">set</span>(nums1) &amp; <span class="built_in">set</span>(nums2))</span><br><span class="line">        <span class="keyword">return</span> lst</span><br></pre></td></tr></table></figure>
<h2 id="202-快乐数"><a href="#202-快乐数" class="headerlink" title="202. 快乐数"></a>202. 快乐数</h2><p>&emsp;&emsp;编写一个算法来判断一个数 n 是不是快乐数。<strong>「快乐数」</strong> 定义为：</p>
<ul>
<li>对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和。</li>
<li>然后重复这个过程直到这个数变为 1，也可能是 无限循环 但始终变不到1。</li>
<li>如果这个过程 结果为 1，那么这个数就是快乐数。</li>
</ul>
<p>如果 <code>n</code> 是 快乐数 就返回 <code>true</code> ；不是，则返回 <code>false</code> 。</p>
<p>示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：n = <span class="number">19</span></span><br><span class="line">输出：true</span><br><span class="line">解释：</span><br><span class="line"><span class="number">12</span> + <span class="number">92</span> = <span class="number">82</span></span><br><span class="line"><span class="number">82</span> + <span class="number">22</span> = <span class="number">68</span></span><br><span class="line"><span class="number">62</span> + <span class="number">82</span> = <span class="number">100</span></span><br><span class="line"><span class="number">12</span> + 02 + 02 = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：n = <span class="number">2</span></span><br><span class="line">输出：false</span><br></pre></td></tr></table></figure>
<p>思路：如果一个数不是快乐数，则其之后的树的平方和一定会出现重复现象的，否则就进入死循环了。所以这道题目使用哈希法，来判断这个 <code>sum</code> 是否重复出现，如果重复了就是 <code>return false</code>， 否则一直找到 <code>sum</code> 为1为止。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">isHappy</span>(<span class="params">self, n: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="comment">#计算每次的平方和</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">calculate_happy</span>(<span class="params">num</span>) :</span><br><span class="line">            s = <span class="number">0</span></span><br><span class="line">            <span class="keyword">while</span> num :</span><br><span class="line">                s += (num % <span class="number">10</span>) * (num % <span class="number">10</span>)</span><br><span class="line">                num //= <span class="number">10</span></span><br><span class="line">            <span class="keyword">return</span> s </span><br><span class="line"></span><br><span class="line">        <span class="comment">#哈希记录平方和</span></span><br><span class="line">        record = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span> :</span><br><span class="line">            n = calculate_happy(n) </span><br><span class="line">            <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="comment">#如果出现重复的平方和，说明这个数不是快乐数</span></span><br><span class="line">            <span class="keyword">if</span> n <span class="keyword">in</span> record :</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span> </span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                record.add(n)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h2 id="1-两数之和"><a href="#1-两数之和" class="headerlink" title="1. 两数之和"></a>1. 两数之和</h2><p>&emsp;&emsp;给定一个整数数组 <code>nums</code> 和一个整数目标值 <code>target</code>，请你在该数组中找出 和为目标值 <code>target</code>  的那 两个 整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。你可以按任意顺序返回答案。</p>
<p>示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = [<span class="number">2</span>,<span class="number">7</span>,<span class="number">11</span>,<span class="number">15</span>], target = <span class="number">9</span></span><br><span class="line">输出：[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">解释：因为 nums[<span class="number">0</span>] + nums[<span class="number">1</span>] == <span class="number">9</span> ，返回 [<span class="number">0</span>, <span class="number">1</span>] 。</span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = [<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>], target = <span class="number">6</span></span><br><span class="line">输出：[<span class="number">1</span>,<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p>思路：以元素为 <code>key</code>，下标为 <code>value</code> 对数组进行统计，遍历数组，如果能在字典中找到 <code>target - nums[i]</code> 说明找到了解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">twoSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        dict_val = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> idx, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(nums) :</span><br><span class="line">            <span class="keyword">if</span> target - val <span class="keyword">not</span> <span class="keyword">in</span> dict_val :</span><br><span class="line">                dict_val[val] = idx</span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                <span class="keyword">return</span> [idx, dict_val[target - val]]</span><br></pre></td></tr></table></figure>
<h2 id="15-三数之和"><a href="#15-三数之和" class="headerlink" title="15. 三数之和"></a>15. 三数之和</h2><p>&emsp;&emsp;给你一个包含 <code>n</code> 个整数的数组 <code>nums</code>，判断 <code>nums</code> 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。<strong>注意</strong>：答案中不可以包含重复的三元组。</p>
<p>示例一：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = [-<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,-<span class="number">1</span>,-<span class="number">4</span>]</span><br><span class="line">输出：[[-<span class="number">1</span>,-<span class="number">1</span>,<span class="number">2</span>],[-<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = []</span><br><span class="line">输出：[]</span><br></pre></td></tr></table></figure>
<p>思路：这道题可以先固定一个数，然后通过解决 <strong>两数之和</strong> 的方法进行求解，但是在 <strong>两数之和</strong> 这道题中，我们只需要求解一个解，而这道题可能有多个解，且题目要求不能出现重复的解，因此如果使用哈希表的方法社涉及大量的去重操作。效率低且容易出错，这里介绍双指针的方法，首先将数组排序，然后有一层 for 循环，i从下标0的地方开始，同时定一个下标 <code>left</code> 定义在 i+1 的位置上，定义下标right 在数组结尾的位置上。依然还是在数组中找到 abc 使得a + b +c =0，我们这里相当于 <code>a = nums[i]，b = nums[left]，c = nums[right]</code>。接下来如果 <code>nums[i] + nums[left] + nums[right] &gt; 0</code> 就说明 此时三数之和大了，因为数组是排序后了，所以 <code>right</code> 下标就应该向左移动，这样才能让三数之和小一些。如果 <code>nums[i] + nums[left] + nums[right] &lt; 0</code> 说明 此时 三数之和小了，<code>left</code> 就向右移动，才能让三数之和大一些，直到 <code>left</code> 与 <code>right</code> 相遇为止。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">threeSum</span>(<span class="params">self, nums</span>):</span><br><span class="line">        ans = []</span><br><span class="line">        nums.sort()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)) :</span><br><span class="line">            <span class="comment">#如果第一个数大于0，则找不到解</span></span><br><span class="line">            <span class="keyword">if</span> nums[i] &gt; <span class="number">0</span> :</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            left = i + <span class="number">1</span></span><br><span class="line">            <span class="comment">#右指针指向数组的末尾</span></span><br><span class="line">            right = <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">#对第一个元素去重</span></span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>] :</span><br><span class="line">                <span class="keyword">continue</span> </span><br><span class="line">            </span><br><span class="line">            <span class="keyword">while</span> left &lt; right :</span><br><span class="line">                total = nums[i] + nums[left] + nums[right]</span><br><span class="line"></span><br><span class="line">                <span class="comment">#如果和大于0，则要减小和即让右指针左移</span></span><br><span class="line">                <span class="keyword">if</span> total &gt; <span class="number">0</span> :</span><br><span class="line">                    right -= <span class="number">1</span></span><br><span class="line">                <span class="comment">#如果和小于0，则要增大和即让左指针右移</span></span><br><span class="line">                <span class="keyword">elif</span> total &lt; <span class="number">0</span> :</span><br><span class="line">                    left += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span> :</span><br><span class="line">                    <span class="comment">#找到一组解</span></span><br><span class="line">                    ans.append([nums[i], nums[left], nums[right]])</span><br><span class="line">                    <span class="comment">#对左边去重</span></span><br><span class="line">                    <span class="keyword">while</span> left != right <span class="keyword">and</span> nums[left] == nums[left + <span class="number">1</span>] :</span><br><span class="line">                        left += <span class="number">1</span></span><br><span class="line">                    <span class="comment">#对右边去重</span></span><br><span class="line">                    <span class="keyword">while</span> left != right <span class="keyword">and</span> nums[right] == nums[right - <span class="number">1</span>] :</span><br><span class="line">                        right -= <span class="number">1</span></span><br><span class="line">                    <span class="comment">#同时收缩左右指针</span></span><br><span class="line">                    left += <span class="number">1</span></span><br><span class="line">                    right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans </span><br></pre></td></tr></table></figure>
<h2 id="18-四数之和"><a href="#18-四数之和" class="headerlink" title="18. 四数之和"></a>18. 四数之和</h2><p>&emsp;&emsp;给你一个由 n 个整数组成的数组 <code>nums</code> ，和一个目标值 <code>target</code> 。请你找出并返回满足下述全部条件且不重复的四元组 <code>[nums[a], nums[b], nums[c], nums[d]]</code>（若两个四元组元素一一对应，则认为两个四元组重复）：</p>
<ul>
<li><code>0 &lt;= a, b, c, d &lt; n</code></li>
<li><code>a</code>、<code>b</code>、<code>c</code> 和 <code>d</code> 互不相同</li>
<li><code>nums[a] + nums[b] + nums[c] + nums[d] == target</code></li>
</ul>
<p>示例 1：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = [<span class="number">1</span>,<span class="number">0</span>,-<span class="number">1</span>,<span class="number">0</span>,-<span class="number">2</span>,<span class="number">2</span>], target = <span class="number">0</span></span><br><span class="line">输出：[[-<span class="number">2</span>,-<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>],[-<span class="number">2</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">2</span>],[-<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<p>示例二：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = [<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>], target = <span class="number">8</span></span><br><span class="line">输出：[[<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>]]</span><br></pre></td></tr></table></figure>
<p>思路：本题跟 <strong>三数之和</strong> 解法一样，但要注意不要判断 <code>nums[i] &gt; target</code> 就返回了，三数之和可以通过 <code>nums[i] &gt; 0</code> 就返回了，因为 0 已经是确定的数了，四数之和这道题目 <code>target</code> 是任意值。类似的，五叔之和，六叔之和都可以这样解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fourSum</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        nums.sort()</span><br><span class="line">        ans = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nums)) :</span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span> <span class="keyword">and</span> nums[i] == nums[i - <span class="number">1</span>] :</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(nums)) :</span><br><span class="line">                <span class="keyword">if</span> j &gt; i + <span class="number">1</span> <span class="keyword">and</span> nums[j] == nums[j - <span class="number">1</span>] :</span><br><span class="line">                    <span class="keyword">continue</span> </span><br><span class="line"></span><br><span class="line">                left = j + <span class="number">1</span></span><br><span class="line">                right = <span class="built_in">len</span>(nums) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">while</span> left &lt; right :</span><br><span class="line">                    total = nums[i] + nums[j] + nums[left] + nums[right]</span><br><span class="line">                    <span class="keyword">if</span> total &gt; target :</span><br><span class="line">                        right -= <span class="number">1</span></span><br><span class="line">                    <span class="keyword">elif</span> total &lt; target :</span><br><span class="line">                        left += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">else</span> :</span><br><span class="line">                        ans.append([nums[i], nums[j], nums[left], nums[right]])</span><br><span class="line">                        <span class="keyword">while</span> left != right <span class="keyword">and</span> nums[left] == nums[left + <span class="number">1</span>] :</span><br><span class="line">                            left += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">while</span> left != right <span class="keyword">and</span> nums[right] == nums[right - <span class="number">1</span>] :</span><br><span class="line">                            right -= <span class="number">1</span></span><br><span class="line">                        left += <span class="number">1</span></span><br><span class="line">                        right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> ans </span><br></pre></td></tr></table></figure>
<h2 id="454-四数相加-II"><a href="#454-四数相加-II" class="headerlink" title="454. 四数相加 II"></a>454. 四数相加 II</h2><p>&emsp;&emsp;给你四个整数数组<code>nums1</code>、<code>nums2</code>、<code>nums3</code> 和 <code>nums4</code> ，数组长度都是 <code>n</code> ，请你计算有多少个元组 <code>(i, j, k, l)</code> 能满足：</p>
<ul>
<li><code>0 &lt;= i, j, k, l &lt; n</code></li>
<li><code>nums1[i] + nums2[j] + nums3[k] + nums4[l] == 0</code></li>
</ul>
<p>示例 1：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums1 = [<span class="number">1</span>,<span class="number">2</span>], nums2 = [-<span class="number">2</span>,-<span class="number">1</span>], nums3 = [-<span class="number">1</span>,<span class="number">2</span>], nums4 = [<span class="number">0</span>,<span class="number">2</span>]</span><br><span class="line">输出：<span class="number">2</span></span><br><span class="line">解释：</span><br><span class="line">两个元组如下：</span><br><span class="line"><span class="number">1.</span> (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>) -&gt; nums1[<span class="number">0</span>] + nums2[<span class="number">0</span>] + nums3[<span class="number">0</span>] + nums4[<span class="number">1</span>] = <span class="number">1</span> + (-<span class="number">2</span>) + (-<span class="number">1</span>) + <span class="number">2</span> = <span class="number">0</span></span><br><span class="line"><span class="number">2.</span> (<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>) -&gt; nums1[<span class="number">1</span>] + nums2[<span class="number">1</span>] + nums3[<span class="number">0</span>] + nums4[<span class="number">0</span>] = <span class="number">2</span> + (-<span class="number">1</span>) + (-<span class="number">1</span>) + <span class="number">0</span> = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>示例 2：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums1 = [<span class="number">0</span>], nums2 = [<span class="number">0</span>], nums3 = [<span class="number">0</span>], nums4 = [<span class="number">0</span>]</span><br><span class="line">输出：<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>思路：这道题目是四个独立的数组，只要找到 <code>nums[i] + nums[j] + nums[k] + nums[l] = 0</code> 就可以，不用考虑有重复的四个元素相加等于0的情况，因此适合使用哈希表法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fourSumCount</span>(<span class="params">self, nums1: <span class="type">List</span>[<span class="built_in">int</span>], nums2: <span class="type">List</span>[<span class="built_in">int</span>], nums3: <span class="type">List</span>[<span class="built_in">int</span>], nums4: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">        hashmap = &#123;&#125;</span><br><span class="line">        n = <span class="built_in">len</span>(nums1)</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="comment">#哈希统计A和B的数组之和的次数</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n) :</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n) :</span><br><span class="line">                <span class="keyword">if</span> (nums1[i] + nums2[j]) <span class="keyword">not</span> <span class="keyword">in</span> hashmap :</span><br><span class="line">                    hashmap[nums1[i] + nums2[j]] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    hashmap[nums1[i] + nums2[j]] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n) :</span><br><span class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(n) :</span><br><span class="line">                sum_ = nums3[k] + nums4[l]</span><br><span class="line">                <span class="comment">#直接相加-(k + l)的次数，因为本道题允许重复的解出现</span></span><br><span class="line">                <span class="keyword">if</span> -sum_ <span class="keyword">in</span> hashmap :</span><br><span class="line">                    count += hashmap[-sum_]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> count </span><br></pre></td></tr></table></figure>
<h2 id="383-赎金信"><a href="#383-赎金信" class="headerlink" title="383. 赎金信"></a>383. 赎金信</h2><p>&emsp;&emsp;给你两个字符串：<code>ransomNote</code> 和 <code>magazine</code> ，判断 <code>ransomNote</code> 能不能由 <code>magazine</code> 里面的字符构成。如果可以，返回 <code>true</code> ；否则返回 <code>false</code> 。<code>magazine</code> 中的每个字符只能在 <code>ransomNote</code> 中使用一次。提示：</p>
<ul>
<li>1 &lt;= ransomNote.length, magazine.length &lt;= 105</li>
<li>ransomNote 和 magazine 由小写英文字母组成</li>
</ul>
<p>思路：这道题跟 <strong>有效的字母异位词</strong> 差不多，哈希表法解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">canConstruct</span>(<span class="params">self, ransomNote: <span class="built_in">str</span>, magazine: <span class="built_in">str</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        record = [<span class="number">0</span>] * <span class="number">26</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(magazine)) :</span><br><span class="line">            record[<span class="built_in">ord</span>(magazine[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(ransomNote)) :</span><br><span class="line">            record[<span class="built_in">ord</span>(ransomNote[i]) - <span class="built_in">ord</span>(<span class="string">&#x27;a&#x27;</span>)] -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">26</span>) :</span><br><span class="line">            <span class="keyword">if</span> record[i] &lt; <span class="number">0</span> :</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 中的图：Dijkstra 算法</title>
    <url>/2022/06/05/Python-%E4%B8%AD%E7%9A%84%E5%9B%BE%EF%BC%9ADijkstra-%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>﻿## 介绍</p>
<p>&emsp;&emsp;图是最有用的数据结构之一。它们可用于对几乎所有事物进行建模——对象关系和网络是最常见的。图像可以表示为网格状的像素图，句子可以表示为单词的图。图表被用于各个领域，从制图到社会心理学，当然它们在计算机科学中也被广泛使用。因此图搜索和遍历起着重要的计算作用。<strong>Dijkstra 算法</strong>旨在找到 <strong>图中节点</strong> 之间的最短路径。它是由荷兰计算机科学家 Edsger Wybe Dijkstra 于 1956 年在思考从鹿特丹到格罗宁根的最短路线时设计的。<strong>Dijkstra 算法</strong> 多年来一直在发生变化，并且存在各种版本和变体。最初用于计算两个节点之间的最短路径。由于它的工作方式 ，适用于计算起始节点和图中每个其他节点之间的最短路径。这种方式可用于生成 <strong>最短路径树</strong>，该树由两个节点以及所有其他节点之间的最短路径组成。然后你可以修剪掉你不感兴趣的树，得到两个节点之间的最短路径，但你不可避免地必须计算整个树，这是 <strong>Dijkstra 算法</strong> 的一个缺点，它不适合大型图。</p>
<h2 id="Dijkstra-算法"><a href="#Dijkstra-算法" class="headerlink" title="Dijkstra 算法"></a>Dijkstra 算法</h2><p>&emsp;&emsp;<strong>Dijkstra 算法</strong> 适用于无向、连接、加权图，<strong>Dijkstra 算法</strong> 可以求出源节点到其他所有节点的最短路径。<br>&emsp;&emsp;一开始，我们要创建一组已访问顶点，以跟踪所有已分配正确最短路径的顶点。我们还需要设置图中所有顶点的“成本”（通向它的当前最短路径的长度）。开始时所有成本都将设置为 <strong>“无穷大(inf)”</strong> ，以确保我们可以与之比较的所有其他成本都小于起始成本。唯一的例外是第一个起始顶点的成本——这个顶点的成本为 0，因为它没有通往自身的路径——标记为 源节点 <code>s</code>。然后依据以下三个规则，直到遍历整个图：</p>
<ul>
<li>每次从未标记的节点中选择距离出发点最近的节点，标记，收录到最优路径集合中。</li>
<li>对于当前节点 <code>n</code> 和其的邻居节点 <code>m</code> 如果 <code>cheapestPath(s, n)</code> + <code>cheapestPath(n, m)</code> &lt; <code>cheapestPath(s, m)</code>，则更新 <code>s</code> 到 <code>m</code> 的最短路径为 <code>cheapestPath(s, n)</code> + <code>cheapestPath(n, m)</code>。</li>
<li>且每次更新最短路径时会保存该节点的前节点。</li>
</ul>
<p>下面用一个无向、加权、连通图来解释上述规则原理：<br><img src="https://img-blog.csdnimg.cn/0670f8adaa494ae0a62bbc218e5bafa1.png#pic_cetner" alt="在这里插入图片描述"><br>假设 Vertex 0 为起点(源节点)。我们将把图中顶点的初始成本设置为无穷大，除了起始顶点：</p>
<p><img src="https://img-blog.csdnimg.cn/ecb846e5938545198777d7137830f21a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>我们选择成本最低的顶点——即 Vertex 0。我们将其标记为已访问并将其添加到我们的已访问顶点集。起始节点将始终具有最低成本，因此它将始终是第一个添加的节点，同时标记 Vertex 0，之后不用再进行访问：</p>
<p><img src="https://img-blog.csdnimg.cn/f653e7a1ed1a4b91ab8a7716d21ef0b2.png#pic_center" alt="在这里插入图片描述"><br>然后，我们将更新相邻顶点（1 和 6）的成本。由于 <code>0 + 4 &lt; infinity</code> 和 <code>0 + 7 &lt; infinity</code>，我们更新这些顶点的成本：<br><img src="https://img-blog.csdnimg.cn/6d1b5a02f4e041d3ae1a1ed6124a69c3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>现在我们访问未标记顶点中的最小成本顶点。<code>4 &lt; 7</code>，所以我们遍历到 Vertex 1：<br><img src="https://img-blog.csdnimg.cn/4dd7bacdc27a45839b8a5259a6b67321.png" alt="在这里插入图片描述"><br>在遍历时，我们将其标记为已访问，然后观察并更新相邻顶点：2、6 和 7：</p>
<ul>
<li>因为 <code>4 + 9 &lt; infinity</code>，Vertex 2 的新成本将是 13。</li>
<li>因为 <code>4 + 11 &gt; 7</code>，Vertex 6 的成本将保持为 7。</li>
<li>因为 <code>4 + 20 &lt; infinity</code>，Vertex 7 的新成本将是 24。</li>
</ul>
<p>则新成本如下：<br><img src="https://img-blog.csdnimg.cn/6c24efc717414f0bb741682569c7de4f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>此时在未标记的顶点中 Vertex 6的成本最小，因此将其作为出发点，将其标记为已访问并更新其相邻顶点的成本：<br><img src="https://img-blog.csdnimg.cn/8bcf03600cbf4d59a77be2f84a810296.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/0fbb3e2d54044d60ba0bd8f97ab7839d.png" alt="在这里插入图片描述"></p>
<p>该过程继续到 Vertex 7：<br><img src="https://img-blog.csdnimg.cn/9281857989fa43dfb5e911440210f953.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/a9cb24833d954817a94429d41f2d9cc7.png" alt="在这里插入图片描述"><br>再一次，到 Vertex 4：<br><img src="https://img-blog.csdnimg.cn/ca19bc820e6f4ad486526b00a9a786d2.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/0fda6dfb583c46e2aa0f88252c53c284.png" alt="在这里插入图片描述"><br>再一次，到 Vertex 2：<br><img src="https://img-blog.csdnimg.cn/23cf0b1e85bd4f06bede62c74b7888fe.png" alt="在这里插入图片描述"><br>我们要考虑的唯一顶点是 Vertex 3。由于<code>11 + 6 &lt; 19</code>，Vertex 3 的成本被更新。然后继续到 Vertex 8。<br><img src="https://img-blog.csdnimg.cn/086b66e6eb914803ac1ab5f1cb37e800.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/1c447967a5af413f9dc5db571e381150.png" alt="在这里插入图片描述"></p>
<p>然后更新 Vertex 3：<br><img src="https://img-blog.csdnimg.cn/4c679ea59ef1485c8013433bb11f0466.png" alt="在这里插入图片描述"><br>最后更新 Vertex 5：<br><img src="https://img-blog.csdnimg.cn/d46ff607bfbe47e390de89d311598096.png" alt="在这里插入图片描述"><br>没有更多未访问的顶点可能需要更新。我们的最终成本表示从节点 0 到图中每个其他节点的最短路径：<img src="https://img-blog.csdnimg.cn/33165330f7db4a3480367a06c72ecd48.png" alt="在这里插入图片描述"><br>动画演示如下：来自 <a href="https://www.youtube.com/watch?v=JLARzu7coEs"><strong><em>https://www.youtube.com/watch?v=JLARzu7coEs</em></strong></a><br><img src="https://img-blog.csdnimg.cn/aa69455364b9476db7bd125011ae7ea9.gif" alt="在这里插入图片描述"></p>
<h2 id="Python-实现-Dijkstra-算法"><a href="#Python-实现-Dijkstra-算法" class="headerlink" title="Python 实现 Dijkstra 算法"></a>Python 实现 Dijkstra 算法</h2><p>为了对我们还没有访问过的顶点进行排序和跟踪——我们将使用 <strong>PriorityQueue(优先队列)</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> PriorityQueue</span><br></pre></td></tr></table></figure>
<p>实现一个名为 <code>Graph</code> 的类的构造函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_vertices</span>):</span><br><span class="line">        self.vertices = num_of_vertices</span><br><span class="line">        <span class="comment">#距离表</span></span><br><span class="line">        self.edges = [[-<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_of_vertices)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_of_vertices)]</span><br><span class="line">        <span class="comment">#记录被访问过的节点</span></span><br><span class="line">        self.visited = []</span><br></pre></td></tr></table></figure>
<p>在这个简单的参数化构造函数中，将图中顶点的数量作为参数，并初始化了三个字段：</p>
<ul>
<li><code>vertices</code>：表示图中的顶点数。</li>
<li><code>edges</code>：以矩阵的形式表示边的列表。对于节点 <code>u</code> 和 <code>v</code>，<code>self.edges[u][v] = weight</code>。</li>
<li><code>visited</code>：将包含访问的顶点的集合。</li>
</ul>
<p>定义一个将向图形添加边的方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_edge</span>(<span class="params">self, u, v, weight</span>):</span><br><span class="line">    <span class="comment">#记录u，v两节点之间的距离</span></span><br><span class="line">    <span class="comment">#要注意的是如果是有向图只需定义单向的权重</span></span><br><span class="line">    <span class="comment">#如果是无向图则需定义双向权重</span></span><br><span class="line">    self.edges[u][v] = weight</span><br><span class="line">    self.edges[v][u] = weight</span><br></pre></td></tr></table></figure>
<p>定义 <strong>Dijkstra 算法</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dijkstra</span>(<span class="params">self, start_vertex</span>):</span><br><span class="line">    <span class="comment">#开始时定义源节点到其他所有节点的距离为无穷大</span></span><br><span class="line">    D = &#123;v: <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(self.vertices)&#125;</span><br><span class="line">    <span class="comment">#源节点到自己的距离为0</span></span><br><span class="line">    D[start_vertex] = <span class="number">0</span></span><br><span class="line">    <span class="comment">#优先队列</span></span><br><span class="line">    pq = PriorityQueue()</span><br><span class="line">    pq.put((<span class="number">0</span>, start_vertex))</span><br><span class="line">    <span class="comment"># 记录每个节点的前节点，便于回溯</span></span><br><span class="line">    previousVertex = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> pq.empty():</span><br><span class="line">        <span class="comment">#得到优先级最高的节点，也就是前节点到其他节点距离最短的节点作为当前出发节点</span></span><br><span class="line">        (dist, current_vertex) = pq.get()</span><br><span class="line">        <span class="comment">#标记已访问过的节点(最有路径集合)</span></span><br><span class="line">        self.visited.append(current_vertex)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> neighbor <span class="keyword">in</span> <span class="built_in">range</span>(self.vertices):</span><br><span class="line">            <span class="comment">#邻居节点之间距离不能为-1</span></span><br><span class="line">            <span class="keyword">if</span> self.edges[current_vertex][neighbor] != -<span class="number">1</span>:</span><br><span class="line">                distance = self.edges[current_vertex][neighbor]</span><br><span class="line">                <span class="comment">#已经访问过的节点不能再次被访问</span></span><br><span class="line">                <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> self.visited:</span><br><span class="line">                    <span class="comment">#更新源节点到其他节点的最短路径</span></span><br><span class="line">                    old_cost = D[neighbor]</span><br><span class="line">                    new_cost = D[current_vertex] + distance</span><br><span class="line">                    <span class="keyword">if</span> new_cost &lt; old_cost:</span><br><span class="line">                        <span class="comment">#加入优先队列</span></span><br><span class="line">                        pq.put((new_cost, neighbor))</span><br><span class="line">                        D[neighbor] = new_cost</span><br><span class="line">                        previousVertex[neighbor] = current_vertex</span><br><span class="line">    <span class="keyword">return</span> D, previousVertex</span><br></pre></td></tr></table></figure>
<p>在这段代码中，首先创建了一个大小为 <code>num_of_vertices</code> 的字典 <code>D</code>，用于统计最短路径的成本。整个列表初始化为无穷大。这将是一个列表，我们在其中保留从 <code>start_vertex</code> 所有其他节点的最短路径。我们将起始顶点的值设置为 0，因为这是它与自身的距离。然后，我们初始化一个优先级队列，我们​​将使用它来快速将顶点从最远到最远排序。我们将起始顶点放入优先级队列中。再然后初始化<code>previousVertex</code> ，用于标记每个节点的前节点。现在，对于优先队列中的每个顶点，我们将首先将它们标记为已访问，然后我们将遍历它们的邻居。如果邻居没有被访问，我们将比较它的旧成本和新成本。旧代价是从起始顶点到邻居的最短路径的当前值，而新代价是从起始顶点到当前顶点的最短路径与当前顶点到相邻顶点的距离之和的值邻居。如果新成本低于旧成本，我们将邻居及其成本放入优先级队列，并相应地更新我们保留最短路径的列表，同时更新邻居节点的前节点。最后，在所有顶点都被访问并且优先级队列为空之后，我们返回字典 <code>D</code> 和 <code>previousVertex</code> 。</p>
<p>实现之前的例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Dijkstra</span>() :</span><br><span class="line">    g = Graph(<span class="number">9</span>)</span><br><span class="line">    g.add_edge(<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">    g.add_edge(<span class="number">0</span>, <span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line">    g.add_edge(<span class="number">1</span>, <span class="number">6</span>, <span class="number">11</span>)</span><br><span class="line">    g.add_edge(<span class="number">1</span>, <span class="number">7</span>, <span class="number">20</span>)</span><br><span class="line">    g.add_edge(<span class="number">1</span>, <span class="number">2</span>, <span class="number">9</span>)</span><br><span class="line">    g.add_edge(<span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>)</span><br><span class="line">    g.add_edge(<span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>)</span><br><span class="line">    g.add_edge(<span class="number">3</span>, <span class="number">4</span>, <span class="number">10</span>)</span><br><span class="line">    g.add_edge(<span class="number">3</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">    g.add_edge(<span class="number">4</span>, <span class="number">5</span>, <span class="number">15</span>)</span><br><span class="line">    g.add_edge(<span class="number">4</span>, <span class="number">7</span>, <span class="number">1</span>)</span><br><span class="line">    g.add_edge(<span class="number">4</span>, <span class="number">8</span>, <span class="number">5</span>)</span><br><span class="line">    g.add_edge(<span class="number">5</span>, <span class="number">8</span>, <span class="number">12</span>)</span><br><span class="line">    g.add_edge(<span class="number">6</span>, <span class="number">7</span>, <span class="number">1</span>)</span><br><span class="line">    g.add_edge(<span class="number">7</span>, <span class="number">8</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    D, previousVertex = g.dijkstra(<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#每个节点的前节点，可通过回溯得到最短路径</span></span><br><span class="line">    <span class="built_in">print</span>(previousVertex)</span><br><span class="line">    <span class="keyword">for</span> vertex <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(D)):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;distance from vertex <span class="subst">&#123;<span class="number">0</span>&#125;</span> to vertex <span class="subst">&#123;vertex&#125;</span> is <span class="subst">&#123;D[vertex]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>结果：<br><img src="https://img-blog.csdnimg.cn/ddf8f813e6f144ea8ba79629faf258a1.png" alt="在这里插入图片描述"></p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>得到节点s和t之间的最短路径。</p>
<p><img src="https://img-blog.csdnimg.cn/83858695054f4fe28992aec28377d6da.png#pic_center" alt="在这里插入图片描述"><br>上图是一个有向图，而我们在第一个例子中定义的是无向图，因此要修改代码。在代码中与无向图的差异只是一行，即定义权重时只定义一边，只需注释掉 <code>self.edges[v][u] = weight</code> 即可。为了实现方便，图中节点的名称并未使用字符表示，而是使用数字进行表示，在搜索完之后根据字典再对应回去。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> PriorityQueue</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Graph</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_vertices</span>):</span><br><span class="line">        self.vertices = num_of_vertices</span><br><span class="line">        <span class="comment">#距离表</span></span><br><span class="line">        self.edges = [[-<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_of_vertices)] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(num_of_vertices)]</span><br><span class="line">        <span class="comment">#记录被访问过的节点</span></span><br><span class="line">        self.visited = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_edge</span>(<span class="params">self, u, v, weight</span>):</span><br><span class="line">        <span class="comment">#记录u，v两节点之间的距离</span></span><br><span class="line">        <span class="comment">#要注意的是如果是有向图只需定义单向的权重</span></span><br><span class="line">        <span class="comment">#如果是无向图则需定义双向权重</span></span><br><span class="line">        self.edges[u][v] = weight</span><br><span class="line">        <span class="comment"># self.edges[v][u] = weight</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dijkstra</span>(<span class="params">self, start_vertex</span>):</span><br><span class="line">        <span class="comment">#开始时定义源节点到其他所有节点的距离为无穷大</span></span><br><span class="line">        D = &#123;v: <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>) <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(self.vertices)&#125;</span><br><span class="line">        <span class="comment">#源节点到自己的距离为0</span></span><br><span class="line">        D[start_vertex] = <span class="number">0</span></span><br><span class="line">        <span class="comment">#优先队列</span></span><br><span class="line">        pq = PriorityQueue()</span><br><span class="line">        pq.put((<span class="number">0</span>, start_vertex))</span><br><span class="line">        <span class="comment"># 记录每个节点的前节点，便于回溯</span></span><br><span class="line">        previousVertex = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> pq.empty():</span><br><span class="line">            <span class="comment">#得到优先级最高的节点，也就是前节点到其他节点距离最短的节点作为当前出发节点</span></span><br><span class="line">            (dist, current_vertex) = pq.get()</span><br><span class="line">            <span class="comment">#标记已访问过的节点(最有路径集合)</span></span><br><span class="line">            self.visited.append(current_vertex)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> neighbor <span class="keyword">in</span> <span class="built_in">range</span>(self.vertices):</span><br><span class="line">                <span class="comment">#邻居节点之间距离不能为-1</span></span><br><span class="line">                <span class="keyword">if</span> self.edges[current_vertex][neighbor] != -<span class="number">1</span>:</span><br><span class="line">                    distance = self.edges[current_vertex][neighbor]</span><br><span class="line">                    <span class="comment">#已经访问过的节点不能再次被访问</span></span><br><span class="line">                    <span class="keyword">if</span> neighbor <span class="keyword">not</span> <span class="keyword">in</span> self.visited:</span><br><span class="line">                        <span class="comment">#更新源节点到其他节点的最短路径</span></span><br><span class="line">                        old_cost = D[neighbor]</span><br><span class="line">                        new_cost = D[current_vertex] + distance</span><br><span class="line">                        <span class="keyword">if</span> new_cost &lt; old_cost:</span><br><span class="line">                            <span class="comment">#加入优先队列</span></span><br><span class="line">                            pq.put((new_cost, neighbor))</span><br><span class="line">                            D[neighbor] = new_cost</span><br><span class="line">                            previousVertex[neighbor] = current_vertex</span><br><span class="line">        <span class="keyword">return</span> D, previousVertex</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Dijkstra</span>():</span><br><span class="line">    g = Graph(<span class="number">6</span>)</span><br><span class="line">    g.add_edge(<span class="number">0</span>, <span class="number">1</span>, <span class="number">6</span>)</span><br><span class="line">    g.add_edge(<span class="number">0</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    g.add_edge(<span class="number">0</span>, <span class="number">2</span>, <span class="number">5</span>)</span><br><span class="line">    g.add_edge(<span class="number">1</span>, <span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line">    g.add_edge(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    g.add_edge(<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    g.add_edge(<span class="number">2</span>, <span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line">    g.add_edge(<span class="number">3</span>, <span class="number">4</span>, <span class="number">7</span>)</span><br><span class="line">    g.add_edge(<span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>)</span><br><span class="line">    g.add_edge(<span class="number">5</span>, <span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    D, previousVertex = g.dijkstra(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># print(previousVertex)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#节点名字与数字的对应表</span></span><br><span class="line">    dic = &#123;<span class="number">0</span> : <span class="string">&#x27;s&#x27;</span>, <span class="number">1</span> : <span class="string">&#x27;v&#x27;</span>, <span class="number">2</span> : <span class="string">&#x27;u&#x27;</span>, <span class="number">3</span> : <span class="string">&#x27;w&#x27;</span>, <span class="number">4</span> : <span class="string">&#x27;t&#x27;</span>, <span class="number">5</span> : <span class="string">&#x27;z&#x27;</span>&#125;</span><br><span class="line">    path = []</span><br><span class="line">    cheapest_path = []</span><br><span class="line">    key = <span class="number">4</span></span><br><span class="line">    <span class="comment">#回溯，得到源节点到目标节点的最佳路径</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">if</span> key == <span class="number">0</span> :</span><br><span class="line">            path.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            path.append(key)</span><br><span class="line">            key = previousVertex[key]</span><br><span class="line">    <span class="comment">#节点名字由数字转成字符</span></span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> path[ : : -<span class="number">1</span>] :</span><br><span class="line">        cheapest_path.append(dic[point])</span><br><span class="line">    cheapest_path = <span class="string">&quot;-&gt;&quot;</span>.join(cheapest_path)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;distance from vertex <span class="subst">&#123;dic[<span class="number">0</span>]&#125;</span> to vertex <span class="subst">&#123;dic[<span class="number">4</span>]&#125;</span> is <span class="subst">&#123;D[<span class="number">4</span>]&#125;</span>,&quot;</span></span><br><span class="line">            <span class="string">f&quot;the cheapest path is <span class="subst">&#123;cheapest_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    Dijkstra()</span><br></pre></td></tr></table></figure>
<p>结果：<br><img src="https://img-blog.csdnimg.cn/7ec4381a769b49cfa4bea631c9a4a608.png" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>Python</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>图</tag>
        <tag>Dijkstra</tag>
      </tags>
  </entry>
  <entry>
    <title>【Opencv】目标追踪——高斯混合模型分离算法(MOG)</title>
    <url>/2022/06/05/%E3%80%90Opencv%E3%80%91%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AA%E2%80%94%E2%80%94%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B%E5%88%86%E7%A6%BB%E7%AE%97%E6%B3%95-MOG/</url>
    <content><![CDATA[<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1    环境"></a>1    环境</h1><ul>
<li>Python 3.8.8</li>
<li>PyCharm 2021</li>
<li>opencv-python</li>
</ul>
<h1 id="2-效果"><a href="#2-效果" class="headerlink" title="2    效果"></a>2    效果</h1><p><img src="https://img-blog.csdnimg.cn/3c23354eb51a4c6ab84cb9762f6a1e98.gif#pic_center" alt="在这里插入图片描述"></p>
<h1 id="3-原理"><a href="#3-原理" class="headerlink" title="3    原理"></a>3    原理</h1><p>&emsp;&emsp;视频图像中的目标检测与跟踪，是计算机视觉的基础课题，同时具有广泛的应用价值。视觉目标(单目标)跟踪任务就是在给定某视频序列初始帧的目标大小与位置的情况下，预测后续帧中该目标的大小与位置。依照目标与摄像头之间的关系可分为两种场景的目标追踪：</p>
<ul>
<li>静态场景：目标检测相对简单，研究渐趋成熟。</li>
<li>动态场景：相对复杂，当前研究领域的热点。</li>
</ul>
<p>本文只介绍静态场景的目标追踪，动态的在后序文章中会分享。</p>
<p>&emsp;&emsp;在静态场景中，背景是静止的，则我们可以通过背景减除(Background Subtraction)来进行预处理。例如，考虑像访客柜台这样的情况，其中静态摄像机(监控)拍摄进入或离开房间的访客数量，或者交通摄像机提取有关车辆的信息等。在所有这些情况下，首先需要单独提取人员或车辆. 从技术上讲，需要从静态背景中提取移动的前景。那么我们可以通过帧差法来计算像素差从而获取到前景对象。</p>
<p>&emsp;&emsp;如果只有背景图像，例如没有访客的房间图像，没有车辆的道路图像等，这很容易。只需从背景中减去新图像。就可以单独获得前景对象。但在大多数情况下，可能没有这样的图像，因此我们需要从我们拥有的任何图像中提取背景。当有车辆的影子时，情况变得更加复杂。由于阴影也在移动，简单的减法也会将其标记为前景。它使事情复杂化。</p>
<p>&emsp;&emsp;高斯混合模型分离算法(MOG)算法在一定程度上可解决上述问题，2001年，由P.KadewTraKuPong和R.Bowden在论文 <strong><em>“An improved adaptive background mixture model for real-time tracking with shadow detection”</em></strong> 中提出。MOG2算法，也是高斯混合模型分离算法，是MOG的改进算法。基于2004年发布的 <strong><em>“Improved adaptive Gausian mixture model for background subtraction”</em></strong> 和2006年发布的 <strong><em>“Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction”</em></strong> 两篇文章提出。该算法的一个重要特征是它为 <strong>每个</strong> 像素选择适当数量的高斯分布，它可以更好地适应不同场景的照明变化等。可以大家会有疑问，就是为什么一个像素也可以构成高斯分布呢，这里其实是因为我们的视频会持续一段时间，这样每个像素在每个时刻 $\boldsymbol{t}$ 都有对应的状态。因此上述的 <strong>每个</strong> 像素指的是一个像素在不同时刻 $\boldsymbol{t}$ 的状态。MOG算法的基本思路是基本思路：将图像分为3-5个高斯模型。如果一个像素点与任何一个高斯模型的均值 $\boldsymbol{\mu}$ 的之差大于其3倍的标准差 $\boldsymbol{\sigma}$，则为前景即运动物体，否则则是背景。算法流程如下：</p>
<ul>
<li>初始各种参数。</li>
<li>使用过去 <strong>T</strong> 帧图像构造模型。</li>
<li>对于一个新来的像素，如果该像素点的值与其模型均值 $\boldsymbol{\mu}$ 之差在 $\boldsymbol{3*\sigma}$ 内，则属于该分布，并对其进行参数更新。</li>
<li>如果不满足该高斯模型，重新建立一个新的高斯模型。</li>
</ul>
<h1 id="4-代码"><a href="#4-代码" class="headerlink" title="4    代码"></a>4    代码</h1><p>使用 <code>cv2.createBackgroundSubtractorMOG2(history = 500, varThreshold = 16, detectShadows = true)</code> 初始化一个MOG2模型，该函数的参数如下：</p>
<ul>
<li>history：用于训练背景的帧数，默认为500帧。</li>
<li>varThreshold：方差阈值，用于判断当前像素是前景还是背景。一般默认16，如果光照变化明显，如阳光下的水面，建议设为25，36。</li>
<li>detectShadows：是否检测影子，设为True为检测，False为不检测，检测影子会增加程序时间复杂度，如无特殊要求，建议设为False。</li>
</ul>
<p>使用 <code>cv2.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3))</code> 初始化形态学需要的卷积核 kernel，等效成 <code>np.ones((3, 3), np.uint8)</code> 。</p>
<p>使用 <code>cv2.VideoCapture(video_path)</code> 创建一个视频读取对象capture，<code>capture.read()</code> 进行捕捉画面，返回值如下：</p>
<ul>
<li>ret：布尔值，表示是否正确捕捉到图像帧。</li>
<li>frame：图像帧。</li>
</ul>
<p>使用 <code>cv2.morphologyEx(fgmask, cv.MORPH_OPEN, kernel)</code> 进行形态学处理，这是因为MOG2检测出的前景中有许多白点(如下图)，所以使用开操作对白点进行腐蚀。</p>
<p><img src="https://img-blog.csdnimg.cn/0935bdf21ac14d1dacbfc8269c17a066.png#pic_center" alt="\[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-D8X2h5uB-1649644124426)(C:\Users\爱上层楼\AppData\Roaming\Typora\typora-user-images\image-20220411102139496.png)\]"></p>
<p>使用 <code>cv2.imshow()</code> 展示图片，使用 <code>cv2.waitkey(10) &amp; 0xff == &#39;q&#39;</code> 来延长放映的时间。</p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tracking_by_bg_substract</span>() :</span><br><span class="line">    model = cv.createBackgroundSubtractorMOG2()</span><br><span class="line">    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">    capture = cv.VideoCapture(<span class="string">&#x27;videos/static_bg_people.avi&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> capture.isOpened() :</span><br><span class="line">        ret, frame = capture.read()</span><br><span class="line">        <span class="keyword">if</span> ret :</span><br><span class="line">            <span class="comment">#对图像帧进行MOG2算法检测</span></span><br><span class="line">            fgmask = model.apply(frame)</span><br><span class="line">            fgmask = cv.morphologyEx(fgmask, cv.MORPH_OPEN, kernel)</span><br><span class="line">            cv.imshow(<span class="string">&#x27;frame&#x27;</span>, frame)</span><br><span class="line">            cv.imshow(<span class="string">&#x27;fgmask&#x27;</span>, fgmask)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> cv.waitKey(<span class="number">10</span>) &amp; <span class="number">0xff</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>) :</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    capture.release()</span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tracking_by_bg_substract()</span><br></pre></td></tr></table></figure>
<p>效果如下，效果还不错。<img src="https://img-blog.csdnimg.cn/79eeb342bf014220b913a8852779e659.gif" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>目标追踪</tag>
      </tags>
  </entry>
  <entry>
    <title>优化算法</title>
    <url>/2022/06/05/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;在机器学习模型中，我们会使用损失函数对模型的输出和标注信息计算他们之间的差异，然后使用损失进行反向传播，在反向传播中，我们的目的是不断地更新参数使得模型损失越来越小直至达到最小，这过程是优化参数的过程，基础的优化算法是使用梯度下降法(如下图)，梯度下降法利用了梯度的反方向是函数下降最快的方向的特性，该过程可以理解成寻找山谷。随后为了提高效率和准确率许多的改进的优化算法被提出，下面我们将介绍几种常用的优化算法。</p>
<p><img src="https://img-blog.csdnimg.cn/f106af1dda3c43e7a79f35ab00f213f1.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="1-梯度下降算法"><a href="#1-梯度下降算法" class="headerlink" title="1    梯度下降算法"></a>1    梯度下降算法</h1><p>&emsp;&emsp;假设线性回归函数为：$\boldsymbol{h_\theta(x^{(i)}) = \theta    _1x^{(i)} + \theta_0}$，代价函数为：$\boldsymbol{J(\theta_0,<br>\theta_1) = \frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})^2}$，其中 $\boldsymbol{i= 1,2, … ,𝑚}$ 表示样本数，$\boldsymbol{𝑗 = 0,1}$ 表示特征数，这里我们使用偏置项 $\boldsymbol{x_0^{(i)} = 1}$。</p>
<h2 id="1-1-BGD"><a href="#1-1-BGD" class="headerlink" title="1.1    BGD"></a>1.1    BGD</h2><p>&emsp;&emsp;批量梯度下降(BGD)是最原始的形式，在每一次迭代时使用所有样本来对参数进行更新，也即使用了所有样本只更新了一次参数。更新算法如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{repeat:\ \ \ \theta_j = \theta_j - \alpha\frac{1}{2m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\ \ \ (for\ j = 0,1)}</script><p>优点：</p>
<ul>
<li>目标函数为凸函数时，能得到全局最优解。</li>
<li>易于并行实现。</li>
</ul>
<p>缺点：</p>
<ul>
<li>当样本数目过多时，训练过程较慢，时间成本高。</li>
</ul>
<h2 id="1-2-SGD"><a href="#1-2-SGD" class="headerlink" title="1.2    SGD"></a>1.2    SGD</h2><p>&emsp;&emsp;随机梯度下降(SGD)在每一次迭代时使用一个样本来对参数进行更新。更新算法如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{repeat:\ \ \ for\ i=1,2,\cdots,m\{\theta_j = \theta_j - \alpha(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\ \ \ (for\ j = 0,1)\}}</script><p>优点：</p>
<ul>
<li>训练速度快。</li>
</ul>
<p>缺点：</p>
<ul>
<li>准确度下降，很大程度上并不是全局最优。</li>
<li>不易于并行实现。</li>
</ul>
<h2 id="1-3-MBGD"><a href="#1-3-MBGD" class="headerlink" title="1.3    MBGD"></a>1.3    MBGD</h2><p>&emsp;&emsp;小批量梯度下降(MBGD)在每一次迭代时使用 $\boldsymbol{batch\_size}$ 个样本来对参数进行更新。更新算法如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{batch\_size = 10, m = 100}\\\boldsymbol{repeat:\ \ \ for\ i=1,11,\cdots,91\{\theta_j = \theta_j - \frac{\alpha}{10}\sum_{k=i}^{i+ 9}(h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)}\ \ \ (for\ j = 0,1)\}}</script><p>MBGD 减少了 BGD 和 SGD 的缺点，结合了 BGD 和 SGD 的优点，我们在平时的实验过程中往往使用 MBGD。</p>
<h1 id="2-基于动量的优化算法"><a href="#2-基于动量的优化算法" class="headerlink" title="2    基于动量的优化算法"></a>2    基于动量的优化算法</h1><h2 id="2-1-基于动量的SGD"><a href="#2-1-基于动量的SGD" class="headerlink" title="2.1    基于动量的SGD"></a>2.1    基于动量的SGD</h2><p>&emsp;&emsp;梯度下降法在遇到平坦或高曲率区域时，学习过程有时很慢。利用动量算法能比较好解决这个问题。动量算法与传统梯度下降优化的效果对比如下：</p>
<p><img src="https://img-blog.csdnimg.cn/a3936c6b7ded4cdfaa85956564e41796.png#pic_center" alt="在这里插入图片描述"><br>从上图可以看出，不使用动量算法的 SGD 学习速度较慢，振幅较大； 而使用动量算法的 SGD，振幅较小，而且会较快到达极值点。动量(Momentum)是模拟物理里动量的概念，具有物理上惯性的含义，一个物体在运动时具有惯性，把这个思想运用到梯度下降计算中，可以增加算法的收敛速度和稳定性。在动量学习算法中，我们假设是单位质量，因此速度向量 $\boldsymbol{v}$ 也可以看作是粒子的动量。超参数 $\boldsymbol{α ∈ [0, 1)}$ 决定了之前梯度的贡献衰减得有快，示意图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/4cbb15c7066040bebc912664d46734a8.png#pic_center" alt="在这里插入图片描述"><br>由上图知动量算法每下降一步都是由前面下降方向的一个累积和当前点的梯度方向组合而成。含动量的随机梯度下降法的算法流程如下：<br><img src="https://img-blog.csdnimg.cn/dcb5843843c84e189bac707011f322aa.png#pic_center" alt="在这里插入图片描述"><br>在实践中，$\boldsymbol{\alpha}$ 的一般取值为 $\mathbf{0.5}$，$\mathbf{0.9}$ 和 $\mathbf{0.99}$。和学习率一样，$\boldsymbol{\alpha}$ 也会随着时间不断调整。一般初始值是一个较小的值，随后会慢慢变大。随着时间推移调整 $\boldsymbol{\alpha}$ 没有收缩 $\boldsymbol{ϵ}$ 重要。</p>
<h2 id="2-2-基于NAG的SGD"><a href="#2-2-基于NAG的SGD" class="headerlink" title="2.2    基于NAG的SGD"></a>2.2    基于NAG的SGD</h2><p>&emsp;&emsp;Nesterov Accelerated Gradient，简称 NAG 算法，是普通动量算法的改进版本。普通动量算法中每一步都要将两个梯度方向(历史梯度、当前梯度)做一个合并再 下降，那就可以先按照历史梯度往前走那么一小步，按照前面一小步位置的“超前梯度”来做梯度合并。这样就可以先往前走一步，在靠前一点的位 置(如下图中的C点)看到梯度，然后按照那个位置再来修正这一步的梯度方向。<br><img src="https://img-blog.csdnimg.cn/a3dc3ca536a845c4bdc8d848352830bd.png#pic_center" alt="在这里插入图片描述"><br>仔细观察他们的示意图可以发现，普通动量的下降方向的合成是四边形合成而 NAG 是三角合成，NAG 更新规则如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{v\leftarrow\alpha - ϵ∇_\theta[\frac{1}{m}\sum_{i = 1}^{m}L(f(x^{(i)};\theta+\alpha v),y^{(i)})]},\\
\boldsymbol{\theta\leftarrow\theta +     v}</script><p>其中参数 $\boldsymbol{α}$ 和 $\boldsymbol{ϵ}$ 发挥了和标准动量方法中类似的作用。Nesterov动量和标准动量之间的区别体现在梯度计算上。Nesterov 动量中，梯度计算在施加当前速度之后。因此，Nesterov 动量可以解释为往标准动量方法中添加了一个校正因子。含 Nesterov 动量的随机梯度下降法的算法流程如下：<br><img src="https://img-blog.csdnimg.cn/3ca0dec460d647788edc689172bd774d.png#pic_center" alt="在这里插入图片描述"><br>NAG 算法的预更新方法能防止大幅振荡，不会错过最小值，并会对参数更新更加敏感。</p>
<h1 id="3-自适应优化算法"><a href="#3-自适应优化算法" class="headerlink" title="3    自适应优化算法"></a>3    自适应优化算法</h1><p>&emsp;&emsp;传统梯度下降算法对学习率这个超参数非常敏感，难以驾驭，对参数空 间的某些方向也没有很好的方法。这些不足在深度学习中，因高维空间、多层神经网络等因素，常会出现平坦、鞍点、悬崖等问题，因此，传统梯度下降法在深度学习中显得力不从心。上面介绍的动量算法在一定程度上缓解了对参数空间某些方向的问题，但需要新增一个超参数，而且对学习率的控制还不是很理想。为了更好地驾驭这个超参数，自适应优化算法被提出，使用自适应优化算法， 学习率不再是一个固定不变值，它会根据不同情况自动调整来适应相应的情况。</p>
<h2 id="3-1-AdaGrad"><a href="#3-1-AdaGrad" class="headerlink" title="3.1    AdaGrad"></a>3.1    AdaGrad</h2><p>&emsp;&emsp;AdaGrad 算法能够独立地适应所有模型参数的学习率，缩放每个参数反比于其所有梯度历史平方值总和的平方根。具有损失最大偏导的参数相应地有一个快速下降的学习率，而具有小偏导的参数在学习率上有相对较小的下降。净效果是在参数空间中更为平缓的倾斜方向会取得更大的进步。因此，AdaGrad算法非常适合处理稀疏数据。对于训练深度神经网络模型而言，从训练开始时积累梯度平方会导致有效学习率过早和过量的减小从而使得模型的效果不好。算法流程如下：<br><img src="https://img-blog.csdnimg.cn/9f97d5043af04aadb9a4d176b247a9c3.png#pic_center" alt="在这里插入图片描述"><br>其中 $\boldsymbol{\delta}$ 一般取一个较小值，这是为了出现分母为零的情况，$\boldsymbol{\bigodot}$ 表示逐元运算。且由上面的算法流程可知：</p>
<ul>
<li>随着迭代时间越长，累积梯度 $\boldsymbol{r}$ 越大，导致学习速率 $\boldsymbol{\frac{ϵ}{\delta + \sqrt{r}}}$ 随着时间减小，在接近目标值时，不会因为学习速率过大而越过极值点。</li>
<li>不同参数之间的学习速率不同，因此，与前面固定学习速率相比， 不容易在鞍点卡住。</li>
<li>如果梯度累积参数 $\boldsymbol{r}$ 比较小，则学习速率会比较大，所以参数迭代的步长就会比较大。相反，如果梯度累积参数比较大，则学习速率会比较小， 所以迭代的步长会比较小。</li>
</ul>
<h2 id="3-2-RMSProp"><a href="#3-2-RMSProp" class="headerlink" title="3.2    RMSProp"></a>3.2    RMSProp</h2><p>&emsp;&emsp;RMSProp 算法通过修改AdaGrad得来，其目的是在非凸背景下效果更好。RMSProp 使用指数衰减平均以丢弃遥远过去的历史，使其能够在找到凸碗状结构后快速收敛，它就像一个初始化于该碗状结构的 AdaGrad 算法实例。相比于 AdaGrad，使用移动平均引入了一个新的超参数ρ，用来控制移动平均的长度范围。算法流程如下：<br><img src="https://img-blog.csdnimg.cn/442473914fe548b385af1dbcde83cd4b.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="3-3-Adam"><a href="#3-3-Adam" class="headerlink" title="3.3    Adam"></a>3.3    Adam</h2><p>&emsp;&emsp;Adam(Adaptive Moment Estimation)本质上是带有动量项的 RMSprop，它利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率。Adam 的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳。 Adam 是另一种学习速率自适应的深度神经网络方法，它利用梯度的一 阶矩估计和二阶矩估计动态调整每个参数的学习速率。算法流程如下：<br><img src="https://img-blog.csdnimg.cn/71e41ed786314382ae7c8e83db3473b7.png#pic_center" alt="在这里插入图片描述"><br>Adam 通常被认为对超参数的选择相当鲁棒，尽管学习率有时需要从建议的默认修改。</p>
<h1 id="4-优化器的选择"><a href="#4-优化器的选择" class="headerlink" title="4    优化器的选择"></a>4    优化器的选择</h1><p>&emsp;&emsp;AdaGrad、RMSprop、和 Adam 被认为是自适应优化算法，因为它们会自动更新学习率。而使用 SGD 时，必须手动选择学习率和动量参数，通常会随着时间的推移而降低学习率。<br>&emsp;&emsp;有时可以考虑综合使用这些优化算法，如采用先使用 Adam，然后使用 SGD 的优化方法，这个想法，实际上是由于在训练的早期阶段 SGD 对参数调整和初始化非常敏感。因此，我们可以通过先使用 Adam 优化算法来进行训 练，这将大大地节省训练时间，且不必担心初始化和参数调整，一旦用 Adam 训练获得较好的参数后，就可以切换到 SGD + 动量优化，以达到最佳性能。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>激活函数</title>
    <url>/2022/06/05/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[<h1 id="1-定义"><a href="#1-定义" class="headerlink" title="1    定义"></a>1    定义</h1><p>&emsp;&emsp;激活函数 (<strong><em>Activation functions</em></strong>) 对于人工神经网络模型去学习、理解非常复杂和非线性的函数来说具有十分重要的作用。它们将非线性特性引入到神经网络中。在下图中，输入的 inputs 通过加权，求和后，还被作用了一个函数，这个函数就是激活函数。引入激活函数是为了增加神经网络模型的非线性。没有激活函数的每层都相当于矩阵相乘。就算你叠加了若干层之后，无非还是个矩阵相乘罢了。<br><img src="https://img-blog.csdnimg.cn/2076a4e3b2ad4eac9c75c74ffbcb8ede.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="2-激活函数的必要性"><a href="#2-激活函数的必要性" class="headerlink" title="2    激活函数的必要性"></a>2    激活函数的必要性</h1><p>&emsp;&emsp;如果不用激活函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合，这种情况就是最原始的感知机(<strong><em>Perceptron</em></strong>)。这种情况无论有多少层神经网络均可以仅使用输入层和输出层代替，不同的地方就是线性函数的系数不同。激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中。</p>
<h1 id="3-常用的激活函数"><a href="#3-常用的激活函数" class="headerlink" title="3    常用的激活函数"></a>3    常用的激活函数</h1><h2 id="3-1-单位阶跃函数"><a href="#3-1-单位阶跃函数" class="headerlink" title="3.1    单位阶跃函数"></a>3.1    单位阶跃函数</h2><p>&emsp;&emsp;单位阶跃函数，又称赫维赛德阶跃函数，方程式如下：</p>
<script type="math/tex; mode=display">f(x)= \begin{cases} 0,& x < 0\\ 1, & x  \geq 0
\end{cases}</script><p>函数曲线如下：</p>
<p><img src="https://img-blog.csdnimg.cn/d965af45e97a409a828d082480f1d064.png#pic_center" alt="在这里插入图片描述"><br>可以看出是个不连续函数，它是一个几乎必然是零的随机变量的累积分布函数，激活值只有 0 和 1，即百分百确定和百分百不确定，适合二分类问题。导数方程式如下：</p>
<script type="math/tex; mode=display">
f'(x) = \begin{cases} 0 , & x \not= 0 \\ ?, & x = 0 \end{cases}</script><h2 id="3-2-Logistic函数"><a href="#3-2-Logistic函数" class="headerlink" title="3.2    Logistic函数"></a>3.2    Logistic函数</h2><p>&emsp;&emsp;<strong><em>Logistic</em></strong> 函数也叫 <strong><em>Sigmoid</em></strong> 函数，用于隐层神经元输出，取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，因此 <strong><em>Sigmoid</em></strong> 函数作为输出层时可以用来做二分类。在特征相差比较复杂或是相差不是特别大时效果比较好。方程式如下：</p>
<script type="math/tex; mode=display">
f(x) = \frac{1}{1 + e^{-x}}</script><p>函数曲线如下：</p>
<p><img src="https://img-blog.csdnimg.cn/fe7116031cc14dbcbc272b91c967f2c6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>其导数方程式如下：</p>
<script type="math/tex; mode=display">
f'(x) = f(x)(1 - f(x))</script><p><strong><em>Logistic</em></strong> 函数平滑、易于求导，但是计算量大，反向传播求误差梯度时，求导涉及除法；反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练。</p>
<h2 id="3-3-Tanh函数"><a href="#3-3-Tanh函数" class="headerlink" title="3.3    Tanh函数"></a>3.3    Tanh函数</h2><p>&emsp;&emsp;<strong><em>Tanh</em></strong> 函数能够将输入“压缩”到(−1,1)区间，方程式如下：</p>
<script type="math/tex; mode=display">
f(x) = Tanh(x) = \frac{(e^x - e^{-x})}{(e^x + e^{-x})}</script><p>函数曲线如下：<br><img src="https://img-blog.csdnimg.cn/05e7390b3cd84914a07d489c89847e27.png#pic_center" alt="在这里插入图片描述"><br>可以看到 <strong><em>tanh</em></strong> 激活函数可通过 <strong><em>Sigmoid</em></strong> 函数缩放平移后实现。其导数方程式如下：</p>
<script type="math/tex; mode=display">
f'(x) = 1 - f(x)^2</script><p>与 <strong><em>sigmoid</em></strong> 函数相比，它的输出均值为0，使其收敛速度要比 <strong><em>sigmoid</em></strong> 快，可以减少迭代次数。它的缺点是需要幂运算，计算成本高；同样存在梯度消失，因为在两边一样有趋近于0的情况。</p>
<h2 id="3-4-ReLU函数"><a href="#3-4-ReLU函数" class="headerlink" title="3.4    ReLU函数"></a>3.4    ReLU函数</h2><p>&emsp;&emsp;整流线性单位函数(<strong><em>ReLU</em></strong> )又称修正线性单元, 是一种人工神经网络中常用的激励函数(<strong><em>activation function</em></strong>)，通常指代以斜坡函数及其变种为代表的非线性函数。<strong><em>ReLU</em></strong> 认为有一定的生物学原理，并且由于在实践中通常有着比其他常用激励函数(譬如 <strong><em>Sigmoid</em></strong> 函数)更好的效果，而被如今的深度神经网络广泛使用于诸如图像识别等计算机视觉人工智能领域。方程式如下：</p>
<script type="math/tex; mode=display">
f(x) = max(0, x)</script><p>而在神经网络中，<strong><em>ReLU</em></strong> 作为神经元的激活函数，定义了该神经元在线性变换 $\boldsymbol{w^T + b}$之后的非线性输出结果。换言之，对于进入神经元的来自上一层神经网络的输入向量 $\boldsymbol{x}$，使用 <strong><em>ReLU</em></strong> 的神经元会输出：</p>
<script type="math/tex; mode=display">
max(0, \boldsymbol{w^T + b})</script><p>函数曲线如下：<br><img src="https://img-blog.csdnimg.cn/600ebf00777349dda56b058e7e6d4a36.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_13,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>导数方程式如下：</p>
<script type="math/tex; mode=display">
f'(x) = \begin{cases} 0, & x < 0 \\ 1, &x\geq 0 \end{cases}</script><p>相对 <strong><em>sigmoid</em></strong> 和 <strong><em>tanh</em></strong>，极大地改善了梯度消失的问题，收敛速度块；不需要进行指数运算，因此运算速度快，复杂度低；<strong><em>ReLU</em></strong> 函数会使得一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的互相依存关系，缓解了过拟合问题的发生。它的缺点是对参数初始化和学习率非常敏感；存在神经元死亡；<strong><em>ReLU</em></strong> 函数的输出均值大于0，偏移现象和神经元死亡会共同影响网络的收敛性。</p>
<h2 id="3-5-LeakyReLU函数"><a href="#3-5-LeakyReLU函数" class="headerlink" title="3.5    LeakyReLU函数"></a>3.5    LeakyReLU函数</h2><p>&emsp;&emsp;<strong><em>ReLU</em></strong> 函数在 $x &lt; 0$ 时导数值恒为 0，也可能会造成梯度弥散现象，为了克服这个问题，<strong><em>LeakyReLU</em></strong> 函数被提出，方程式如下：</p>
<script type="math/tex; mode=display">
f(x) = max(\alpha x,x)</script><p>其函数曲线如下：<br><img src="https://img-blog.csdnimg.cn/4e2f998d4f6241b098e583da08723e03.png#pic_center" alt="在这里插入图片描述"><br>导数方程式如下：</p>
<script type="math/tex; mode=display">
f'(x) = \begin{cases} 1 ,& x \geq 0 \\ \alpha, &x < 0 \end{cases}</script><p>其中 $\alpha$ 为用户自行设置的某较小数值的超参数，如 0.02 等。当 $\alpha = 0$ 时，LeayReLU 函数退化为 <strong><em>ReLU</em></strong> 函数；当 $\alpha \not = 0$ 时，$x &lt; 0$ 处能够获得较小的导数值 $\alpha$，从而避免出现梯度弥散现象。</p>
<h2 id="3-6-Softmax函数"><a href="#3-6-Softmax函数" class="headerlink" title="3.6    Softmax函数"></a>3.6    Softmax函数</h2><p>&emsp;&emsp;<strong><em>Softmax</em></strong> 函数，或称归一化指数函数，有多个输入，是 <strong><em>Sigmoid</em></strong> 函数的一种推广。它能将一个含任意实数的 $K$ 维向量 $\boldsymbol{z}$ “压缩”到另一个 $K$ 维实向量 $\boldsymbol{\sigma(z)}$ 中，使得每一个元素的范围都在(0，1)之间，并且所有元素的和为1。那么我们就可以将它理解成概率，在最后选取输出结点的时候，我们就可以选取概率最大(也就是值对应最大的)结点，作为我们的预测目标。方程式如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{\sigma(z)_j = \frac{e^{z_j}}{\sum_{k = 1}^{K} e^{z_k}}\qquad for\ j = 1,\cdots, K}</script><p><strong><em>Softmax</em></strong> 的使用包括两个好处，第一个好处是好求导，第二个就是它使得好结果和坏结果之间的差异更加显著，更有利于学习了。关于 <strong><em>Softmax</em></strong> 与 <strong><em>Loss Function</em></strong> 之间的求导可参考这篇文章<a href="https://zhuanlan.zhihu.com/p/25723112"><strong><em>https://zhuanlan.zhihu.com/p/25723112</em></strong></a></p>
<h1 id="4-选择恰当的激活函数"><a href="#4-选择恰当的激活函数" class="headerlink" title="4    选择恰当的激活函数"></a>4    选择恰当的激活函数</h1><p>&emsp;&emsp;在搭建神经网络时，如果搭建的神经网络层数不 多，选择 <strong><em>Sigmoid</em></strong>、<strong><em>Tanh</em></strong>、<strong><em>ReLU</em></strong>，<strong><em>LeakyReLU</em></strong>，<strong><em>Softmax</em></strong> 都可以；而如果搭建的网络层次较 多，那就需要小心，选择不当就可导致梯度消失问题。此时一般不宜选择 <strong><em>Sigmoid</em></strong>、<strong><em>Tanh</em></strong> 激活函数，因它们的导数都小于1，尤其是 <strong><em>Sigmoid</em></strong> 的导数在 [0,1/4]之间，多层叠加后，根据微积分链式法则，随着层数增多，导数或偏导将指数级变小。所以层数较多的激活函数需要考虑其导数不宜小于1当然 也不能大于1，大于1将导致梯度爆炸，导数为1最好，而激活函数 <strong><em>ReLU</em></strong> 及其变种正好满足这个条件。所以，搭建比较深的神经网络时，一般使用 <strong><em>ReLU</em></strong> 激活函数， 当然一般神经网络也可使用。此外，激活函数 <strong><em>Softmax</em></strong> 由于$\boldsymbol{\sum_{j = 0}^{K}\sigma(z)_j} = 1$ 的性质，常用于多分类神经网络输出层。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>【Opencv】图像分割——区域生长</title>
    <url>/2022/06/05/%E3%80%90Opencv%E3%80%91%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E2%80%94%E2%80%94%E5%8C%BA%E5%9F%9F%E7%94%9F%E9%95%BF/</url>
    <content><![CDATA[<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1    环境"></a>1    环境</h1><ul>
<li>Python 3.8.8</li>
<li>PyCharm 2021</li>
<li>opencv-python</li>
</ul>
<h1 id="2-效果"><a href="#2-效果" class="headerlink" title="2    效果"></a>2    效果</h1><p><img src="https://img-blog.csdnimg.cn/25a660a9b01b458bb555118218f30342.gif#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/b8142811e30142519a2d4d2e2cd53f67.gif#pic_center" alt="在这里插入图片描述"></p>
<h1 id="3-原理"><a href="#3-原理" class="headerlink" title="3    原理"></a>3    原理</h1><p>&emsp;&emsp;区域生长的基本思想是将具有相似性质的像素集合起来构成区域。具体先对每个需要分割的区域找一个种子像素作为生长的起点，然后将种子像素周围邻域中与种子像素具有相同或相似性质的像素（根据某种事先确定的生长或相似准则来判定）合并到种子像素所在的区域中。将这些新像素当做新的种子像素继续进行上面的过程，直到再没有满足条件的像素可被包括进来，这样，一个区域就长成了。<br>&emsp;&emsp;区域生长的算法实现：</p>
<ul>
<li>根据图像的不同应用选择一个或一组种子，它或者是最亮或最暗的点，或者是位于点簇中心的点，当然也可以手动选择种子点。</li>
<li>选择一个描述符（条件），常见的有基于区域灰度差、基于区域灰度分布统计性质。</li>
<li>从该种子开始向外扩张，首先把种子像素加入结果集合，然后不断将与集合中各个像素连通、且满足描述符的像素加入集合。</li>
<li>上一过程进行到不再有满足条件的新结点加入集合为止。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/3122cf0544c841c6bcde899af2ecf27c.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="4-案例"><a href="#4-案例" class="headerlink" title="4    案例"></a>4    案例</h1><p>&emsp;&emsp;本次案例采用了一张医学图像，为肺部 <strong>CT</strong> 图像，提取肺的轮廓以判断肺的健康性。</p>
<p><img src="https://img-blog.csdnimg.cn/1fcafbf84ec64432a631ae3a448353d8.png#pic_center" alt="在这里插入图片描述"><br>实现的主要流程如下：</p>
<ul>
<li>读入CT图片，让图片和鼠标进行交互，在三个位置进行左击鼠标生成三个红点，保存每次点击时的 $(y,x)$ 到开始的 $seeds$ 中，完成 $seeds$ 初始化。完成此过程的为 $cv2.setMouseCallback()$。</li>
<li>以上面步骤得到的 $seeds$ 进行区域生长，创建与原 $CT$ 图大小相同的空白图 $seedMark$，根据初始化的种子点的坐标在 $seedMark$ 标记为 $255$。在定义种子点的八领域坐标，当种子与其八邻域的像素差大于 $6$ 且之前在 $seedMark$ 没有被标记过时，则不合并，反之将其与种子进行合并，方式为令 $seedMark$ 的对应坐标的像素为 $255$，并将其存入种子队列作为下次生长时的种子，将当前种子点从种子队列中去除。</li>
<li>输入 $q$ 回车结束交互，效果展示。</li>
</ul>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算种子点和其领域的像素值之差</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getGrayDiff</span>(<span class="params">gray, current_seed, tmp_seed</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">abs</span>(<span class="built_in">int</span>(gray[current_seed[<span class="number">0</span>], current_seed[<span class="number">1</span>]]) - <span class="built_in">int</span>(gray[tmp_seed[<span class="number">0</span>], tmp_seed[<span class="number">1</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 区域生长算法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regional_growth</span>(<span class="params">gray, seeds</span>):</span><br><span class="line">	<span class="comment">#八领域</span></span><br><span class="line">    connects = [(-<span class="number">1</span>, -<span class="number">1</span>), (<span class="number">0</span>, -<span class="number">1</span>), (<span class="number">1</span>, -<span class="number">1</span>), (<span class="number">1</span>, <span class="number">0</span>), \</span><br><span class="line">                (<span class="number">1</span>, <span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>), (-<span class="number">1</span>, <span class="number">1</span>), (-<span class="number">1</span>, <span class="number">0</span>)]</span><br><span class="line">    seedMark = np.zeros((gray.shape))</span><br><span class="line">    height, width = gray.shape</span><br><span class="line">    threshold = <span class="number">6</span></span><br><span class="line">    seedque = deque()</span><br><span class="line">    label = <span class="number">255</span></span><br><span class="line">    seedque.extend(seeds)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> seedque :</span><br><span class="line">    	<span class="comment">#队列具有先进先出的性质。所以要左删</span></span><br><span class="line">        current_seed = seedque.popleft()</span><br><span class="line">        seedMark[current_seed[<span class="number">0</span>], current_seed[<span class="number">1</span>]] = label</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>) :</span><br><span class="line">            tmpX = current_seed[<span class="number">0</span>] + connects[i][<span class="number">0</span>]</span><br><span class="line">            tmpY = current_seed[<span class="number">1</span>] + connects[i][<span class="number">1</span>]</span><br><span class="line">            <span class="comment">#处理边界情况</span></span><br><span class="line">            <span class="keyword">if</span> tmpX &lt; <span class="number">0</span> <span class="keyword">or</span> tmpY &lt; <span class="number">0</span> <span class="keyword">or</span> tmpX &gt;= height <span class="keyword">or</span> tmpY &gt;= width :</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            grayDiff = getGrayDiff(gray, current_seed, (tmpX, tmpY))</span><br><span class="line">            <span class="keyword">if</span> grayDiff &lt; threshold <span class="keyword">and</span> seedMark[tmpX, tmpY] != label :</span><br><span class="line">                seedque.append((tmpX, tmpY))</span><br><span class="line">                seedMark[tmpX, tmpY] = label</span><br><span class="line">    <span class="keyword">return</span> seedMark</span><br><span class="line"></span><br><span class="line"><span class="comment">#交互函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Event_Mouse</span>(<span class="params">event, x, y, flags, param</span>) :</span><br><span class="line">	<span class="comment">#左击鼠标</span></span><br><span class="line">    <span class="keyword">if</span> event == cv.EVENT_LBUTTONDOWN :</span><br><span class="line">    	<span class="comment">#添加种子</span></span><br><span class="line">        seeds.append((y, x))</span><br><span class="line">        <span class="comment">#画实心点</span></span><br><span class="line">        cv.circle(img, center = (x, y), radius = <span class="number">2</span>,</span><br><span class="line">                  color = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thickness = -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Region_Grow</span>(<span class="params">img</span>):</span><br><span class="line">    cv.namedWindow(<span class="string">&#x27;img&#x27;</span>)</span><br><span class="line">    cv.setMouseCallback(<span class="string">&#x27;img&#x27;</span>, Event_Mouse)</span><br><span class="line">    cv.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span> :</span><br><span class="line">        cv.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">        <span class="keyword">if</span> cv.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>) :</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    cv.destroyAllWindows()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    CT = cv.imread(<span class="string">&#x27;images/CT.png&#x27;</span>, <span class="number">1</span>)</span><br><span class="line">    seedMark = np.uint8(regional_growth(cv.cvtColor(CT, cv.COLOR_BGR2GRAY), seeds))</span><br><span class="line"></span><br><span class="line">    cv.imshow(<span class="string">&#x27;seedMark&#x27;</span>, seedMark)</span><br><span class="line">    cv.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">    plt.subplot(<span class="number">131</span>), plt.imshow(cv.cvtColor(CT, cv.COLOR_BGR2RGB))</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>), plt.title(<span class="string">f&#x27;$input\_image$&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">132</span>), plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>), plt.title(<span class="string">f&#x27;$seeds\_image$&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">133</span>), plt.imshow(seedMark, cmap=<span class="string">&#x27;gray&#x27;</span>, vmin = <span class="number">0</span>, vmax = <span class="number">255</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>), plt.title(<span class="string">f&#x27;$segmented\_image$&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    img = cv.imread(<span class="string">&#x27;./images/CT.png&#x27;</span>)</span><br><span class="line">    seeds = []</span><br><span class="line">    Region_Grow(img)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/488a9baf9bea44528c9a7e1528372991.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>【Opencv】图像分割——区域分裂合并</title>
    <url>/2022/06/05/%E3%80%90Opencv%E3%80%91%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E2%80%94%E2%80%94%E5%8C%BA%E5%9F%9F%E5%88%86%E8%A3%82%E5%90%88%E5%B9%B6/</url>
    <content><![CDATA[<h1 id="1-环境"><a href="#1-环境" class="headerlink" title="1    环境"></a>1    环境</h1><ul>
<li>Python 3.8.8</li>
<li>PyCharm 2021</li>
<li>opencv-python</li>
</ul>
<h1 id="2-效果"><a href="#2-效果" class="headerlink" title="2    效果"></a>2    效果</h1><p><img src="https://img-blog.csdnimg.cn/04ac6b270c534055a3acc8e63711927a.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="3-原理"><a href="#3-原理" class="headerlink" title="3    原理"></a>3    原理</h1><p>&emsp;&emsp;区域生长是从某个或者某些像素点出发，最后得到整个区域，进而实现目标提取。分裂合并差不多是区域生长的逆过程：从整个图像出发，不断分裂得到各个子区域，然后再把前景区域合并，实现目标提取。分裂合并的假设是对于一幅图像，前景区域由一些相互连通的像素组成的，因此，如果把一幅图像分裂到像素级，那么就可以判定该像素是否为前景像素。当所有像素点或者子区域完成判断以后，把前景区域或者像素合并就可得到前景目标。<br><img src="https://img-blog.csdnimg.cn/d5a4e02a2c774c27a3be1b462886d5e0.png#pic_center" alt="在这里插入图片描述"><br>在区域分裂合并中最常用的方法是四叉树分解法，算法过程如下，设 $R$ 代表整个正方形图像区域，$P$ 代表逻辑谓词，$P$ 可以理解成分裂和合并的准则函数，基本分裂合并算法步骤如下：</p>
<ul>
<li>对任一个区域，如果 $P(R_i)=false$ 就将其分裂成不重叠的四等份。</li>
<li>对相邻的两个区域 $R_i$ 和 $R_j$，它们也可以大小不同（即不在同一层），如果条件 $P(R_i∪R_j)=true$满足，就将它们合并起来。</li>
<li>如果无法进一步分裂或合并，则结束。</li>
</ul>
<p>这种方法对复杂图像的分割效果较好，但算法较复杂，计算量大，分裂还可能破坏区域的边界。</p>
<h1 id="4-代码"><a href="#4-代码" class="headerlink" title="4    代码"></a>4    代码</h1><p>将物体与背景分离，主要流程如下：</p>
<ul>
<li>读取图片的灰度图，这是为了分裂和合并时的方便。</li>
<li>此次实例采用了递归数据结构进行分裂和合并，分裂合并的准则采用的表达式为$(area[row][col] - mean) &lt; 2 * std$，当区域内超过$95\%$ 的像素满足这一条件时，就返回True，对当前区域进行合并处理，否则以左上方块、右上方、左下方和右下方的顺序继续递归分裂。</li>
<li>合并的操作是对当前区域进行阈值分割，本实验采用了双阈值法，因为灰度图中五角星、椭圆、背景、五边形的像素值分别为：84、91、195、218。</li>
</ul>
<p>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#分裂</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Division_Judge</span>(<span class="params">img, h0, w0, h, w</span>) :</span><br><span class="line">    area = img[h0 : h0 + h, w0 : w0 + w]</span><br><span class="line">    mean = np.mean(area)</span><br><span class="line">    std = np.std(area, ddof = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    total_points = <span class="number">0</span></span><br><span class="line">    operated_points = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(area.shape[<span class="number">0</span>]) :</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(area.shape[<span class="number">1</span>]) :</span><br><span class="line">            <span class="keyword">if</span> (area[row][col] - mean) &lt; <span class="number">2</span> * std :</span><br><span class="line">                operated_points += <span class="number">1</span></span><br><span class="line">            total_points += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> operated_points / total_points &gt;= <span class="number">0.95</span> :</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Merge</span>(<span class="params">img, h0, w0, h, w</span>) :</span><br><span class="line">    <span class="comment"># area = img[h0 : h0 + h, w0 : w0 + w]</span></span><br><span class="line">    <span class="comment"># _, thresh = cv.threshold(area, 0, 255, cv.THRESH_OTSU + cv.THRESH_BINARY_INV)</span></span><br><span class="line">    <span class="comment"># img[h0 : h0 + h, w0 : w0 + w] = thresh</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(h0, h0 + h) :</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(w0, w0 + w) :</span><br><span class="line">            <span class="keyword">if</span> img[row, col] &gt; <span class="number">100</span> <span class="keyword">and</span> img[row, col] &lt; <span class="number">200</span>:</span><br><span class="line">                img[row, col] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                img[row, col] = <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Recursion</span>(<span class="params">img, h0, w0, h, w</span>) :</span><br><span class="line">    <span class="comment">#如果满足分裂条件继续分裂</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> Division_Judge(img, h0, w0, h, w) <span class="keyword">and</span> <span class="built_in">min</span>(h, w) &gt; <span class="number">5</span> :</span><br><span class="line">        <span class="comment">#递归继续判断能否继续分裂</span></span><br><span class="line">        <span class="comment">#左上方块</span></span><br><span class="line">        Division_Judge(img, h0, w0, <span class="built_in">int</span>(h0 / <span class="number">2</span>), <span class="built_in">int</span>(w0 / <span class="number">2</span>))</span><br><span class="line">        <span class="comment">#右上方块</span></span><br><span class="line">        Division_Judge(img, h0, w0 + <span class="built_in">int</span>(w0 / <span class="number">2</span>), <span class="built_in">int</span>(h0 / <span class="number">2</span>), <span class="built_in">int</span>(w0 / <span class="number">2</span>))</span><br><span class="line">        <span class="comment">#左下方块</span></span><br><span class="line">        Division_Judge(img, h0 + <span class="built_in">int</span>(h0 / <span class="number">2</span>), w0, <span class="built_in">int</span>(h0 / <span class="number">2</span>), <span class="built_in">int</span>(w0 / <span class="number">2</span>))</span><br><span class="line">        <span class="comment">#右下方块</span></span><br><span class="line">        Division_Judge(img, h0 + <span class="built_in">int</span>(h0 / <span class="number">2</span>), w0 + <span class="built_in">int</span>(w0 / <span class="number">2</span>), <span class="built_in">int</span>(h0 / <span class="number">2</span>), <span class="built_in">int</span>(w0 / <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="comment">#合并</span></span><br><span class="line">        Merge(img, h0, w0, h, w)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Division_Merge_Segmented</span>() :</span><br><span class="line">    img = cv.imread(<span class="string">&#x27;images/shapes.png&#x27;</span>)</span><br><span class="line">    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line">    hist, bins = np.histogram(img_gray, bins = <span class="number">256</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;五角星、椭圆、背景、五边形的像素值分别为：&#x27;</span></span><br><span class="line">          <span class="string">f&#x27;<span class="subst">&#123;<span class="string">&quot;、&quot;</span>.join(<span class="string">&quot;%s&quot;</span> % pixel <span class="keyword">for</span> pixel <span class="keyword">in</span> np.unique(img_gray))&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    segemented_img = img_gray.copy()</span><br><span class="line">    Recursion(segemented_img, <span class="number">0</span>, <span class="number">0</span>, segemented_img.shape[<span class="number">0</span>], segemented_img.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">    plt.subplot(<span class="number">131</span>), plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>), plt.title(<span class="string">f&#x27;$input\_image$&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">132</span>), plt.imshow(img_gray, cmap=<span class="string">&#x27;gray&#x27;</span>, vmin = <span class="number">0</span>, vmax = <span class="number">255</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>), plt.title(<span class="string">f&#x27;$gray\_image$&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">133</span>), plt.imshow(segemented_img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>), plt.title(<span class="string">f&#x27;$segmented\_image$&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    Division_Merge_Segmented()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode——二叉树的前中后序遍历</title>
    <url>/2022/06/05/LeetCode%E2%80%94%E2%80%94%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%89%8D%E4%B8%AD%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86/</url>
    <content><![CDATA[<p>﻿二叉树主要有两种遍历方式：</p>
<ul>
<li>深度优先遍历：先往深走，遇到叶子节点再往回走。</li>
<li>广度优先遍历：一层一层的去遍历，也就是常说的层遍历。</li>
</ul>
<p>在深度优先遍历中：有三个顺序，前中后序遍历，这中间的”前中后”指的是遍历父节点的先后顺序，且左节点永远在右节点前面遍历。</p>
<ul>
<li>前序遍历(父左右)：F、B、A、D、C、E、G、I、H。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/995903c9c7ca4e478bbfd83931f7f6f6.png#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>中序遍历(左父右)：A、B、C、D、E、F、G、H、I。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/5ba6538ec0ca442b882ba49a27438913.png#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>后序遍历(左右父)：A、C、E、D、B、H、I、G、F。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/00f4a4459c8040cf963cbd3ac1dea329.png#pic_center" alt="在这里插入图片描述"></p>
<p>图片来源：<a href="https://zh.m.wikipedia.org/wiki/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86"><strong><em>https://zh.m.wikipedia.org/wiki/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86</em></strong></a><br>在树的遍实现方法中，有两种比较主流：迭代和递归。下面以力扣的三道题目作为例子：</p>
<ul>
<li>144.二叉树的前序遍历</li>
<li>94.二叉树的中序遍历</li>
<li>145.二叉树的后序遍历</li>
</ul>
<p>递归：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#前序</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">preorderTraversal</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        answer = []</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">node</span>) :</span><br><span class="line">            <span class="keyword">if</span> node <span class="keyword">is</span> <span class="literal">None</span> :</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            </span><br><span class="line">            answer.append(node.val)</span><br><span class="line">            dfs(node.left)</span><br><span class="line">            dfs(node.right)</span><br><span class="line"></span><br><span class="line">        dfs(root)</span><br><span class="line">        <span class="keyword">return</span> answer</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#中序</span></span><br><span class="line"> <span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inorderTraversal</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        answer = []</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">node</span>) :</span><br><span class="line">            <span class="keyword">if</span> node <span class="keyword">is</span> <span class="literal">None</span> :</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line"></span><br><span class="line">            dfs(node.left)</span><br><span class="line">            answer.append(node.val)</span><br><span class="line">            dfs(node.right)</span><br><span class="line"></span><br><span class="line">        dfs(root)</span><br><span class="line">        <span class="keyword">return</span> answer</span><br><span class="line"></span><br><span class="line"><span class="comment">#后序</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">postorderTraversal</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">dfs</span>(<span class="params">node</span>) :</span><br><span class="line">            <span class="keyword">if</span> node <span class="keyword">is</span> <span class="literal">None</span> :</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            </span><br><span class="line">            dfs(node.left)</span><br><span class="line">            dfs(node.right)</span><br><span class="line">            answer.append(node.val)</span><br><span class="line"></span><br><span class="line">        answer = []</span><br><span class="line">        dfs(root)</span><br><span class="line">        <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure>
<p>迭代：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, left=None, right=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.left = left</span></span><br><span class="line"><span class="comment">#         self.right = right</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#前序</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">preorderTraversal</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span> :</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        </span><br><span class="line">        stack = []</span><br><span class="line">        result = []</span><br><span class="line"></span><br><span class="line">        stack.append(root)</span><br><span class="line">        <span class="keyword">while</span> stack :</span><br><span class="line">            node = stack.pop()</span><br><span class="line">            result.append(node.val)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> node.right :</span><br><span class="line">                stack.append(node.right)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> node.left :</span><br><span class="line">                stack.append(node.left)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment">#中序</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inorderTraversal</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span> :</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">        result = []</span><br><span class="line">        stack = []</span><br><span class="line">        curr = root </span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> curr <span class="keyword">or</span> stack :</span><br><span class="line">            <span class="comment">#访问最左边节点</span></span><br><span class="line">            <span class="keyword">if</span> curr :</span><br><span class="line">                stack.append(curr)</span><br><span class="line">                curr = curr.left</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                node = stack.pop()</span><br><span class="line">                result.append(node.val)</span><br><span class="line">                <span class="comment">#访问栈顶元素的右边节点</span></span><br><span class="line">                curr = node.right</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment">#后序</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">postorderTraversal</span>(<span class="params">self, root: <span class="type">Optional</span>[TreeNode]</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> root <span class="keyword">is</span> <span class="literal">None</span> :</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">        result = []</span><br><span class="line">        stack = []</span><br><span class="line">        stack.append(root)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> stack :</span><br><span class="line">            node = stack.pop()</span><br><span class="line">            result.append(node.val)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> node.left :</span><br><span class="line">                stack.append(node.left)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> node.right :</span><br><span class="line">                stack.append(node.right)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result[ : : -<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>二叉树</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】图像分割——聚类算法</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E2%80%94%E2%80%94%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="1-原理"><a href="#1-原理" class="headerlink" title="1    原理"></a>1    原理</h1><p>KMeans算法概述</p>
<ul>
<li>KMeans算法的作者是MacQueen， KMeans的算法是对数据进行分类的算法，采用的硬分类方式，是属于非监督学习的算法；</li>
<li>对于给定的样本集，按照样本之间的距离大小，将样本划分为K个簇，让簇内的点尽量紧密的连接在一起，而让簇间的距离尽量的大。</li>
</ul>
<p>KMeans算法流程</p>
<ul>
<li>1：选择K个点作为初始质心。</li>
<li>2：<strong><em>Repeat</em></strong></li>
<li>3： 计算邻近度，将每个点指派到最近的质心，形成K个簇；</li>
<li>4： 重新计算每个簇的质心；</li>
<li>5： <strong><em>Until</em></strong> 质心不发生变化或者新的中心和之前的中心之间的距离小于某阈值，或迭代次数超过某阈值，认为聚类已经收敛，终止。</li>
</ul>
<h1 id="2-API"><a href="#2-API" class="headerlink" title="2    API"></a>2    API</h1><p>函数原型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">compactness, labels, (centers) = kmeans(data, K, bestLabels, criteria, attempts, flags, centers=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>参数：</p>
<ul>
<li><strong>data</strong>：输入的样本数据，必须是按行组织样本，每一行为一个样本数据，列表示样本的维度。</li>
<li><strong>K</strong>：最终的簇的数目。</li>
<li><strong>bestLabels</strong>：预设的分类标签或者None。<ul>
<li><strong>criteria</strong>：迭代停止的模式选择，这是一个含有三个元素的元组型数。格式为（type, max_iter, epsilon） 其中，type有如下模式：<ul>
<li><strong>cv2.TERM_CRITERIA_EPS</strong> ：精确度（误差）满足epsilon，则停止。</li>
<li><strong>cv2.TERM_CRITERIA_MAX_ITER</strong>：迭代次数超过max_iter，则停止。</li>
<li><strong>cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER</strong>：两者结合，满足任意一个结束。</li>
</ul>
</li>
</ul>
</li>
<li><strong>attempts</strong>：重复试验kmeans算法次数，将会返回最好的一次结果。</li>
<li><strong>flags</strong>：初始中心选择，可选以下三种：<ul>
<li><strong>cv2.KMEANS_PP_CENTERS</strong>：使用kmeans++算法的中心初始化算法，即初始中心的选择使眼色相差最大。</li>
<li><strong>cv2.KMEANS_RANDOM_CENTERS</strong>：每次随机选择初始中心</li>
</ul>
</li>
</ul>
<p>返回值：</p>
<ul>
<li><strong>compactness</strong>：密度，返回每个点到相应重心的距离的平方和。</li>
<li><strong>labels</strong>：结果标记，每个成员被标记为分组的序号，如 0,1,2,3,4…等。</li>
<li><strong>centers</strong>：由聚类的中心的描述信息(可能是坐标，也可能是色彩值)组成的数组。</li>
</ul>
<h1 id="3-图像分割"><a href="#3-图像分割" class="headerlink" title="3    图像分割"></a>3    图像分割</h1><ul>
<li>在一张图片中，每一个像素点对应位置坐标和色彩坐标，用k-means算法对图像聚类不是聚类位置信息，而是对其色彩进行聚类。</li>
<li>kmeans能够实现简单的分割，当然效果不是非常好，需要经过一些后处理调整，才能得到高精度的分割图。</li>
</ul>
<p>本次的案例是分割下面图片的各个区域。即分割出天空、楼房、草坪、湖面。</p>
<p><img src="https://img-blog.csdnimg.cn/5dd79562edbd411880a1ffaf95cb5166.png#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_KMeans</span>(<span class="params">image_path</span>) :</span><br><span class="line">    image = cv.imread(image_path, cv.IMREAD_COLOR)</span><br><span class="line">    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)</span><br><span class="line">    pixel_value = np.float32(image.reshape((-<span class="number">1</span>, <span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#终止条件</span></span><br><span class="line">    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, <span class="number">200</span>, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#起始的中心选择</span></span><br><span class="line">    flags = cv.KMEANS_RANDOM_CENTERS</span><br><span class="line"></span><br><span class="line">    <span class="comment">#定义簇的数量</span></span><br><span class="line">    K = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    _, labels, center = cv.kmeans(pixel_value, K, <span class="literal">None</span>, criteria, <span class="number">10</span>, flags)</span><br><span class="line">    center = np.uint8(center)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#将所有像素转换为质心的颜色</span></span><br><span class="line">    segmented_image = center[labels.flatten()]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#重塑回原始图像尺寸</span></span><br><span class="line">    segmented_image = segmented_image.reshape((image.shape))</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize = (<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line">    plt.subplot(<span class="number">121</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">f&#x27;$input\_image$&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">122</span>)</span><br><span class="line">    plt.imshow(segmented_image)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">f&#x27;$segmented\_image$&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;segmented_result.png&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test_KMeans(<span class="string">&#x27;images/shenzhen.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/8cce34e39c164692a08fe3acbadc5a8f.png#pic_center" alt="在这里插入图片描述"></p>
<p>整体效果还是不错的，但是一些细节的地方处理的不好，比如说湖面有部分被分为了天空，改进策略有有规则地初始化质心等。</p>
<h1 id="4-代码解释"><a href="#4-代码解释" class="headerlink" title="4    代码解释"></a>4    代码解释</h1><p>大家有疑惑的地方就是<code>segmented_image = center[labels.flatten()]</code>是怎么将所有像素转换为质心的颜色的。我们前面说过，返回值center是色彩的描述信息，当图片为三通道时，center的维度就是(K，Channels)，K是簇的个数，Channels是图片的通道数，如当center返回值是[[ 33  71  57]， [193 202 214]，[ 65 134 173]]时，[ 33  71  57]分别表示第一个簇心的R、G、B通道的像素值。其次labels返回每个成员被标记为分组的序号，如 0,1,2,3,4…等，在过程中是将R、G、B通道的像素信息整合到一起来标记，所以labels的维度只相当于某一通道展平，如图片本来是[2，4，3]，那labels是[8，1]。因此labels中每个标记对应center中的每个簇的下标，如0对应center下标为0的簇心信息。则<code>segmented_image = center[labels.flatten()]</code>也是将一个通道”拓展”成三通道的过程。也等效于于下面的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">labels = labels.flatten()</span><br><span class="line">   segmented_image = np.zeros((<span class="built_in">len</span>(labels), <span class="number">3</span>), dtype = np.uint8)</span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)) :</span><br><span class="line">       segmented_image[i] = center[labels[i]]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>聚类</tag>
        <tag>opencv</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】图像分割——分水岭算法</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E2%80%94%E2%80%94%E5%88%86%E6%B0%B4%E5%B2%AD%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="1-原理"><a href="#1-原理" class="headerlink" title="1    原理"></a>1    原理</h1><p>&emsp;&emsp;分水岭分割方法，是一种基于拓扑理论的数学形态学的分割方法，其基本思想是把图像看作是测地学上的拓扑地貌，图像中每一点像素的灰度值表示该点的海拔高度，每一个局部极小值及其影响区域称为集水盆，而集水盆的边界则形成分水岭。分水岭的概念和形成可以通过模拟浸入过程来说明。在每一个局部极小值表面，刺穿一个小孔，然后把整个模型慢慢浸入水中，随着浸入的加深，每一个局部极小值的影响域慢慢向外扩展，在两个集水盆汇合处构筑大坝，即形成分水岭。这种方法也称作泛洪法，对应的还有降雨法。</p>
<p><img src="https://img-blog.csdnimg.cn/b5945e2ce1f64e16889a1b0c1e8d7ae0.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;分水岭的计算过程是一个迭代标注过程。分水岭比较经典的计算方法是L. Vincent提出的。在该算法中，分水岭计算分两个步骤，一个是排序过程，一个是淹没过程。首先对每个像素的灰度级进行从低到高排序，然后在从低到高实现淹没过程中，对每一个局部极小值在 $h$ 阶高度的影响域采用先进先出(FIFO)结构进行判断及标注。具体流程如下：</p>
<ul>
<li>把梯度图像中的像素按照灰度值进行分类，设定一个测地距离阈值(测地线距离(Geodesic Distance)：地球表面两点之间的最短路径的距离)。</li>
<li>找到灰度值最小的像素点，让 $threshold$ 从最小值开始增长，这些点为起始点。</li>
<li>水平面在增长的过程中，会碰到周围的邻域像素，测量这些像素到起始点(灰度值最低点)的测地距离，如果小于设定阈值，则将这些像素淹没，否则在这些像素上设置大坝，这样就对这些邻域像素进行了分类。</li>
<li>随着水平面越来越高，会设置更多更高的大坝，直到灰度值的最大值，所有区域都在分水岭线上相遇，这些大坝就对整个图像像素的进行了分区。<br><img src="https://img-blog.csdnimg.cn/1c41a28800204914b434e12cd29d9a58.png#pic_center" alt="在这里插入图片描述"></li>
</ul>
<h1 id="2-算法改进"><a href="#2-算法改进" class="headerlink" title="2    算法改进"></a>2    算法改进</h1><p>&emsp;&emsp;基于梯度图像的直接分水岭算法容易导致图像的过分割，产生这一现象的原因主要是由于输入的图像存在过多的极小区域而产生许多小的集水盆地，从而导致分割后的图像不能将图像中有意义的区域表示出来。</p>
<p><img src="https://img-blog.csdnimg.cn/3be1a8b65e8c44fb81658e34d359d63e.png#pic_center" alt="在这里插入图片描述"><br>在 $OpenCv$ 中算法不从最小值开始增长，可以将相对较高的灰度值像素作为起始点（需要用户手动标记），从标记处开始进行淹没，则很多小区域都会被合并为一个区域，这被称为基于图像标(mark)的分水岭算法。其中标记的每个点就相当于分水岭中的注水点，从这些点开始注水使得水平面上升。手动标记太麻烦，我们可是使用距离转换(<code>cv2.distanceTransform</code>函数)的方法进行标记。<code>cv2.distanceTransform</code>计算的是图像内非零值像素点到最近的零值像素点的距离，即计算二值图像中所有像素点距离其最近的值为 0 的像素点的距离。当然，如果像素点本身的值为 0，则这个距离也为 0。<img src="https://img-blog.csdnimg.cn/82fa1dec155c49498e2019e59485ebe5.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="3-API"><a href="#3-API" class="headerlink" title="3    API"></a>3    API</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.watershed( InputArray image, InputOutputArray markers )</span><br></pre></td></tr></table></figure>
<ul>
<li>第一个参数 $image$，必须是一个8bit 3通道彩色图像矩阵序列。</li>
<li>关键是第二个参数 markers：在执行分水岭函数watershed之前，必须对第二个参数 $markers$ 进行处理，它应该包含不同区域的轮廓，每个轮廓有一个自己唯一的编号，轮廓的定位可以通过 $Opencv$ 中 <code>connectedComponents</code> 方法实现，这个是执行分水岭之前的要求。</li>
</ul>
<p>算法会根据markers传入的轮廓作为种子(也就是所谓的注水点)，对图像上其他的像素点根据分水岭算法规则进行判断，并对每个像素点的区域归属进行划定，直到处理完图像上所有像素点。而区域与区域之间的分界处的值被置为“-1”，以做区分。</p>
<h1 id="4-实例"><a href="#4-实例" class="headerlink" title="4    实例"></a>4    实例</h1><p>目标是将下图中的硬币和背景分离：</p>
<p><img src="https://img-blog.csdnimg.cn/00924d9e96e941a3a17f1e33d3cb7b64.png#pic_center" alt="在这里插入图片描述"><br>在编程之前为了更好理解过程，要先介绍几个概念。</p>
<ul>
<li>背景：不感兴趣的区域，越远离目标图像中心的区域就越是背景</li>
<li>前景：感兴趣的区域，越靠近目标图像中心就越是前景</li>
<li>未知区域：即不确定区域，边界所在的区域</li>
</ul>
<p>流程图：</p>
<p><img src="https://img-blog.csdnimg.cn/401a998689c8405b91e7a1442ec00b94.png#pic_center" alt="在这里插入图片描述"><br>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_watershed</span>() :</span><br><span class="line">    image = cv.imread(<span class="string">&#x27;images/coins.jpg&#x27;</span>)</span><br><span class="line">    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="comment">#基于直方图的二值化处理</span></span><br><span class="line">    _, thresh = cv.threshold(image_gray, <span class="number">0</span>, <span class="number">255</span>, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#做开操作，是为了除去白噪声</span></span><br><span class="line">    kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>), dtype = np.uint8)</span><br><span class="line">    opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#做膨胀操作，是为了让前景漫延到背景，让确定的背景出现</span></span><br><span class="line">    sure_bg = cv.dilate(opening, kernel, iterations = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#为了求得确定的前景，也就是注水处使用距离的方法转化</span></span><br><span class="line">    dist_transform = cv.distanceTransform(opening, cv.DIST_L2, <span class="number">5</span>)</span><br><span class="line">    <span class="comment">#归一化所求的距离转换，转化范围是[0, 1]</span></span><br><span class="line">    cv.normalize(dist_transform, dist_transform, <span class="number">0</span>, <span class="number">1.0</span>, cv.NORM_MINMAX)</span><br><span class="line">    <span class="comment">#再次做二值化，得到确定的前景</span></span><br><span class="line">    _, sure_fg = cv.threshold(dist_transform, <span class="number">0.5</span> * dist_transform.<span class="built_in">max</span>(), <span class="number">255</span>, <span class="number">0</span>)</span><br><span class="line">    sure_fg = np.uint8(sure_fg)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#得到不确定区域也就是边界所在区域，用确定的背景图减去确定的前景图</span></span><br><span class="line">    unknow = cv.subtract(sure_bg, sure_fg)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#给确定的注水位置进行标上标签，背景图标为0，其他的区域由1开始按顺序进行标</span></span><br><span class="line">    _, markers = cv.connectedComponents(sure_fg)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># cv.imshow(&#x27;markers&#x27;, markers.astype(np.uint8))</span></span><br><span class="line">    <span class="comment"># cv.waitKey(0)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#让标签加1，这是因为在分水岭算法中，会将标签为0的区域当作边界区域（不确定区域）</span></span><br><span class="line">    markers += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#是上面所求的不确定区域标上0</span></span><br><span class="line">    markers[unknow == <span class="number">255</span>] = <span class="number">0</span></span><br><span class="line">    <span class="comment"># print(markers.dtype)  int32</span></span><br><span class="line">    markers_copy = markers.copy()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用分水岭算法执行基于标记的图像分割，将图像中的对象与背景分离</span></span><br><span class="line">    markers = cv.watershed(image, markers)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#分水岭算法得到的边界点的像素值为-1</span></span><br><span class="line">    image[markers == -<span class="number">1</span>] = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>]</span><br><span class="line"></span><br><span class="line">    images = [thresh, opening, sure_bg, dist_transform, sure_fg, unknow, markers_copy, image]</span><br><span class="line"></span><br><span class="line">    titles = [<span class="string">&#x27;thresh&#x27;</span>, <span class="string">&#x27;opening&#x27;</span>, <span class="string">&#x27;sure_bg&#x27;</span>, <span class="string">&#x27;dist_tranform&#x27;</span>, <span class="string">&#x27;sure_fg&#x27;</span>, <span class="string">&#x27;unknow&#x27;</span>, <span class="string">&#x27;markers&#x27;</span>, <span class="string">&#x27;image&#x27;</span>]</span><br><span class="line">    plt.figure(figsize = (<span class="number">8</span>, <span class="number">6.1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(images)) :</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">7</span> :</span><br><span class="line">            plt.subplot(<span class="number">2</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">            plt.imshow(cv.cvtColor(images[i], cv.COLOR_BGR2RGB))</span><br><span class="line">            plt.title(titles[i])</span><br><span class="line">            plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            plt.subplot(<span class="number">2</span>, <span class="number">4</span>, i + <span class="number">1</span>)</span><br><span class="line">            plt.imshow(images[i], cmap = <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">            plt.title(titles[i])</span><br><span class="line">            plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;figure.png&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    test_watershed()</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/c730e7f6226a4b08b6f1b22c4fe14abd.png#pic_center" alt="在这里插入图片描述"><br>从上面看来效果还是蛮好的。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>图像分割</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode——回溯算法的经典问题</title>
    <url>/2022/06/05/LeetCode%E2%80%94%E2%80%94%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%E7%9A%84%E7%BB%8F%E5%85%B8%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="17-电话号码的字母组合"><a href="#17-电话号码的字母组合" class="headerlink" title="17. 电话号码的字母组合"></a>17. 电话号码的字母组合</h1><p>给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按任意顺序 返回。给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。</p>
<p><img src="https://img-blog.csdnimg.cn/ccfb1550c00046609eba8783710053ad.png#pic_center" alt="在这里插入图片描述"><br>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：digits = <span class="string">&quot;23&quot;</span></span><br><span class="line">输出：[<span class="string">&quot;ad&quot;</span>,<span class="string">&quot;ae&quot;</span>,<span class="string">&quot;af&quot;</span>,<span class="string">&quot;bd&quot;</span>,<span class="string">&quot;be&quot;</span>,<span class="string">&quot;bf&quot;</span>,<span class="string">&quot;cd&quot;</span>,<span class="string">&quot;ce&quot;</span>,<span class="string">&quot;cf&quot;</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">letterCombinations</span>(<span class="params">self, digits: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="keyword">if</span> digits == <span class="string">&quot;&quot;</span> :</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        <span class="comment">#数字字母映射表</span></span><br><span class="line">        mapping = &#123;</span><br><span class="line">            <span class="string">&#x27;2&#x27;</span> : <span class="string">&#x27;abc&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;3&#x27;</span> : <span class="string">&#x27;def&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;4&#x27;</span> : <span class="string">&#x27;ghi&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;5&#x27;</span> : <span class="string">&#x27;jkl&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;6&#x27;</span> : <span class="string">&#x27;mno&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;7&#x27;</span> : <span class="string">&#x27;pqrs&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;8&#x27;</span> : <span class="string">&#x27;tuv&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;9&#x27;</span> : <span class="string">&#x27;wxyz&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">        res = []</span><br><span class="line">        res_str = []</span><br><span class="line"></span><br><span class="line">        mapping_digits = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(digits)) :</span><br><span class="line">            mapping_digits.append(mapping[digits[i]])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtracking</span>(<span class="params">res_str, index</span>) :</span><br><span class="line">            <span class="comment">#递归终止条件</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(res_str) == <span class="built_in">len</span>(digits) :</span><br><span class="line">                res.append(<span class="string">&quot;&quot;</span>.join(res_str))</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mapping_digits[index])) :</span><br><span class="line">                res_str.append(mapping_digits[index][i])</span><br><span class="line">                <span class="comment">#回溯</span></span><br><span class="line">                backtracking(res_str, index + <span class="number">1</span>)</span><br><span class="line">                <span class="comment">#撤销</span></span><br><span class="line">                res_str.pop()</span><br><span class="line">        backtracking(res_str, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h1 id="39-组合总和"><a href="#39-组合总和" class="headerlink" title="39. 组合总和"></a>39. 组合总和</h1><p>给你一个 无重复元素 的整数数组 <strong>candidates</strong> 和一个目标整数 <strong>target</strong> ，找出 <strong>candidates</strong> 中可以使数字和为目标数 target 的 所有 不同组合 ，并以列表形式返回。你可以按 任意顺序 返回这些组合。<strong>candidates</strong> 中的 同一个 数字可以 无限制重复被选取 。如果至少一个数字的被选数量不同，则两种组合是不同的。 对于给定的输入，保证和为 target 的不同组合数少于 150 个。</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：candidates = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">7</span>], target = <span class="number">7</span></span><br><span class="line">输出：[[<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">7</span>]]</span><br><span class="line">解释：</span><br><span class="line"><span class="number">2</span> 和 <span class="number">3</span> 可以形成一组候选，<span class="number">2</span> + <span class="number">2</span> + <span class="number">3</span> = <span class="number">7</span> 。注意 <span class="number">2</span> 可以使用多次。<span class="number">7</span> 也是一个候选， <span class="number">7</span> = <span class="number">7</span> 。仅有这两种组合。</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combinationSum</span>(<span class="params">self, candidates: <span class="type">List</span>[<span class="built_in">int</span>], target: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        res = []</span><br><span class="line">        res_temp = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtracking</span>(<span class="params">candidates, target, res_temp, startIndex</span>) :</span><br><span class="line">            <span class="comment">#递归终止条件</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">sum</span>(res_temp) == target :</span><br><span class="line">                res.append(res_temp[:])</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">#应满足的条件</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">sum</span>(res_temp) &gt; target :</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(startIndex, <span class="built_in">len</span>(candidates)) :</span><br><span class="line">                <span class="comment">#剪枝</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">sum</span>(res_temp) + candidates[col] &gt; target :</span><br><span class="line">                    <span class="keyword">return</span> </span><br><span class="line">                res_temp.append(candidates[col])</span><br><span class="line">                <span class="comment">#回溯</span></span><br><span class="line">                backtracking(candidates, target, res_temp, col)</span><br><span class="line">                <span class="comment">#撤销</span></span><br><span class="line">                res_temp.pop()</span><br><span class="line">        candidates = <span class="built_in">sorted</span>(candidates)</span><br><span class="line">        backtracking(candidates, target, res_temp, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h1 id="46-全排列"><a href="#46-全排列" class="headerlink" title="46. 全排列"></a>46. 全排列</h1><p>给定一个不含重复数字的数组 nums ，返回其 所有可能的全排列 。你可以按任意顺序 返回答案。</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">输出：[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],[<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">permute</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        res_temp = []</span><br><span class="line">        res = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtracking</span>(<span class="params">res_temp</span>) :</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(res_temp) == <span class="built_in">len</span>(nums) :</span><br><span class="line">                res.append(res_temp[ : ])</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">                </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(nums)) :</span><br><span class="line">                <span class="comment">#不能含有相同元素</span></span><br><span class="line">                <span class="keyword">if</span> nums[i] <span class="keyword">in</span> res_temp :</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                res_temp.append(nums[i])</span><br><span class="line">                backtracking(res_temp)</span><br><span class="line">                res_temp.pop()</span><br><span class="line">        backtracking(res_temp)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h1 id="51-N-皇后"><a href="#51-N-皇后" class="headerlink" title="51. N 皇后"></a>51. N 皇后</h1><p><strong>n 皇后问题</strong> 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。给你一个整数 n ，返回所有不同的 <strong>n 皇后问题</strong> 的解决方案。每一种解法包含一个不同的 <strong>n 皇后问题</strong> 的棋子放置方案，该方案中 ‘Q’ 和 ‘.’ 分别代表了皇后和空位。</p>
<p>示例：<br><img src="https://img-blog.csdnimg.cn/884157d59df945709d4b2cb35abcc73f.png#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：n = <span class="number">4</span></span><br><span class="line">输出：[[<span class="string">&quot;.Q..&quot;</span>,<span class="string">&quot;...Q&quot;</span>,<span class="string">&quot;Q...&quot;</span>,<span class="string">&quot;..Q.&quot;</span>],[<span class="string">&quot;..Q.&quot;</span>,<span class="string">&quot;Q...&quot;</span>,<span class="string">&quot;...Q&quot;</span>,<span class="string">&quot;.Q..&quot;</span>]]</span><br><span class="line">解释：如上图所示，<span class="number">4</span> 皇后问题存在两个不同的解法。</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">solveNQueens</span>(<span class="params">self, n: <span class="built_in">int</span></span>):</span><br><span class="line">        chess = [[<span class="string">&#x27;.&#x27;</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> n:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        res = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">IsVaild</span>(<span class="params">chess, row, col, n</span>):</span><br><span class="line">            <span class="comment"># 判断列</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> chess[i][col] == <span class="string">&#x27;Q&#x27;</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 判断左对角线</span></span><br><span class="line">            i = row -<span class="number">1</span></span><br><span class="line">            j = col -<span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> i &gt;= <span class="number">0</span> <span class="keyword">and</span> j &gt;= <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> chess[i][j] == <span class="string">&#x27;Q&#x27;</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">                j -= <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 判断右对角线</span></span><br><span class="line">            i = row - <span class="number">1</span></span><br><span class="line">            j = col + <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> i&gt;=<span class="number">0</span> <span class="keyword">and</span> j &lt; <span class="built_in">len</span>(chess):</span><br><span class="line">                <span class="keyword">if</span> chess[i][j] == <span class="string">&#x27;Q&#x27;</span>:</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtracking</span>(<span class="params">chess, row, n</span>):</span><br><span class="line">            <span class="comment">#递归终止条件</span></span><br><span class="line">            <span class="keyword">if</span> row == n:</span><br><span class="line">                res_temp = []</span><br><span class="line">                <span class="keyword">for</span> result <span class="keyword">in</span> chess:</span><br><span class="line">                    res_temp.append(<span class="string">&quot;&quot;</span>.join(result))</span><br><span class="line">                res.append(res_temp)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> IsVaild(chess, row, col, n):</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                chess[row][col] = <span class="string">&#x27;Q&#x27;</span></span><br><span class="line">                <span class="comment"># print(chess)</span></span><br><span class="line">                backtracking(chess, row + <span class="number">1</span>, n)</span><br><span class="line">                chess[row][col] = <span class="string">&#x27;.&#x27;</span></span><br><span class="line"></span><br><span class="line">        backtracking(chess, <span class="number">0</span>, n)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h1 id="77-组合"><a href="#77-组合" class="headerlink" title="77. 组合"></a>77. 组合</h1><p>给定两个整数 n 和 k，返回范围 [1, n] 中所有可能的 k 个数的组合。你可以按 任何顺序 返回答案。</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：n = <span class="number">4</span>, k = <span class="number">2</span></span><br><span class="line">输出：</span><br><span class="line">[</span><br><span class="line">  [<span class="number">2</span>,<span class="number">4</span>],</span><br><span class="line">  [<span class="number">3</span>,<span class="number">4</span>],</span><br><span class="line">  [<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">3</span>],</span><br><span class="line">  [<span class="number">1</span>,<span class="number">4</span>],</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">combine</span>(<span class="params">self, n: <span class="built_in">int</span>, k: <span class="built_in">int</span></span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        res = []</span><br><span class="line">        res_temp = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtracking</span>(<span class="params">res_temp, k, index</span>) :</span><br><span class="line">            <span class="comment">#终止条件</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(res_temp) == k :</span><br><span class="line">                res.append(res_temp[ : ])</span><br><span class="line">                <span class="keyword">return</span> </span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(index, n + <span class="number">1</span>) :</span><br><span class="line">                <span class="comment">#剪枝操作</span></span><br><span class="line">                <span class="keyword">if</span> (n + <span class="number">1</span>) - i + <span class="built_in">len</span>(res_temp) &lt; k :</span><br><span class="line">                    <span class="keyword">return</span> </span><br><span class="line">                res_temp.append(i)</span><br><span class="line">                backtracking(res_temp, k, i + <span class="number">1</span>)</span><br><span class="line">                res_temp.pop()</span><br><span class="line"></span><br><span class="line">        backtracking(res_temp, k, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<h1 id="78-子集"><a href="#78-子集" class="headerlink" title="78. 子集"></a>78. 子集</h1><p>给你一个整数数组 nums ，数组中的元素 <strong>互不相同</strong> 。返回该数组所有可能的子集（幂集）。解集 <strong>不能</strong> 包含重复的子集。你可以按 <strong>任意顺序</strong> 返回解集。</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">输入：nums = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">输出：[[],[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">1</span>,<span class="number">3</span>],[<span class="number">2</span>,<span class="number">3</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">subsets</span>(<span class="params">self, nums: <span class="type">List</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="type">List</span>[<span class="type">List</span>[<span class="built_in">int</span>]]:</span><br><span class="line">        res = []</span><br><span class="line">        res_temp = []</span><br><span class="line">        nums = <span class="built_in">sorted</span>(nums)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">backtracking</span>(<span class="params">res_temp, startIndex</span>) :</span><br><span class="line">            res.append(res_temp[ : ])</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(startIndex, <span class="built_in">len</span>(nums)) :</span><br><span class="line">                res_temp.append(nums[i])</span><br><span class="line">                backtracking(res_temp, i + <span class="number">1</span>)</span><br><span class="line">                res_temp.pop()</span><br><span class="line"></span><br><span class="line">        backtracking(res_temp, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据结构与算法</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>KNN 算法实现图像分类</title>
    <url>/2022/06/05/KNN-%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<h1 id="1-scikit-learn介绍"><a href="#1-scikit-learn介绍" class="headerlink" title="1    scikit-learn介绍"></a>1    scikit-learn介绍</h1><p>scikit-learn与机器学习的关系：</p>
<ul>
<li>Scikit-learn是基于Python语言的第三方机器学习库。它包含了几乎所有主流机器学习算法的实现，并提供一致的调用接口。</li>
<li>Scikit-learn基于 NumPy 和 SciPy 等科学计算库，支持支持向量机、随机森林、梯度提升树、K 均值、聚类等机器学习算法。</li>
</ul>
<p>scikit-learn功能：</p>
<ul>
<li>Scikit-learn (简记sklearn)是当今非常流行的机器学习工具，也是最有名的Python机器学习库。</li>
<li>Scikit-learn主要功能包括分类、回归、聚类、数据降维、模型选择和数据预处理六大部分。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/d28f060a579d458788a9f08947ba51fa.png" alt="在这里插入图片描述"></p>
<h1 id="2-scikit-learn常用模块"><a href="#2-scikit-learn常用模块" class="headerlink" title="2    scikit-learn常用模块"></a>2    scikit-learn常用模块</h1><h2 id="2-1-数据集模块"><a href="#2-1-数据集模块" class="headerlink" title="2.1    数据集模块"></a>2.1    数据集模块</h2><p>如果要使用Scikit-learn库中提供的数据集，要通过<code>from sklearn import dataset</code>导入数据集模块。</p>
<ul>
<li><code>loaders</code> 可用来加载小的标准数据集，如<code>dataset.load_iris</code></li>
<li><code>fetchers</code> 可用来下载并加载大的真实数据集，如<code>dataset.fetch_olivetti_faces</code></li>
</ul>
<p><code>loaders</code>和<code>fetchers</code>的所有函数都返回一个字典一样的对象，里面至少包含两项:shape为n_samples*n_features的数组，对应的字典key是<code>data</code>以及长度为n_samples的numpy数组，包含了目标值，对应的字典key是<code>target</code>。通过将<code>return_X_y</code>参数设置为True，几乎所有这些函数都可以将输出约束为只包含特征和标签的元组。</p>
<ul>
<li><code>generation functions</code> 可以用来生成受控的合成数据集(synthetic datasets)，这些函数返回一个元组(X,y)，该元组由shape为n_samples*n_features的numpy数组<code>X</code>和长度为n_samples的包含目标<code>y</code>的数组组成。</li>
</ul>
<h2 id="2-2-数据预处理模块"><a href="#2-2-数据预处理模块" class="headerlink" title="2.2    数据预处理模块"></a>2.2    数据预处理模块</h2><p>Scikit-learn的<code>sklearn.preprocessing</code>模块中提供了数据标准化、规范化、二值化、分类特征编码、推断缺失数据等数据预处理方法，通过<code>from sklearn import preprocessing</code>导入。</p>
<p><img src="https://img-blog.csdnimg.cn/0eb1f02d56884792a08f1287a2e4b4e0.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-3-特征提取与选择模块"><a href="#2-3-特征提取与选择模块" class="headerlink" title="2.3    特征提取与选择模块"></a>2.3    特征提取与选择模块</h2><p>特征提取是数据预处理任务中重要的一个环节。特征提取对最终结果的影响要高过数据处理算法本身，通过<code>from sklearn import feature_extraction</code> (特征提取)和<code>from sklearn import feature_selection</code> (特征选择)导入。</p>
<p><img src="https://img-blog.csdnimg.cn/ebaae532ff1f4d359102f2db8fffa65c.png" alt="在这里插入图片描述"></p>
<h1 id="3-K邻近算法-K-Nearest-Neighbor-KNN-介绍"><a href="#3-K邻近算法-K-Nearest-Neighbor-KNN-介绍" class="headerlink" title="3    K邻近算法(K-Nearest Neighbor, KNN)介绍"></a>3    K邻近算法(K-Nearest Neighbor, KNN)介绍</h1><p>基本思想：给定一个训练数据集，对新输入的样本，在训练数据集中找到与该样本最邻近的k个实例(也就是所谓的k个邻居)，这k个实例中的多数属于某个类别，就把输入样本划分到该类别中。k近邻算法通常又可以分为分类算法和回归算法。</p>
<ul>
<li><strong>分类算法</strong>中采用多数表决法，就是选择k个样本中出现最多的类别标记作为预测结果。<br><img src="https://img-blog.csdnimg.cn/0467531ebc8a47df9c033636136d9748.png" alt="在这里插入图片描述"></li>
<li><strong>回归算法</strong>中采用平均法，将k个样本实际输出标记的平均值或加权平均值作为预测结果。</li>
</ul>
<p><strong>优点</strong>：准确性高，对异常值和噪声有较高的容忍度。同时应用广泛，不论是分类还是回归都可以使用。<br><strong>缺点</strong>：KNN是一种懒惰学习方法，在训练得是很好不是真正在学些什么，只是一字不差地存储训练数据。计算量较大，对内存要求也比较大。因为，每次对一个未标记样本进行分类时，都需要全部计算一遍距离。当数据样本分布不平衡时，对稀有类别的预测准确率较低。</p>
<h1 id="4-KNN算法实现Iris数据集的分类"><a href="#4-KNN算法实现Iris数据集的分类" class="headerlink" title="4    KNN算法实现Iris数据集的分类"></a>4    KNN算法实现Iris数据集的分类</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment">#return_X_y = True为了返回的数据是元组而不是字典</span></span><br><span class="line">X, y = load_iris(return_X_y = <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#将数据集进行划分，训练集占7份，测试集占3份</span></span><br><span class="line">train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = <span class="number">0.3</span>, train_size = <span class="number">0.7</span>, stratify = y, random_state = <span class="number">42</span>)</span><br><span class="line">scores = []</span><br><span class="line"><span class="comment">#使用不同的邻居数进行训练测试</span></span><br><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>) :</span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors = n)</span><br><span class="line">    <span class="comment">#训练</span></span><br><span class="line">    knn.fit(train_X, train_y)</span><br><span class="line">    <span class="comment">#预测</span></span><br><span class="line">    pred = knn.predict(test_X)</span><br><span class="line">    <span class="comment">#准确率并保留3位小数</span></span><br><span class="line">    score = <span class="built_in">round</span>(knn.score(test_X, test_y), <span class="number">3</span>)</span><br><span class="line">    scores.append(score)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>), scores, <span class="string">&#x27;o--&#x27;</span>, color = <span class="string">&#x27;blue&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$n\_neighbors$&#x27;</span>, fontsize = <span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;$precision$&#x27;</span>, fontsize = <span class="number">14</span>)</span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">6</span>), scores) :</span><br><span class="line">    plt.text(x - <span class="number">0.18</span>, y - <span class="number">0.1</span>, <span class="string">f&#x27;$<span class="subst">&#123;y&#125;</span>$&#x27;</span>, fontsize = <span class="number">14</span>)</span><br><span class="line">plt.title(<span class="string">f&#x27;$precision\ of\ different\ neighors$&#x27;</span>, fontsize = <span class="number">14</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">1</span>, <span class="number">6</span>))</span><br><span class="line">plt.yticks(np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>))</span><br><span class="line">plt.show()</span><br><span class="line">plt.savefig(<span class="string">&#x27;figure.png&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/52a03d882ee9419e9d16f6f3523bb568.png#pic_center" alt="在这里插入图片描述"></p>
<p>从结果上我们能看出，<strong><em>n_neighbors</em></strong> 也就邻居的数量的选取的不同会影响最终的正确率，但他们之间不是简单的线性关系，<strong><em>n_neighbors</em></strong> 过大或过小都会增大噪声对模型的影响，可能会出现过度拟合的情况。常见做法是，<strong><em>n_neighbors</em></strong> 一般取奇数，尽量避免可能投票表决相等的情况。如上面的简单例子，模型在 <strong><em>n_neighbors</em></strong> 为$1、3、5$条件下表现得相对好一些。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>传统算法</category>
      </categories>
      <tags>
        <tag>KNN</tag>
        <tag>图像分类</tag>
      </tags>
  </entry>
  <entry>
    <title>对抗攻击</title>
    <url>/2022/06/05/%E5%AF%B9%E6%8A%97%E6%94%BB%E5%87%BB/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;在人工智能带来的风险中，对抗攻击就是重要风险之一。攻击者可以通过各种手段绕过，或直接对机器学习模型进行攻击达到对抗目的，使我们的模型失效或误判。如果类似攻击发生在无人驾驶、金融AI等领域则将导致严重后果。所以，需要未雨绸缪，认识各种对抗攻击，并有效地破解各种对抗攻击。</p>
<h1 id="1-原理"><a href="#1-原理" class="headerlink" title="1    原理"></a>1    原理</h1><p>&emsp;&emsp;对抗攻击最核心的手段就是制造对抗样本去迷惑模型，比如在计算机视觉领域，攻击样本就是向原始样本中添加一些人眼无法察觉的噪声，这些噪声不会影响人类识别，但却很容易迷惑机器学习模型，使它做出错误的判断。如下图所示，在雪山样本中增加一些噪声，结果分类模型就把它视为狗了。<br><img src="https://img-blog.csdnimg.cn/949bdab6932d41db8afe9a83ad323625.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;机器学习算法的输入形式为数值型向量（Numeric Vectors）。通过设计 一种特别的输入以使模型输出错误的结果，这便被称为对抗性攻击。<br>&emsp;&emsp;由于机器学习算法的输入形式是一种数值型向量（Numeric Vectors）， 所以攻击者就会通过设计一种有针对性的数值型向量从而让机器学习模型做 出误判，这便被称为对抗性攻击。和其他攻击不同，对抗性攻击主要发生在构造对抗性数据的时候，之后该对抗性数据就如正常数据一样输入机器学习模型并得到欺骗的识别结果。</p>
<h1 id="2-攻击方式"><a href="#2-攻击方式" class="headerlink" title="2    攻击方式"></a>2    攻击方式</h1><h2 id="2-1-针对模型的攻击"><a href="#2-1-针对模型的攻击" class="headerlink" title="2.1    针对模型的攻击"></a>2.1    针对模型的攻击</h2><h3 id="2-1-1-白盒攻击"><a href="#2-1-1-白盒攻击" class="headerlink" title="2.1.1    白盒攻击"></a>2.1.1    白盒攻击</h3><p>&emsp;&emsp;攻击者能够获知机器学习所使用的算法，以及算法所使用的参数。攻击者在产生对抗性攻击数据的过程中能够与机器学习的系统有所交互。</p>
<h3 id="2-1-2-黑盒攻击"><a href="#2-1-2-黑盒攻击" class="headerlink" title="2.1.2    黑盒攻击"></a>2.1.2    黑盒攻击</h3><p>&emsp;&emsp;攻击者并不知道机器学习所使用的算法和参数，但攻击者仍能与机器学习的系统有所交互，比如可以通过传入任意输入观察输出，判断输出。</p>
<h2 id="2-2-针对输出的攻击"><a href="#2-2-针对输出的攻击" class="headerlink" title="2.2    针对输出的攻击"></a>2.2    针对输出的攻击</h2><h3 id="2-2-1-无目标攻击"><a href="#2-2-1-无目标攻击" class="headerlink" title="2.2.1    无目标攻击"></a>2.2.1    无目标攻击</h3><p>&emsp;&emsp;对于一张图像，生成一个对抗样本，使得标注系统在其上的标注与原标 注无关，即只要攻击成功就好，而对抗样本的最终属于哪一类不做限制。</p>
<h3 id="2-2-2-有目标攻击"><a href="#2-2-2-有目标攻击" class="headerlink" title="2.2.2    有目标攻击"></a>2.2.2    有目标攻击</h3><p>&emsp;&emsp;对于一张图像和一个目标标注句子，生成一个对抗样本，使得标注系统 在其上的标注与目标标注完全一致，即不仅要求攻击成功，还要求生成的对抗样本属于特定的类。</p>
<h1 id="3-对抗样本生成方式"><a href="#3-对抗样本生成方式" class="headerlink" title="3    对抗样本生成方式"></a>3    对抗样本生成方式</h1><p>&emsp;&emsp;快速梯度符号法（<strong><em>FGSM</em></strong> ）攻击是一种以错误分类为目标的白盒攻击。这种攻击非常强大，但也很直观。它旨在通过利用神经网络的学习方式梯度来攻击神经网络。其训练目标是最大化损失函数 $J(x^<em>,y)$以获取对抗样本$x^</em>$，其中$J$是分类算法中衡量分类误差的损失函数，通常取交叉熵损失。最大化$J$即使添加噪声后的样本不再属于$y$类，由此则达到 了下图所示的目的。<br><img src="https://img-blog.csdnimg.cn/6e4f600e3b99407fa44cc15e834ffd5e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>其中$x^*=x+ε·sign(∇_xJ(x,y))$，$sign()$是符号函数，括号里面是损失函数对$x$的偏导，$ε$表示对图片的扰动程度。从图中，$x$是正确分类为“熊猫”的原始输入图像，$y$模型参数$(x,\theta)$下的真实标签，$J(θ,x,y)$是用于训练网络的损失。攻击将梯度反向传播回输入数据以计算$∇_xJ(θ,x,y)$，然后，它通过一小步调整输入数据（$ε$，0.007在上图中）在方向$sign(∇_xJ(θ,x,y))$上使损失最大化。添加噪声之前，原始图像有 $0.557$ 可能被认为是一只熊猫，添加噪声 后，这张图像有 $0.993$ 的可能认为是一种长臂猿。</p>
<h1 id="4-实例"><a href="#4-实例" class="headerlink" title="4    实例"></a>4    实例</h1><p>&emsp;&emsp;本次实例受到攻击的模型 <strong><em>MNIST</em></strong> 数据集分类的模型。可以训练并保存自己的 <strong><em>MNIST</em></strong> 模型，也可以从<a href="https://drive.google.com/drive/folders/1fn83DF14tWmit0RTKWRhPq5uVXt73e0h"><strong><em>https://drive.google.com/drive/folders/1fn83DF14tWmit0RTKWRhPq5uVXt73e0h</em></strong></a>下载预训练模型。开始之前要先介绍一下重要的参数 $epsilons$ ：用于运行的 $epsilon$ 值列表。在列表中保留 0 很重要，因为它代表了原始测试集上的模型性能。此外，直观地说，我们预计 $epsilon$ 越大，扰动越明显，但在降低模型精度方面攻击越有效。由于这里的数据范围是[0，1]，任何 $epsilon$ 值不应超过 1。下面是攻击后的图片计算公式：</p>
<script type="math/tex; mode=display">
attack\_image=image+epsilon∗sign(image\_grad)=x+ϵ∗sign(∇ xJ(θ,x,y)) \tag 1</script><p>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transform</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置gpu</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"><span class="comment">#数据下载</span></span><br><span class="line">dataset = torchvision.datasets.MNIST(</span><br><span class="line">    root = <span class="string">&#x27;data&#x27;</span>,</span><br><span class="line">    train = <span class="literal">False</span>,</span><br><span class="line">    download = <span class="literal">True</span>,</span><br><span class="line">    <span class="comment">#将PIL类型转成tensor</span></span><br><span class="line">    transform = transform.Compose([</span><br><span class="line">        transform.ToTensor()</span><br><span class="line">    ])</span><br><span class="line">)</span><br><span class="line">test_loader = DataLoader(dataset, batch_size = <span class="number">1</span>, shuffle = <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#设置不同的干扰程度</span></span><br><span class="line">epsilons = [<span class="number">0</span>, <span class="number">.05</span>, <span class="number">.1</span>, <span class="number">.15</span>, <span class="number">.2</span>, <span class="number">.25</span>, <span class="number">.3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size = <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size = <span class="number">5</span>)</span><br><span class="line">        self.dropout = nn.Dropout2d()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">320</span>, <span class="number">50</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">50</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(F.max_pool2d(self.conv1(x), <span class="number">2</span>))</span><br><span class="line">        x = F.relu(F.max_pool2d(self.dropout(self.conv2(x)), <span class="number">2</span>))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">320</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        <span class="comment">#传入self.training参数使得训练时使用dropout层，测试时不用</span></span><br><span class="line">        x = F.dropout(x, training = self.training)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model = Net().to(device)</span><br><span class="line"><span class="comment">#下载预训练好的参数</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;lenet_mnist_model.pth&#x27;</span>, map_location = <span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line"><span class="comment">#切换到训练模式</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment">#就算攻击后的图片，如公式（1）所示</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fgsm_attack</span>(<span class="params">image, epsilon, data_grad</span>) :</span><br><span class="line">    <span class="comment">#sign（）函数返回数值的符号，如果为正数返回1，如果为负数返回-1.否则返回0</span></span><br><span class="line">    sign_data_grad = torch.sign(data_grad)</span><br><span class="line">    attack_image = image + epsilon * sign_data_grad</span><br><span class="line">    <span class="comment">#因为经过上步骤之后，图片的像素值可能不再[0， 1]区间，所以要限制到[0, 1]之间</span></span><br><span class="line">    <span class="keyword">return</span> torch.clamp(attack_image, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">t</span>(<span class="params">model, epsilon, test_loader</span>) :</span><br><span class="line">    <span class="comment">#统计被攻击后依然分类正确的图片，也即攻击对分类没有影响</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="comment">#记录攻击成功和攻击失败的图片</span></span><br><span class="line">    adv_examples = []</span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> test_loader :</span><br><span class="line">        data, label = data.to(device), label.to(device)</span><br><span class="line">        <span class="comment">#因为要计算输入图片的梯度，所以要使requires_grad参数为True</span></span><br><span class="line">        data.requires_grad = <span class="literal">True</span></span><br><span class="line">        <span class="comment">#输出</span></span><br><span class="line">        output = model(data)</span><br><span class="line">        <span class="comment">#输出的最大值对应的下标就是模型的分类情况</span></span><br><span class="line">        _, init_pred = torch.<span class="built_in">max</span>(output, dim = <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#如果分类没有成功，则不必攻击，没有意义</span></span><br><span class="line">        <span class="keyword">if</span> init_pred.item() != label.item() :</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment">#计算损失值</span></span><br><span class="line">        loss = F.nll_loss(output, label)</span><br><span class="line">        <span class="comment">#梯度清零</span></span><br><span class="line">        model.zero_grad()</span><br><span class="line">        <span class="comment">#反向传播计算梯度</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment">#得到输入图片的梯度值</span></span><br><span class="line">        data_grad = data.grad.data</span><br><span class="line">        <span class="comment">#对图片进行攻击</span></span><br><span class="line">        attack_data = fgsm_attack(data, epsilon, data_grad)</span><br><span class="line">        <span class="comment">#攻击后图片的模型分类输出</span></span><br><span class="line">        output = model(attack_data)</span><br><span class="line">        <span class="comment">#得到分类的种类</span></span><br><span class="line">        _, final_pred = torch.<span class="built_in">max</span>(output, dim = <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#如果攻击后的模型预测与未攻击之前的一样，说明攻击失败</span></span><br><span class="line">        <span class="keyword">if</span> final_pred.item() == label.item() :</span><br><span class="line">            correct += <span class="number">1</span></span><br><span class="line">            <span class="comment">#记录攻击失败的攻击前、攻击后的模型预测情况和图片</span></span><br><span class="line">            <span class="keyword">if</span> epsilon == <span class="number">0</span> <span class="keyword">and</span> <span class="built_in">len</span>(adv_examples) &lt; <span class="number">5</span> :</span><br><span class="line">                adv_ex = attack_data.squeeze().detach().cpu().numpy()</span><br><span class="line">                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="comment">#记录攻击成功的攻击前、攻击后的模型预测情况和图片</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(adv_examples) &lt; <span class="number">5</span>:</span><br><span class="line">                adv_ex = attack_data.squeeze().detach().cpu().numpy()</span><br><span class="line">                adv_examples.append((init_pred.item(), final_pred.item(), adv_ex))</span><br><span class="line">    <span class="comment">#输出攻击失败的图片占比</span></span><br><span class="line">    final_acc = correct / <span class="built_in">float</span>(<span class="built_in">len</span>(test_loader))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epsilon: &#123;&#125;\tTest Accuracy = &#123;&#125; / &#123;&#125; = &#123;&#125;&quot;</span>.<span class="built_in">format</span>(epsilon, correct, <span class="built_in">len</span>(test_loader), final_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Return the accuracy and an adversarial example</span></span><br><span class="line">    <span class="keyword">return</span> final_acc, adv_examples</span><br><span class="line"></span><br><span class="line">accuracies = []</span><br><span class="line">examples = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run test for each epsilon</span></span><br><span class="line"><span class="keyword">for</span> eps <span class="keyword">in</span> epsilons:</span><br><span class="line">    acc, ex = t(model, eps, test_loader)</span><br><span class="line">    accuracies.append(acc)</span><br><span class="line">    examples.append(ex)</span><br><span class="line"></span><br><span class="line"><span class="comment">#作出在不同的epsilon下攻击失败的图片占比</span></span><br><span class="line">fig1 = plt.figure()</span><br><span class="line">plt.plot(epsilons, accuracies, <span class="string">&#x27;o-&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;eps&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;acc&#x27;</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">0</span>, <span class="number">0.35</span>, <span class="number">0.05</span>))</span><br><span class="line">plt.yticks(np.arange(<span class="number">0</span>, <span class="number">1.1</span>, <span class="number">0.1</span>))</span><br><span class="line">plt.savefig(<span class="string">&#x27;acc_Vs_eps.png&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#展示在不同的epsilon情况的具体的攻击情况</span></span><br><span class="line">cnt = <span class="number">0</span></span><br><span class="line">fig2 = plt.figure(figsize = (<span class="number">8</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(epsilons)) :</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(examples[i])) :</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line">        plt.subplot(<span class="built_in">len</span>(epsilons), <span class="built_in">len</span>(examples[i]), cnt)</span><br><span class="line">        <span class="comment"># plt.axis(&#x27;off&#x27;)</span></span><br><span class="line">        plt.xticks([], [])</span><br><span class="line">        plt.yticks([], [])</span><br><span class="line">        <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">            plt.ylabel(<span class="string">f&#x27;eps : <span class="subst">&#123;epsilons[i]&#125;</span>&#x27;</span>, fontsize = <span class="number">14</span>)</span><br><span class="line">        plt.title(<span class="string">f&#x27;<span class="subst">&#123;examples[i][j][<span class="number">0</span>]&#125;</span> -&gt; <span class="subst">&#123;examples[i][j][<span class="number">1</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">        plt.imshow(examples[i][j][<span class="number">2</span>], cmap = <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">&#x27;test.png&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>$Accuracy$ 和 $epsilon$ 的关系如下 ：<br><img src="https://img-blog.csdnimg.cn/878844193d29475398768d8b88907c45.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>如前所述，随着 $epsilon$ 的增加，我们预计测试精度会降低。这是因为更大的 $epsilon$ 意味着我们朝着使损失最大化的方向迈出了更大的一步，当 $epsilon$ 仅为 $0.3$ 是精确度就已经降到了 $0.1$ 以下请注意，即使 $epsilon$ 值是线性间隔的，曲线中的趋势也不是线性的。<br>对抗样本如下：<br><img src="https://img-blog.csdnimg.cn/c9128b0976ce40dda9a6e6cceadfbd91.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>随着 $epsilon$ 的增加，测试精度会降低，但扰动变得更容易察觉。实际上，攻击者必须考虑在准确性降低和可感知性之间进行权衡。在上图中，展示了一些在每个 $epsilon$ 值上成功的对抗性示例。绘图的每一行显示不同的 $epsilon$ 值。第一行是 $epsilon=0$ 也就是 $ε=0$ 表示没有扰动的原始“干净”图像的示例。每张图片的标题显示“原始分类 -&gt; 对抗分类”。当 $epsilon=0.15$ 时扰动开始变得明显。然而，在所有情况下，尽管增加了噪音，人类仍然能够识别正确的类别，但机器无法识别。</p>
<h1 id="5-流程图"><a href="#5-流程图" class="headerlink" title="5    流程图"></a>5    流程图</h1><p>&emsp;&emsp;上面所实现的攻击过程可以简化成以下流程图：<br><img src="https://img-blog.csdnimg.cn/09ba7a15ba8d47f4802c760d9001c23a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>参考：<br><a href="https://pytorch.org/tutorials/beginner/fgsm_tutorial.html#fast-gradient-sign-attack"><strong><em>https://pytorch.org/tutorials/beginner/fgsm_tutorial.html#fast-gradient-sign-attack</em></strong></a></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>对抗攻击</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】图像的轮廓查找</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91%E5%9B%BE%E5%83%8F%E7%9A%84%E8%BD%AE%E5%BB%93%E6%9F%A5%E6%89%BE/</url>
    <content><![CDATA[<h1 id="1-原理"><a href="#1-原理" class="headerlink" title="1    原理"></a>1    原理</h1><p>&emsp;&emsp;边界或者轮廓可以简单认为成将连续的点（连着边界）连在一起的曲线，具有相同的颜色或者灰度。轮廓在形状分析和物体的检测和识别中很有用。<br><img src="https://img-blog.csdnimg.cn/b693a0ef9e12450f992dd8a7008c4d38.png#pic_center" alt="在这里插入图片描述"><br>在机器视觉领域最常用的轮廓查找的算法之一是 <strong><em>Moore-Neighbor</em></strong> 算法，像素的摩尔邻域 $P$ 是与该像素共享顶点或边的 $8$ 个像素的集合。这些像素即 如下图所示的像素$P1$、$P2$、$P3$、$P4$、$P5$、$P6$、$P7$和$P8$。 摩尔邻域（也称为8 邻域或 间接邻域）是文献中经常出现的一个重要概念。<br><img src="https://img-blog.csdnimg.cn/7b438ebe573b4ad2940239b55e6eb119.png#pic_center" alt="在这里插入图片描述"></p>
<p>其大概的原理如下：</p>
<ul>
<li>找到一个黑色像素，并将它定为你的起始像素。（定位一个起始像素可以以多种方式来完成的；我们将从网格的左下角开始，自下而上扫描每一列像素，从最左向右的每列像素，直到遇到一个黑色的像素，我们将其作为我们的起始像素）。</li>
<li>每次碰到黑色像素P时，都回溯，即回到之前站立的白色像素，然后以顺时针方向绕过像素$P$，访问其摩尔邻域中的每个像素，直到击中黑色像素。</li>
<li>重复这个过程，当起始像素被第二次访问时算法终止，在整个运行过程走过的黒色像素就是目标的边界像素。走过的黑色像素将成为图案的轮廓。<br><img src="https://img-blog.csdnimg.cn/8dbd5f94195643d487fd1958dd58d8e5.png#pic_center" alt="在这里插入图片描述"><br>动画演示，说明 <strong><em>Moore-Neighbor</em></strong> 跟踪如何继续跟踪给定模式的轮廓。（以顺时针方向跟踪轮廓）<br><img src="https://img-blog.csdnimg.cn/3582e3c5e5f246abacfa1e5de28981c0.gif#pic_center" alt="在这里插入图片描述"></li>
</ul>
<h1 id="2-API"><a href="#2-API" class="headerlink" title="2    API"></a>2    API</h1><p>此部分参考了<a href="https://blog.csdn.net/sunny2038/article/details/12889059"><strong><em>https://blog.csdn.net/sunny2038/article/details/12889059</em></strong></a></p>
<p>在 <strong><em>OpenCv</em></strong> 中轮廓查找主要由如下两个 <strong><em>API</em></strong> 来完成。第一个是查找函数 <strong><em>findContours</em></strong>，第二个是绘制轮廓的函数 <strong><em>drawContours</em></strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">contours, hierarchy = cv2.findContours(image, mode, method[, contours[, hierarchy[, offset ]]])</span><br></pre></td></tr></table></figure>
<p>输入：</p>
<ul>
<li>第一个参数是寻找轮廓的图像，注意是二值图。</li>
<li>第二个参数表示轮廓的检索模式，有四种，<strong><em>cv2.RETR_EXTERNAL</em></strong> 表示只检测外轮廓，<strong><em>cv2.RETR_LIST</em></strong> 检测的轮廓不建立等级关系，<strong><em>cv2.RETR_CCOMP</em></strong> 建立两个等级的轮廓，上面的一层为外边界，里面的一层为内孔的边界信息。如果内孔内还有一个连通物体，这个物体的边界也在顶层。<strong><em>cv2.RETR_TREE</em></strong> 建立一个等级树结构的轮廓。</li>
<li>第三个参数method为轮廓的近似办法，<strong><em>cv2.CHAIN_APPROX_NONE</em></strong> 存储所有的轮廓点，相邻的两个点的像素位置差不超过 <strong><em>1</em></strong>，即$max(abs(x1-x2)，abs(y2-y1))==1$，<strong><em>cv2.CHAIN_APPROX_SIMPLE</em></strong> 压缩水平方向，垂直方向，对角线方向的元素，只保留该方向的终点坐标，例如一个矩形轮廓只需 <strong><em>4</em></strong> 个点来保存轮廓信息，<strong><em>cv2.CHAIN_APPROX_TC89_L1</em></strong>，<strong><em>CV_CHAIN_APPROX_TC89_KCOS</em></strong> 使用 <strong><em>teh-Chinl chain</em></strong> 近似算法</li>
</ul>
<p>输出：</p>
<ul>
<li><strong><em>contours</em></strong> 是轮廓本身。</li>
<li><strong><em>hierarchy</em></strong> 是每条轮廓对应的属性。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset ]]]]])</span><br></pre></td></tr></table></figure>
<p>输入：</p>
<ul>
<li>第一个参数是指明在哪幅图像上绘制轮廓。</li>
<li>第二个参数是轮廓本身，在 <strong><em>Python</em></strong> 中是一个 <strong><em>list</em></strong>。</li>
<li>第三个参数指定绘制轮廓list中的哪条轮廓，如果是-1，则绘制其中的所有轮廓。<strong><em>thickness</em></strong> 表明轮廓线的宽度。</li>
</ul>
<h1 id="3-案例"><a href="#3-案例" class="headerlink" title="3    案例"></a>3    案例</h1><p>绘制下面所有飞机的轮廓<br><img src="https://img-blog.csdnimg.cn/8c723b97c003411d8f661f6933e7bde3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib</span><br><span class="line"></span><br><span class="line">img_planes = cv.imread(<span class="string">&#x27;images/planes.png&#x27;</span>, <span class="number">0</span>)</span><br><span class="line">img = np.zeros((img_planes.shape[<span class="number">0</span>], img_planes.shape[<span class="number">1</span>], <span class="number">3</span>))</span><br><span class="line"><span class="comment">#查找轮廓，要注意传入的图像一定要是二值图，因为我这里的图片本就是二值化图片，所以不需要二值化</span></span><br><span class="line">contours, hierarphy = cv.findContours(img_planes, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)</span><br><span class="line"><span class="comment">#绘制轮廓</span></span><br><span class="line">cv.drawContours(img, contours,  -<span class="number">1</span>, (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), <span class="number">1</span>)</span><br><span class="line">cv.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/0c3f2720f4594b04aac5724e1a4c899a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>轮廓检测</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】圆环展平</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91%E5%9C%86%E7%8E%AF%E5%B1%95%E5%B9%B3/</url>
    <content><![CDATA[<p>﻿# 环境</p>
<ul>
<li>Python 3.8.8</li>
<li>PyCharm 2021</li>
<li>opencv-python</li>
</ul>
<h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><p>原始圆环：<br><img src="https://img-blog.csdnimg.cn/9dc57d6282ca431e8724d120c1939094.bmp?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_18,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>展平之后：<br><img src="https://img-blog.csdnimg.cn/e9c20d8ea6094e71808eac912222c3d3.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h1><ul>
<li>首先是对圆环进行圆检测，检测出外圆和内圆的圆心和半径。关于圆检测，可以看我这篇博客<a href="https://blog.csdn.net/weixin_53598445/article/details/123495680"><strong><em>https://blog.csdn.net/weixin_53598445/article/details/123495680</em></strong></a></li>
<li>后以外圆的周长，圆环的宽度也即内圆和外圆的半径之差作为宽创建一个矩形，若无法检测内圆，可以粗略使用外圆半径的二分之一作为宽。</li>
<li>从圆环的最外圈开始遍历，最外圈即对应着矩形中的第一行(遍历时半径从外围开始逐渐减一)，宽度为多少，则矩形中就有多少行以圆心为中心构成极坐标系，则圆环上任意一点可以用 <strong><em>rho</em></strong> 和 <strong><em>theta</em></strong> 来表示再根据下面所示公式计算出该点在图上的真实坐标，把像素值赋给矩形框中对应的位置。</li>
</ul>
<script type="math/tex; mode=display">
x = center.x+rho * cos\theta\\
y=center.y - rho * sin\theta\\</script><ul>
<li>因为在计算过程中像素值可能是 <strong><em>float</em></strong> 类型，所以要将矩形的数据类型转回 <strong><em>np.uint8</em></strong> 类型。</li>
</ul>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">circle_flatten</span>() :</span><br><span class="line">    img = cv.imread(<span class="string">&#x27;images/circle_band.bmp&#x27;</span>)</span><br><span class="line">    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="comment"># img_gray = cv.medianBlur(img_gray, 3)</span></span><br><span class="line"></span><br><span class="line">    circles = cv.HoughCircles(img_gray, cv.HOUGH_GRADIENT, <span class="number">1</span>, <span class="number">50</span>, param1 = <span class="number">170</span>, param2 = <span class="number">100</span>).squeeze()</span><br><span class="line">    <span class="comment">#获得检测到的所有圆的半径</span></span><br><span class="line">    circle_radius = circles[ : , <span class="number">2</span>]</span><br><span class="line">    <span class="comment">#获得最大半径的下标</span></span><br><span class="line">    radius_biggest_index = np.argsort(circle_radius)[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(radius_biggest_index)</span><br><span class="line">    <span class="comment">#做出最大圆</span></span><br><span class="line">    circle = np.uint16(np.around(circles[radius_biggest_index]))</span><br><span class="line">    cv.circle(img, (circle[<span class="number">0</span>], circle[<span class="number">1</span>]), radius = circle[<span class="number">2</span>], color = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thickness = <span class="number">5</span>)</span><br><span class="line">    cv.circle(img, (circle[<span class="number">0</span>], circle[<span class="number">1</span>]), radius = <span class="number">2</span>, color = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), thickness = <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#取展平后条形圆环的宽为最大半径的一半，而长取最大圆的周长</span></span><br><span class="line">    height = <span class="built_in">int</span>(circle_radius[radius_biggest_index] * np.pi * <span class="number">2</span>)</span><br><span class="line">    width = <span class="built_in">int</span>(circle_radius[radius_biggest_index] / <span class="number">3</span>)</span><br><span class="line">    rectangle = np.zeros([width, height])</span><br><span class="line">    <span class="built_in">print</span>(rectangle.shape)</span><br><span class="line">    <span class="built_in">print</span>(img_gray.shape)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(width) :</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(height) :</span><br><span class="line">            <span class="comment">#转成极坐标系</span></span><br><span class="line">            theta = np.pi * <span class="number">2.0</span> / height * (col + <span class="number">1</span>)</span><br><span class="line">            rho = circle_radius[radius_biggest_index] - row - <span class="number">1</span></span><br><span class="line">            <span class="comment">#以圆心为原点，求得原来圆环对应的坐标</span></span><br><span class="line">            position_x = <span class="built_in">int</span>(circle[<span class="number">0</span>] + rho * np.cos(theta) + <span class="number">0.5</span>)</span><br><span class="line">            position_y = <span class="built_in">int</span>(circle[<span class="number">1</span>] - rho * np.sin(theta) + <span class="number">0.5</span>)</span><br><span class="line">            rectangle[row, col] = img_gray[position_y, position_x]</span><br><span class="line">    <span class="comment">#要转回np.uint8型数据，否则显示有问题</span></span><br><span class="line">    rectangle = np.uint8(rectangle)</span><br><span class="line">    cv.imwrite(<span class="string">&#x27;flatten.png&#x27;</span>, rectangle)</span><br><span class="line">    cv.imshow(<span class="string">&#x27;rectangle&#x27;</span>, rectangle)</span><br><span class="line">    cv.imshow(<span class="string">&#x27;img&#x27;</span>, img)</span><br><span class="line">    cv.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    circle_flatten()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】检测黑白棋</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91%E6%A3%80%E6%B5%8B%E9%BB%91%E7%99%BD%E6%A3%8B/</url>
    <content><![CDATA[<p>﻿# 环境</p>
<ul>
<li>Python 3.8.8</li>
<li>Pycharm 2021</li>
<li>opencv-Python</li>
</ul>
<h1 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h1><p><img src="https://img-blog.csdnimg.cn/244a523c9e3948aa9e859bbf9167a102.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6L-b5Ye755qE5Y2X5pa55LuU,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h1><p>圆检测的原理是在直线检测原理上的拓展，可以先看看我这篇博客<a href="https://blog.csdn.net/weixin_53598445/article/details/123341281">霍夫直线检测</a>下面介绍圆检测的不同之处。<br>圆的表达式如下：</p>
<script type="math/tex; mode=display">
(x-a)^2+(y-b)^2=r</script><p>其中$a$和$b$表示圆心坐标，$r$表示圆半径，因此标准佛如霍夫圆检测就是在这三个参数组成的三维空间累加器上进行圆检测，此时效率就会很低，所以$OpenCv$中使用 <strong><em>霍夫梯度</em></strong> 进行圆形的检测。霍夫梯度法将圆检测分成两个阶段，第一阶段是检测圆心，第二段是利用圆心推导出圆半径，公式如下：</p>
<script type="math/tex; mode=display">
a = x - rcos\theta \\
b = y - rsin\theta</script><ul>
<li>圆心检测的原理：圆心是圆周角法线的交汇处，设置一个阈值，在某点的相交的直线的条数大于这个阈值就认为该交汇点为圆心。<br><img src="https://img-blog.csdnimg.cn/713e17b9acc14b1f836512dcce3b4aa3.png#pic_center" alt="在这里插入图片描述"></li>
<li>圆半径确定原理：圆心到圆周上的距离(半径)是相同的，确定一个阈值，只要相同距离的数量打于该阈值，就认为该距离是该圆心的半径。</li>
</ul>
<h1 id="API"><a href="#API" class="headerlink" title="API"></a>API</h1><p>HoughCircles(image, method, dp, minDist,param1=100, param2=100, minRadius=0, maxRadius=0 )</p>
<ul>
<li>method: CV_HOUGH_GRADENT</li>
<li>dp:累加面分辨率(大小) = 原始图像分辨率(大小) × 1 / dp。默认 dp = 1 时，两者分辨率相同。</li>
<li>minDist: 两个圆心的最小距离。若两圆心距离 &lt; minDist，则认为是同一个圆</li>
<li>param1: canny边缘检测高阈值, 低限阈值是这个值的一半。越大检测圆边界时，要求的亮度梯度越大，一些灰灰的不明显的边界就会略去。</li>
<li>param2:累加平面某点是否是圆心的判定阈值。越小，越多假的圆会被检测到，越大，能通过检测的圆就更接近完美的圆形，默认为 100。</li>
<li>后两个参数：允许检测到的圆的最大和最小半径。</li>
</ul>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="comment">#黑白棋子用不同颜色进行检测</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">circle_detect</span>() :</span><br><span class="line">    img = cv.imread(<span class="string">&#x27;images/weiqi.png&#x27;</span>)</span><br><span class="line">    cimg = copy.deepcopy(img)</span><br><span class="line">    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line">    <span class="comment"># img_gray = cv.GaussianBlur(img_gray, (5, 5), 0)</span></span><br><span class="line">    <span class="comment">#降噪</span></span><br><span class="line">    img_gray = cv.medianBlur(img_gray, <span class="number">5</span>)</span><br><span class="line">    circles = cv.HoughCircles(img_gray, cv.HOUGH_GRADIENT, <span class="number">1</span>, <span class="number">10</span>, param1 = <span class="number">120</span>, param2 = <span class="number">50</span>).squeeze()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> circle <span class="keyword">in</span> circles :</span><br><span class="line">        <span class="comment">#转成np.uint16数据类型扩大数据范围</span></span><br><span class="line">        circle = np.uint16(np.around(circle))</span><br><span class="line">        <span class="comment">#做二值化处理，白棋为白，黑棋为黑，若圆心的值为255则为白棋，否则为黑棋</span></span><br><span class="line">        _, img_thresh = cv.threshold(img_gray, <span class="number">80</span>, <span class="number">255</span>, cv.THRESH_BINARY)</span><br><span class="line">        <span class="comment">#注意x和y与w和h的对应</span></span><br><span class="line">        <span class="keyword">if</span> img_thresh[circle[<span class="number">1</span>], circle[<span class="number">0</span>]] == <span class="number">255</span> :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;chess is black!&#x27;</span>)</span><br><span class="line">            <span class="comment"># 画出检测到的圆</span></span><br><span class="line">            cv.circle(img, center=(circle[<span class="number">0</span>], circle[<span class="number">1</span>]), radius=circle[<span class="number">2</span>],</span><br><span class="line">                      color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), thickness=<span class="number">2</span>)</span><br><span class="line">            <span class="comment"># 画出圆心</span></span><br><span class="line">            cv.circle(img, center=(circle[<span class="number">0</span>], circle[<span class="number">1</span>]), radius=<span class="number">2</span>,</span><br><span class="line">                      color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), thickness=<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;chess is white!&#x27;</span>)</span><br><span class="line">            <span class="comment"># 画出检测到的圆</span></span><br><span class="line">            cv.circle(img, center=(circle[<span class="number">0</span>], circle[<span class="number">1</span>]), radius=circle[<span class="number">2</span>],</span><br><span class="line">                      color=(<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thickness=<span class="number">2</span>)</span><br><span class="line">            <span class="comment"># 画出圆心</span></span><br><span class="line">            cv.circle(img, center=(circle[<span class="number">0</span>], circle[<span class="number">1</span>]), radius=<span class="number">2</span>,</span><br><span class="line">                      color=(<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thickness=<span class="number">3</span>)</span><br><span class="line">        cv.imshow(<span class="string">&#x27;canny&#x27;</span>, img_thresh)</span><br><span class="line">    <span class="built_in">print</span>(img.shape, cimg.shape)</span><br><span class="line">    img_concatenate = np.concatenate((cimg, img), axis = <span class="number">1</span>)</span><br><span class="line">    cv.imwrite(<span class="string">&#x27;img_con.png&#x27;</span>, img_concatenate)</span><br><span class="line">    cv.imshow(<span class="string">&#x27;img&#x27;</span>, img_concatenate)</span><br><span class="line">    cv.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    circle_detect()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】霍夫直线检测</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91%E9%9C%8D%E5%A4%AB%E7%9B%B4%E7%BA%BF%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;Hough变换是实现边缘检测的一种有效方法，其基本思想是将测量空间的一点变换到参量空间的一条曲线或曲面，而具有同一参量特征的点变换后在参量空间中相交，通过判断交点处的积累程度来完成特 征曲线的检测。</p>
<h1 id="1-原理"><a href="#1-原理" class="headerlink" title="1    原理"></a>1    原理</h1><p>&emsp;&emsp;保罗·哈夫于1962年提出了Hough变换法，并申请了专利。该方法 将图像空间中的检测问题转换到参数空间，通过在参数空间里进行简单的累加统计完成检测任务，并用大多数边界点满足的某种参数形式来描述图像的区域边界曲线。这种方法对于被噪声干扰或间断区域边界的图像具有良好的容错性。Hough变换最初主要应用于检测图像空间中的直线，最早的直线变换是在两个笛卡儿坐标系之间进行的，这给检测斜率无穷大的直线带来了困难。1972年，杜达（Duda）将变换形式进行了转化，将数据空间中的点变换为$ρ-θ$参数空间中的曲线，改善了其检测直线的性能。该方法被不断地研究和发展，在图像分析、计算机视觉、模式识别等领域得到了非常广泛的应用，已经成为模式识别的一种重要工具。<br>&emsp;&emsp;直线的方程可由下面式子表示：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&y = kx + b
\end{aligned}</script><p>其中，$k$和$b$分别是斜率和截距。现在将$y=kx+b$转换成$b=-xk+y$，因为$k$和$b$都是确定值所以在$x-y$平面上的一条线在$k-b$平面上代表一个点。<br><img src="https://img-blog.csdnimg.cn/64100f724418433081bc664409610d9d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>反过来在$k-b$平面上的一条直线$b=-xk+y$在$x-y$平面上代表一个点，因为此时$x$和$y$在直线$b=-xk+y$中分别是斜率和截距为定值。<img src="https://img-blog.csdnimg.cn/d8b534a8ef3543029459d03145af5e50.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>其次是过$x-y$平面上的某一点（$x_0$，$y_0$） 的所有直线的参数都满足方程$y_0=kx_0+b$。即过$x-y$平面上点（$x_0$，$y_0$）的一族直线在参数$k-b$平面上对应于一条直线。同样的道理将该族直线$y_0=kx_0+b$转变到$k-b$平面上有$b=-x_0k+y_0$，此时斜率($-x_0$)和斜距($y_0$)固定，$b$为$k$的函数，所以在$k-b$平面上对应于一条直线。<br><img src="https://img-blog.csdnimg.cn/7ac9ad092de04348a84be04a4d4c0b8e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>有了上面的知识，再来看看在$x-y$平面上三点共线是怎么等效到到$k-b$平面的。<img src="https://img-blog.csdnimg.cn/a220aa987f0e4e0698eedd3aa685e24d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>可以看出如果笛卡尔坐标系的点共线，这些点在霍夫空间对应的直线交于一点：这也是必然，共线只有一种取值可能。再来考虑特殊情况，当三点共线恰好垂直$x$轴呢？此时直线的斜率$k$为无穷大，$y=kx+b$形式的直线方程无法表示$x=c$（$c$为常数）形式的直线。所以在实际应用中，一般采用距离和角度参数方程来表示如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&ρ=xcosθ+ysinθ
\end{aligned}</script><p>其中，$ρ$为原点到直线的垂直距离，$θ$为$ρ$与$x$轴的夹角，转换过程如下，注意的是这个并不是极坐标表达式，只是形式写起来跟极坐标的形式是一样的。这是因为$ρ$和$θ$都是固定的，对应唯一的直线，而如果是极坐标，那其他对的$ρ$和$θ$也会满足这一直线。<br><img src="https://img-blog.csdnimg.cn/f6320bded9244ea08fa7d461f27cc9b6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;根据$ρ=xcosθ+ysinθ$，直线上不同的点在参数空间中被变换为一族相交于$p$点的正弦曲线，因此可以通过检测参数空间中的局部最大值$p$点，来实现$x-y$坐标系中直线的检测。<img src="https://img-blog.csdnimg.cn/237a541294ca45d4bffba326725dc444.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h1 id="2-算法流程"><a href="#2-算法流程" class="headerlink" title="2    算法流程"></a>2    算法流程</h1><p>①将参数空间量化成$m×n$（$m$为$θ$的等份数，$n$为$ρ$的等份数）个单元，并设置累加器矩阵$Q[m×n]$；<br>②给参数空间中的每个单元分配一个累加器$Q$($θ_i$，$p_j$)（$0&lt;i&lt;m-<br>1$， $0&lt;j&lt;n-1$），并把累加器的初始值置为零；<br>③将直角坐标系中的各点（$x_k$，$y_k$）（$k=1$，$2$，…，$s$，$s$为直角坐 标系中的点数）代入式$ρ=xcosθ+ysinθ$，然后将$θ_0～θ_{m-1}$也都代入其中，分别计算出相应的值$p_j$；<br>④在参数空间中，找到每一个（$θ_i$，$p_j$）所对应的单元，并将该 单元的累加器加1，即$Q$($θ_i$，$p_j$) $=$ $Q$($θ_i$，$p_j$) $+1$，对该单元进行一次投票；<br>⑤待$x-y$坐标系中的所有点都进行运算之后，检查参数空间的累加 器，必有一个出现最大值，这个累加器对应单元的参数值作为所求直线的参数输出。当然你可以指定一个阈值，就是投票数达到多少就可以认定为一条直线，这样就可以一次性输出多条直线。<br>例子：<img src="https://img-blog.csdnimg.cn/26e7458220644cf6868d5efe41530bda.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>将$r$($p$)分成了9份，区间是[0，9]，$r$一定是取有效值，因为我们的图像的最长直线就是其对角线；然后将$θ$以90°为步长分成了4个区间，当然你可以分成你想要的$θ$区间。然后开始遍历 <strong><em>Canny</em></strong> 图像(很关键，我们在利用霍夫变换进行直线检测时，要先对图像进行边缘检测)。<br><img src="https://img-blog.csdnimg.cn/379fb78303764ca59dfe1ac590c7c20e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_10,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>遇到黑点直接跳过，我们只关注白点。然后将每个白点的坐标($x_0$，$y_0$)和四个角度$θ$($θ_1=90°$，$θ_2=180°$，$θ_3=270°$，$θ_4=360°$)带入到$r=xcosθ+ysinθ$中，得到对应的$r_1$，$r_2$，$r_3$，$r_4$，根据这些$r$值在对应区间进行投票。不断重复上述步骤直至图像遍历完毕。就可以根据$r$的投票数来确定直线。</p>
<h1 id="3-优缺点"><a href="#3-优缺点" class="headerlink" title="3    优缺点"></a>3    优缺点</h1><p>&emsp;&emsp;霍夫变换是一种全局性的检测方法，具有极佳的抗干扰能力，可 以很好地抑制数据点集中存在的干扰，同时还可以将数据点集拟合成多条直线。但是，霍夫变换的精度不容易控制，参数的微变就可能影响效果的大幅度变化，因此，不适合对拟合直线的精度要求较高的实际问题。同时，它所要求的巨大计算量使其处理速度很慢，从而限制了它在实时性要求很高的领域的应用</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>直线检测</tag>
      </tags>
  </entry>
  <entry>
    <title>【Opencv】基于色差的简单目标提取</title>
    <url>/2022/06/05/%E3%80%90Opencv%E3%80%91%E5%9F%BA%E4%BA%8E%E8%89%B2%E5%B7%AE%E7%9A%84%E7%AE%80%E5%8D%95%E7%9B%AE%E6%A0%87%E6%8F%90%E5%8F%96/</url>
    <content><![CDATA[<p>﻿&emsp;&emsp;所有颜色都是由$R$(红)、$G$(绿)、$B$(蓝) 3个单色调配而成， 每种单色都人为地从$0～255$分成了$256$个级，所以根据$R$、 $G$、$B$的不同 组合可以表示$256×256×256=16777216$种颜色，被称为全彩色图像(full-color image)或者真彩色图像(true-color image)。一幅全彩色图像如果不压缩，文件将会很大。例如，一幅$640×480$像素的全彩色图像，一个像素由$3$个字节来表示$R$、 $G$、$B$各个分量，需要保存$640×480×3=921600$(约1MB)字节。<br>&emsp;&emsp;对于自然界的目标提取，可以根据目标的颜色特征，尽量使用$R$、 $G$、$B$分量及它们之间的差分组合，这样可以有效避免自然光变化的影响，快速有效地提取目标。<br>&emsp;&emsp;举例：要从果树上提取桃子的红色区域所在位置，如下面照片所示。<br><img src="https://img-blog.csdnimg.cn/313a98f1bee1467c9339e536403aa572.png#pic_center" alt="在这里插入图片描述"><br>由于成熟桃子一般带红色，因此对彩色原图像首先利用红、绿色差信息提取图像中桃子的红色区域。对图像中的像素点($x_i$，$y_i$)($x_i$、$y_i$分别为像素点$i$的$x$坐标和$y$坐标，$0≤i<n$，$n$为图像中像素点的总数)，设其红色($R$)分量和绿色($G$)分量的像素值分别为$R$($x_i$，$y_i$)和$G$($x_i$，$y_i$)，其差值为 $β_i$=$R$($x_i$，$y_i$)$-$$G$($x_i$，$y_i$)，由此获得一个灰度图像($RG$图像)， 若$β_i>0$，设灰度图像上该点的像素值为βi，否则为0(黑色)。之后做出$RG$图像的直方图找出谷点$α$(作为二值化的阈值)。逐像素扫描$RG$图像，若$β_i&gt;α$，则将该点像素值设为$255$(白色)，否则设为$0$(黑色)，获得二值图像。然后再对图像进行形态学处理。<br>色差图：<img src="https://img-blog.csdnimg.cn/4adfb47ec7b94fba98ff2ed6019ee00f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_7,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>直方图：<img src="https://img-blog.csdnimg.cn/1ba1842112184652bae36b507744b887.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>二值化：<img src="https://img-blog.csdnimg.cn/ece126cc2d1043278bc11c48829b8960.png#pic_center" alt="在这里插入图片描述"><br>形态学处理：<br><img src="https://img-blog.csdnimg.cn/94950280d75e4703917866a2cb779531.png#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;peach.jpg&#x27;</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">#因为cv2读取的照片类型是BGR类型，所以要转成RGB类型的照片</span></span><br><span class="line">img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class="line"><span class="comment">#得到r, g, b通道的照片</span></span><br><span class="line">r, g, b = cv2.split(img_rgb)</span><br><span class="line"><span class="comment">#获得RG灰度图像</span></span><br><span class="line">c = r - g</span><br><span class="line"><span class="comment">#求出色差图的直方图，查看分割的最优阈值</span></span><br><span class="line">hist, bins = np.histogram(c, bins = <span class="number">256</span>, <span class="built_in">range</span> = (<span class="number">0</span>, <span class="number">256</span>))</span><br><span class="line">plt.plot(hist)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#采用190作为阈值</span></span><br><span class="line">thresh_value = np.<span class="built_in">sum</span>(c[np.where(c != <span class="number">0</span>)]) / np.<span class="built_in">sum</span>(c != <span class="number">0</span>)</span><br><span class="line">_, peach = cv2.threshold(c, <span class="number">190</span>, <span class="number">255</span>, cv2.THRESH_BINARY_INV)</span><br><span class="line"><span class="comment">#进行腐蚀操作，将小白点去除</span></span><br><span class="line">kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">peach = cv2.erode(peach, kernel, iterations = <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>目标提取</tag>
      </tags>
  </entry>
  <entry>
    <title>DeepDearm 模型</title>
    <url>/2022/06/05/DeepDearm-%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;卷积神经网络取得了突破性进展，效果也非常理想，但是卷积神经网络的学习过程难以从理论上难以解释，因此被不少人诟病。因此可视化其的学习过程十分重要，<strong><em>DeepDream</em></strong> 模型的目的也正是如此。<strong><em>DeepDearm</em></strong> 模型在2015年由谷歌提出，理论基础是2013年所提出的《<strong><em>Visualizing and Understanding Convolutional Neural Networks</em></strong>》，该文章提出了使用梯度上升的方法可视化网络每一层的特征，即用一张噪声图像输入网络，反向更新的时候不更新网络权重，而是更新初始图像的像素值，以这种训练图像的方式可视化网络。深度学习领域奠基性的经典教材《<strong><em>深度学习</em></strong>》的封面就是使用 <strong><em>DeepDream</em></strong> 模型生成的。<br><img src="https://img-blog.csdnimg.cn/a46f6ff3a5394b24bb104b813a2b0894.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="1-DeepDream原理"><a href="#1-DeepDream原理" class="headerlink" title="1    DeepDream原理"></a>1    DeepDream原理</h1><p>&emsp;&emsp;<strong><em>DeepDream</em></strong> 为了说明CNN学习到的各特征的意义，将采用放大处理的方式。具体来说就是使用梯度上升的方法可视化网络每一层的特征，即用一张噪声图像输入网络，但反向更新的时候不更新网络权重，而是更新初始图像的像素值，以这种“训练图像”的方式可视化网络。此外输入图像也可以是一些正常的图片，这样的话就是生成背景图像之类的。<br>&emsp;&emsp;<strong><em>DeepDream</em></strong> 如何放大图像特征？比如：有 一个网络学习了分类猫和狗的任务，给这个网络一张云的图像，这朵云可能比较像狗，那么机器提取的特征可能也会像狗。假设对应一个特征最后输入概率为[0.6，0.4]，0.6表示为狗的概率，0.4则表示为猫的概率，那么采用$L_2$范数可以很好达到放大特征的效果。对于这样一个特征，$L_2 = x_1^{2} + x_2^{2}$，若$x_1$ 越大，$x_2$越小，则$L_2$越大，所以只需要最大化$L_2$就能保证当$x_1$ &gt; $x_1$的时候， 迭代的轮数越多$x_1$越大，$x_2$越小，所以图像就会越来越像狗。每次迭代相当 于计算$L_2$范数，然后用梯度上升的方法调整图像。优化的就不再是优化权重参数，而是特征值或像素点，因此，构建损失函数时，不使用通常的交叉熵，而是最大化特征值的L2范数。使图像经过网络之后提取的特征更像网络隐含的特征。具体实现的时候还要通过多尺度、随机 移动等方法获取比较好的结果。</p>
<h1 id="2-DeepDream算法流程"><a href="#2-DeepDream算法流程" class="headerlink" title="2    DeepDream算法流程"></a>2    DeepDream算法流程</h1><p>&emsp;&emsp;使用基本图像，它输入到预训练的CNN。并正向传播到特定层。<br>&emsp;&emsp;为了更好地理解该层学到了什么，我们需要最大化通过该层激活值。这里要解释一下什么是激活值，激活值表示属于某类的概率大小，比如说二分类问题中，用[0，1]表示两类的标签，我们规定当神经网络的输出大于0就被分类到1(100% 被激活)，小于0就分到0(没有被激活)，所以在此情况下激活值只有100%或者0%，但是我们在平常的多分类任务中希望它可以是0%~100%的任意值。激活值越大，激活程度越高，对于分类，也就意味着它属于这一类的概率越大。<strong><em>DeepDream</em></strong> 以该层输出为梯度，然后在输入图像上完成渐变上升，以最大化该层的激活值。不过，光这样做并不能产生好的图像。为了提高训练质量，需要使用一些技术使得到的图像更好。通常可以进行高斯模糊以使图像更平滑，使用多尺度(又称为八度)的图像进行计算。先连续缩小输入图像，然后，再逐步放大，并将结果合并为一个图像输出。<img src="https://img-blog.csdnimg.cn/73c78c56c6bb4b4bbc66a6c9d16c28a8.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;先对图像连续做二次等比例缩小，该比例是1.5，之所以要缩小，图像缩小是为了让图像的像素点调整后所得结果图案能显示的更加平滑，过程主要是抑制了图像的高频成分，放大了低频成分。缩小二次后，把图像每个像素点当作参数，对它们求偏导，这样就可以知道如何调整图像像素点能够对给定网络层的输出产生最大化的刺激。</p>
<h1 id="3-PyTorch实现DeepDream"><a href="#3-PyTorch实现DeepDream" class="headerlink" title="3    PyTorch实现DeepDream"></a>3    PyTorch实现DeepDream</h1><p>&emsp;&emsp;本次实现是取 <strong><em>VGG19</em></strong> 模型为预训练模型，将获取的特征最大化之后展示在一张普通的图像上，本次使用的是梵高的星空图。为了训练更加有效，还使用对图像进行不同大小的缩放处理。<br><strong><em>1)</em></strong> 下载预训练模型。<strong><em>VGG19</em></strong> 模型包括了三种不同的模块，第一个是特征提取模块 <strong><em>(features)</em></strong> ，一共有36层，第二个是池化层 <strong><em>(avgpool)</em></strong> ，只有一层，第三个是分类层 <strong><em>(classifier)</em></strong> ，一共有6层。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">vgg = models.vgg19(pretrained = <span class="literal">True</span>).to(device)</span><br><span class="line">modulelist = <span class="built_in">list</span>(vgg.features.modules())</span><br></pre></td></tr></table></figure>
<p><strong><em>2)</em></strong> 函数 <strong><em>prod</em></strong> 主要功能是传入输入图像，正 向传播到 <strong><em>VGG19</em></strong> 的指定层(如第8层或第32层等)，然后，用梯度上升更新输入图像的特征值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">prod</span>(<span class="params">image, feature_layers, iterations, lr, transform, device, vgg, modulelist</span>) :</span><br><span class="line">    <span class="built_in">input</span> = transform(image).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.to(device).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    vgg.zero_grad()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations) :</span><br><span class="line">        out = <span class="built_in">input</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(feature_layers) :</span><br><span class="line">            out = modulelist[j + <span class="number">1</span>](out)</span><br><span class="line">        loss = out.norm()</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad() :</span><br><span class="line">            <span class="built_in">input</span> += lr * <span class="built_in">input</span>.grad</span><br><span class="line"></span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.squeeze()</span><br><span class="line">    <span class="comment"># input = input.transpose(0, 1)</span></span><br><span class="line">    <span class="comment"># input = input.transpose(1, 2)</span></span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="built_in">input</span> = np.clip(deprocess(<span class="built_in">input</span>, device).detach().cpu().numpy(), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    image = Image.fromarray(np.uint8(<span class="built_in">input</span> * <span class="number">255</span>))</span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure>
<p><strong><em>3)</em></strong> 函数 <strong><em>deep_dream_vgg</em></strong> 是一个递归函数，多次缩小图像，然后调用函数 <strong><em>prod</em></strong> 。接着再放大结果，并与按一定比例图像混合在一起，最终得到与输入图像相同大小的输出图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">deep_dream_vgg</span>(<span class="params">image, feature_layers, iterations, lr, transform, device, vgg, modulelist, octave_scale = <span class="number">2</span>, num_octaves = <span class="number">100</span></span>) :</span><br><span class="line">    <span class="keyword">if</span> num_octaves &gt; <span class="number">0</span> :</span><br><span class="line">        image1 = image.<span class="built_in">filter</span>(ImageFilter.GaussianBlur(<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">if</span> (image1.size[<span class="number">0</span>] / octave_scale &lt; <span class="number">1</span> <span class="keyword">or</span> image1.size[<span class="number">1</span>] / octave_scale &lt; <span class="number">1</span>) :</span><br><span class="line">            size = image1.size</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            size = (<span class="built_in">int</span>(image1.size[<span class="number">0</span>] / octave_scale), <span class="built_in">int</span>(image1.size[<span class="number">1</span>] / octave_scale))</span><br><span class="line"></span><br><span class="line">        image1 = image1.resize(size, Image.ANTIALIAS)</span><br><span class="line">        image1 = deep_dream_vgg(image1, feature_layers, iterations, lr, transform, device, vgg, modulelist, octave_scale, num_octaves - <span class="number">1</span>)</span><br><span class="line">        size = (image.size[<span class="number">0</span>], image.size[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        image1 = image1.resize(size, Image.ANTIALIAS)</span><br><span class="line">        image = ImageChops.blend(image, image1, <span class="number">0.6</span>)</span><br><span class="line">        <span class="comment"># PIL.ImageChops.blend(image1, image2, alpha)</span></span><br><span class="line">        <span class="comment"># out = image1 * (1.0 - alpha) + image2 * alpha</span></span><br><span class="line">    img_result = prod(image, feature_layers, iterations, lr, transform, device, vgg, modulelist)</span><br><span class="line">    img_result = img_result.resize(image.size)</span><br><span class="line">    <span class="keyword">return</span> img_result</span><br></pre></td></tr></table></figure>
<h1 id="4-全部代码-详细注释"><a href="#4-全部代码-详细注释" class="headerlink" title="4    全部代码(详细注释)"></a>4    全部代码(详细注释)</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageFilter, ImageChops</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment">#下载图片</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">path</span>) :</span><br><span class="line">    img = Image.<span class="built_in">open</span>(path)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="comment">#因为在图像处理过程中有归一化的操作，所以要&quot;反归一化&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">deprocess</span>(<span class="params">image, device</span>):</span><br><span class="line">    image = image * torch.tensor([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>], device = device) + torch.tensor([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], device = device)</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment">#传入输入图像，正 向传播到VGG19的指定层，然后，用梯度上升更新 输入图像的特征值。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prod</span>(<span class="params">image, feature_layers, iterations, lr, transform, device, vgg, modulelist</span>) :</span><br><span class="line">    <span class="built_in">input</span> = transform(image).unsqueeze(<span class="number">0</span>)         <span class="comment">#对图像进行resize，转成tensor和归一化操作，要增加一个维度，表示一个样本，[1, C, H, W]</span></span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.to(device).requires_grad_(<span class="literal">True</span>) <span class="comment">#对图片进行追踪计算梯度</span></span><br><span class="line">    vgg.zero_grad()                               <span class="comment">#梯度清零</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations) :</span><br><span class="line">        out = <span class="built_in">input</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(feature_layers) :          <span class="comment">#遍历features模块的各层</span></span><br><span class="line">            out = modulelist[j + <span class="number">1</span>](out)          <span class="comment">#以上一层的输出特征作为下一层的输入特征</span></span><br><span class="line">        loss = out.norm()                         <span class="comment">#计算特征的二范数</span></span><br><span class="line">        loss.backward()                           <span class="comment">#反向传播计算梯度，其中图像的每个像素点都是参数</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad() :</span><br><span class="line">            <span class="built_in">input</span> += lr * <span class="built_in">input</span>.grad              <span class="comment">#更新原始图像的像素值</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.squeeze()                       <span class="comment">#训练完成后将表示样本数的维度去除</span></span><br><span class="line">    <span class="comment"># 交互维度</span></span><br><span class="line">    <span class="comment"># input = input.transpose(0, 1)</span></span><br><span class="line">    <span class="comment"># input = input.transpose(1, 2)</span></span><br><span class="line">    <span class="built_in">input</span> = <span class="built_in">input</span>.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)                <span class="comment">#维度转换，因为tensor的维度是(C, H, W)，而array是(H, W, C)</span></span><br><span class="line">    <span class="built_in">input</span> = np.clip(deprocess(<span class="built_in">input</span>, device).detach().cpu().numpy(), <span class="number">0</span>, <span class="number">1</span>)<span class="comment">#将像素值限制在(0, 1)之间</span></span><br><span class="line">    image = Image.fromarray(np.uint8(<span class="built_in">input</span> * <span class="number">255</span>))<span class="comment">#将array类型的图像转成PIL类型图像，要乘以255是因为转成tensor时函数自动除以了255</span></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="comment">#多次缩小图像，然后调用函数 prod。接着在放大结果，并与按一定比例图像混合在一起，最终得到与输入 图像相同大小的输出图像。</span></span><br><span class="line"><span class="comment">#octave_scale参数决定了有多少个尺度的图像, num_octaves参数决定一共有多少张图像</span></span><br><span class="line"><span class="comment">#octave_scale和num_octaves两个参数的选定对生成图像的影响很大。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">deep_dream_vgg</span>(<span class="params">image, feature_layers, iterations, lr, transform, device, vgg, modulelist, octave_scale = <span class="number">2</span>, num_octaves = <span class="number">100</span></span>) :</span><br><span class="line">    <span class="keyword">if</span> num_octaves &gt; <span class="number">0</span> :</span><br><span class="line">        image1 = image.<span class="built_in">filter</span>(ImageFilter.GaussianBlur(<span class="number">2</span>))<span class="comment">#高斯模糊</span></span><br><span class="line">        <span class="keyword">if</span> (image1.size[<span class="number">0</span>] / octave_scale &lt; <span class="number">1</span> <span class="keyword">or</span> image1.size[<span class="number">1</span>] / octave_scale &lt; <span class="number">1</span>) :<span class="comment">#当图像的大小小于octave_scale时图像尺度不再变化</span></span><br><span class="line">            size = image1.size</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            size = (<span class="built_in">int</span>(image1.size[<span class="number">0</span>] / octave_scale), <span class="built_in">int</span>(image1.size[<span class="number">1</span>] / octave_scale))</span><br><span class="line"></span><br><span class="line">        image1 = image1.resize(size, Image.ANTIALIAS)<span class="comment">#缩小图片</span></span><br><span class="line">        image1 = deep_dream_vgg(image1, feature_layers, iterations, lr, transform, device, vgg, modulelist, octave_scale, num_octaves - <span class="number">1</span>)<span class="comment">#递归</span></span><br><span class="line">        size = (image.size[<span class="number">0</span>], image.size[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        image1 = image1.resize(size, Image.ANTIALIAS)<span class="comment">#放大图像</span></span><br><span class="line">        image = ImageChops.blend(image, image1, <span class="number">0.6</span>) <span class="comment">#按一定比例将图像混合在一起</span></span><br><span class="line">        <span class="comment"># PIL.ImageChops.blend(image1, image2, alpha)</span></span><br><span class="line">        <span class="comment"># out = image1 * (1.0 - alpha) + image2 * alpha</span></span><br><span class="line">    img_result = prod(image, feature_layers, iterations, lr, transform, device, vgg, modulelist)</span><br><span class="line">    img_result = img_result.resize(image.size)</span><br><span class="line">    <span class="keyword">return</span> img_result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment">#对图像进行预处理</span></span><br><span class="line">    tranform = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">        transforms.ToTensor(), <span class="comment">#将PIL类型转成tensor类型，注意再次过程中像素值已经转到了[0, 1]之间，方式是除以255</span></span><br><span class="line">        transforms.Normalize(mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], <span class="comment">#归一化</span></span><br><span class="line">                             std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    vgg = models.vgg19(pretrained = <span class="literal">True</span>).to(device) </span><br><span class="line">    </span><br><span class="line">    modulelist = <span class="built_in">list</span>(vgg.features.modules())<span class="comment">#要注意网络层转成列表元素之后，第一个元素是全部的网络层，下标从1开始迭代网络层,这也是后面是modulelist[j + 1]的原因</span></span><br><span class="line">    night_sky = load_image(<span class="string">&#x27;starry_night.jpg&#x27;</span>)</span><br><span class="line">    night_sky_30 = deep_dream_vgg(night_sky, <span class="number">36</span>, <span class="number">6</span>, <span class="number">0.2</span>, tranform, device, vgg, modulelist)</span><br><span class="line">    plt.imshow(night_sky_30)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>运行结果：<br>输入图像：<br><img src="https://img-blog.csdnimg.cn/bedf2246f48340e79d79d3815c7dd784.png#pic_center" alt="在这里插入图片描述"></p>
<p><strong><em>VGG19</em></strong> 的第10层学习的特征：<br><img src="https://img-blog.csdnimg.cn/d3c6a7a59552430096a65277dc160629.png#pic_center" alt="在这里插入图片描述"><br><strong><em>VGG19</em></strong> 的第20层学习的特征：<img src="https://img-blog.csdnimg.cn/1d9b2c340fba45cb9891defe7c3d327c.png#pic_center" alt="在这里插入图片描述"><br><strong><em>VGG19</em></strong> 的第30层学习的特征：<br><img src="https://img-blog.csdnimg.cn/772fd62917694486910afecef0b27613.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;<strong><em>VGG19</em></strong> 预训练模型是基于ImageNet大数据集训练的模型，该数据集共有1000个类别。从上面的结果可以看出，越靠近顶部的层，其激活值表现就越全面或抽象，如像某些类别(比如狗)的图案。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>迁移学习</title>
    <url>/2022/06/05/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;迁移学习在计算机视觉任务和自然语言处理任务中经常使用，这些模型往往需要大数据、复杂的网络结构。如果使用迁移学习，可将预训练的模型作为新模型的起点，这些预训练的模型在开发神经网络的时候已经在大数据集上训练好、模型设计也比较好，这样的模型通用性也比较好。如果要解决的问题与这些模型相关性较强，那么使用这些预训练模型，将大大地提升模型的性能和泛化能力。</p>
<h1 id="1-原理"><a href="#1-原理" class="headerlink" title="1    原理"></a>1    原理</h1><p>&emsp;&emsp;迁移学习(Transfer Learning)是机器学习的一个研究方向，主要研究如何将任务 A 上面学习到的知识迁移到任务 B 上，以提高在任务 B 上的泛化性能。例如任务 A 为猫狗分类问题，需要训练一个分类器能够较好的分辨猫和狗的样本图片，任务 B 为牛羊分类问题。可以发现，任务 A 和任务 B 存在大量的共享知识，比如这些动物都可以从毛发、体型、形 态、发色等方面进行辨别。因此在任务 A 训练获得的分类器已经掌握了这部份知识，在训练任务 B 的分类器时，可以不从零开始训练，而是在任务 A 上获得的知识的基础上面进行训练(Feature Extraction)或微调(Fine tuning)，这和“站在巨人的肩膀上”思想非常类似。通过迁移任务 A 上学习的知识，在任务 B 上训练分类器可以使用更少的样本和更少的训练代价，并且获得不错的泛化能力。<br><img src="https://img-blog.csdnimg.cn/71014ae2eca346d18f7e7a09c2d81e97.png#pic_center" alt="在这里插入图片描述"><br>在神经网络迁移学习中，主要有两个应用场景：特征提取和微调。<br> <strong><em>❑ 特征提取(Feature Extraction)</em></strong> ：冻结除最终完全连接层之外的所有网络的权重。最后一个全连接层被替换为具有随机权重的新层，因只需要更新最后一层全连接层，使得更新参数极大地减少，节省大量的 <strong><em>训练时间</em></strong> 和 <strong><em>GPU</em></strong> 资源。<br><strong><em>❑ 微调(Fine Tuning)</em></strong> ：对于卷积神经网络，一般认为它能够逐层提取特征，越末层的网络的抽象特征提取能力越强，输出层一般使用与类别数相同输出节点的全连接层，作为分类网络的概率分布预测。对于相似的任务 A 和 B，如果它们的特征提取方法是相近的，则网络的前面数层可以重用。而微调技术就是使用预训练网络初始化网络，而不是随机初始化，用新数据训练部分或整个网络。小幅度更新前面的层的参数。</p>
<h1 id="2-实例"><a href="#2-实例" class="headerlink" title="2    实例"></a>2    实例</h1><p>&emsp;&emsp;进行迁移学习需要使用对应的预训练模型。PyTorch提供了很多现成的预 训练模块，我们直接拿来使用就可以。主要集成在 <strong><em>torchvision.models</em></strong> 模块中，预训练模型可以通过传递参数 <strong><em>pretrained = True</em></strong> 构造。主要的模型有 <strong><em>AlexNet，VGG，ResNet，SqueezeNet，DenseNet，Inception v3，GoogLeNet，ShuffleNet v2</em></strong> 等。<br>&emsp;&emsp;所有的预训练模型都要求输入图片以相同的方式进行标准化，即：小批l量3通道RGB格式 <strong><em>(3 × H × W)</em></strong> ，其中H和W应等于 <strong><em>224</em></strong> 。图片加载时像素值的范围应在 <strong><em>[0, 1]</em></strong> 内，然后通过指定 <strong><em>mean = [0.485, 0.456, 0.406]</em></strong> 和 <strong><em>std = [0.229, 0.224, 0.225]</em></strong> 进行标准化。</p>
<h2 id="2-1-特征提取"><a href="#2-1-特征提取" class="headerlink" title="2.1    特征提取"></a>2.1    特征提取</h2><p>&emsp;&emsp;本次案例使用的数据集是 <strong><em>CIFAR-10数据集</em></strong> ，目标是对数据集中10类物体进行分类，只使用几层的卷积和全连接层的分类正确率只有 68% 左右，结果不算好。此案例使用迁移学习中特征提取方法来实现这个任务，预训练模型采用 <strong><em>retnet18</em></strong> 网络。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#导入相关包</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment">#为适合预训练模型，增加了一些预处理功能，如数据标准化，对图片进行裁剪等</span></span><br><span class="line">trans_train = transforms.Compose([</span><br><span class="line">    transforms.RandomSizedCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                         std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line"><span class="comment">#对测试集的预处理有一定不同，这一点对结果的影响很大</span></span><br><span class="line">trans_vaild = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">256</span>),</span><br><span class="line">    transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                         std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br><span class="line"></span><br><span class="line"><span class="comment">#CIFAR10数据集下载</span></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(</span><br><span class="line">    root = <span class="string">&#x27;data&#x27;</span>,</span><br><span class="line">    download = <span class="literal">False</span>,</span><br><span class="line">    train = <span class="literal">True</span>,</span><br><span class="line">    transform = trans_train</span><br><span class="line">)</span><br><span class="line">trainloader = DataLoader(trainset, batch_size = <span class="number">64</span>, shuffle = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">testset = torchvision.datasets.CIFAR10(</span><br><span class="line">    root = <span class="string">&#x27;data&#x27;</span>,</span><br><span class="line">    download = <span class="literal">False</span>,</span><br><span class="line">    train = <span class="literal">False</span>,</span><br><span class="line">    transform = trans_vaild</span><br><span class="line">)</span><br><span class="line">testloader = DataLoader(testset, batch_size = <span class="number">64</span>, shuffle = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#这里会自动下载预训练模型，该模型网络架构为resnet18，</span></span><br><span class="line"><span class="comment">#已经在 ImageNet大数据集上训练好了，该数据集有1000类别</span></span><br><span class="line">net = models.resnet18(pretrained = <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#冻结于训练模型的全部参数</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> net.parameters() :</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"><span class="comment">#修改最后的全连接层，CIFAR10数据集只有10类</span></span><br><span class="line">net.fc = nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看总参数及训练参数</span></span><br><span class="line">total_params = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> net.parameters())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;原参数的数量 : <span class="subst">&#123;total_params&#125;</span>&#x27;</span>) <span class="comment">#11181642</span></span><br><span class="line">total_params_trainable = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> net.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;需要训练的参数 : <span class="subst">&#123;total_params_trainable&#125;</span>&#x27;</span>) <span class="comment">#5130</span></span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment">#要注意这个地方 net.fc.parameters()，只更新最后的全连接参数而不是net.parameters()</span></span><br><span class="line">optimizer = optim.SGD(net.fc.parameters(), lr = <span class="number">0.001</span>, weight_decay = <span class="number">0.001</span>, momentum = <span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line">net = net.to(device)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>) :</span><br><span class="line">    prev_time = datetime.now()</span><br><span class="line">    train_losses = <span class="number">0.0</span></span><br><span class="line">    train_acc = <span class="number">0.0</span></span><br><span class="line">    net.train()</span><br><span class="line">    <span class="keyword">for</span> x, label <span class="keyword">in</span> trainloader :</span><br><span class="line">        x, label = x.to(device), label.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        out = net(x)</span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line">        train_losses += loss.item()</span><br><span class="line">        _, pred = torch.<span class="built_in">max</span>(out, dim = <span class="number">1</span>)</span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">        train_acc += num_correct / x.size(<span class="number">0</span>)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    <span class="comment">#计算每个循环所花费的时间</span></span><br><span class="line">    cur_time = datetime.now()</span><br><span class="line">    h, remainder = <span class="built_in">divmod</span>((cur_time - prev_time).seconds, <span class="number">3600</span>)</span><br><span class="line">    m, s = <span class="built_in">divmod</span>(remainder, <span class="number">60</span>)</span><br><span class="line">    time_str = <span class="string">&quot;Time %02d:%02d:%02d&quot;</span> % (h, m, s)</span><br><span class="line">    <span class="comment">#测试</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad() :</span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        test_losses = <span class="number">0.0</span></span><br><span class="line">        test_acc = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> x, label <span class="keyword">in</span> testloader :</span><br><span class="line">            x, label = x.to(device), label.to(device)</span><br><span class="line">            out = net(x)</span><br><span class="line">            loss = criterion(out, label)</span><br><span class="line">            test_losses += loss.item()</span><br><span class="line">            _, pred = torch.<span class="built_in">max</span>(out, dim = <span class="number">1</span>)</span><br><span class="line">            num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">            test_acc += num_correct / x.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Eopch <span class="subst">&#123;epoch&#125;</span>. Train Loss: <span class="subst">&#123;(train_losses / <span class="built_in">len</span>(trainloader)):<span class="number">.4</span>f&#125;</span>, &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Train Acc: <span class="subst">&#123;(train_acc / <span class="built_in">len</span>(trainloader)):<span class="number">.3</span>f&#125;</span>, &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Vaild Loss: <span class="subst">&#123;(test_losses / <span class="built_in">len</span>(testloader)):<span class="number">.4</span>f&#125;</span>, &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Vaild Acc: <span class="subst">&#123;(test_acc / <span class="built_in">len</span>(testloader)):<span class="number">.3</span>f&#125;</span>, &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Time: <span class="subst">&#123;time_str&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>结果：<img src="https://img-blog.csdnimg.cn/81642eab98af493d8df742178ef43f48.png#pic_center" alt="在这里插入图片描述"><br>在前三个Epoch准确率就达到了 73.6% ，最终结果会达到 75% 左右，从精确率比第6章提升了近10个百分点。但是对于分类效果来说仍不是很理想。</p>
<h2 id="2-2-微调"><a href="#2-2-微调" class="headerlink" title="2.2    微调"></a>2.2    微调</h2><p>&emsp;&emsp;微调允许修改预先训练好的网络参数来学习目标任务，所以，虽然训练时间要比特征抽取方法长，但精度更高。微调的大致过程是在预先训练过的网络上添加新的随机初始化层，此外预先训练的网络参数也会被更新，但会使用较小的学习率以防止预先训练好的参数发生较大的改变。<br>&emsp;&emsp;在本次的微调任务中采用了数据增强的方法来使得分类效果更加。因为数据增强是提高模型的泛化能力最重要因素，数据增强技术主要有  <strong><em>水平或垂直翻转图像、裁剪、色彩 变换、扩展和旋转</em></strong> 等，通过数据增强技术不仅可以扩大训练数据集的规 模、降低模型对某些属性的依赖，从而提高模型的泛化能力，同时可以对图像进行不同方式的裁剪，使感兴趣的物体出现在不同的位置，从而减轻模型对物体出现位置的依赖性。并通过调整亮度、色彩等因素来降低模型对色彩的敏感度等。在PyTorch中图像增强的方法集成在 <strong><em>torchvision.transforms</em></strong> 模块中，主要的有：<br><strong><em>❑</em></strong> <strong><em>torchvision.transforms.Resize()</em></strong> ：随机比例缩放。<br><strong><em>❑</em></strong> <strong><em>torhvision.transforms.RandomCrop()</em></strong> ：在图像随机位置进行裁取。<br><strong><em>❑</em></strong> <strong><em>torhvision.transforms.CenterCrop()</em></strong> ：在图像中心置进行裁取。<br><strong><em>❑</em></strong> <strong><em>torchvision.transforms.RandomHorizontalFlip()</em></strong> ：随机水平翻转。<br><strong><em>❑</em></strong> <strong><em>torchvision.transforms.RandomVerticalFlip()</em></strong> ：随机竖直翻转。<br><strong><em>❑</em></strong> <strong><em>torchvision.transforms.RandomRotation()</em></strong> ：随机旋转。<br><strong><em>❑</em></strong> <strong><em>torchvision.transforms.ColorJitter()</em></strong> ：改变亮度、对比度和颜色。<br>微调的代码与特征提取的不同地方主要在图像预处理部分和参数更新部分。<br>这里对训练数据添加了几种数据增强方法，如图像裁剪、旋转、颜色改变等方法。测试数据与特征提取一样，没有变化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trans_train = transforms.Compose([</span><br><span class="line">    transforms.RandomResizedCrop(<span class="number">256</span>, scale = (<span class="number">0.8</span>, <span class="number">1.0</span>)),</span><br><span class="line">    transforms.RandomRotation(degrees = <span class="number">15</span>),</span><br><span class="line">    transforms.ColorJitter(),</span><br><span class="line">    transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean = [<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                         std = [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])])</span><br></pre></td></tr></table></figure>
<p>优化器部分，注意不要冻结预训练模型的参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">optimizer = optim.SGD(net.parameters(), lr = <span class="number">0.001</span>, weight_decay = <span class="number">0.001</span>, momentum = <span class="number">0.9</span>)</span><br></pre></td></tr></table></figure>
<p>结果：<br><img src="https://img-blog.csdnimg.cn/b245be1a9569429195db8f05e02bafc3.png#pic_center" alt="在这里插入图片描述"><br>由结果知微调+数据增强的方法在第三个Epoch正确率就可以达到 92% ，最终结果可达到 95% 左右，正确很高。本次实验只设置了20个Eopch，当继续增加Epoch时，正确率会接近 100% 。</p>
<p><strong>参考文献：</strong><br><strong><em>❑</em></strong> ：<strong>Python深度学习基于PyTorch</strong><br><strong><em>❑</em></strong> ：<strong>TensorFlow深度学习</strong></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>PyTorch</tag>
        <tag>迁移学习</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习</title>
    <url>/2022/06/05/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>﻿# 前言</p>
<p>&emsp;&emsp;强化学习是机器学习领域除有监督学习、无监督学习外的另一个研究分支，它主要利用智能体与环境进行交互，从而学习到能获得良好结果的策略。与有监督学习不同，强化学习的动作并没有明确的标注信息，只有来自环境的反馈的奖励信息，它通常具有一定的滞后性，用于反映动作的“好与坏”。一个完整的强化 学习过程是从一开始什么都不懂，通过不断尝试，从错误或惩罚中学习，最 后找到规律，学会达到目的的方法。<img src="https://img-blog.csdnimg.cn/dbc62de270404be49f3b1ece58c682b2.png#pic_center" alt="在这里插入图片描述"><br>应用领域：<br><strong><em>❑</em></strong> 游戏理论与多主体交互。<br><strong><em>❑</em></strong> 机器人。<br><strong><em>❑</em></strong> 电脑网络。<br><strong><em>❑</em></strong> 车载导航。<br><strong><em>❑</em></strong> 工业物流。</p>
<h1 id="1-原理"><a href="#1-原理" class="headerlink" title="1    原理"></a>1    原理</h1><p>&emsp;&emsp;在强化学习问题中，具有感知和决策能力的对象叫作智能体(Agent)，它可以是一段算 法代码，也可以是具有机械结构的机器人软硬件系统。智能体通过与外界的环境进行交互从而完成某个任务，这里的环境(Environment)是指能受到智能体的动作而产生影响，并给出相应反馈的外界环境的总和。对于智能体来说，它通过感知环境的状态(State)而产生决策动作(Action)；对于环境来说，它从某个初始初始状态𝑠1开始，通过接受智能体的动作来动态地改变自身状态，并给出相应的奖励(Reward)信号。<br>&emsp;&emsp;从概率角度描述强化学习过程，它包含了如下 5 个基本对象：<br> <strong><em>❑ 状态𝑠</em></strong> ：反映了环境的状态特征，在时间戳𝑡上的状态记为$𝑠_𝑡$，它可以是原始的视觉图 像、语音波形等信号，也可以是高层抽象过后的特征，如小车的速度、位置等数据，所有的(有限)状态构成了状态空间$S$<br><strong><em>❑ 动作𝑎</em></strong> ：是智能体采取的行为，在时间戳𝑡上的状态记为$𝑎_𝑡$，可以是向左、向右等离散动 作，也可以是力度、位置等连续动作，所有的(有限)动作构成了动作空间$A$<br><strong><em>❑ 策略𝜋(𝑎|𝑠)</em></strong>　：代表了智能体的决策模型，接受输入为状态𝑠，并给出决策后执行动作的概率分布𝑝(𝑎|𝑠)，满足 <strong><em>∑𝜋(𝑎|𝑠)  = 1, 𝑎∈𝐴</em></strong>，这种具有一定随机性的动作概率输出称为随机性策略(Stochastic Policy)。特别地，当策略模型总是输出某个动作的概率为 1，其它为 0 时，这种策略模型称为确定性策略(Deterministic Policy)，即 <strong><em>𝑎 = 𝜋(𝑠)</em></strong><br><strong><em>❑ 奖励𝑟(𝑠, 𝑎)</em></strong> ：表达环境在状态𝑠时接受动作𝑎后给出的反馈信号，一般是一个标量值，它 在一定程度上反映了动作的好与坏，在时间戳𝑡上的获得的激励记为𝑟𝑡(部分资料上记为𝑟𝑡+1，这是因为激励往往具有一定滞后性)<br><strong><em>❑ 状态转移概率𝑝(𝑠′|𝑠, 𝑎)</em></strong> ：表达了环境模型状态的变化规律，即当前状态𝑠的环境在接受动作𝑎后，状态改变为𝑠′的概率分布，满足 <strong><em>∑ 𝑝(𝑠′|𝑠, 𝑎) = 1，𝑠′∈𝑆</em></strong><br>交互过程可由下图表示：<br><img src="https://img-blog.csdnimg.cn/d5d51d62eabd4c94a2f1b6562f5ba9ee.png#pic_center" alt="在这里插入图片描述"><br>由交互过程我们得到整个强化学习系统的输入是：<br><strong><em>❑</em></strong> State 为Observation。<br><strong><em>❑</em></strong> Actions 在每个状态下，有什么行动。<br><strong><em>❑</em></strong> Reward 进入每个状态时，能带来正面或负面的回报。<br>输出是：<br><strong><em>❑</em></strong> Policy 在每个状态下，会选择哪个行动。</p>
<p>&emsp;&emsp;增强学习的任务就是找到一个最优的策略Policy，从而使Reward最多。智能体从环境的初始状态$𝑠_1$开始，通过策略模型𝜋(𝑎|𝑠)采样某个具体的动作$𝑎_1$执行，环境受到动作$𝑎_1$的影响，状态根据内部状态转移模型𝑝(𝑠′|𝑠, 𝑎)发生改变，变为新的状态$s_2$，同时给出智能体的反馈信号：奖励$𝑟_1$，由奖励函数𝑟($𝑠_1$, $𝑎_1$)产生。如此循环交互，直至达到游戏终止状态$𝑎_T$，这个过程产生了一系列的有序数据：𝜏 = $𝑠_1, 𝑎_1, 𝑟_1, 𝑠_2, 𝑎_2, 𝑟_2, ⋯ , 𝑠_𝑇$<br>&emsp;&emsp;这个序列代表了智能体与环境的一次交换过程，叫做轨迹(Trajectory)，记为𝜏，一次交互过程叫作一个回合(Episode)，𝑇代表了回合的时间戳数(或步数)。有些环境有明确的终止状态(Terminal State)，比如太空侵略者中的小飞机被击中后则游戏结束；而部分环境没有明确的终止标志，如部分游戏只要保持健康状态，则可以无限玩下去，此时𝑇代表∞。增强学习的算法就是需要根据这些样本来 改进策略，从而使得到的样本中的奖励更好。<br>&emsp;&emsp;强化学习有多种算法，目前比较常用的算法是，通过行为的价值来选取 特定行为的方法，如Q-learning、SARSA，使用神经网络学习的DQN(Deep Q Network)，以及DQN的后续算法，还有直接输出行为的Policy Gradients 等。</p>
<h1 id="2-Q-Learning"><a href="#2-Q-Learning" class="headerlink" title="2    Q-Learning"></a>2    Q-Learning</h1><h2 id="2-1-原理"><a href="#2-1-原理" class="headerlink" title="2.1    原理"></a>2.1    原理</h2><p>&emsp;&emsp;Q-Learning算法是强化学习中重要且最基础的算法，大多数现代的强化 学习算法，大都是Q-Learning的一些改进。Q-Learning的核心是Q-Table。Q- Table的行和列分别表示State和Action的值，Q-Table的值Q(s,a)衡量当前 States采取行动a的主要依据。</p>
<h2 id="2-2-主要流程"><a href="#2-2-主要流程" class="headerlink" title="2.2    主要流程"></a>2.2    主要流程</h2><p><strong><em>❑</em></strong> 初始化Q表(初始化为0或随机初始化)<br><strong><em>Repeat：</em></strong><br><strong><em>❑</em></strong> 生成一个在0与1之间的随机数，如果该数大于预先给定的一 个阈值ε，则选择随机动作；否则选择动点依据最高可能性的奖励基于当前状态s和Q表。<br><strong><em>❑</em></strong> 依据上步执行动作。<br><strong><em>❑</em></strong> 采取行动后观察奖励值r和新状态$s_{t+1}$。<br><strong><em>❑</em></strong> 基于奖励值r，利用式下式更新Q表。<img src="https://img-blog.csdnimg.cn/9f75c81d5238492498f6cfd2b0413d03.png" alt="在这里插入图片描述"><br>其中α为学习率，γ为折扣率。<br><strong><em>❑</em></strong> 把$s_{t+1}$赋给$s_{t}$</p>
<p>流程图：<br><img src="https://img-blog.csdnimg.cn/37f7ec73ff5f4d25aff7e2202331c82f.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-3-Q函数"><a href="#2-3-Q函数" class="headerlink" title="2.3    Q函数"></a>2.3    Q函数</h2><p>&emsp;&emps;Q-Learning算法的核心是Q(s,a)函数，其中s表示状态，a表示行动， Q(s,a)的值为在状态s执行a行为后的最大期望奖励值。Q(s,a)函数可以看作一 个表格，每一行表示一个状态，每一列代表一个行动。<img src="https://img-blog.csdnimg.cn/79aa5961edcb49e3935920db9f4b691d.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;得到Q函数后，就可以在每个状态做出合适的决策了。如当处于$s_1$时， 只需考虑Q($s_1$, :)这些值，并挑选其中最大的Q函数值，并执行相应的动作。</p>
<h2 id="2-4-贪婪策略"><a href="#2-4-贪婪策略" class="headerlink" title="2.4    贪婪策略"></a>2.4    贪婪策略</h2><p>&emsp;&emsp;在状态s1时，我们一般是执行根据max(Q($s_1$, : ))中对应的动作a。如果每次都按照这种策略选择行动就有可能局限于现有经验中，不 利于发现更有价值或更新的情况。所以，除根据经验选择行动外，一般还会给主体(Agent)一定的机会或概率，以探索的方式选择行动。 这种平衡“经验”和“探索”的方法又称为ε贪婪(ε-greedy)策略。根据预 先设置好的ε值(该值一般较小，如取0.1)，主体有ε的概率随机行动，有1- ε的概率根据经验选择行动。</p>
<h2 id="2-5-PyTorch实现"><a href="#2-5-PyTorch实现" class="headerlink" title="2.5    PyTorch实现"></a>2.5    PyTorch实现</h2><p>&emsp;&emsp;本次用于训练的小游戏是机器人寻找目标星星，如果小机器人接触到五角、星，它就能赢得100分的奖励，如果它接触到小树将得到-100的惩罚。根据奖励进行不断优化最佳路径。<br><img src="https://img-blog.csdnimg.cn/a6a0a9ef9b6b4343a4c9015106b76358.png#pic_center" alt="在这里插入图片描述"><br>首先要创建游戏并进行交互主要包含了 5 个步骤：<br><strong><em>❑</em></strong> 创建游戏。并返回游戏对象env。<br><strong><em>❑</em></strong> 复位游戏状态。一般游戏环境都具有初始状态，通过调用 env.reset()即可复位游戏状 态，同时返回游戏的初始状态 observation。<br><strong><em>❑</em></strong> 显示游戏画面。通过调用 env.render()即可显示每个时间戳的游戏画面，一般用做测试。在训练时渲染画面会引入一定的计算代价，因此训练时可不显示画面。<br><strong><em>❑</em></strong> 与游戏环境交互。通过 env.step(action)即可执行 action 动作，并返回新的状态observation、当前奖励 reward、游戏是否结束标志 done。通过循环此步骤即可持续与环境交互，直至游戏回合结束。<br><strong><em>❑</em></strong> 销毁游戏。调用 env.close()即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Env</span>(tk.Tk):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Env, self).__init__()</span><br><span class="line">        self.action_space = [<span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;l&#x27;</span>, <span class="string">&#x27;r&#x27;</span>]</span><br><span class="line">        self.n_actions = <span class="built_in">len</span>(self.action_space)</span><br><span class="line">        self.title(<span class="string">&#x27;Q Learning&#x27;</span>)</span><br><span class="line">        self.geometry(<span class="string">&#x27;&#123;0&#125;x&#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(HEIGHT * UNIT, HEIGHT * UNIT))</span><br><span class="line">        self.shapes = self.load_images()</span><br><span class="line">        self.canvas = self._build_canvas()</span><br><span class="line">        self.texts = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_build_canvas</span>(<span class="params">self</span>):</span><br><span class="line">        canvas = tk.Canvas(self, bg=<span class="string">&#x27;white&#x27;</span>,</span><br><span class="line">                           height=HEIGHT * UNIT,</span><br><span class="line">                           width=WIDTH * UNIT)</span><br><span class="line">        <span class="comment"># create grids</span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, WIDTH * UNIT, UNIT):  <span class="comment"># 0~400 by 100</span></span><br><span class="line">            x0, y0, x1, y1 = c, <span class="number">0</span>, c, HEIGHT * UNIT</span><br><span class="line">            canvas.create_line(x0, y0, x1, y1)</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, HEIGHT * UNIT, UNIT):  <span class="comment"># 0~400 by 100</span></span><br><span class="line">            x0, y0, x1, y1 = <span class="number">0</span>, r, HEIGHT * UNIT, r</span><br><span class="line">            canvas.create_line(x0, y0, x1, y1)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 把图标加载到环境中</span></span><br><span class="line">        self.rectangle = canvas.create_image(<span class="number">50</span>, <span class="number">50</span>, image=self.shapes[<span class="number">0</span>])</span><br><span class="line">        self.tree1 = canvas.create_image(<span class="number">250</span>, <span class="number">150</span>, image=self.shapes[<span class="number">1</span>])</span><br><span class="line">        self.tree2 = canvas.create_image(<span class="number">150</span>, <span class="number">250</span>, image=self.shapes[<span class="number">1</span>])</span><br><span class="line">        self.star = canvas.create_image(<span class="number">250</span>, <span class="number">250</span>, image=self.shapes[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对环境进行包装</span></span><br><span class="line">        canvas.pack()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> canvas</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_images</span>(<span class="params">self</span>):</span><br><span class="line">        rectangle = PhotoImage(</span><br><span class="line">            Image.<span class="built_in">open</span>(<span class="string">&quot;img/bob.png&quot;</span>).resize((<span class="number">65</span>, <span class="number">65</span>)))</span><br><span class="line">        tree = PhotoImage(</span><br><span class="line">            Image.<span class="built_in">open</span>(<span class="string">&quot;img/tree.png&quot;</span>).resize((<span class="number">65</span>, <span class="number">65</span>)))</span><br><span class="line">        star = PhotoImage(</span><br><span class="line">            Image.<span class="built_in">open</span>(<span class="string">&quot;img/star.jpg&quot;</span>).resize((<span class="number">65</span>, <span class="number">65</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> rectangle, tree, star</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">text_value</span>(<span class="params">self, row, col, contents, action, font=<span class="string">&#x27;Helvetica&#x27;</span>, size=<span class="number">10</span>,</span></span><br><span class="line"><span class="params">                   style=<span class="string">&#x27;normal&#x27;</span>, anchor=<span class="string">&quot;nw&quot;</span></span>):</span><br><span class="line">        <span class="keyword">if</span> action == <span class="number">0</span>:</span><br><span class="line">            origin_x, origin_y = <span class="number">7</span>, <span class="number">42</span></span><br><span class="line">        <span class="keyword">elif</span> action == <span class="number">1</span>:</span><br><span class="line">            origin_x, origin_y = <span class="number">85</span>, <span class="number">42</span></span><br><span class="line">        <span class="keyword">elif</span> action == <span class="number">2</span>:</span><br><span class="line">            origin_x, origin_y = <span class="number">42</span>, <span class="number">5</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            origin_x, origin_y = <span class="number">42</span>, <span class="number">77</span></span><br><span class="line"></span><br><span class="line">        x, y = origin_y + (UNIT * col), origin_x + (UNIT * row)</span><br><span class="line">        font = (font, <span class="built_in">str</span>(size), style)</span><br><span class="line">        text = self.canvas.create_text(x, y, fill=<span class="string">&quot;black&quot;</span>, text=contents,</span><br><span class="line">                                       font=font, anchor=anchor)</span><br><span class="line">        <span class="keyword">return</span> self.texts.append(text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_value_all</span>(<span class="params">self, q_table</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> self.texts:</span><br><span class="line">            self.canvas.delete(i)</span><br><span class="line">        self.texts.clear()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(HEIGHT):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(WIDTH):</span><br><span class="line">                <span class="keyword">for</span> action <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">4</span>):</span><br><span class="line">                    state = [i, j]</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">str</span>(state) <span class="keyword">in</span> q_table.keys():</span><br><span class="line">                        temp = q_table[<span class="built_in">str</span>(state)][action]</span><br><span class="line">                        self.text_value(j, i, <span class="built_in">round</span>(temp, <span class="number">2</span>), action)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">coords_to_state</span>(<span class="params">self, coords</span>):</span><br><span class="line">        x = <span class="built_in">int</span>((coords[<span class="number">0</span>] - <span class="number">50</span>) / <span class="number">100</span>)</span><br><span class="line">        y = <span class="built_in">int</span>((coords[<span class="number">1</span>] - <span class="number">50</span>) / <span class="number">100</span>)</span><br><span class="line">        <span class="keyword">return</span> [x, y]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">state_to_coords</span>(<span class="params">self, state</span>):</span><br><span class="line">        x = <span class="built_in">int</span>(state[<span class="number">0</span>] * <span class="number">100</span> + <span class="number">50</span>)</span><br><span class="line">        y = <span class="built_in">int</span>(state[<span class="number">1</span>] * <span class="number">100</span> + <span class="number">50</span>)</span><br><span class="line">        <span class="keyword">return</span> [x, y]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset</span>(<span class="params">self</span>):</span><br><span class="line">        self.update()</span><br><span class="line">        time.sleep(<span class="number">0.5</span>)</span><br><span class="line">        x, y = self.canvas.coords(self.rectangle)</span><br><span class="line">        self.canvas.move(self.rectangle, UNIT / <span class="number">2</span> - x, UNIT / <span class="number">2</span> - y)</span><br><span class="line">        self.render()</span><br><span class="line">        <span class="comment"># return observation</span></span><br><span class="line">        <span class="keyword">return</span> self.coords_to_state(self.canvas.coords(self.rectangle))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self, action</span>):</span><br><span class="line">        state = self.canvas.coords(self.rectangle)</span><br><span class="line">        base_action = np.array([<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">        self.render()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> action == <span class="number">0</span>:  <span class="comment"># up</span></span><br><span class="line">            <span class="keyword">if</span> state[<span class="number">1</span>] &gt; UNIT:</span><br><span class="line">                base_action[<span class="number">1</span>] -= UNIT</span><br><span class="line">        <span class="keyword">elif</span> action == <span class="number">1</span>:  <span class="comment"># down</span></span><br><span class="line">            <span class="keyword">if</span> state[<span class="number">1</span>] &lt; (HEIGHT - <span class="number">1</span>) * UNIT:</span><br><span class="line">                base_action[<span class="number">1</span>] += UNIT</span><br><span class="line">        <span class="keyword">elif</span> action == <span class="number">2</span>:  <span class="comment"># left</span></span><br><span class="line">            <span class="keyword">if</span> state[<span class="number">0</span>] &gt; UNIT:</span><br><span class="line">                base_action[<span class="number">0</span>] -= UNIT</span><br><span class="line">        <span class="keyword">elif</span> action == <span class="number">3</span>:  <span class="comment"># right</span></span><br><span class="line">            <span class="keyword">if</span> state[<span class="number">0</span>] &lt; (WIDTH - <span class="number">1</span>) * UNIT:</span><br><span class="line">                base_action[<span class="number">0</span>] += UNIT</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 移动</span></span><br><span class="line">        self.canvas.move(self.rectangle, base_action[<span class="number">0</span>], base_action[<span class="number">1</span>])</span><br><span class="line">        self.canvas.tag_raise(self.rectangle)</span><br><span class="line">        next_state = self.canvas.coords(self.rectangle)</span><br><span class="line">        <span class="comment"># 判断得分条件</span></span><br><span class="line">        <span class="keyword">if</span> next_state == self.canvas.coords(self.star):</span><br><span class="line">            reward = <span class="number">100</span></span><br><span class="line">            done = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">elif</span> next_state <span class="keyword">in</span> [self.canvas.coords(self.tree1),</span><br><span class="line">                            self.canvas.coords(self.tree2)]:</span><br><span class="line">            reward = -<span class="number">100</span></span><br><span class="line">            done = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            reward = <span class="number">0</span></span><br><span class="line">            done = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        next_state = self.coords_to_state(next_state)</span><br><span class="line">        <span class="keyword">return</span> next_state, reward, done</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 渲染环境</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">render</span>(<span class="params">self</span>):</span><br><span class="line">        time.sleep(<span class="number">0.03</span>)</span><br><span class="line">        self.update()</span><br></pre></td></tr></table></figure>
<p>Q函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">QLearningAgent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, actions</span>):</span><br><span class="line">        <span class="comment"># 四种动作分别用序列表示：[0, 1, 2, 3]</span></span><br><span class="line">        self.actions = actions</span><br><span class="line">        self.learning_rate = <span class="number">0.01</span></span><br><span class="line">        self.discount_factor = <span class="number">0.9</span></span><br><span class="line">        <span class="comment">#epsilon贪婪策略取值</span></span><br><span class="line">        self.epsilon = <span class="number">0.1</span></span><br><span class="line">        self.q_table = defaultdict(<span class="keyword">lambda</span>: [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 采样 &lt;s, a, r, s&#x27;&gt;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self, state, action, reward, next_state</span>):</span><br><span class="line">        current_q = self.q_table[state][action]</span><br><span class="line">        <span class="comment"># 更新Q表</span></span><br><span class="line">        new_q = reward + self.discount_factor * <span class="built_in">max</span>(self.q_table[next_state])</span><br><span class="line">        self.q_table[state][action] += self.learning_rate * (new_q - current_q)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从Q-table中选取动作</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_action</span>(<span class="params">self, state</span>):</span><br><span class="line">        <span class="keyword">if</span> np.random.rand() &lt; self.epsilon:</span><br><span class="line">            <span class="comment"># 贪婪策略随机探索动作</span></span><br><span class="line">            action = np.random.choice(self.actions)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 从q表中选择</span></span><br><span class="line">            state_action = self.q_table[state]</span><br><span class="line">            action = self.arg_max(state_action)</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">arg_max</span>(<span class="params">state_action</span>):</span><br><span class="line">        max_index_list = []</span><br><span class="line">        max_value = state_action[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> index, value <span class="keyword">in</span> <span class="built_in">enumerate</span>(state_action):</span><br><span class="line">            <span class="keyword">if</span> value &gt; max_value:</span><br><span class="line">                max_index_list.clear()</span><br><span class="line">                max_value = value</span><br><span class="line">                max_index_list.append(index)</span><br><span class="line">            <span class="keyword">elif</span> value == max_value:</span><br><span class="line">                max_index_list.append(index)</span><br><span class="line">        <span class="keyword">return</span> random.choice(max_index_list)</span><br></pre></td></tr></table></figure>
<p>训练：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">env = Env()</span><br><span class="line">agent = QLearningAgent(actions=<span class="built_in">list</span>(<span class="built_in">range</span>(env.n_actions)))</span><br><span class="line"><span class="comment">#共进行200次游戏</span></span><br><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    state = env.reset()</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        env.render()</span><br><span class="line">        <span class="comment"># agent产生动作</span></span><br><span class="line">        action = agent.get_action(<span class="built_in">str</span>(state))</span><br><span class="line">        next_state, reward, done = env.step(action)</span><br><span class="line">        <span class="comment"># 更新Q表</span></span><br><span class="line">        agent.learn(<span class="built_in">str</span>(state), action, reward, <span class="built_in">str</span>(next_state))</span><br><span class="line">        state = next_state</span><br><span class="line">        env.print_value_all(agent.q_table)</span><br><span class="line">        <span class="comment"># 当到达终点就终止游戏开始新一轮训练</span></span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h1 id="3-SARSA-算法"><a href="#3-SARSA-算法" class="headerlink" title="3    SARSA 算法"></a>3    SARSA 算法</h1><p>&emsp;&emsp;SARSA 算法通过：$𝑄^π(𝑠_𝑡, 𝑎_𝑡)$ ← $𝑄^π(𝑠_𝑡, 𝑎_𝑡)$ + 𝛼(𝑟$(𝑠_𝑡, 𝑎_𝑡)$ + 𝛾$𝑄^π(𝑠_{𝑡+1}, 𝑎_{𝑡+1})$ − $𝑄^π(𝑠_𝑡, 𝑎_𝑡)$方式估计 Q 函数，在轨迹的每一步，只需要$𝑠_𝑡、𝑎_𝑡、𝑟_𝑡、𝑠_{𝑡+1}、𝑎_{𝑡+1}$数据即可更新一次 Q 网络，所以叫做 SARSA 算法(State Action Reward State Action)。SARSA 算法与Q-Leanring算法的不同之处就是在于 Q 表的更新方式的不同。</p>
<h2 id="3-1-主要流程"><a href="#3-1-主要流程" class="headerlink" title="3.1    主要流程"></a>3.1    主要流程</h2><p><strong><em>❑</em></strong> 获取初始状态s。<br><strong><em>❑</em></strong> 执行上一步选择的行动a，获得奖励r和新状态next_s。<br><strong><em>❑</em></strong> 在新状态next_s，根据当前的Q表，选定要执行的下一行动next_a。<br><strong><em>❑</em></strong> 用r、next_a、next_s，根据SARSA逻辑更新Q表。<br><strong><em>❑</em></strong> 把next_s赋给s，把next_a赋给a。</p>
<h2 id="3-2-PyTorch实现"><a href="#3-2-PyTorch实现" class="headerlink" title="3.2    PyTorch实现"></a>3.2    PyTorch实现</h2><p>&emsp;&emsp;SARSA算法与Q-Learning算法的差异是在Q表的更新方式，所以主要修改学习函数。<br><strong><em>❑</em></strong> 修改学习函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 采样 &lt;s, a, r,a&#x27;,s&#x27;&gt;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self, state, action, reward,next_action,next_state</span>):</span><br><span class="line">        current_q = self.q_table[state][action]</span><br><span class="line">        <span class="comment"># 更新Q表</span></span><br><span class="line">        new_q = reward + self.discount_factor * (self.q_table[next_state][next_action])</span><br><span class="line">        self.q_table[state][action] += self.learning_rate * (new_q - current_q)</span><br></pre></td></tr></table></figure>
<p><strong><em>❑</em></strong> 修改训练代码:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">env = Env()</span><br><span class="line">agent = QLearningAgent(actions=<span class="built_in">list</span>(<span class="built_in">range</span>(env.n_actions)))</span><br><span class="line"><span class="comment">#共进行200次游戏</span></span><br><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    state = env.reset()</span><br><span class="line">    action = agent.get_action(<span class="built_in">str</span>(state))</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        env.render()</span><br><span class="line">        <span class="comment">#获取新的状态、奖励分数</span></span><br><span class="line">        next_state, reward, done = env.step(action)</span><br><span class="line">        <span class="comment">#产生新的动作</span></span><br><span class="line">        next_action = agent.get_action(<span class="built_in">str</span>(state))</span><br><span class="line">        <span class="comment"># 更新Q表，sarsa根据新的状态及动作获取Q表的值</span></span><br><span class="line">        <span class="comment">#而不是基于新状态对所有动作的最大值</span></span><br><span class="line">        agent.learn(<span class="built_in">str</span>(state), action, reward, next_action,<span class="built_in">str</span>(next_state))</span><br><span class="line">        state = next_state</span><br><span class="line">        action=next_action</span><br><span class="line">        env.print_value_all(agent.q_table)</span><br><span class="line">        <span class="comment"># 当到达终点就终止游戏开始新一轮训练</span></span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p><strong>github地址：</strong><a href="https://github.com/aishangcengloua/MLData/tree/master/PyTorch/ReinforcementLearning">https://github.com/aishangcengloua/MLData/tree/master/PyTorch/ReinforcementLearning</a></p>
<p><strong>参考文献：</strong><br><strong><em>❑</em></strong> ：<strong>Python深度学习基于PyTorch</strong><br><strong><em>❑</em></strong> ：<strong>TensorFlow深度学习</strong></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>PyTorch</tag>
        <tag>强化学习</tag>
      </tags>
  </entry>
  <entry>
    <title>conda 环境下更新 pip 失败</title>
    <url>/2022/06/05/conda-%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%9B%B4%E6%96%B0-pip-%E5%A4%B1%E8%B4%A5/</url>
    <content><![CDATA[<p>﻿conda 环境下更新 pip 失败，出现以下问题：<br><strong><em>1.</em></strong> Script file ‘D:\Anaconda\Anaconda3\Scripts\pip-script.py’ is not present.</p>
<p>在使用网上的正常方法如：easy_install pip 等方法后依旧出现以下问题：</p>
<p><strong><em>1.</em></strong>  The easy_install command is deprecated and will be removed in a future version.<br><strong><em>2.</em></strong> D:\Anaconda\Anaconda3\python.exe: No module named pip.<strong>main</strong>; ‘pip’ is a package and cannot be directly executed</p>
<p>在 conda 环境下输入以下命令即可解决：</p>
<p><strong><em>1.</em></strong> curl <a href="https://bootstrap.pypa.io/get-pip.py">https://bootstrap.pypa.io/get-pip.py</a> -o get-pip.py<br><strong><em>2.</em></strong> python get-pip.py —force-reinstall</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>conda</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title>自定义数据集</title>
    <url>/2022/06/05/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;我们知道，现在会很多框架中都有集成数据集的库，我们可以通过几行简单的代码进行下载，如我们前几篇博客中的 MNIST 手写数字集和 Fashion MNIST数据集均可以通过PyTorch中的torchvision库下载。但库中收集到的数据集始终有限，我们则需要利用爬虫等技术进行收集新数据集，如果要用于模型训练，则需要我们自定义数据集。</p>
<h1 id="1-猫狗数据集"><a href="#1-猫狗数据集" class="headerlink" title="1    猫狗数据集"></a>1    猫狗数据集</h1><p>&emsp;&emsp;猫狗数据集可以从kaggle官网下载，该数据集包含test1文件夹和train文件夹，train文件夹中包含12500张猫的图片和12500张狗的图片，图片的文件名中带序号：<br><img src="https://img-blog.csdnimg.cn/cdee8a259541497ca443d4a270a07f67.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="2-自定义数据加载"><a href="#2-自定义数据加载" class="headerlink" title="2    自定义数据加载"></a>2    自定义数据加载</h1><p>&emsp;&emsp;实际应用中，样本以及样本标签的存储方式可能各不相同，如有些场合所有的图片存储在同一目录下，类别名可从图片名字中推导出。有些数据集样本的标签信息保存为 JSON 格式的文本文件中，需要按照 JSON 格式查询每个样本的标签。不管数据集是以什么方式存储的，我们总是能够用过逻辑规则获取所有样本的路径和标签信息。</p>
<h2 id="2-1-创建编码表"><a href="#2-1-创建编码表" class="headerlink" title="2.1    创建编码表"></a>2.1    创建编码表</h2><p>&emsp;&emsp;样本的类别一般以字符串类型的类别名标记，但是对于神经网络来说，首先需要将类别名进行数字编码，然后在合适的时候再转换成 One-hot 编码或其他编码格式。考虑𝑛个类 别的数据集，我们将每个类别随机编码为𝑙 ∈ [0, 𝑛 − 1]的数字，类别名与数字的映射关系称编码表，一旦创建后，一般不能变动。<br>&emsp;&emsp;针对猫狗数据集，我用0和1来标注其种类。首先遍历train文件夹得所有子目录(图片)，再以类别名作为字典的键，后以编码表的现有键值对数量作为类别的标签映射数字，并保存至字典对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">root</span>) :</span><br><span class="line">    name2label = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> <span class="built_in">sorted</span>(os.listdir(os.path.join(root))) :</span><br><span class="line">        name = name.split(sep = <span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">not</span> <span class="keyword">in</span> name2label.keys() :</span><br><span class="line">            name2label[name] = <span class="built_in">len</span>(name2label.keys())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> name2label <span class="comment">#out :　&#123;&#x27;cat&#x27;: 0, &#x27;dog&#x27;: 1&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="2-2-创建样本和标签表格"><a href="#2-2-创建样本和标签表格" class="headerlink" title="2.2    创建样本和标签表格"></a>2.2    创建样本和标签表格</h2><p>&emsp;&emsp;编码表确定后，我们需要根据实际数据的存储方式获得每个样本的存储路径以及它的标签数字，最终保存为csv文件，csv文件格式 是一种以逗号为分隔符号的纯文本格式。通过将所有样本信息存储在一个 csv 文件中有诸多好处，比如可以直接进行数据集的划分，可以随机采样 Batch 等。csv 文件中可以保存数据集所有样本的信息，也可以根据训练集、验证集和测试集分别创建 3 个 csv 文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_csv</span>(<span class="params">root, filename, name2label</span>):</span><br><span class="line">    <span class="comment"># 从 csv 文件返回 images,labels 列表</span></span><br><span class="line">    images = []</span><br><span class="line">    <span class="comment"># glob.glob用于返回符合格式的路径</span></span><br><span class="line">    images += glob.glob(os.path.join(root, <span class="string">&#x27;*.png&#x27;</span>))</span><br><span class="line">    images += glob.glob(os.path.join(root, <span class="string">&#x27;*.jpeg&#x27;</span>))</span><br><span class="line">    images += glob.glob(os.path.join(root, <span class="string">&#x27;*.jpg&#x27;</span>))</span><br><span class="line">    <span class="comment"># 随机打乱照片顺序(路径顺序)</span></span><br><span class="line">    random.shuffle(images)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(filename), mode=<span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        writer = csv.writer(file)</span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> images:</span><br><span class="line">            <span class="comment"># 得到照片得种类名字</span></span><br><span class="line">            img = name.split(os.sep)[-<span class="number">1</span>][<span class="number">0</span> : <span class="number">3</span>]</span><br><span class="line">            <span class="built_in">print</span>(img)</span><br><span class="line">            writer.writerow([name, name2label[img]])</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/00d0a46668bf447b90a73daa57ae3ccd.png#pic_center" alt="在这里插入图片描述"><br>创建完 csv 文件后，下一次只需要从 csv 文件中读取样本路径和标签信息即可，而不需要每次都生成 csv 文件，提高计算效率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_csv</span>(<span class="params">filename, name2label</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(filename)) <span class="keyword">as</span> file:</span><br><span class="line">        reader = csv.reader(file)</span><br><span class="line">        images, labels = [], []</span><br><span class="line">        <span class="keyword">for</span> img, label <span class="keyword">in</span> reader:</span><br><span class="line">            images.append(img)</span><br><span class="line">            labels.append(<span class="built_in">int</span>(label))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> images, labels</span><br></pre></td></tr></table></figure>
<h2 id="2-3-数据集划分"><a href="#2-3-数据集划分" class="headerlink" title="2.3    数据集划分"></a>2.3    数据集划分</h2><p>&emsp;&emsp;数据集的划分需要根据实际情况来灵活调整划分比率。当数据集样本数较多时，可以选择 80%-10%-10%的比例分配给训练集、验证集和测试集。这里猫狗的数据集因为训练集和测试集各有12500张且已分开，因此只需要从训练集中划分10% 作为验证集。对于小型的数据集，尽管样本数量较小，但还是需要适当增加验证集和测试集的比例，以保证获得准确的测试结果。<br>&emsp;&emsp;首先调用 load_csv 函数加载 images 和 labels 列表，根据当前模式参数 mode 加载对应部分的图片和标签。具体地，如果模式参数为 train，则分别取 images 和 labels 的前 90%数据作为训练集；如果模式参数为 val，则分别取 images 和 labels 的 90%到 100%区域数据作为验证集。(因为猫狗数据集已经有测试集，所以不再考虑)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_cat_dog</span>(<span class="params">filename, mode = <span class="string">&#x27;train&#x27;</span></span>) :</span><br><span class="line">    images, labels = load_csv(filename, name2label)</span><br><span class="line">    <span class="keyword">if</span> mode == <span class="string">&#x27;val&#x27;</span> :</span><br><span class="line">        images = images[<span class="built_in">int</span>(<span class="built_in">len</span>(images) * <span class="number">0.9</span>) : ]</span><br><span class="line">        labels = labels[<span class="built_in">int</span>(<span class="built_in">len</span>(labels) * <span class="number">0.9</span>) : ]</span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        images = images[ : <span class="built_in">int</span>(<span class="built_in">len</span>(images) * <span class="number">0.9</span>)]</span><br><span class="line">        labels = labels[ : <span class="built_in">int</span>(<span class="built_in">len</span>(labels) * <span class="number">0.9</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">len</span>(images), <span class="built_in">len</span>(labels))</span><br><span class="line">    <span class="keyword">return</span> images, labels</span><br></pre></td></tr></table></figure>
<h1 id="3-PyTorch实现自定义数据集"><a href="#3-PyTorch实现自定义数据集" class="headerlink" title="3    PyTorch实现自定义数据集"></a>3    PyTorch实现自定义数据集</h1><p>&emsp;&emsp;首先我们先回顾一下在线下载MNIST手写数字数据集及训练的大致过程代码过程。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 数据下载</span></span><br><span class="line">dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./mnist/&#x27;</span>,</span><br><span class="line">                                     train=<span class="literal">True</span>,</span><br><span class="line">                                     transform=transform,</span><br><span class="line">                                     download=<span class="literal">True</span>,)</span><br><span class="line"><span class="comment"># 生成可迭代对象</span></span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH):</span><br><span class="line">    <span class="keyword">for</span> i, (image, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>从上面可知，PyTorch中数据传递机制是这样的：</p>
<ul>
<li>创建Dataset</li>
<li>Dataset传递给DataLoader</li>
<li>DataLoader迭代产生训练数据提供给模型</li>
</ul>
<p>&emsp;&emsp;数据集的自定义过程主要体现在创建Dataset过程，编写过程要继承torch.utils.data.Dataset ，该类是一个表示数据集的抽象类。任何自定义的数据集都需要继承这个类。必须要重写getitem(self, index)、 len(self) 两个内建方法，用来表示从索引到样本的映射(Map)，重写之后我们可以直接使用下标来获取想要的数据。我们在使用 torch.utils.data.DataLoader 构建数据集时传入的参数是 images 和 labels 组成的 tuple，因此在对数据对象迭代时，返回的是(𝑿𝑖, 𝒀𝑖)的 tuple 对象，其中𝑿𝑖是第𝑖 个 Batch 的图片张量数据，𝒀𝑖是第𝑖个 Batch 的图片标签数据。代码如下，还是以猫狗数据集为例，且在前面我们已经将训练集和测试集数据保存到 train.csv 和 test.csv 文件(注意测试集和训练集的区别，测试集是没有标签的)中，我这里代码只显示训练集的获取，测试集类似。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为图片大小不一，所以要对图片进行transform</span></span><br><span class="line">transform = transforms.Compose([transforms.Resize(<span class="number">256</span>), <span class="comment"># 重塑大小至256</span></span><br><span class="line">                                transforms.RandomCrop(<span class="number">244</span>),<span class="comment"># 裁剪至244</span></span><br><span class="line">                                transforms.RandomHorizontalFlip(), <span class="comment"># 随机水平翻转</span></span><br><span class="line">                                transforms.ToTensor(), <span class="comment"># 转成张量</span></span><br><span class="line">                                transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])]) <span class="comment"># 标准化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CatVsDog</span>(<span class="title class_ inherited__">Dataset</span>) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filename, mode = <span class="string">&#x27;train&#x27;</span>, transform = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(CatVsDog, self).__init__()</span><br><span class="line">        <span class="comment"># 读取图片及其标签</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(filename)) <span class="keyword">as</span> file:</span><br><span class="line">            reader = csv.reader(file)</span><br><span class="line">            images, labels = [], []</span><br><span class="line">            <span class="keyword">for</span> img, label <span class="keyword">in</span> reader:</span><br><span class="line">                images.append(img)</span><br><span class="line">                labels.append(<span class="built_in">int</span>(label))</span><br><span class="line">        <span class="comment"># 数据划分，90% 作为训练集，10% 作为验证集</span></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;train&#x27;</span> :</span><br><span class="line">            images = images[ : <span class="built_in">int</span>(<span class="built_in">len</span>(images) * <span class="number">0.9</span>)]</span><br><span class="line">            labels = labels[ : <span class="built_in">int</span>(<span class="built_in">len</span>(labels) * <span class="number">0.9</span>)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> mode == <span class="string">&#x27;val&#x27;</span> :</span><br><span class="line">            images = images[<span class="built_in">int</span>(<span class="built_in">len</span>(images) * <span class="number">0.9</span>) : ]</span><br><span class="line">            labels = labels[<span class="built_in">int</span>(<span class="built_in">len</span>(labels) * <span class="number">0.9</span>) : ]</span><br><span class="line"></span><br><span class="line">        self.images, self.labels = images, labels</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        <span class="comment"># 读取图片</span></span><br><span class="line">        image = Image.<span class="built_in">open</span>(os.path.join(self.images[item]))</span><br><span class="line">        <span class="comment"># 转换</span></span><br><span class="line">        <span class="keyword">if</span> self.transform :</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        label = torch.from_numpy(np.array(self.labels[item]))</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.images)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span> :</span><br><span class="line">    train_dataset = CatVsDog(<span class="string">&#x27;train.csv&#x27;</span>, mode = <span class="string">&#x27;train&#x27;</span>, transform = transform)</span><br><span class="line">    val_dataset = CatVsDog(<span class="string">&#x27;train.csv&#x27;</span>, mode = <span class="string">&#x27;val&#x27;</span>, transform = transform)</span><br><span class="line">    <span class="comment"># 返回 batch 的数据对象</span></span><br><span class="line">    train_loader = DataLoader(train_dataset, shuffle = <span class="literal">True</span>, batch_size = <span class="number">64</span>)</span><br><span class="line">    val_loader = DataLoader(val_dataset, shuffle = <span class="literal">False</span>, batch_size = <span class="number">64</span>)</span><br><span class="line">    <span class="comment"># 生成可迭代对象</span></span><br><span class="line">    image_train, label_train = <span class="built_in">iter</span>(train_loader).<span class="built_in">next</span>()</span><br><span class="line">    image_val, label_val = <span class="built_in">iter</span>(val_loader).<span class="built_in">next</span>()</span><br><span class="line">    <span class="comment"># 选择第一张图片</span></span><br><span class="line">    image_train_sample, label_train_sample = image_train[<span class="number">0</span>].squeeze(), label_train[<span class="number">0</span>]</span><br><span class="line">    image_val_sample, label_val_sample = image_val[<span class="number">0</span>].squeeze(), label_val[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 进行轴转化，因为tensor的三通道为(C, H, W)，要转成(H, W, C)</span></span><br><span class="line">    image_train_sample = image_train_sample.permute((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)).numpy()</span><br><span class="line">    image_val_sample = image_val_sample.permute((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)).numpy()</span><br><span class="line">    <span class="comment"># 因为前面以标准差和均值都是0.5标准化了图片，所以要转回来</span></span><br><span class="line">    image_train_sample = image_train_sample * <span class="number">0.5</span></span><br><span class="line">    image_train_sample = image_train_sample + <span class="number">0.5</span></span><br><span class="line">    image_val_sample = image_val_sample * <span class="number">0.5</span></span><br><span class="line">    image_val_sample = image_val_sample + <span class="number">0.5</span></span><br><span class="line">    <span class="comment"># 限制像素值的大小</span></span><br><span class="line">    image_train_sample = np.clip(image_train_sample, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    image_val_sample = np.clip(image_val_sample, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 显示</span></span><br><span class="line">    plt.subplot(<span class="number">121</span>)</span><br><span class="line">    plt.imshow(image_train_sample)</span><br><span class="line">    plt.title(label_train_sample.item())</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">122</span>)</span><br><span class="line">    plt.imshow(image_val_sample)</span><br><span class="line">    plt.title(label_val_sample.item())</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>), plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># def load_data(root) :</span></span><br><span class="line"><span class="comment">#     name2label = &#123;&#125;</span></span><br><span class="line"><span class="comment">#     for name in sorted(os.listdir(os.path.join(root))) :</span></span><br><span class="line"><span class="comment">#         name = name.split(sep = &#x27;.&#x27;)[0]</span></span><br><span class="line"><span class="comment">#         if name not in name2label.keys() :</span></span><br><span class="line"><span class="comment">#             name2label[name] = len(name2label.keys())</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     return name2label #out :　&#123;&#x27;cat&#x27;: 0, &#x27;dog&#x27;: 1&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># def create_csv(root, filename, name2label):</span></span><br><span class="line"><span class="comment">#     # 从 csv 文件返回 images,labels 列表</span></span><br><span class="line"><span class="comment">#     images = []</span></span><br><span class="line"><span class="comment">#     # glob.glob用于返回符合格式的路径</span></span><br><span class="line"><span class="comment">#     images += glob.glob(os.path.join(root, &#x27;*.png&#x27;))</span></span><br><span class="line"><span class="comment">#     images += glob.glob(os.path.join(root, &#x27;*.jpeg&#x27;))</span></span><br><span class="line"><span class="comment">#     images += glob.glob(os.path.join(root, &#x27;*.jpg&#x27;))</span></span><br><span class="line"><span class="comment">#     # 随机打乱照片顺序(路径顺序)</span></span><br><span class="line"><span class="comment">#     random.shuffle(images)</span></span><br><span class="line"><span class="comment">#     with open(os.path.join(filename), mode=&#x27;w&#x27;, newline=&#x27;&#x27;) as file:</span></span><br><span class="line"><span class="comment">#         writer = csv.writer(file)</span></span><br><span class="line"><span class="comment">#         for name in images:</span></span><br><span class="line"><span class="comment">#             # 得到照片得种类名字</span></span><br><span class="line"><span class="comment">#             img = name.split(os.sep)[-1][0 : 3]</span></span><br><span class="line"><span class="comment">#             print(img)</span></span><br><span class="line"><span class="comment">#             writer.writerow([name, name2label[img]])</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># def load_csv(filename, name2label):</span></span><br><span class="line"><span class="comment">#     with open(os.path.join(filename)) as file:</span></span><br><span class="line"><span class="comment">#         reader = csv.reader(file)</span></span><br><span class="line"><span class="comment">#         images, labels = [], []</span></span><br><span class="line"><span class="comment">#         for img, label in reader:</span></span><br><span class="line"><span class="comment">#             images.append(img)</span></span><br><span class="line"><span class="comment">#             labels.append(int(label))</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     return images, labels</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># def load_cat_dog(filename, mode = &#x27;train&#x27;) :</span></span><br><span class="line"><span class="comment">#     images, labels = load_csv(filename, name2label)</span></span><br><span class="line"><span class="comment">#     if mode == &#x27;val&#x27; :</span></span><br><span class="line"><span class="comment">#         images = images[int(len(images) * 0.9) : ]</span></span><br><span class="line"><span class="comment">#         labels = labels[int(len(labels) * 0.9) : ]</span></span><br><span class="line"><span class="comment">#     else :</span></span><br><span class="line"><span class="comment">#         images = images[ : int(len(images) * 0.9)]</span></span><br><span class="line"><span class="comment">#         labels = labels[ : int(len(labels) * 0.9)]</span></span><br><span class="line"><span class="comment">#     print(len(images), len(labels))</span></span><br><span class="line"><span class="comment">#     return images, labels</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># name2label = load_data(&#x27;train&#x27;)</span></span><br><span class="line"><span class="comment"># # print(name2label)</span></span><br><span class="line"><span class="comment"># create_csv(&#x27;train&#x27;, &#x27;train.csv&#x27;, name2label)</span></span><br><span class="line"><span class="comment"># images, labels = load_csv(&#x27;train.csv&#x27;, name2label)</span></span><br><span class="line"><span class="comment"># # load_cat_dog(&#x27;train.csv&#x27;, mode = &#x27;val&#x27;)</span></span><br></pre></td></tr></table></figure>
<p>运行结果：<img src="https://img-blog.csdnimg.cn/4d0a63fd7fb44a47a4c5fb73aa80d30a.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
        <tag>数据集</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Pandas 库教程</title>
    <url>/2022/06/05/Python-Pandas-%E5%BA%93%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;Python有了NumPy的Pandas，用Python处理数据就像使用Exel或SQL一样简单方便。Pandas是基于NumPy的Python 库，它被广泛用于快速分析数据，以及数据清洗和准备等工作。可以把 Pandas 看作是 Python版的Excel或Table。Pandas 有两种数据结构：Series和DataFrame，Pandas经过几个版本的更新，目前已经成为数据清洗、处理和分析的不二选择。</p>
<h1 id="1-Pandas数据结构"><a href="#1-Pandas数据结构" class="headerlink" title="1    Pandas数据结构"></a>1    Pandas数据结构</h1><p>&emsp;&emsp;Pandas主要采用Series和DataFrame两种数据结构。Series是一种类似一维数据的数据结构，由数据(values)及索引(indexs)组成，而DataFrame是一个表格型的数据结构，它有一组序列，每列的数据可以为不同类型（NumPy数据组中数据要求为相同类型）,它既有行索引，也有列索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入相关模块</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">b = np.array([<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">c = np.array([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line"><span class="comment"># 转成 DataFrame 结构</span></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;a&#x27;</span> : a, <span class="string">&#x27;b&#x27;</span> : b, <span class="string">&#x27;c&#x27;</span> : c, <span class="string">&#x27;c&#x27;</span> : c&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/2f7abab6f650412bacf6b5d7d4e08ba3.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="1-1-Series"><a href="#1-1-Series" class="headerlink" title="1.1    Series"></a>1.1    Series</h2><p>&emsp;&emsp;Series是一维带标签的数组，数组里可以放任意的数据(整数，浮点数，字符串， Python Object)。Series的标签索引(它位置索引自然保留)使用起来比 ndarray 方便多了，且定位也更精确，不会产生歧义其基本的创建函数是：</p>
<p><center>s = pd.Series（data， index=index）</center></p>


<ul>
<li>其中index是一个列表，用来作为数据的标签。</li>
<li>data的类型可以是Python字典、ndarray对象、一个标量值，如3等。</li>
</ul>
<h3 id="1-1-1-Series数据操作"><a href="#1-1-1-Series数据操作" class="headerlink" title="1.1.1    Series数据操作"></a>1.1.1    Series数据操作</h3><p><strong>(1) 创建Series</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = pd.Series([<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, -<span class="number">1</span>, <span class="number">2</span>, <span class="number">8</span>])</span><br><span class="line">s</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/6b698613c109455d919a1ca944400f16.png" alt="在这里插入图片描述"><br><strong>(2) Series 索引</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.values       <span class="comment">#显示s1的所有值 out : array([ 1,  3,  6, -1,  2,  8], dtype=int64)</span></span><br><span class="line">s.index        <span class="comment">#显示s1的索引（位置索引或标签索引） out : RangeIndex(start=0, stop=6, step=1)</span></span><br><span class="line">s1 = pd.Series([<span class="number">1</span>, <span class="number">3</span>, <span class="number">6</span>, -<span class="number">1</span>, <span class="number">2</span>, <span class="number">8</span>], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;f&#x27;</span>])  <span class="comment">#定义标签索引</span></span><br><span class="line">s1</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/46730349e1c245e8af2b32239fac095b.png" alt="在这里插入图片描述"><br><strong>(3) 数据访问</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 访问Series中数据的两种方法</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">s1 = pd.Series([ <span class="number">75</span>, <span class="number">90</span>, <span class="number">61</span>],index=[<span class="string">&#x27;张三&#x27;</span>, <span class="string">&#x27;李四&#x27;</span>, <span class="string">&#x27;陈五&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(s1[<span class="number">0</span>])             <span class="comment">#通过元素储存位置访问</span></span><br><span class="line"><span class="built_in">print</span>(s1[<span class="string">&#x27;张三&#x27;</span>])         <span class="comment">#通过指定索引访问</span></span><br><span class="line"><span class="comment"># 结果均为 75</span></span><br></pre></td></tr></table></figure>
<p><strong>(4) 数据修改</strong><br>可以直接通过赋值的方法修改Series中的对应值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改Series中的值</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">s1 = pd.Series([ <span class="number">75</span>, <span class="number">90</span>, <span class="number">61</span>],index=[<span class="string">&#x27;张三&#x27;</span>, <span class="string">&#x27;李四&#x27;</span>, <span class="string">&#x27;陈五&#x27;</span>])</span><br><span class="line">s1[<span class="string">&#x27;张三&#x27;</span>] = <span class="number">60</span>         <span class="comment">#通过指定索引访问</span></span><br><span class="line">s1[<span class="number">1</span>] = <span class="number">60</span>            <span class="comment">#通过元素储存位置访问</span></span><br><span class="line"><span class="built_in">print</span>(s1)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/3549682bb0f74af18a92b8469d6c0b90.png" alt="在这里插入图片描述"><br><strong>(5) 算术运算</strong><br>Pandas会根据索引index索引对相应数据进行计算。如代码所示，可以直接对Series结构进行加减乘除运算符，当出现index不匹配的情况时会输出NaN。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">sr1 = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>])</span><br><span class="line">sr2 = pd.Series([<span class="number">1</span>, <span class="number">5</span>, <span class="number">8</span>, <span class="number">9</span>],[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;e&#x27;</span>,<span class="string">&#x27;f&#x27;</span>])</span><br><span class="line">sr2 - sr1</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/74b6deaa293c4a4f92ba525e32843940.png" alt="在这里插入图片描述"></p>
<h3 id="1-1-2-Series数据分析"><a href="#1-1-2-Series数据分析" class="headerlink" title="1.1.2    Series数据分析"></a>1.1.2    Series数据分析</h3><p><strong>(1) 切片操作</strong><br>数据切片的概念源于Numpy数组，Series对象使用类似NumPy中ndarray的数据访问方法实现切片操作。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Series的切片操作</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">s1 = pd.Series([ <span class="number">75</span>, <span class="number">90</span>, <span class="number">61</span>, <span class="number">59</span>],index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>]) </span><br><span class="line">s1[<span class="number">1</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/47a761f9bfac44458a643dbcd0114c1d.png" alt="在这里插入图片描述"><br><strong>(2) 数据缺失处理</strong><br>Pandas工具包提供了相应处理方法可以轻松实现缺失数据的处理，如下表：<br><img src="https://img-blog.csdnimg.cn/5bb9ae15c81944e18de361076e298d8f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Series填充缺失值</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">s1 = pd.Series([ <span class="number">75</span>, <span class="number">90</span>, np.NaN, <span class="number">59</span>],index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>]) </span><br><span class="line"><span class="comment"># 查看缺失值</span></span><br><span class="line">s1.isnull() </span><br><span class="line"><span class="comment"># a    False</span></span><br><span class="line"><span class="comment"># b    False</span></span><br><span class="line"><span class="comment"># c     True</span></span><br><span class="line"><span class="comment"># d    False</span></span><br><span class="line"><span class="comment"># 删除缺失值</span></span><br><span class="line">s1.dropna()</span><br><span class="line"><span class="comment"># a    75.0</span></span><br><span class="line"><span class="comment"># b    90.0</span></span><br><span class="line"><span class="comment"># d    59.0</span></span><br><span class="line"><span class="comment"># 填充缺失值</span></span><br><span class="line">s1.fillna(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># a    75.0</span></span><br><span class="line"><span class="comment"># b    90.0</span></span><br><span class="line"><span class="comment"># c     0.0</span></span><br><span class="line"><span class="comment"># d    59.0</span></span><br></pre></td></tr></table></figure>
<p><strong>(3) 统计分析</strong><br>Pandas数据分析库提供了强大的数据统计功能，因此通过Series可以非常方便进行数据统计分析。下面是一些常用的Series描述性统计方法。<br><img src="https://img-blog.csdnimg.cn/58c0834348834178b6c721b68d493284.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<h2 id="1-2-DataFrame"><a href="#1-2-DataFrame" class="headerlink" title="1.2    DataFrame"></a>1.2    DataFrame</h2><p>&emsp;&emsp;DataFrame除了索引有位置索引也有标签索引，而且其数据组织方式与MySQL的表极为相似，除了形式相似，很多操作也类似，这就给操作DataFrame带来极大方便。这些是DataFrame特色的一小部分，它还有比数据库表更强大的功能，如强大统计、可视化等等。<br>&emsp;&emsp;DataFrame有几个要素：index、columns、values等，columns就像数据库表的列表，index是索引，values就是值。DataFrame的基本格式是：</p>
<center>df = pd.DataFrame(data， index=index， columns=columns)</center>


<ul>
<li>其中 index是行标签， columns是列标签、</li>
<li>data可以是由一维 numpy数组，list， Series构成的字典、二维 numpy数组、一个 Series、另外的 DataFrame对象</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">####自动生成一个3行4列的DataFrame，并定义其索引（如果不指定，缺省为整数索引）####及列名</span></span><br><span class="line">df = pd.DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">3</span>,<span class="number">4</span>)), columns=[<span class="string">&#x27;a1&#x27;</span>, <span class="string">&#x27;a2&#x27;</span>, <span class="string">&#x27;a3&#x27;</span>, <span class="string">&#x27;a4&#x27;</span>], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/12056e93c8b944dbb839bf78c39975ac.png" alt="在这里插入图片描述"><br>获取一些 DataFrame 结构的属性</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.index     <span class="comment">#显示索引(有标签索引则显示标签索引，否则显示位置索引)</span></span><br><span class="line">df.columns   <span class="comment">##显示列名</span></span><br><span class="line">df.values    <span class="comment">##显示值</span></span><br></pre></td></tr></table></figure>
<h3 id="1-2-1-生成DataFrame"><a href="#1-2-1-生成DataFrame" class="headerlink" title="1.2.1    生成DataFrame"></a>1.2.1    生成DataFrame</h3><p>&emsp;&emsp;生成DataFrame有很多，比较常用的有导入等长列表、字典、numpy数组、数据文件等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data=&#123;<span class="string">&#x27;name&#x27;</span> : [<span class="string">&#x27;zhanghua&#x27;</span>, <span class="string">&#x27;liuting&#x27;</span>, <span class="string">&#x27;gaofei&#x27;</span>, <span class="string">&#x27;hedong&#x27;</span>], <span class="string">&#x27;age&#x27;</span>:[<span class="number">40</span>, <span class="number">45</span>, <span class="number">50</span>, <span class="number">46</span>], <span class="string">&#x27;addr&#x27;</span>: [<span class="string">&#x27;jianxi&#x27;</span>, <span class="string">&#x27;pudong&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="string">&#x27;xian&#x27;</span>]&#125;</span><br><span class="line"> </span><br><span class="line">df = pd.DataFrame(data)</span><br><span class="line"><span class="comment">#改变列的次序</span></span><br><span class="line">df = pd.DataFrame(data, columns=[<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;addr&#x27;</span>], index=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/c74b20dcf7ff4c10925d37777d13b31a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_8,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<h3 id="1-2-2-数据访问"><a href="#1-2-2-数据访问" class="headerlink" title="1.2.2    数据访问"></a>1.2.2    数据访问</h3><p><strong>(1) 使用obj[]来获取列或行</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[[<span class="string">&#x27;name&#x27;</span>]]          <span class="comment">#选取某一列</span></span><br><span class="line">df[[<span class="string">&#x27;name&#x27;</span>, <span class="string">&#x27;age&#x27;</span>]]   <span class="comment">##选择多列</span></span><br><span class="line">df[<span class="string">&#x27;a&#x27;</span> : <span class="string">&#x27;c&#x27;</span>]         <span class="comment">##选择行，包括首位行</span></span><br><span class="line">df[<span class="number">1</span> : <span class="number">3</span>]             <span class="comment">##选择行（利用位置索引），不包括尾行</span></span><br><span class="line">df[df[<span class="string">&#x27;age&#x27;</span>] &gt; <span class="number">40</span>]    <span class="comment">###使用过滤条件</span></span><br></pre></td></tr></table></figure>
<p><strong>(2) 使用obj.loc[] 或obj.iloc[]获取行或列数据*</strong></p>
<ul>
<li>loc通过行标签获取行数据，iloc通过行号获取行数据</li>
<li>loc 在index的标签上进行索引,范围包括start和end.</li>
<li>iloc 在index的位置上进行索引,不包括end.</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd    </span><br><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]   </span><br><span class="line">index = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>]    </span><br><span class="line">columns=[<span class="string">&#x27;c1&#x27;</span>, <span class="string">&#x27;c2&#x27;</span>, <span class="string">&#x27;c3&#x27;</span>]    </span><br><span class="line">df = pd.DataFrame(data = data, index = index, columns = columns)</span><br><span class="line"><span class="comment">###########loc的使用############</span></span><br><span class="line">df.loc[[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>]]              <span class="comment">#通过行标签获取行数据</span></span><br><span class="line">df.loc[[<span class="string">&#x27;a&#x27;</span>],[<span class="string">&#x27;c1&#x27;</span>,<span class="string">&#x27;c3&#x27;</span>]]      <span class="comment">#通过行标签、列名称获取行列数据</span></span><br><span class="line">df.loc[[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>],[<span class="string">&#x27;c1&#x27;</span>,<span class="string">&#x27;c3&#x27;</span>]]  <span class="comment">#通过行标签、列名称获取行列数据</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#########iloc的使用###############</span></span><br><span class="line">df.iloc[<span class="number">1</span>]                     <span class="comment">#通过行号获取行数据</span></span><br><span class="line">df.iloc[<span class="number">0</span>:<span class="number">2</span>]                   <span class="comment">#通过行号获取行数据，不包括索引2的值</span></span><br><span class="line">df.iloc[<span class="number">1</span>:,<span class="number">1</span>]                  <span class="comment">##通过行号、列行获取行、列数据</span></span><br><span class="line">df.iloc[<span class="number">1</span>:,[<span class="number">1</span>,<span class="number">2</span>]]              <span class="comment">##通过行号、列行获取行、列数据</span></span><br><span class="line">df.iloc[<span class="number">1</span>:,<span class="number">1</span>:<span class="number">3</span>]                <span class="comment">##通过行号、列行获取行、列数据</span></span><br></pre></td></tr></table></figure>
<h3 id="1-2-3-数据修改"><a href="#1-2-3-数据修改" class="headerlink" title="1.2.3    数据修改"></a>1.2.3    数据修改</h3><p>&emsp;&emsp;我们可以像操作数据库表一样操作DataFrame，删除数据、插入数据、修改字段名、索引名、修改数据等，以下通过一些实例来说明。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data=&#123;<span class="string">&#x27;name&#x27;</span> : [<span class="string">&#x27;zhanghua&#x27;</span>, <span class="string">&#x27;liuting&#x27;</span>, <span class="string">&#x27;gaofei&#x27;</span>, <span class="string">&#x27;hedong&#x27;</span>], <span class="string">&#x27;age&#x27;</span>:[<span class="number">40</span>, <span class="number">45</span>, <span class="number">50</span>, <span class="number">46</span>], <span class="string">&#x27;addr&#x27;</span>: [<span class="string">&#x27;jianxi&#x27;</span>, <span class="string">&#x27;pudong&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="string">&#x27;xian&#x27;</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data, index = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/62e3b3bb0ee94856a6702c7e006167a8.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data=&#123;<span class="string">&#x27;name&#x27;</span> : [<span class="string">&#x27;zhanghua&#x27;</span>, <span class="string">&#x27;liuting&#x27;</span>, <span class="string">&#x27;gaofei&#x27;</span>, <span class="string">&#x27;hedong&#x27;</span>], <span class="string">&#x27;age&#x27;</span>:[<span class="number">40</span>, <span class="number">45</span>, <span class="number">50</span>, <span class="number">46</span>], <span class="string">&#x27;addr&#x27;</span>: [<span class="string">&#x27;jianxi&#x27;</span>, <span class="string">&#x27;pudong&#x27;</span>, <span class="string">&#x27;beijing&#x27;</span>, <span class="string">&#x27;xian&#x27;</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data, index = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line">df.drop(<span class="string">&#x27;d&#x27;</span>, axis = <span class="number">0</span>)<span class="comment">###删除行，如果欲删除列，使axis=1即可</span></span><br><span class="line">df  <span class="comment">###从副本中删除，原数据没有被删除</span></span><br><span class="line">df.drop(<span class="string">&#x27;addr&#x27;</span>, axis = <span class="number">1</span>)   <span class="comment">###删除第addr列</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># ###添加一行，注意需要ignore_index=True，否则会报错</span></span><br><span class="line">df.append(&#123;<span class="string">&#x27;name&#x27;</span> : <span class="string">&#x27;wangkuan&#x27;</span>, <span class="string">&#x27;age&#x27;</span> : <span class="number">38</span>, <span class="string">&#x27;addr&#x27;</span> : <span class="string">&#x27;henan&#x27;</span>&#125;, ignore_index = <span class="literal">True</span>)</span><br><span class="line">df  <span class="comment">###原数据未变</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># ###添加一行，并创建一个新DataFrame</span></span><br><span class="line">df = df.append(&#123;<span class="string">&#x27;name&#x27;</span> : <span class="string">&#x27;wangkuan&#x27;</span>, <span class="string">&#x27;age&#x27;</span> : <span class="number">38</span>, <span class="string">&#x27;addr&#x27;</span> : <span class="string">&#x27;henan&#x27;</span>&#125;, ignore_index = <span class="literal">True</span>)</span><br><span class="line">df.index=[<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>,<span class="string">&#x27;c&#x27;</span>,<span class="string">&#x27;d&#x27;</span>,<span class="string">&#x27;e&#x27;</span>] <span class="comment">###修改d4的索引</span></span><br><span class="line">df</span><br><span class="line">df.loc[<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;age&#x27;</span>] = <span class="number">39</span>  <span class="comment">###修改索引为e列名为age的值</span></span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<h3 id="1-2-4-缺失值处理"><a href="#1-2-4-缺失值处理" class="headerlink" title="1.2.4    缺失值处理"></a>1.2.4    缺失值处理</h3><p>&emsp;&emsp;与Series数据结构一样Pandas提供了3种方法用于处理数据集中的缺失值。<br> <img src="https://img-blog.csdnimg.cn/c63dfd34e2764aebabf77fdb66faa74d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zyo5Y2X5pa55YaN5LiK5LiA5bGC5qW8,size_15,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br><strong>(1) dropna</strong><br>dropna默认丢弃任何含有缺失值的行，因此如果需要丢弃任何含有缺失的列，只需传入axis=1即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = &#123;<span class="string">&#x27;one&#x27;</span> : [<span class="number">1</span>, <span class="number">2</span>, np.nan, <span class="number">3</span>], <span class="string">&#x27;two&#x27;</span> : [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>], <span class="string">&#x27;three&#x27;</span> : [<span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data, index = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;e&#x27;</span>])</span><br><span class="line">df.dropna(axis = <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/4ec4c77a8ea54f36ba457f733b7515fe.png" alt="在这里插入图片描述"><br><strong>(2) fillna</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = &#123;<span class="string">&#x27;one&#x27;</span> : [<span class="number">1</span>, <span class="number">2</span>, np.nan, <span class="number">3</span>], <span class="string">&#x27;two&#x27;</span> : [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>], <span class="string">&#x27;three&#x27;</span> : [<span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]&#125;</span><br><span class="line">df = pd.DataFrame(data, index = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>])</span><br><span class="line"><span class="comment"># 直接替换缺失值</span></span><br><span class="line">df.fillna(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 使用字典方式且使用缺失值那列的平均数替换</span></span><br><span class="line">trans = &#123;<span class="string">&#x27;one&#x27;</span> : df[<span class="string">&#x27;one&#x27;</span>].mean()&#125;</span><br><span class="line">df.fillna(trans, inplace = <span class="literal">True</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20439d00f8ec4552927bb94065277e79.png" alt="在这里插入图片描述"></p>
<h3 id="1-2-5-Pandas的三板斧"><a href="#1-2-5-Pandas的三板斧" class="headerlink" title="1.2.5    Pandas的三板斧"></a>1.2.5    Pandas的三板斧</h3><p>&emsp;&emsp;我们知道数据库中有很多函数可用作用于表中元素，DataFrame也可将函数(内置或自定义)应用到各列或行上，而且非常方便和简洁，具体可用通过DataFrame的apply、applymap和map来实现，其中apply、map对数据集中的每列或每行的逐元操作，applymap对dataframe的每个元素进行操作，这些函数是数据处理的强大工具。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = DataFrame(np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>, <span class="number">4</span>), columns = [<span class="string">&#x27;a1&#x27;</span>, <span class="string">&#x27;a2&#x27;</span>, <span class="string">&#x27;a3&#x27;</span>, <span class="string">&#x27;a4&#x27;</span>], index = [<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">df</span><br><span class="line">df.apply(<span class="keyword">lambda</span> x : x.<span class="built_in">max</span>() - x.<span class="built_in">min</span>(), axis = <span class="number">0</span>) <span class="comment">###列级处理，每列的最大值减去最小值</span></span><br><span class="line">df.apply(<span class="keyword">lambda</span> x : x * <span class="number">2</span>) <span class="comment">###每个元素乘2</span></span><br><span class="line">df.iloc[<span class="number">1</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> x : x * <span class="number">2</span>) <span class="comment">###d第二行的每个元素乘2</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/4d790627b6a94201bb695fea041d9a42.png" alt="在这里插入图片描述"></p>
<h3 id="1-2-6-处理时间序列"><a href="#1-2-6-处理时间序列" class="headerlink" title="1.2.6    处理时间序列"></a>1.2.6    处理时间序列</h3><p>&emsp;&emsp;pandas最基本的时间序列类型就是以时间戳(时间点)(通常以python字符串或datetime对象表示)为索引的Series</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dates = [<span class="string">&#x27;2022-02-05&#x27;</span>, <span class="string">&#x27;2022-02-06&#x27;</span>, <span class="string">&#x27;2022-02-07&#x27;</span>, <span class="string">&#x27;2022-02-08&#x27;</span>, <span class="string">&#x27;2022-02-09&#x27;</span>]</span><br><span class="line">ts = pd.Series(np.random.randn(<span class="number">5</span>), index = pd.to_datetime(dates))</span><br><span class="line">ts</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/1b2f6d1c6ed04f5b8a077c13f616ad3d.png" alt="在这里插入图片描述"><br>索引为日期的DataFrame数据的索引、选取以及子集构造</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ts.index</span><br><span class="line"><span class="comment">#传入可以被解析成日期的字符串</span></span><br><span class="line">ts[<span class="string">&#x27;2022-02-05&#x27;</span>]</span><br><span class="line"><span class="comment">#传入年或年月</span></span><br><span class="line">ts[<span class="string">&#x27;2022-02&#x27;</span>]</span><br><span class="line"><span class="comment">#时间范围进行切片</span></span><br><span class="line">ts[<span class="string">&#x27;2022-02-07&#x27;</span>: <span class="string">&#x27;2022-02-09&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/87bbebce123b4aea978acfe23582c615.png" alt="在这里插入图片描述"></p>
<h3 id="1-2-7-数据离散化"><a href="#1-2-7-数据离散化" class="headerlink" title="1.2.7    数据离散化"></a>1.2.7    数据离散化</h3><p>&emsp;&emsp;如何离散化连续性数据？在一般开发语言中，可以通过控制语句来实现，但如果分类较多时，这种方法不但繁琐，效率也比较低。在Pandas中现成方法，如cut或qcut等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = DataFrame(&#123;<span class="string">&#x27;age&#x27;</span> : [<span class="number">21</span>, <span class="number">25</span>, <span class="number">30</span>, <span class="number">32</span>, <span class="number">36</span>, <span class="number">40</span>, <span class="number">45</span>, <span class="number">50</span>], <span class="string">&#x27;type&#x27;</span> : [<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;2&#x27;</span>]&#125;, columns = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;type&#x27;</span>])</span><br><span class="line">df</span><br><span class="line"><span class="comment">###现在需要对age字段进行离散化, 划分为(20,30],(30,40],(40,50].</span></span><br><span class="line">level = [<span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>] <span class="comment">###划分为(20,30],(30,40],(40,50]</span></span><br><span class="line">groups = [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>]</span><br><span class="line">df[<span class="string">&#x27;age_groups&#x27;</span>] = pd.cut(df[<span class="string">&#x27;age&#x27;</span>], level, labels = groups) <span class="comment">###增加新的列age_groups</span></span><br><span class="line">df1 = df[df.columns]</span><br><span class="line">df1</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/ec26bd9c35224a3a957eaf6dc2a8f449.png" alt="在这里插入图片描述"></p>
<h3 id="1-2-8-交叉表"><a href="#1-2-8-交叉表" class="headerlink" title="1.2.8    交叉表"></a>1.2.8    交叉表</h3><p>我们平常看到的数据格式大多像数据库中的表，如购买图书的基本信息：<br><img src="https://img-blog.csdnimg.cn/bb347d7d29c5410ca9b731b5fef279ec.png#pic_center" alt="在这里插入图片描述"><br>这样的数据比较规范，比较适合于一般的统计分析。但如果我们想查看客户购买各种书的统计信息，就需要把以上数据转换为如下格式：<br><img src="https://img-blog.csdnimg.cn/f6f59ac390f64c92a6f4d2d1e08c6097.png#pic_center" alt="在这里插入图片描述"><br>不难发现要想转换成交叉表只需将信息表的行和列进行旋转即可得到</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df=DataFrame(&#123;<span class="string">&#x27;书代码&#x27;</span> : [<span class="string">&#x27;p211&#x27;</span>, <span class="string">&#x27;p211&#x27;</span>, <span class="string">&#x27;sp2&#x27;</span>, <span class="string">&#x27;sp2&#x27;</span>, <span class="string">&#x27;hd28&#x27;</span>, <span class="string">&#x27;hd28&#x27;</span>], <span class="string">&#x27;客户类型&#x27;</span> : [<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;C&#x27;</span>], <span class="string">&#x27;购买量&#x27;</span> : [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">10</span>, <span class="number">1</span>]&#125;, columns = [<span class="string">&#x27;书代码&#x27;</span>, <span class="string">&#x27;客户类型&#x27;</span>, <span class="string">&#x27;购买量&#x27;</span>])</span><br><span class="line"><span class="comment">###转换后，出现一些NaN值或空值，我们可以把NaN修改为0</span></span><br><span class="line">df1 = pd.pivot_table(df, values = <span class="string">&#x27;购买量&#x27;</span>, index = <span class="string">&#x27;客户类型&#x27;</span>, columns = <span class="string">&#x27;书代码&#x27;</span>, fill_value = <span class="number">0</span>)</span><br><span class="line">df1</span><br></pre></td></tr></table></figure>
<h1 id="2-实例分析"><a href="#2-实例分析" class="headerlink" title="2    实例分析"></a>2    实例分析</h1><p><strong>(1) 把csv数据导入pandas</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame                  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np                            </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd             </span><br><span class="line"></span><br><span class="line">path = <span class="string">&#x27;pandas-data/stud_score.csv&#x27;</span></span><br><span class="line">data = pd.read_csv(path, encoding = <span class="string">&#x27;gbk&#x27;</span>) <span class="comment">#要修改编码方式，否则中文不能正常显示</span></span><br><span class="line"><span class="comment">#其他参数：</span></span><br><span class="line"><span class="comment">###header=None 表示无标题,此时缺省列名为整数；如果设为0，表示第0行为标题</span></span><br><span class="line"><span class="comment">###names，encoding，skiprows等，skiprows较为常用，用来删除第一行</span></span><br><span class="line"><span class="comment">#读取excel文件，可用 read_excel</span></span><br><span class="line">df = DataFrame(data)</span><br><span class="line">df.head() <span class="comment">###显示前5行</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/95cec7a6fd2e4df7bd427d52348e09ea.png#pic_center" alt="在这里插入图片描述"><br><strong>(2) 查看df的统计信息</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.count()  <span class="comment">#统计非NaN行数</span></span><br><span class="line">df.info()   <span class="comment">#查看数据的缺失情况</span></span><br><span class="line">df.describe() <span class="comment">##各列的数据情况</span></span><br><span class="line">df[<span class="string">&#x27;sub_score&#x27;</span>].std()     <span class="comment">##求学生成绩的标准差</span></span><br><span class="line">df[<span class="string">&#x27;sub_score&#x27;</span>].var()     <span class="comment">##求学生成绩的方差</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/f8136c0350ef41c0a1849f82cafc5416.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/4f973a28e5d54c12a1034a852293f21d.png#pic_center" alt="在这里插入图片描述"><br><strong>(3) 选择部分列</strong><br>因为在现实数据中，常常存在着大量冗余数据，本次的例子中第四列就是冗余的，因此这里选择学生代码、课程代码、课程名称、程程成绩，注册日期列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#根据列的索引来选择</span></span><br><span class="line">df.iloc[ : , [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>]]    </span><br><span class="line"><span class="comment">#或根据列名称来选择</span></span><br><span class="line">df = df.loc[ : ,[<span class="string">&#x27;stud_code&#x27;</span>, <span class="string">&#x27;sub_code&#x27;</span>, <span class="string">&#x27;sub_name&#x27;</span>, <span class="string">&#x27;sub_score&#x27;</span>, <span class="string">&#x27;stat_date&#x27;</span>]]</span><br></pre></td></tr></table></figure>
<p><strong>(4) 补充缺省值</strong><br><strong><em>a</em></strong>.用指定值补充NaN值,这里要求把stat_date的缺省值（NaN）改为’2022-2-8’</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df1 = df.fillna(&#123;<span class="string">&#x27;stat_date&#x27;</span> : <span class="string">&#x27;2022-2-8&#x27;</span>&#125;)</span><br><span class="line">df1.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/5d23d86b8c9a4b09b4daad8d5cea2231.png#pic_center" alt="在这里插入图片描述"><br><strong><em>b.</em></strong> 可视化前五名学生的成绩</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties </span><br><span class="line">%matplotlib</span><br><span class="line"></span><br><span class="line">df2 = df1.loc[ : , [<span class="string">&#x27;sub_name&#x27;</span>, <span class="string">&#x27;sub_score&#x27;</span>]].head(<span class="number">5</span>)</span><br><span class="line"><span class="comment">#设置字体类型及大小</span></span><br><span class="line">font = FontProperties(fname = <span class="string">r&quot;c:\windows\fonts\simkai.ttf&quot;</span>, size=<span class="number">14</span>) </span><br><span class="line"><span class="comment">#设置画布大小</span></span><br><span class="line">plt.figure(figsize = (<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">x = np.arange(<span class="number">5</span>)</span><br><span class="line">y = np.array(df2[<span class="string">&#x27;sub_score&#x27;</span>])</span><br><span class="line">xticks = <span class="built_in">list</span>(df2[<span class="string">&#x27;sub_name&#x27;</span>])</span><br><span class="line"><span class="comment">#画柱状图，两柱之间相差距离为0.35</span></span><br><span class="line">plt.bar(x, y, align = <span class="string">&#x27;center&#x27;</span>, width = <span class="number">0.35</span>, color = <span class="string">&#x27;b&#x27;</span>, alpha = <span class="number">0.8</span>)</span><br><span class="line"><span class="comment">#设置横纵坐标标签及主题</span></span><br><span class="line">plt.xticks(x, xticks, fontproperties = font)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;课程类别&#x27;</span>, fontproperties = font)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;成绩&#x27;</span>, fontproperties = font)</span><br><span class="line">plt.title(<span class="string">&#x27;不同课程的成绩&#x27;</span>, fontproperties = font)</span><br><span class="line"><span class="comment">#设置数字标签</span></span><br><span class="line"><span class="keyword">for</span> a, b <span class="keyword">in</span> <span class="built_in">zip</span>(x, y):</span><br><span class="line">    plt.text(a, b + <span class="number">0.05</span>, <span class="string">f&#x27;<span class="subst">&#123;b : <span class="number">0.1</span>f&#125;</span>&#x27;</span>, ha = <span class="string">&#x27;center&#x27;</span>, va = <span class="string">&#x27;bottom&#x27;</span>, fontsize = <span class="number">14</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">100</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/b8dea4c0431c477aa9412c9a697f9a97.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Numpy 库教程</title>
    <url>/2022/06/05/Python-Numpy-%E5%BA%93%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="1-Numpy概述"><a href="#1-Numpy概述" class="headerlink" title="1    Numpy概述"></a>1    Numpy概述</h1><h2 id="1-1-概念"><a href="#1-1-概念" class="headerlink" title="1.1    概念"></a>1.1    概念</h2><p>&emsp;&emsp;Python本身含有列表和数组，但对于大数据来说，这些结构是有很多不足的。由于列表的元素可以是任何对象，因此列表中所保存的是对象的指针。对于数值运算来说这种    结构比较浪费内存和CPU资源。至于数组对象，它可以直接保存 数值，和C语言的一维数组比较类似。但是由于它不支持多维，在上面的函数也不多，因此也不适合做数值运算。Numpy提供了两种基本的对象：ndarray(N-dimensional Array Object)和 ufunc(Universal Function Object)。ndarray是存储单一数据类型的多维数组，而ufunc则是能够对数组进行处理的函数。</p>
<h2 id="1-2-功能"><a href="#1-2-功能" class="headerlink" title="1.2    功能"></a>1.2    功能</h2><ul>
<li>创建n维数组(矩阵)</li>
<li>对数组进行函数运算，使用函数计算十分快速，节省了大量的时间，且不需要编写循环，十分方便</li>
<li>数值积分、线性代数运算、傅里叶变换</li>
<li>ndarray快速节省空间的多维数组，提供数组化的算术运算和高级的 广播功能。</li>
</ul>
<h2 id="1-3-对象"><a href="#1-3-对象" class="headerlink" title="1.3    对象"></a>1.3    对象</h2><ul>
<li>NumPy中的核心对象是ndarray</li>
<li>ndarray可以看成数组，存放<strong>同类元素</strong></li>
<li>NumPy里面所有的函数都是围绕ndarray展开的<br><img src="https://img-blog.csdnimg.cn/0da1aaff2da046bf8c2896e88bc351ea.png#pic_center" alt="在这里插入图片描述"></li>
<li>ndarray 内部由以下内容组成：<ul>
<li>一个指向数据(内存或内存映射文件中的一块数据)的指针。</li>
<li>数据类型或 dtype，描述在数组中的固定大小值的格子。</li>
<li>一个表示数组形状(shape)的元组，表示各维度大小的元组。形状为(row×col)。</li>
</ul>
</li>
</ul>
<h2 id="1-4-数据类型"><a href="#1-4-数据类型" class="headerlink" title="1.4    数据类型"></a>1.4    数据类型</h2><p>&emsp;&emsp;numpy 支持的数据类型比 Python 内置的类型要多很多，基本上可以和C语言的数据类型对应上主要包括int8、int16、int32、int64、uint8、uint16、uint32、uint64、float16、float32、float64</p>
<h2 id="1-5-数组属性"><a href="#1-5-数组属性" class="headerlink" title="1.5    数组属性"></a>1.5    数组属性</h2><div class="table-container">
<table>
<thead>
<tr>
<th>属性</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>ndarray.ndim</td>
<td>秩，即轴的数量或维度的数量</td>
</tr>
<tr>
<td>ndarray.shape</td>
<td>数组的维度(n×m)，对于矩阵，n 行 m 列</td>
</tr>
<tr>
<td>ndarray.size</td>
<td>数组元素的总个数，相当于 .shape 中 n*m 的值</td>
</tr>
<tr>
<td>ndarray.dtype</td>
<td>ndarray 对象的元素类型</td>
</tr>
<tr>
<td>ndarray.itemsize</td>
<td>ndarray 对象中每个元素的大小，以字节为单位</td>
</tr>
<tr>
<td>ndarray.flags</td>
<td>ndarray 对象的内存信息</td>
</tr>
<tr>
<td>ndarray.real</td>
<td>ndarray元素的实部</td>
</tr>
<tr>
<td>ndarray.imag</td>
<td>ndarray元素的虚部</td>
</tr>
<tr>
<td>ndarray.data</td>
<td>包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性。</td>
</tr>
</tbody>
</table>
</div>
<h1 id="2-Numpy数组操作"><a href="#2-Numpy数组操作" class="headerlink" title="2    Numpy数组操作"></a>2    Numpy数组操作</h1><h2 id="2-1-Numpy创建"><a href="#2-1-Numpy创建" class="headerlink" title="2.1    Numpy创建"></a>2.1    Numpy创建</h2><h3 id="2-1-1-利用列表生成数组"><a href="#2-1-1-利用列表生成数组" class="headerlink" title="2.1.1    利用列表生成数组"></a>2.1.1    利用列表生成数组</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">lst = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">nd1 = np.array(lst)</span><br><span class="line"><span class="built_in">print</span>(nd1, <span class="built_in">type</span>(nd1))</span><br><span class="line"><span class="comment">#[1 2 3 4] &lt;class &#x27;numpy.ndarray&#x27;&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-1-2-利用random模块生成数组"><a href="#2-1-2-利用random模块生成数组" class="headerlink" title="2.1.2    利用random模块生成数组"></a>2.1.2    利用random模块生成数组</h3><p>下面是random模块的一些常用函数<br><img src="https://img-blog.csdnimg.cn/d4ae670c6f3c43b58e79ea916bbe309d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAYWlzaGFuZ2Nlbmdsb3Vh,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>使用如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#0到1标准正态分布</span></span><br><span class="line">arr1 = np.random.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment">#0到1均匀分布</span></span><br><span class="line">arr2 = np.random.rand(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment">#均匀分布的随机数（浮点数），前两个参数表示随机数的范围，第三个表示生成随机数的个数</span></span><br><span class="line">arr3 = np.random.uniform(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment">#均匀分布的随机数（整数），前两个参数表示随机数的范围，第三个表示生成随机数的个数</span></span><br><span class="line">arr4 = np.random.randint(<span class="number">0</span>, <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;arr1 : <span class="subst">&#123;arr1&#125;</span>\narr2 : <span class="subst">&#123;arr2&#125;</span>\narr3 : <span class="subst">&#123;arr3&#125;</span>\narr4 : <span class="subst">&#123;arr4&#125;</span>&#x27;</span>)</span><br><span class="line">out : </span><br><span class="line"><span class="comment"># arr1 : [[-0.31637952 -0.08258995  1.43866984]</span></span><br><span class="line"><span class="comment">#  [-0.11216775  0.43881134  0.11745847]</span></span><br><span class="line"><span class="comment">#  [-1.1770306  -0.97657465  2.2368878 ]]</span></span><br><span class="line"><span class="comment"># arr2 : [[0.16350611 0.4467384  0.9465067 ]</span></span><br><span class="line"><span class="comment">#  [0.1882318  0.40261184 0.93577701]</span></span><br><span class="line"><span class="comment">#  [0.56243911 0.69179631 0.83407725]]</span></span><br><span class="line"><span class="comment"># arr3 : [4.41402883 6.03259052]</span></span><br><span class="line"><span class="comment"># arr4 : [9 7 7]</span></span><br></pre></td></tr></table></figure>
<p>如果想使每次生成的数据相同，可以指定一个随机种子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">123</span>)</span><br><span class="line">arr = np.random.rand(<span class="number">2</span>, <span class="number">3</span>)<span class="comment">#[[0.69646919 0.28613933 0.22685145] [0.55131477 0.71946897 0.42310646]]</span></span><br><span class="line"><span class="comment">#打乱数组</span></span><br><span class="line">np.random.shuffle(arr)<span class="comment">#[[0.55131477 0.71946897 0.42310646] [0.69646919 0.28613933 0.22685145]]</span></span><br></pre></td></tr></table></figure>
<h3 id="2-1-3-创建特定形状数组"><a href="#2-1-3-创建特定形状数组" class="headerlink" title="2.1.3    创建特定形状数组"></a>2.1.3    创建特定形状数组</h3><p>主要有如下几种：<br><img src="https://img-blog.csdnimg.cn/9004347860b34573ada67ef10559bab4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAYWlzaGFuZ2Nlbmdsb3Vh,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#未初始化的数组</span></span><br><span class="line">arr1 = np.empty((<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line"><span class="comment">#数组元素以 0 来填充</span></span><br><span class="line">arr2 = np.zeros((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment">#数组元素以 1 来填充</span></span><br><span class="line">arr3 = np.ones((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment">#数组以指定的数来进行填充，这里举例3</span></span><br><span class="line">arr4 = np.full((<span class="number">2</span>, <span class="number">3</span>), <span class="number">3</span>)</span><br><span class="line"><span class="comment">#生成单位，对角线上元素为 1，其他为0</span></span><br><span class="line">arr5 = np.eye(<span class="number">2</span>)</span><br><span class="line"><span class="comment">#二维矩阵输出矩阵对角线的元素，一维矩阵形成一个以一维数组为对角线元素的矩阵</span></span><br><span class="line">arr6 = np.diag(np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]))</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;在创建给定长度的等差数列时，要注意的是np.linspace形成的数组一定包括范围的首位两个元素，则步长为(end - start) / (length - 1)。而np.arange是自己指定的步长(默认为1)也就意味着形成的数组不一定包括末尾数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr7 = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>) <span class="comment">#out : array([0.        , 0.33333333, 0.66666667, 1.        ])</span></span><br><span class="line">arr8 = np.arange(<span class="number">0</span>, <span class="number">9</span>, <span class="number">2</span>) <span class="comment">#out : array([0, 2, 4, 6, 8])</span></span><br></pre></td></tr></table></figure>
<h2 id="2-2-索引和切片"><a href="#2-2-索引和切片" class="headerlink" title="2.2    索引和切片"></a>2.2    索引和切片</h2><p>&emsp;&emsp;Numpy可以通过索引或切片来访问和修改，与 Python 中 list 的切片操作一样，设置start, stop 及 step 参数。</p>
<h3 id="2-2-1-元素表示"><a href="#2-2-1-元素表示" class="headerlink" title="2.2.1    元素表示"></a>2.2.1    元素表示</h3><p>&emsp;&emsp;Numpy数组的下标表示与list是一样的，对于矩阵来说，要注意中括号里要用逗号将行和列的表示进行分隔。基本的表示方法如下图，左边为表达式，右边为表达式获取的元 素。注意，不同的边界，表示不同的表达式。<br><img src="https://img-blog.csdnimg.cn/39e56a70c178467981715909b9900c59.png#pic_center" alt="在这里插入图片描述"><br>例子：<br>a = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])<br>a[0] : 指的是第一行<br>a[1, 2] 或者 a[1][2] :  全下标定位单个元素，在a中表示7这个元素</p>
<h3 id="2-2-2-切片表示"><a href="#2-2-2-切片表示" class="headerlink" title="2.2.2    切片表示"></a>2.2.2    切片表示</h3><p>&emsp;&emsp;若a = np.arange(10)，b = a[2 : 7 : 2]则表示从索引 2 开始到索引 7 停止，间隔为 2，即b为[2, 4, 6]。此外也可以通过切片操作来对元素进行修改，如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line">a[<span class="number">0</span> , <span class="number">1</span> : <span class="number">3</span>] = <span class="number">100</span>, <span class="number">101</span><span class="comment">#a[0 , 1 : 3]表示第一行的第二列和第二列即[2, 3]</span></span><br><span class="line">a <span class="comment">#out : array([[  1, 100, 101], [  4,   5,   6], [  7,   8,   9]])</span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-3-多维数组的切片"><a href="#2-2-3-多维数组的切片" class="headerlink" title="2.2.3    多维数组的切片"></a>2.2.3    多维数组的切片</h3><p>&emsp;&emsp;NumPy的多维数组和一维数组类似。多维数组有多个轴。从内到外分别是第0轴，第1轴，第2轴……切片后的数据与切片前的数据共享原数组的储存空间<br><img src="https://img-blog.csdnimg.cn/2bbc116566a343ceb4e630d257824193.png#pic_center" alt="在这里插入图片描述"><br>当然，切片操作是针对我们想要获取的数据是连续的，如果我们想要获取离散数据就不能使用切片的方法，再者就是我们不能一个一个来进行提取，Numpy有一种很方便的方法可以获得离散数据。即下面</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[ <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],[ <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],[ <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],[ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]]) </span><br><span class="line">rows = np.array( [ [<span class="number">0</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">3</span>] ] ) <span class="comment">#表示第1、4行</span></span><br><span class="line">cols = np.array( [ [<span class="number">0</span>,<span class="number">2</span>],[<span class="number">0</span>,<span class="number">2</span>] ] ) <span class="comment">#表示第1、3列</span></span><br><span class="line">y = x[rows,cols]</span><br><span class="line">y <span class="comment"># out : array([[ 0,  2], [ 9, 11]])</span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-4-布尔索引"><a href="#2-2-4-布尔索引" class="headerlink" title="2.2.4    布尔索引"></a>2.2.4    布尔索引</h3><p>&emsp;&emsp;顾名思义，通过布尔运算（如：比较运算符）来获取符合指定条件的元素的数组。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([[ <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],[ <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],[ <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],[ <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>]]) </span><br><span class="line"><span class="built_in">print</span>(x[x &gt; <span class="number">5</span>]) <span class="comment"># out : [ 6  7  8  9 10 11]</span></span><br><span class="line">b = x &gt; <span class="number">5</span></span><br><span class="line">b <span class="comment"># 打印布尔运算的结果</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/e5abf4ccec1047b98a07c78373649fa3.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-2-5-元素查找定位"><a href="#2-2-5-元素查找定位" class="headerlink" title="2.2.5    元素查找定位"></a>2.2.5    元素查找定位</h3><p>&emsp;&emsp;Numpy库中提供了where函数来查找满足条件元素的索引，表示如下：</p>
<ul>
<li>np.where(condition, x, y): 满足条件(condition)，输出x，不满足输出y</li>
<li>np.where(condition): 输出满足条件 (即非0) 元素的坐标</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">10</span>,<span class="number">3</span>]).reshape(<span class="number">2</span>,<span class="number">3</span>) </span><br><span class="line">c = np.where(a &gt; <span class="number">5</span>) <span class="comment"># 返回索引 out : (array([0, 1, 1], dtype=int64), array([2, 0, 1], dtype=int64))</span></span><br><span class="line">a[c] <span class="comment"># 获得元素</span></span><br></pre></td></tr></table></figure>
<h3 id="2-2-6-元素删除"><a href="#2-2-6-元素删除" class="headerlink" title="2.2.6    元素删除"></a>2.2.6    元素删除</h3><p>np.delete(arr, obj, axis=None)</p>
<ul>
<li>第一个参数：要处理的矩阵，</li>
<li>第二个参数，处理的位置，下标</li>
<li>第三个参数，0表示按照行删除，1表示按照列删除，默认为0</li>
<li>返回值为删除后的剩余元素构成的矩阵</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">np.delete(arr, [<span class="number">1</span>], <span class="number">0</span>) <span class="comment"># 表示删除第二行</span></span><br></pre></td></tr></table></figure>
<h2 id="2-3-Numpy数组的拼接和分割"><a href="#2-3-Numpy数组的拼接和分割" class="headerlink" title="2.3    Numpy数组的拼接和分割"></a>2.3    Numpy数组的拼接和分割</h2><h3 id="2-3-1-拼接"><a href="#2-3-1-拼接" class="headerlink" title="2.3.1    拼接"></a>2.3.1    拼接</h3><p>下面的图列举了常见的用于数组或向量 合并的方法。<br><img src="https://img-blog.csdnimg.cn/5705454adc5847259a5ebc413b989138.png#pic_center" alt="在这里插入图片描述"><br>说明：</p>
<ul>
<li>append、concatenate以及stack都有一个axis参数，用于控制数组的合 并方式是按行还是按列。</li>
<li>对于append和concatenate，待合并的数组必须有相同的行数或列数</li>
<li>stack、hstack、dstack，要求待合并的数组必须具有相同的形状</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">np.hstack((a,b)) <span class="comment">#等效于 np.concatenate((a,b),axis = 1)</span></span><br><span class="line"><span class="comment"># out : array([[1, 2, 5, 6], [3, 4, 7, 8]])</span></span><br><span class="line"></span><br><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">np.vstack((a,b)) <span class="comment">#等价于 np.concatenate((a,b),axis = 0)</span></span><br><span class="line"><span class="comment"># out : array([[1, 2], [3, 4], [5, 6], [7, 8]])</span></span><br></pre></td></tr></table></figure>
<h3 id="2-3-2-分割"><a href="#2-3-2-分割" class="headerlink" title="2.3.2    分割"></a>2.3.2    分割</h3><ul>
<li>水平分割：np.split(arr,n,axis=1) 或 np.hsplit(arr,n)：按列分成n份。返回一个list</li>
<li>垂直分割：np.split(arr,n,axis=0) 或 np.vsplit(arr,n)：按行分成n份，返回一个list</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">np.split(x, <span class="number">3</span>) <span class="comment"># out : [array([[0, 1, 2, 3]]), array([[4, 5, 6, 7]]), array([[ 8,  9, 10, 11]])]</span></span><br><span class="line"></span><br><span class="line">y = np.arange(<span class="number">9</span>).reshape(<span class="number">1</span>, <span class="number">9</span>)</span><br><span class="line">np.split(y, <span class="number">3</span>, axis = <span class="number">1</span>) <span class="comment"># out : [array([[0, 1, 2]]), array([[3, 4, 5]]), array([[6, 7, 8]])]</span></span><br></pre></td></tr></table></figure>
<h2 id="2-4-维度变换"><a href="#2-4-维度变换" class="headerlink" title="2.4    维度变换"></a>2.4    维度变换</h2><p>&emsp;&emsp;在机器学习以及深度学习的任务中，通常需要将处理好的数据以模型能 接收的格式输入给模型，然后由模型通过一系列的运算，最终返回一个处理 结果。然而，由于不同模型所接收的输入格式不一样，往往需要先对其进行 一系列的变形和运算，从而将数据处理成符合模型要求的格式。在矩阵或者 数组的运算中，经常会遇到需要把多个向量或矩阵按某轴方向合并，或展平 (如在卷积或循环神经网络中，在全连接层之前，需要把矩阵展平)的情 况。下面介绍几种常用的数据变形方法。<br><img src="https://img-blog.csdnimg.cn/3177245df8f047448b88a34354c543ef.png#pic_center" alt="在这里插入图片描述"><br><strong>1)</strong> <strong>reshape</strong><br>&emsp;&emsp;不改变原数组元素，返回一个新的shape维度的数组(维度变换)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">x <span class="comment"># out : array([[ 0,  1,  2,  3], [ 4,  5,  6,  7], [ 8,  9, 10, 11]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定维度时可以只指定行数或列数, 其他用 -1 代替</span></span><br><span class="line">x.reshape(<span class="number">3</span>, -<span class="number">1</span>) <span class="comment"># out : array([[ 0,  1,  2,  3], [ 4,  5,  6,  7], [ 8,  9, 10, 11]])</span></span><br></pre></td></tr></table></figure>
<p><strong>2)</strong> <strong>resize</strong><br>&emsp;&emsp;改变向量的维度(修改向量本身)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr =np.arange(<span class="number">10</span>) </span><br><span class="line"><span class="built_in">print</span>(arr) <span class="comment"># out : [0 1 2 3 4 5 6 7 8 9]</span></span><br><span class="line"></span><br><span class="line">arr.resize(<span class="number">2</span>, <span class="number">5</span>) <span class="comment"># 将向量 arr 维度变换为2行5列 </span></span><br><span class="line"><span class="built_in">print</span>(arr) <span class="comment"># out : [[0 1 2 3 4], [5 6 7 8 9]]</span></span><br></pre></td></tr></table></figure>
<p><strong>3)</strong> <strong>T</strong><br>&emsp;&emsp;转置</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">8</span>).reshape(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">arr.shape <span class="comment"># out : (2, 4)</span></span><br><span class="line">arr.T.shape <span class="comment"># out : (4, 2)</span></span><br></pre></td></tr></table></figure>
<p><strong>4)</strong> <strong>ravel</strong><br>&emsp;&emsp;向量展平</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">8</span>).reshape(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">arr.ravel() <span class="comment"># out : array([0, 1, 2, 3, 4, 5, 6, 7])</span></span><br></pre></td></tr></table></figure>
<p><strong>5)</strong> <strong>flatten</strong><br>&emsp;&emsp;把矩阵转换为向量，这种需求经常出现在卷积网络与全连接层之间。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">8</span>).reshape(<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">arr.flatten() <span class="comment"># out : array([0, 1, 2, 3, 4, 5, 6, 7])</span></span><br></pre></td></tr></table></figure>
<p><strong>6)</strong> <strong>squeez</strong><br>&emsp;&emsp;这是一个主要用来降维的函数，把矩阵中含1的维度去掉</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">8</span>).reshape(<span class="number">2</span>, <span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">arr.shape <span class="comment"># out : (2, 4, 1)</span></span><br><span class="line">arr.squeeze().shape <span class="comment"># out : (2, 4)</span></span><br></pre></td></tr></table></figure>
<p><strong>7)</strong> <strong>transpose</strong><br>&emsp;&emsp;对高维矩阵进行轴对换，这个在深度学习中经常使用，比如把图片中表 示颜色顺序的RGB改为GBR。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">12</span>).reshape(<span class="number">2</span>, <span class="number">6</span>, <span class="number">1</span>)</span><br><span class="line">arr.shape <span class="comment"># out : (2, 6, 1)</span></span><br><span class="line">arr.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).shape <span class="comment"># out : (6, 1, 2)</span></span><br></pre></td></tr></table></figure>
<p><strong>拓展</strong><br><strong>8)</strong> <strong>swapaxes</strong><br>&emsp;&emsp;将两个维度调换, 就是把对应的下标换个位置，类似于transpose</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.arange(<span class="number">20</span>).reshape(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line">arr.swapaxes(<span class="number">1</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="2-5-Numpy数值计算"><a href="#2-5-Numpy数值计算" class="headerlink" title="2.5    Numpy数值计算"></a>2.5    Numpy数值计算</h2><h3 id="2-5-1-通用函数对象-ufunc"><a href="#2-5-1-通用函数对象-ufunc" class="headerlink" title="2.5.1    通用函数对象(ufunc)"></a>2.5.1    通用函数对象(ufunc)</h3><p>&emsp;&emsp;ufunc是universal function的简称，种能对数组每个元素进行运算的函数。NumPy的许多ufunc函数都是用C语言实现的，因此它们的运算速度非常快。下图是在数据批量处过程中较为常用的几个函数<br><img src="https://img-blog.csdnimg.cn/849bf0438b0646bf8dfb8937793e3211.png#pic_center" alt="在这里插入图片描述"><br>使用的格式基本如下：np.函数名(数组， 指定计算的维度(默认为0))，如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">6</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">6</span>], [<span class="number">9</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">4</span>], [<span class="number">3</span>, <span class="number">7</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">5</span>], [<span class="number">4</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">1</span>]])</span><br><span class="line">np.<span class="built_in">sum</span>(a, axis = <span class="number">0</span>) <span class="comment"># out : array([22, 13, 27, 18, 16])</span></span><br><span class="line">np.<span class="built_in">sum</span>(a, axis = <span class="number">1</span>)<span class="comment"># out : array([26, 28, 24, 18]</span></span><br></pre></td></tr></table></figure>
<p>其余函数使用过程均可参考上述求和过程。下面继续介绍一下数组的排序问题。主要使用函数有np.min，np.max，np.median。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>], [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>]])</span><br><span class="line">np.<span class="built_in">min</span>(arr, axis = <span class="number">0</span>) <span class="comment"># out : array([10, 11, 12]) 按行求最小值，即列不变，行变</span></span><br><span class="line">np.<span class="built_in">min</span>(arr, axis = <span class="number">1</span>) <span class="comment"># out : array([10, 13]) 按列求最小值，即行不变，列变</span></span><br></pre></td></tr></table></figure>
<p>我们可以通过np.argmin，np.argmax获得相对应的最小值、最大值的下标</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([[<span class="number">10</span>, <span class="number">14</span>, <span class="number">12</span>], [<span class="number">13</span>, <span class="number">11</span>, <span class="number">15</span>]])</span><br><span class="line">np.argmin(arr, axis = <span class="number">0</span>) <span class="comment"># out : array([0, 1, 0], dtype=int64) 按行求最小值，即列不变，行变</span></span><br><span class="line">np.argmin(arr, axis = <span class="number">1</span>) <span class="comment"># out : array([0, 1], dtype=int64) 按列求最小值，即行不变，列变</span></span><br></pre></td></tr></table></figure>
<p>使用np.sort和np.argsor进行排序并排序后的下标</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">4</span>])</span><br><span class="line">np.sort(arr) <span class="comment"># out : array([1, 2, 3, 4, 5])</span></span><br><span class="line">np.argsort(arr) <span class="comment"># out : array([0, 3, 1, 4, 2], dtype=int64)</span></span><br></pre></td></tr></table></figure>
<h3 id="2-5-2-矩阵运算"><a href="#2-5-2-矩阵运算" class="headerlink" title="2.5.2    矩阵运算"></a>2.5.2    矩阵运算</h3><p><strong>1) 对应元素相乘</strong><br>&emsp;&emsp;对应元素相乘（Element-Wise Product）是两个矩阵中对应元素乘积。 np.multiply函数用于数组或矩阵对应元素相乘，输出与相乘数组或矩阵的大 小一致。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]])</span><br><span class="line">b = np.array([[<span class="number">4</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>]])</span><br><span class="line">np.multiply(a, b) <span class="comment"># 等效于a * b，out : array([[4, 0], [0, 2]])</span></span><br></pre></td></tr></table></figure>
<p>计算过程如下图：<br><img src="https://img-blog.csdnimg.cn/f97314c336bf40f690cdb17e31a8ba30.png#pic_center" alt="在这里插入图片描述"><br><strong>2) 点积</strong><br>&emsp;&emsp;点积运算(Dot Product)又称为内积，在Numpy用np.dot或者np.matmul表示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]])</span><br><span class="line">b = np.array([[<span class="number">4</span>,<span class="number">1</span>],[<span class="number">2</span>,<span class="number">2</span>]])</span><br><span class="line">np.dot(a, b) <span class="comment"># 等效于np.matmul(a, b) out : array([[4, 1], [2, 2]])</span></span><br></pre></td></tr></table></figure>
<p>计算过程如下图：<br><img src="https://img-blog.csdnimg.cn/b2422fbad9e64769a6a9e8523a05e7a4.png#pic_center" alt="在这里插入图片描述"><br><strong>3) 行列</strong><br>&emsp;&emsp;计算行列式的值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>]]) </span><br><span class="line">np.linalg.det(arr) <span class="comment"># out : -2.0000000000000004</span></span><br></pre></td></tr></table></figure>
<p><strong>4) 求逆</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>]]) </span><br><span class="line">np.linalg.inv(arr) <span class="comment"># out : array([[-2. ,  1. ], [ 1.5, -0.5]])</span></span><br></pre></td></tr></table></figure>
<p><strong>5) 特征值和特征向量</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = np.random.randint(-<span class="number">10</span>,<span class="number">10</span>,(<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">C = np.dot(A.T, A)</span><br><span class="line">vals, vecs = np.linalg.eig(C) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;特征值 : <span class="subst">&#123;vals&#125;</span>, 特征向量 : <span class="subst">&#123;vecs&#125;</span>&#x27;</span>)</span><br><span class="line">out : </span><br><span class="line">特征值 : [<span class="number">395.26566729</span> <span class="number">358.52489695</span>  <span class="number">44.41465068</span>  <span class="number">52.79478508</span>]</span><br><span class="line">特征向量 : [[ <span class="number">0.30221599</span>  <span class="number">0.64309202</span> -<span class="number">0.64757004</span> -<span class="number">0.27522935</span>]</span><br><span class="line">             [ <span class="number">0.87819925</span> -<span class="number">0.03518532</span>  <span class="number">0.18871425</span>  <span class="number">0.43808105</span>]</span><br><span class="line">             [-<span class="number">0.35779498</span>  <span class="number">0.26192443</span> -<span class="number">0.27010759</span>  <span class="number">0.85464626</span>]</span><br><span class="line">             [ <span class="number">0.09702746</span> -<span class="number">0.71874212</span> -<span class="number">0.68708214</span>  <span class="number">0.04374437</span>]]</span><br></pre></td></tr></table></figure>
<h2 id="2-6-插值运算"><a href="#2-6-插值运算" class="headerlink" title="2.6    插值运算"></a>2.6    插值运算</h2><p>&emsp;&emsp;这个过程其实就是我们在数学中已知一个函数，然后给出x值，让你根据这个函数求对应的y值，一般在曲线平滑处理中有较多的使用在Numpy中由numpy.interp(x, xp, fp, left=None, right=None, period=None)表示</p>
<ul>
<li>x - 表示将要计算的插值点x坐标</li>
<li>xp - 表示已有的xp数组</li>
<li>fp - 表示对应于已有的xp数组的值</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">2</span> * np.pi, <span class="number">10</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line">xvals = np.linspace(<span class="number">0</span>, <span class="number">2</span> * np.pi, <span class="number">10000</span>)</span><br><span class="line">yinterp = np.interp(xvals, x, y)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;r-&#x27;</span>, xvals, yinterp, <span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/f1f04c7addcd465097961ef90312af6c.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-7-曲线拟合"><a href="#2-7-曲线拟合" class="headerlink" title="2.7    曲线拟合"></a>2.7    曲线拟合</h2><p>&emsp;&emsp;我们在数学建模过程中得到我们的数据之后，如果我们想要使用某个函数去描述数据的规律，这个过程其实就在曲线拟合的过程，这里只介绍最简单的一种拟合方式。Numpy中由numpy.polyfit(x, y, deg)表示</p>
<ul>
<li>x为待拟合的x坐标</li>
<li>y为待拟合的y坐标</li>
<li>deg为拟合自由度，即多项式的最高次幂</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>])</span><br><span class="line">y = np.array([<span class="number">0.0</span>, <span class="number">0.8</span>, <span class="number">0.9</span>, <span class="number">0.1</span>, -<span class="number">0.8</span>, -<span class="number">1.0</span>])</span><br><span class="line"><span class="comment">#得到多项式的系数</span></span><br><span class="line">z = np.polyfit(x, y, <span class="number">3</span>)</span><br><span class="line">z2 = np.polyfit(x, y, <span class="number">5</span>)</span><br><span class="line"><span class="comment">#得到多项式函数</span></span><br><span class="line">f = np.poly1d(z)</span><br><span class="line">f2 = np.poly1d(z2)</span><br><span class="line"><span class="comment">#用两个函数进行拟合</span></span><br><span class="line">xval = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">50</span>)</span><br><span class="line">yval1 = f(xval)</span><br><span class="line">yval2 = f2(xval)</span><br><span class="line"><span class="comment">#作图</span></span><br><span class="line">plt.plot(xval, yval1, <span class="string">&#x27;r--o&#x27;</span>, xval, yval2, <span class="string">&#x27;b-o&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&#x27;The deg is 3&#x27;</span>, <span class="string">&#x27;The deg is 5&#x27;</span>])</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(f) <span class="comment"># out :  0.08704 x^3 - 0.8135 x^2 + 1.693 x - 0.03968</span></span><br><span class="line"><span class="built_in">print</span>(f2) <span class="comment"># out : -0.008333 x^5 + 0.125 x^4 - 0.575 x^3 + 0.625 x^2 + 0.6333 x - 1.74e-14</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/670064fd5f98479397ec0e900be472a5.png#pic_center" alt="在这里插入图片描述"><br>由图能够看出，3和5自由度的函数在前面的函数曲线基本是重合的，但是约在7左右开始朝着相反方向进行变化，因此拟合函数的自由度对效果的影响是非常大的，找到一个合适的自由度至关重要。</p>
<h1 id="3-Numpy-IO操作"><a href="#3-Numpy-IO操作" class="headerlink" title="3    Numpy IO操作"></a>3    Numpy IO操作</h1><p><strong>1) 保存数组</strong><br>&emsp;&emsp;保存一个数组到一个二进制的文件中,保存格式是.npy，Numpy中由np.save(file, array)表示。<br><strong>2) 读取文件</strong><br>&emsp;&emsp;arr = numpy.load(file): 读取npy 文件到内存</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arr = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"><span class="comment">#保存数据</span></span><br><span class="line">np.save(<span class="string">&#x27;test.npy&#x27;</span>, arr)</span><br><span class="line"><span class="comment">#下载数据</span></span><br><span class="line">np.load(<span class="string">&#x27;test.npy&#x27;</span>) <span class="comment"># out : array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])</span></span><br></pre></td></tr></table></figure>
<p><strong>拓展</strong><br>&emsp;&emsp;保存到文本文件</p>
<ul>
<li>np.savetxt(fname, X, fmt=‘%.18e’, delimiter=‘ ‘)</li>
<li>arr = numpy.loadtxt(fname, delimiter=None)</li>
</ul>
<p><strong>参考</strong><br>《Python深度学习基于PyTorch》  吴茂贵</p>
]]></content>
      <categories>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>numpy</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>工业产品缺陷检测 Opencv+Python</title>
    <url>/2022/06/05/%E5%B7%A5%E4%B8%9A%E4%BA%A7%E5%93%81%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B-Opencv-Python/</url>
    <content><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>如下图所示为某种用于试剂检验的产品，需要利用机器视觉的方法检测产品的缺陷。 本设计的目的是综合运用图像处理的知识，检测产品是否有严重缺陷。 在检测算法之前， 作为图像的预处理， 检测和定位产品的外轮廓，矫正产品的姿态，对于后续的算法处理有着重要的意义。<br><img src="https://img-blog.csdnimg.cn/7f7ab2467c43495ba7a8053cdd9d6425.png#pic_center" alt="在这里插入图片描述"><br>数据为真实的工业产品成像，分为放在OK，NG目录下。数据提取地址<a href="https://pan.baidu.com/s/1mfA0OoOSo6SAmioCol5uSw">链接</a> 提取码：s3jl，OK目录下的图像没有缺陷，NG目录是有缺陷的产品，包括如下两种缺陷：<br><img src="https://img-blog.csdnimg.cn/1544c7a71bb245bd8010516ba5210ed0.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1    介绍"></a>1    介绍</h2><p>&emsp;&emsp;随着机器学习的发展,对于工业产品的缺陷检测,深度网络模型检测缺陷的准确率远远高于传统图像处理算法。但是由于成本过高和深度学习的不可解释性,使用传统图像处理方法检测产品缺陷检测在工业上仍占着很大一部分比例。本次课程设计主要是针对磁盘的两种缺陷:胶带和大气泡进行检测。</p>
<h2 id="2-方法"><a href="#2-方法" class="headerlink" title="2    方法"></a>2    方法</h2><h3 id="2-1-产品水平矫正"><a href="#2-1-产品水平矫正" class="headerlink" title="2.1    产品水平矫正"></a>2.1    产品水平矫正</h3><p>&emsp;&emsp;在本次实验中,因图片过大,首先将图片大小重塑至700×700×3。其次要计算产品的倾斜角度,本实验使用的方法是霍夫直线检测算法,该算法通过一种投票算法检测具有特定形状的物体,该过程在一个参数空间中通过计算累计结果的局部最大值得到一个符合该特定形状的集合作为霍夫变换结果,该方法可以进行圆,直线,椭圆等形状的检测。在检测过程中发现在产品上下有一大部分的区域会影响到目标区域的检测,因此将图片裁剪至350×700×3。在检测完直线之后,分别计算每条直线的斜率大小,若两条直线斜率之差小于0.01可近似为一条直线,以相同斜率最多的直线为最终的旋转参考直线。根据目标直线斜率计算倾斜角度,最后对图片进行旋转矫正,结果如图1所示。</p>
<p><img src="https://img-blog.csdnimg.cn/b3479076cd0f4f93bfcffbaf48e9b694.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-2-定位产品的外轮廓"><a href="#2-2-定位产品的外轮廓" class="headerlink" title="2.2    定位产品的外轮廓"></a>2.2    定位产品的外轮廓</h3><p>&emsp;&emsp;先对矫正后的图片进行5×5卷积核的高斯滤波,目的是去掉一些噪声点。其次是对滤波后的图片进行Canny算子边缘检测,查找轮廓之前要进行边缘检测是因为cv2.findContours的图片参数要是Canny算子描述的图片。然后进行卷积核为5×5单位阵卷积核的膨胀、闭操作。最后使用cv2.findContours函数对图片进行轮廓检测如图2所示。</p>
<p><img src="https://img-blog.csdnimg.cn/aaf8de3173a64ed194f7333953bb6b5d.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-3-产品对齐"><a href="#2-3-产品对齐" class="headerlink" title="2.3    产品对齐"></a>2.3    产品对齐</h3><p>&emsp;&emsp;本实验的对齐是以无缺陷的图片为模板而进行的。我们在上述步骤中得到了OK图片和NG图片的多个外轮廓,所以我们要先筛选出产品的外轮廓。本实验首先采用的方法是求得每个轮廓的最小外接矩形面积,返回最大的最小外接矩形,随即将NG图片大小重塑到OK图片大小,这一步的目的是为了下一步对产品进行多边拟合时有更好的效果。大小匹配完成之后,再对所得图片进行轮廓查找,将所得的轮廓进行筛选后对产品进行多边拟合最终得到四边形的四个顶点。上述步骤所得的四个顶点不能直接用于产品图片对齐,这是因为对齐时四个顶点要由上到下、由左到右的顺序进行排列。因此我们要先将四个顶点进行排列,第一、四个点对列求和后的最小最大的下标获得,第二、三个点由对列求方差后的最小最大下标获得。排列完成之后,我们要将所得点与模板点进行匹配得到变换矩阵m,这里使用的函数是cv2.getPerspectiveTransform,最后使用cv2.warpPerspective函数结合变换矩阵对产品进行对齐,效果如图3所示。从图3我们可以看出产品此时并不是十分的水平,原因是产品的顶点并不是尖点,所以在进行多边形拟合之后上下边并不平行。</p>
<p><img src="https://img-blog.csdnimg.cn/30602c4df3ff479d8b243e9f6c967370.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-4-缺陷检测"><a href="#2-4-缺陷检测" class="headerlink" title="2.4    缺陷检测"></a>2.4    缺陷检测</h3><p>&emsp;&emsp;产品检测是以OK图片为模板,用两种NG图片分别与OK图片进行对比,描述出缺陷之处。首先将对齐好的OK和NG图片进行高斯滤波，卷积核大小为3×3。再对图片进行闭操作,卷积核为3×3的单位阵,迭代次数为1。然后对图片进行Canny算子边缘检测,最后对两张图片进行轮廓查找,如图4。</p>
<p><img src="https://img-blog.csdnimg.cn/0aadf0e58c134c429ac30b1b9688f46a.png#pic_center" alt="在这里插入图片描述"><br>在获得OK和NG图片的轮廓图之后,就可以用来缺陷检测。因为提供的产品图像之间可能存在旋转、平移、微小的缩放,所以我们不能直接将OK图减去NG图得到缺陷。本次实验我的思路是:因为旋转、平移、微小之间的差异属于几何特征,所以我使用Hu矩对两张图片的轮廓进行比较。具体过程如下:首先对NG图的轮廓进行迭代,用NG图的轮廓与OK图进行对比,得到一系列的相似度,如果这一系列相似度的最小值大于我所设的阈值(本次实验设置为0.45),那么就可以说明NG图的这个轮廓是缺陷处的轮廓。然后在NG图上绘出这个轮廓如图5。最后统计缺陷轮廓的个数(本实验设置为30),当大于某个阈值时那么就可以说明这张图片就是有缺陷的图片,之所以轮廓个数大于某一值才能认定为缺陷图片,是因为可能出现误检地情况, 如图5的喇叭处就是误保留的轮廓再者就是商标和英文字符串是我们不需要关心的但也被检测在内。</p>
<p><img src="https://img-blog.csdnimg.cn/3386e735ba5d4419a84930e977062d7d.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="3-实验结果及分析"><a href="#3-实验结果及分析" class="headerlink" title="3    实验结果及分析"></a>3    实验结果及分析</h2><p>&emsp;&emsp;基于上述的缺陷检测的方法分别对OK图片和两种NG图片进行检测,结果如表1所示。由表1可知本实验的检测方法在OK图上的正确率只有0.87,原因可能是受光照的影响而导致图片在边缘检测时边缘差异变大而导致轮廓受影响较大;在胶带缺陷上正确率是0.80,原因是缺陷主要集中在产品中间的白色宽带上,使得轮廓的检测并没有很多(小于所设的阈值);而检测方法在大气泡缺陷的图片上正确率有1.00,这是因为大气泡缺陷形成了大量”离散块”,使得检测到的轮廓很多,轮廓个数很容易超过阈值。</p>
<p><img src="https://img-blog.csdnimg.cn/c0afd510ad9f42ce96927cff869bc716.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="4-讨论"><a href="#4-讨论" class="headerlink" title="4    讨论"></a>4    讨论</h2><p>&emsp;&emsp;本次实验主要是针对工业产品的缺陷进行检测,我主要是利用了Hu矩描述图片的不变性来判断轮廓的所属类型来达到检测缺陷的目的,只能是粗略地定位,因为绝大部分的缺陷轮廓都是曲线,如果需要更加精确的定位,可能需要运用特征描述子进行特征匹配来实现。其次就是我的方法的误检地区域很多,特别是在图片的喇叭部分。总的来说,检测方法不是很理想,还需要做更多的尝试来达到精确定位缺陷的目标。<br><strong>代码</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv </span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Horizontal_correction</span>(<span class="params">path</span>) :</span><br><span class="line">    img = cv.imread(path, cv.IMREAD_COLOR)</span><br><span class="line">    img = cv.resize(img, (<span class="number">700</span>, <span class="number">700</span>))</span><br><span class="line">    img = img[<span class="number">300</span> : <span class="number">650</span>]</span><br><span class="line">    gimg = cv.cvtColor(img, cv.COLOR_BGR2GRAY)</span><br><span class="line">    canny = cv.Canny(gimg, <span class="number">70</span>, <span class="number">150</span>)</span><br><span class="line">    lines = cv.HoughLines(canny, <span class="number">1</span>, np.pi / <span class="number">180</span>, <span class="number">200</span>)</span><br><span class="line">    lines = np.array(lines)</span><br><span class="line">    angles = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        <span class="keyword">for</span> rho, theta <span class="keyword">in</span> line :</span><br><span class="line">            a = np.cos(theta)</span><br><span class="line">            b = np.sin(theta)</span><br><span class="line"></span><br><span class="line">            x0 = rho * a</span><br><span class="line">            y0 = rho * b</span><br><span class="line"></span><br><span class="line">            x1 = <span class="built_in">int</span>(x0 + <span class="number">1000</span> * (-b))</span><br><span class="line">            y1 = <span class="built_in">int</span>(y0 + <span class="number">1000</span> * a)</span><br><span class="line">            x2 = <span class="built_in">int</span>(x0 - <span class="number">1000</span> * (-b))</span><br><span class="line">            y2 = <span class="built_in">int</span>(y0 - <span class="number">1000</span> * a)</span><br><span class="line"></span><br><span class="line"><span class="comment">#             cv.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)</span></span><br><span class="line"></span><br><span class="line">            dy = y2 - y1</span><br><span class="line">            dx = x2 - x1</span><br><span class="line">            angle = math.atan2(dy, dx) * <span class="number">180</span> / math.pi</span><br><span class="line">            angles.append(angle)</span><br><span class="line"></span><br><span class="line">    angles = <span class="built_in">sorted</span>(angles, key = <span class="keyword">lambda</span> x : x)</span><br><span class="line">    best_angle = <span class="number">0</span></span><br><span class="line">    angles_temp = []</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt;= <span class="built_in">len</span>(angles) - <span class="number">2</span> :</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i, <span class="built_in">len</span>(angles)) :</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">abs</span>(angles[j] - angles[i]) &lt; <span class="number">1e-2</span> :</span><br><span class="line">                <span class="keyword">if</span> j == <span class="built_in">len</span>(angles) - <span class="number">1</span> :</span><br><span class="line">                    angles_temp.append(angles[i : j + <span class="number">1</span>])</span><br><span class="line">                    i = j</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                angles_temp.append(angles[i : j])</span><br><span class="line">                i = j</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    cnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, lst <span class="keyword">in</span> <span class="built_in">enumerate</span>(angles_temp) :</span><br><span class="line">            <span class="keyword">if</span> cnt &lt; <span class="built_in">len</span>(lst) :</span><br><span class="line">                cnt = <span class="built_in">len</span>(lst)</span><br><span class="line">                best_angle = angles_temp[i][<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">    RotateMatrix = cv.getRotationMatrix2D((img.shape[<span class="number">1</span>] / <span class="number">2</span>, img.shape[<span class="number">0</span>] / <span class="number">2</span>), best_angle, <span class="number">1</span>)</span><br><span class="line">    RotImg = cv.warpAffine(img, RotateMatrix, (img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment">#     concatenate = np.concatenate((img, RotImg), axis = 1)</span></span><br><span class="line"><span class="comment">#     print(RotImg.shape, img.shape)</span></span><br><span class="line"><span class="comment">#     print(angles)</span></span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;concatenate&#x27;, concatenate)</span></span><br><span class="line"><span class="comment">#     cv.waitKey(0)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> RotImg</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Rect</span>(<span class="params">contours</span>) :</span><br><span class="line">    areaInitial = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contours)) :</span><br><span class="line">        contour = contours[i].squeeze()</span><br><span class="line">        min_x, min_y = np.<span class="built_in">min</span>(contour, axis = <span class="number">0</span>)</span><br><span class="line">        max_x, max_y = np.<span class="built_in">max</span>(contour, axis = <span class="number">0</span>)</span><br><span class="line"><span class="comment">#         cv.rectangle(imgGray, (min_x, min_y), (max_x, max_y), color = (0, 0, 255))</span></span><br><span class="line">        area = (max_x - min_x) * (max_y - min_y)</span><br><span class="line">        <span class="keyword">if</span> area &gt; areaInitial :</span><br><span class="line">            areaInitial = area</span><br><span class="line">            rectPoint = [min_y, min_x, max_y, max_x]</span><br><span class="line">    <span class="keyword">return</span> rectPoint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Biggest</span>(<span class="params">contours</span>) :</span><br><span class="line">    biggest = np.array([])</span><br><span class="line">    max_Area = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> contour <span class="keyword">in</span> contours :</span><br><span class="line">        area = cv.contourArea(contour)</span><br><span class="line">        <span class="keyword">if</span> area &gt; <span class="number">5000</span>:</span><br><span class="line">            C = cv.arcLength(contour, <span class="literal">True</span>)</span><br><span class="line">            approx = cv.approxPolyDP(contour, <span class="number">0.02</span> * C, <span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">if</span> area &gt; max_Area <span class="keyword">and</span> <span class="built_in">len</span>(approx) == <span class="number">4</span>:</span><br><span class="line">                biggest = approx</span><br><span class="line">                max_Area = area</span><br><span class="line">    <span class="keyword">return</span> biggest</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">FindContours</span>(<span class="params">img</span>) :</span><br><span class="line">    imgGray = img.copy()</span><br><span class="line">    imgBlur = cv.GaussianBlur(imgGray, (<span class="number">5</span>, <span class="number">5</span>), <span class="number">1</span>)</span><br><span class="line">    imgCanny = cv.Canny(imgBlur, <span class="number">100</span>, <span class="number">200</span>)</span><br><span class="line">    kernel = np.ones((<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">    imgDilate = cv.dilate(imgCanny, kernel, iterations = <span class="number">2</span>)</span><br><span class="line">    imgErode = cv.erode(imgDilate, kernel, iterations = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    contours, hierarchy = cv.findContours(imgErode, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)</span><br><span class="line"><span class="comment">#     cv.drawContours(imgGray, contours, -1, (0, 0, 255), 2)</span></span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;imgGray&#x27;, imgGray)</span></span><br><span class="line"><span class="comment">#     cv.waitKey(0)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> contours</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Reorder</span>(<span class="params">points</span>):</span><br><span class="line">    points = points.reshape((<span class="number">4</span>, <span class="number">2</span>))</span><br><span class="line">    Newpoints = np.zeros((<span class="number">4</span>, <span class="number">2</span>), dtype=np.int32)</span><br><span class="line">    xsum = np.<span class="built_in">sum</span>(points, axis = <span class="number">1</span>)</span><br><span class="line">    xdiff = np.diff(points, axis = <span class="number">1</span>)</span><br><span class="line">    Newpoints[<span class="number">0</span>] = points[np.argmin(xsum)]</span><br><span class="line">    Newpoints[<span class="number">3</span>] = points[np.argmax(xsum)]</span><br><span class="line">    Newpoints[<span class="number">1</span>] = points[np.argmin(xdiff)]</span><br><span class="line">    Newpoints[<span class="number">2</span>] = points[np.argmax(xdiff)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> np.float32(Newpoints)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ImageAlignment</span>(<span class="params">img1, img2</span>) :</span><br><span class="line">    contours1  = FindContours(img1)</span><br><span class="line">    contours2 = FindContours(img2)</span><br><span class="line">    </span><br><span class="line">    rectPoint1 = Rect(contours1)</span><br><span class="line">    rectPoint2 = Rect(contours2)</span><br><span class="line">    img1 = img1[rectPoint1[<span class="number">0</span>] : rectPoint1[<span class="number">2</span>], rectPoint1[<span class="number">1</span>] : rectPoint1[<span class="number">3</span>]]</span><br><span class="line">    img2 = img2[rectPoint2[<span class="number">0</span>] : rectPoint2[<span class="number">2</span>], rectPoint2[<span class="number">1</span>] : rectPoint2[<span class="number">3</span>]]</span><br><span class="line">    img2 = cv.resize(img2, (img1.shape[<span class="number">1</span>], img1.shape[<span class="number">0</span>]), cv.INTER_CUBIC)</span><br><span class="line">    </span><br><span class="line">    contours1 = FindContours(img1)</span><br><span class="line">    contours2 = FindContours(img2)</span><br><span class="line">    </span><br><span class="line">    targetAreaPoint1 = Biggest(contours1)</span><br><span class="line">    targetAreaPoint2 = Biggest(contours2)</span><br><span class="line">    pts1 = np.float32(Reorder(targetAreaPoint1))</span><br><span class="line">    pts2 = np.float32(Reorder(targetAreaPoint2))</span><br><span class="line">    pts = np.float32([[<span class="number">0</span>, <span class="number">0</span>], [img1.shape[<span class="number">1</span>], <span class="number">0</span>], [<span class="number">0</span>, img1.shape[<span class="number">0</span>]], [img1.shape[<span class="number">1</span>], img1.shape[<span class="number">0</span>]]])</span><br><span class="line">    </span><br><span class="line">    RotateMatrix1 = cv.getPerspectiveTransform(pts1, pts)</span><br><span class="line">    RotateMatrix2 = cv.getPerspectiveTransform(pts2, pts)</span><br><span class="line"></span><br><span class="line">    out_img1 = cv.warpPerspective(img1, RotateMatrix1, (img1.shape[<span class="number">1</span>], img1.shape[<span class="number">0</span>]))</span><br><span class="line">    out_img2 = cv.warpPerspective(img2, RotateMatrix2, (img1.shape[<span class="number">1</span>], img1.shape[<span class="number">0</span>]))</span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;out_img1&#x27;, out_img1)</span></span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;out_img2&#x27;, out_img2)</span></span><br><span class="line"><span class="comment">#     concatenate = np.concatenate((out_img1, out_img2), axis = 1)</span></span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;concatenate&#x27;, concatenate)</span></span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;img1&#x27;, img1)</span></span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;img2&#x27;, img2)</span></span><br><span class="line"><span class="comment">#     cv.waitKey(0)</span></span><br><span class="line">    <span class="keyword">return</span> out_img1, out_img2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Detect</span>(<span class="params">img1, img2</span>) :</span><br><span class="line">    cimg1, cimg2 = img1.copy(), img2.copy()</span><br><span class="line">    cimg1 = cv.cvtColor(cimg1, cv.COLOR_BGR2GRAY)</span><br><span class="line">    cimg2 = cv.cvtColor(cimg2, cv.COLOR_BGR2GRAY)</span><br><span class="line">    imgBlur1 = cv.GaussianBlur(cimg1, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)</span><br><span class="line">    imgBlur2 = cv.GaussianBlur(cimg2, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)</span><br><span class="line">    kernel = np.ones((<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">    imgErode1 = cv.erode(imgBlur1, kernel, iterations = <span class="number">1</span>)</span><br><span class="line">    imgErode2 = cv.erode(imgBlur2, kernel, iterations = <span class="number">1</span>)</span><br><span class="line"><span class="comment">#     ret1, imgThresh1 = cv.threshold(imgErode1, 100, 255, cv.THRESH_BINARY)</span></span><br><span class="line"><span class="comment">#     ret2, imgThresh2 = cv.threshold(imgErode2, 100, 255, cv.THRESH_BINARY)</span></span><br><span class="line">    </span><br><span class="line">    imgCanny1 = cv.Canny(imgErode1, <span class="number">70</span>, <span class="number">120</span>)</span><br><span class="line">    imgCanny2 = cv.Canny(imgErode2, <span class="number">70</span>, <span class="number">120</span>)</span><br><span class="line">    </span><br><span class="line">    contours1, hierarchy1 = cv.findContours(imgCanny1, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)</span><br><span class="line">    contours2, hierarchy2 = cv.findContours(imgCanny2, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)</span><br><span class="line">    </span><br><span class="line">    contoursNum = <span class="number">0</span></span><br><span class="line"><span class="comment">#     cv.drawContours(img1, contours1, -1, (0, 255, 0), 1)</span></span><br><span class="line"><span class="comment">#     cv.drawContours(img2, contours2, -1, (0, 0, 255), 1)</span></span><br><span class="line"><span class="comment">#     concatenate = np.concatenate((img1, img2), axis = 1)</span></span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;concatenate&#x27;, concatenate)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contours2)) :</span><br><span class="line">        defects = []</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(contours1)) :</span><br><span class="line">            similiarity = cv.matchShapes(contours2[i], contours1[j], cv.CONTOURS_MATCH_I1, <span class="number">0</span>)</span><br><span class="line">            defects.append(similiarity)</span><br><span class="line">        min_similarity = <span class="built_in">min</span>(defects)</span><br><span class="line">        <span class="keyword">if</span> min_similarity &gt; <span class="number">0.45</span> :</span><br><span class="line">            cv.drawContours(img2, contours2, i, (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>)</span><br><span class="line">            contoursNum += <span class="number">1</span> </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> contoursNum &gt; <span class="number">30</span> :</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Approximately defect(s) detected&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span> :</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Unable to detect defects&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#     cv.imshow(&#x27;canny1&#x27;, img1)</span></span><br><span class="line">    cv.imshow(<span class="string">&#x27;canny2&#x27;</span>, img2)</span><br><span class="line">    cv.waitKey(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">daqipao_path = <span class="built_in">list</span>(<span class="built_in">sorted</span>(os.listdir(<span class="string">&#x27;opencv_course_design_data/NG/daqipao/&#x27;</span>)))</span><br><span class="line">jiaodai_path = <span class="built_in">list</span>(<span class="built_in">sorted</span>(os.listdir(<span class="string">&#x27;opencv_course_design_data/NG/jiaodai/&#x27;</span>)))</span><br><span class="line">OK_path = <span class="built_in">list</span>(<span class="built_in">sorted</span>(os.listdir(<span class="string">&#x27;opencv_course_design_data/OK/&#x27;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> daqipao_path :</span><br><span class="line">    RotImg1 = RotImg2 = Horizontal_correction(<span class="string">&#x27;opencv_course_design_data/OK/OK_0032.bmp&#x27;</span>)</span><br><span class="line">    RotImg2 = Horizontal_correction(os.path.join(<span class="string">&#x27;opencv_course_design_data/NG/daqipao&#x27;</span>, path))</span><br><span class="line">    imgAlignment1, imgAlignment2 = ImageAlignment(RotImg1, RotImg2)</span><br><span class="line">    Detect(imgAlignment1, imgAlignment2)</span><br><span class="line"><span class="comment"># for path in jiaodai_path :</span></span><br><span class="line"><span class="comment">#     RotImg1 = RotImg2 = Horizontal_correction(&#x27;opencv_course_design_data/OK/OK_0032.bmp&#x27;)</span></span><br><span class="line"><span class="comment">#     RotImg2 = Horizontal_correction(os.path.join(&#x27;opencv_course_design_data/NG/jiaodai&#x27;, path))</span></span><br><span class="line"><span class="comment">#     imgAlignment1, imgAlignment2 = ImageAlignment(RotImg1, RotImg2)</span></span><br><span class="line"><span class="comment">#     Detect(imgAlignment1, imgAlignment2)</span></span><br><span class="line"><span class="comment"># for path in OK_path :</span></span><br><span class="line"><span class="comment">#     RotImg1 = RotImg2 = Horizontal_correction(&#x27;opencv_course_design_data/OK/OK_0032.bmp&#x27;)</span></span><br><span class="line"><span class="comment">#     RotImg2 = Horizontal_correction(os.path.join(&#x27;opencv_course_design_data/OK/&#x27;, path))</span></span><br><span class="line"><span class="comment">#     imgAlignment1, imgAlignment2 = ImageAlignment(RotImg1, RotImg2)</span></span><br><span class="line"><span class="comment">#     Detect(imgAlignment1, imgAlignment2)</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
        <tag>opencv</tag>
        <tag>产品缺陷检测</tag>
      </tags>
  </entry>
  <entry>
    <title>基于 HoG 的图像特征提取及其分类研究</title>
    <url>/2022/06/05/%E5%9F%BA%E4%BA%8E-HoG-%E7%9A%84%E5%9B%BE%E5%83%8F%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%8F%8A%E5%85%B6%E5%88%86%E7%B1%BB%E7%A0%94%E7%A9%B6/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p> &emsp;&emsp; 最近写了一个python的图片分类任务的作业，本篇博客是将我所做的流程所进行的整理。数据链接：<a href="https://pan.baidu.com/s/1OhsEgLGZ_MYxESPPGM5g5g">百度网盘</a> 提取码：rkhw，HoG特征理论知识可参考<a href="https://blog.csdn.net/zouxy09/article/details/7929348">这里</a>，PCA降维可参考<a href="https://blog.csdn.net/qq_38262266/article/details/100592330">这里</a></p>
<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1    介绍"></a>1    介绍</h1><p> &emsp;&emsp; 特征提取是图像处理中的一大领域,著名的提取算法有HoG(Histogram of Oriented Gradient)[1]、LBP(Local Binary Pattern)[2]和Haar-like[3]等等。近些年来,随着GPU算力的急速发展,深度学习也得到了迅速发展,使得图像特征提取的效率大大提升,各种分类任务的正确率不断的刷新提升。而深度学习存在着较差的可解释性和海量数据需求的问题,这是对机器视觉任务来说是伪命题,与之相反的是,传统特征提取方法可视性非常强,且现有的卷积神经网络可能与这些特征提取方法有一定类似性,因为每个滤波权重实际上是一个线性的识别模式,与这些特征提取过程的边界与梯度检测类似。因此对我们的学习来说,传统特征提取方法的学习是不可少的,本次实验是基于HoG 的图像特征提取及其分类研究。<br>&emsp;&emsp;HOG特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。最早出现在2005年CVPR上，法国的研究人员Navneet Dalal 和Bill Triggs利用HOG特征+SVM进行行人检测,在当时得到了较好的检测效果。主要流程如下:<br><img src="https://img-blog.csdnimg.cn/5cdd3d64f5544f70a0261cb352950e2b.png" alt="在这里插入图片描述"><br>&emsp;&emsp;本次的实验也是基于上述流程进行一步一步实现,最终实现分类。</p>
<h1 id="2-方法"><a href="#2-方法" class="headerlink" title="2    方法"></a>2    方法</h1><h2 id="2-1-数据集准备"><a href="#2-1-数据集准备" class="headerlink" title="2.1    数据集准备"></a>2.1    数据集准备</h2><p>&emsp;&emsp;本次分类任务是对猫、狗、人脸、蛇四种类别的分类。收集每种类别各4000张图片,其中87.5%作为训练集,12.5%作为预测集,且每个类别的占比相同。灰度图的形式读取图片,将图片重塑大小至256×256,最后给数据集的车、狗、人脸、蛇分别打上1,2,3,4的标签,以便训练预测以及后续的性能评估。</p>
<h2 id="2-2-特征提取"><a href="#2-2-特征提取" class="headerlink" title="2.2    特征提取"></a>2.2    特征提取</h2><p>&emsp;&emsp;1)采用不同的Gamma值(默认2.2)校正法对输入图像进行颜色空间的标准化(归一化),目的是调节图像的对比度,降低图像局部的阴影和光照变化所造成的影响,同时可以抑制噪音的干扰。2)计算图像每个像素的梯度(包括大小和方向),主要是为了捕获轮廓信息,同时进一步弱化光照的干扰。本实验使用Sobel算子进行计算。3)将图像划分成小cells,因考虑到设备的性能及维度过大问题,而本实验一个cell的大小为32×32个像素。3)统计每个cell的梯度直方图(不同梯度的个数),形成每个cell的描述子。4)对每个cell的梯度方向进行投票,本实验将cell的梯度方向180度分成9个方向块即9个bins,每个bin的范围为20,cell梯度的大小作为权值加到bins里面。5)本实验将每四个cell组成一个block(2×2cell/block),一个block内所有cell的特征描述子串联起来便得到该block的HOG特征描述子。6)将图像image内的所有block的bins串联起来就可以得到该图片的HoG特征向量。这一步中由于是串联求和过程,使得梯度强度的变化范围非常大。这就需要对block的梯度强度做归一化。归一化能够进一步地对光照、阴影和边缘进行压缩。</p>
<h2 id="2-3-降维"><a href="#2-3-降维" class="headerlink" title="2.3    降维"></a>2.3    降维</h2><p>&emsp;&emsp;在提取特征的步骤中,我们可以算出每一张图片提取出的特征向量的维度是2×2×9×7×7等于1764维,这是较大的维数,里面包含了许多冗余信息,所以我们应考虑对特征向量进行降维。本实验实现的是PCA(主成分分析)算法的降维,其主要过程如下:1)对所有样本进行中心化:$x_i$←$x_i$-$\displaystyle\sum_{i=1}^{n} x_i$。2)计算样本的协方差矩阵$xx^T$。3)对协方差矩阵$xx^T$做特征值分解。4)取最大的m个特征值所对应的单位特征向量:$ω_1,ω_2,⋯,ω_m$。5)得到投影矩阵。</p>
<h2 id="2-4-分类"><a href="#2-4-分类" class="headerlink" title="2.4    分类"></a>2.4    分类</h2><p>&emsp;&emsp;本实验的分类器利用了sklearn库中的svm模型,设置不同的惩罚参数(默认1.0)和核函数(默认’rbf’)的类型进行多次训练和测试。</p>
<h1 id="3-实验结果及分析"><a href="#3-实验结果及分析" class="headerlink" title="3    实验结果及分析"></a>3    实验结果及分析</h1><p>&emsp;&emsp;本实验采用不同的惩罚程度、核函数、gamma校正值、特征维数的分类性能进行对比，采用了精确率、召回率和micro_F1分数对实验结果进行性能评估。</p>
<h2 id="3-1-模型对分类性能的影响"><a href="#3-1-模型对分类性能的影响" class="headerlink" title="3.1    模型对分类性能的影响"></a>3.1    模型对分类性能的影响</h2><p>&emsp;&emsp;不同惩罚程度的模型性能对比如表1所示。随着惩罚程度的减少,也即松弛变量减小,训练集的正确率从0.866降低至0.753,这是因为对误分类的惩罚减小,允许容错。按照理论来讲此时模型的泛化能力应增强,但是测试集精确率、召回率和micro_F1分数均从0.557减小至0.539,原因未能找到。此外,本实验还统计了此特征提取方法对应的每一类的分类情况,从表1中我们可以看出在车和人脸两类上召回率分别达到0.730和0.830左右,而狗和蛇两类分类的效果很差,分别只有0.334和0.324左右。<br><img src="https://img-blog.csdnimg.cn/cb332fe044f4441cb2fe1bfdbb7ce7df.png" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;不同和函数对模型性能的影响表2所示。在rbf、linear和poly三种核函数中,高斯核函数rbf的性能是最好的有0.557,这是因为训练的维度是14000×404,样本数n远远大于特征维数m,这也导致了linear性能最差;而多项式核函数poly的训练集的精确率有0.977,原因是多项式的阶数很高,网络变得更加复杂,但这也导致了过拟合。对于四种类别之间的分类召回率差异仍未得到很好的改善。<br><img src="https://img-blog.csdnimg.cn/2b9c29e3ffdd426ba35ebfee05158bfe.png" alt="在这里插入图片描述"></p>
<h2 id="3-2-特征对分类性能的影响"><a href="#3-2-特征对分类性能的影响" class="headerlink" title="3.2    特征对分类性能的影响"></a>3.2    特征对分类性能的影响</h2><p>&emsp;&emsp;不同gamma值对分类性能的影响如表3所示。随着gamma值从2.2减小至0.5,模型性能由0.557减小至0.530,车、人脸两类分类的召回率由0.730、0.830减小至0.694、0.722,蛇的召回率由0.324升至0.460,狗的召回率先有小幅度上升后减小至0.242,而训练集的精确率由0.866升至0.880,说明模型存在较为明显的过拟合问题。此外,车和人脸的分类召回率依然大幅度超过狗和蛇的分类精确率。<br><img src="https://img-blog.csdnimg.cn/fa8f9e6cf0024f0186859339bef60a16.png" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;不同特征维数对分类性能的影响如表4所示。特征维数由100增加至704,训练集精确率由0.779增加至0.879,性能由0.589减小至0.555,四个类别的分类召回率出了狗均减小。原因是随着特征维数的增大,保留了更多的冗余信息,导致模型过拟合。<br><img src="https://img-blog.csdnimg.cn/ea2f6a128c4f4e7fa7d14caf32696797.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/3fdd7de68ee04500b4a002d4846ff48b.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/52a7dd24db794a1eae12f1f8b7dd450e.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/ce11010f86144d85883ddef1b27aeabb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAYWlzaGFuZ2Nlbmdsb3Vh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/37adc3e7ea1e46b892ea19dfa1ff475e.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/5b7b1e4792e542ea8056cc01b12901ca.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/bba8bbca343248e5985fdf0680d49a62.png" alt="在这里插入图片描述"></p>
<h1 id="4-结论"><a href="#4-结论" class="headerlink" title="4    结论"></a>4    结论</h1><p>&emsp;&emsp;本实验通过修改模型参数和特征提取参数来对比分类性能,从表1到表4,无论怎么修改参数,分类性能最高为0.589,始终未超过0.600。本次实验的测试集正确率很低,便考虑到可能是出现预测失衡的原因,因此在具体类别的分类情况上用召回率来衡量更合适。将四个类别的分类召回率进行统计,发现车和人脸的分类效果十分好,最高可以分别达到0.758和0.848,HoG特征与SVM的结合之所以对这两类数据分类有较好的结果是因为HoG特征有对光照的不敏感,即使存在部分遮挡也可检测出来、能够反映人体的轮廓，并且它对图像中的人体的亮度和颜色变化不敏感的优点,因此HoG特征适合行人检测和车俩检测等领域。而本次实验对狗和蛇的分类性能很差,最高分别只有0.354和0.467,原因可能是HoG无法从含有狗和蛇的图片中有效提取它们的梯度和梯度方向,是否可以通过对图片的预处理比如裁剪操作来提高精度,还需要后续的实验。</p>
<p><center>参考文献</center></p>

<p> [1] Dalal N ,  Triggs B . Histograms of Oriented Gradients for Human Detection[C]// IEEE Computer Society Conference on Computer Vision &amp; Pattern Recognition. IEEE, 2005.<br>[2] Ojala T ,  Pietikainen M ,  Maenpaa T . Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns[C]// IEEE Transactions on Pattern Analysis and Machine Intelligence. IEEE, 2002:971-987.<br>[3] Papageorgiou C P ,  Oren M ,  Poggio T . General framework for object detection[C]// Computer Vision, 1998. Sixth International Conference on. IEEE, 1998.</p>
<p><strong><em>代码</em></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line">%matplotlib</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HoG</span>(<span class="title class_ inherited__">object</span>) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img, cell_w, bin_count</span>) :</span><br><span class="line">        rows, cols = img.shape</span><br><span class="line">        img = np.power(img / <span class="number">255.0</span>, <span class="number">2.2</span>) * <span class="number">255</span></span><br><span class="line">        self.img = img</span><br><span class="line">        self.cell_w = cell_w</span><br><span class="line">        self.bin_count = bin_count</span><br><span class="line">        self.angle_unit = <span class="number">180.0</span> / bin_count</span><br><span class="line">        self.cell_x = <span class="built_in">int</span>(rows / cell_w)</span><br><span class="line">        self.cell_y = <span class="built_in">int</span>(cols / cell_w)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#求每个像素的x和y方向的梯度值和梯度方向</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Pixel_gradient</span>(<span class="params">self</span>) :</span><br><span class="line">        gradient_values_x = cv.Sobel(self.img, cv.CV_64F, <span class="number">1</span>, <span class="number">0</span>, ksize = <span class="number">5</span>)<span class="comment">#x方向梯度</span></span><br><span class="line">        gradient_values_y = cv.Sobel(self.img, cv.CV_64F, <span class="number">0</span>, <span class="number">1</span>, ksize = <span class="number">5</span>)<span class="comment">#y方向梯度</span></span><br><span class="line">        gradient_magnitude = np.sqrt(np.power(gradient_values_x, <span class="number">2</span>) + np.power(gradient_values_y, <span class="number">2</span>))<span class="comment">#计算总梯度</span></span><br><span class="line"><span class="comment">#         gradient_angle = cv.phase(gradient_values_x, gradient_values_y, angleInDegrees=True)#计算梯度方向</span></span><br><span class="line">        gradient_angle = np.arctan2( gradient_values_x, gradient_values_y )</span><br><span class="line">        gradient_angle[ gradient_angle &gt; <span class="number">0</span> ] *= <span class="number">180</span> / <span class="number">3.14</span></span><br><span class="line">        gradient_angle[ gradient_angle &lt; <span class="number">0</span> ] = ( gradient_angle[ gradient_angle &lt; <span class="number">0</span> ] + <span class="number">3.14</span> ) * <span class="number">180</span> / <span class="number">3.14</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> gradient_magnitude, gradient_angle</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#求每个cell的x和y方向的梯度值和梯度方向</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Cell_gradient</span>(<span class="params">self, gradient</span>) :</span><br><span class="line">        cell = np.zeros((self.cell_x, self.cell_y, self.cell_w, self.cell_w))</span><br><span class="line">        gradient_x = np.split(gradient, self.cell_x, axis = <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.cell_x) :</span><br><span class="line">            gradient_y = np.split(gradient_x[i], self.cell_y, axis = <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.cell_y) :</span><br><span class="line">                cell[i][j] = gradient_y[j]</span><br><span class="line">        <span class="keyword">return</span> cell</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#对每个梯度方向进行投票</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Get_bins</span>(<span class="params">self, cell_gradient, cell_angle</span>) :</span><br><span class="line">        bins = np.zeros((cell_gradient.shape[<span class="number">0</span>], cell_gradient.shape[<span class="number">1</span>], self.bin_count))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bins.shape[<span class="number">0</span>]) :</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(bins.shape[<span class="number">1</span>]) :</span><br><span class="line">                tmp_unit = np.zeros(self.bin_count)</span><br><span class="line">                cell_gradient_list = np.int8(cell_gradient[i][j].flatten())</span><br><span class="line">                cell_angle_list = cell_angle[i][j].flatten()</span><br><span class="line">                cell_angle_list = np.int8( cell_angle_list / self.angle_unit )<span class="comment">#0-9</span></span><br><span class="line">                cell_angle_list[ cell_angle_list &gt;=<span class="number">9</span> ] = <span class="number">0</span></span><br><span class="line"><span class="comment">#                 cell_angle_list = cell_angle_list.flatten()</span></span><br><span class="line"><span class="comment">#                 cell_angle_list = np.int8(cell_angle_list / self.angle_unit) % self.bin_count</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(cell_angle_list)) :</span><br><span class="line">                    tmp_unit[cell_angle_list[m]] += <span class="built_in">int</span>(cell_gradient_list[m])<span class="comment">#将梯度值作为投影的权值</span></span><br><span class="line">        </span><br><span class="line">                bins[i][j] = tmp_unit</span><br><span class="line">        <span class="keyword">return</span> bins </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#获取整幅图像的特征向量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Block_Vector</span>(<span class="params">self</span>) :</span><br><span class="line">        gradient_magnitude, gradient_angle = self.Pixel_gradient()</span><br><span class="line">        cell_gradient_values = self.Cell_gradient(gradient_magnitude)</span><br><span class="line">        cell_angle = self.Cell_gradient(gradient_angle)</span><br><span class="line">        bins = self.Get_bins(cell_gradient_values, cell_angle)</span><br><span class="line">        </span><br><span class="line">        block_vector = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.cell_x - <span class="number">1</span>) :</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(self.cell_y - <span class="number">1</span>) :</span><br><span class="line">                feature = []</span><br><span class="line">                feature.extend(bins[i][j])</span><br><span class="line">                feature.extend(bins[i + <span class="number">1</span>][j])</span><br><span class="line">                feature.extend(bins[i][j + <span class="number">1</span>])</span><br><span class="line">                feature.extend(bins[i + <span class="number">1</span>][j + <span class="number">1</span>])</span><br><span class="line">                </span><br><span class="line">                mag = <span class="keyword">lambda</span> vector : math.sqrt(<span class="built_in">sum</span>(i ** <span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> vector))</span><br><span class="line">                magnitude = mag(feature)</span><br><span class="line">                <span class="keyword">if</span> magnitude != <span class="number">0</span> :</span><br><span class="line">                    normalize = <span class="keyword">lambda</span> vector, magnitude: [element / magnitude <span class="keyword">for</span> element <span class="keyword">in</span> vector]</span><br><span class="line">                    feature = normalize(feature, magnitude)</span><br><span class="line">                    </span><br><span class="line">                block_vector.extend(feature)</span><br><span class="line">        <span class="keyword">return</span> np.array(block_vector)    </span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PCA</span>() :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_components</span>) :</span><br><span class="line">        self.n_components = n_components</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X</span>) :</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">deMean</span>(<span class="params">X</span>) :</span><br><span class="line">            <span class="keyword">return</span> X - np.mean(X, axis = <span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">calcCov</span>(<span class="params">X</span>) :</span><br><span class="line">            <span class="keyword">return</span> np.cov(X, rowvar = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">deEigenvalue</span>(<span class="params">cov</span>) :</span><br><span class="line">            <span class="keyword">return</span> np.linalg.eig(cov)</span><br><span class="line">        </span><br><span class="line">        n, self.d = X.shape</span><br><span class="line">        <span class="keyword">assert</span> self.n_components &lt;= self.d</span><br><span class="line">        <span class="keyword">assert</span> self.n_components &lt;= n</span><br><span class="line">        </span><br><span class="line">        X = deMean(X)</span><br><span class="line">        cov = calcCov(X) </span><br><span class="line">        eigenvalue, featurevector = deEigenvalue(cov)</span><br><span class="line">        index = np.argsort(eigenvalue)</span><br><span class="line">        n_index = index[-self.n_components : ]</span><br><span class="line">        self.w = featurevector[ : , n_index]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self, X</span>) :</span><br><span class="line">        n, d = X.shape</span><br><span class="line">        <span class="keyword">assert</span> d == self.d</span><br><span class="line">        <span class="keyword">return</span> np.dot(X, self.w)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataSet</span>(<span class="title class_ inherited__">object</span>) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root, division</span>) :</span><br><span class="line">        self.root = root</span><br><span class="line">        self.division = division</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">data_segmentation</span>(<span class="params">self, car, dog, face, snake</span>) :</span><br><span class="line">        <span class="comment">#将每一类图片分割成训练集和测试集，四种类分别设置标签是[1, 2, 3， 4]方便后续的性能评估</span></span><br><span class="line">        train_car, test_car = car[ : <span class="built_in">int</span>(car.shape[<span class="number">0</span>] * self.division)], car[<span class="built_in">int</span>(car.shape[<span class="number">0</span>] * self.division) : ]</span><br><span class="line">        train_car_target, test_car_target = np.full(<span class="built_in">len</span>(train_car) , <span class="number">1</span>, dtype = np.int64), np.full(<span class="built_in">len</span>(test_car) , <span class="number">1</span>, dtype = np.int64)</span><br><span class="line">        train_dog, test_dog = dog[ : <span class="built_in">int</span>(dog.shape[<span class="number">0</span>] * self.division)], dog[<span class="built_in">int</span>(dog.shape[<span class="number">0</span>] * self.division) : ]</span><br><span class="line">        train_dog_target, test_dog_target = np.full(<span class="built_in">len</span>(train_dog) , <span class="number">2</span>, dtype = np.int64), np.full(<span class="built_in">len</span>(test_dog) , <span class="number">2</span>, dtype = np.int64)</span><br><span class="line">        train_face, test_face = face[ : <span class="built_in">int</span>(face.shape[<span class="number">0</span>] * self.division)], face[<span class="built_in">int</span>(face.shape[<span class="number">0</span>] * self.division) : ]</span><br><span class="line">        train_face_target, test_face_target = np.full(<span class="built_in">len</span>(train_face) , <span class="number">3</span>, dtype = np.int64), np.full(<span class="built_in">len</span>(test_face) , <span class="number">3</span>, dtype = np.int64)</span><br><span class="line">        train_snake, test_snake = snake[ : <span class="built_in">int</span>(snake.shape[<span class="number">0</span>] * self.division)], snake[<span class="built_in">int</span>(snake.shape[<span class="number">0</span>] * self.division) : ]</span><br><span class="line">        train_snake_target, test_snake_target = np.full(<span class="built_in">len</span>(train_snake) , <span class="number">4</span>, dtype = np.int64), np.full(<span class="built_in">len</span>(test_snake) , <span class="number">4</span>, dtype = np.int64)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#将四类图片拼接成一个大的矩阵</span></span><br><span class="line">        train_data = np.concatenate([train_car, train_dog, train_face, train_snake])</span><br><span class="line">        test_data = np.concatenate([test_car, test_dog, test_face, test_snake])</span><br><span class="line">        train_target = np.concatenate([train_car_target, train_dog_target, train_face_target, train_snake_target])</span><br><span class="line">        test_target = np.concatenate([test_car_target, test_dog_target, test_face_target, test_snake_target])</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#以索引方式打乱训练集</span></span><br><span class="line">        index = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(train_data))]</span><br><span class="line">        random.shuffle(index)</span><br><span class="line">        train_data = train_data[index]</span><br><span class="line">        train_target = train_target[index]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> train_data, train_target, test_data, test_target</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">datasets</span>(<span class="params">self</span>) :</span><br><span class="line">        <span class="comment">#读取每类图片的名字</span></span><br><span class="line">        image_car = <span class="built_in">list</span>(<span class="built_in">sorted</span>(os.listdir(os.path.join(self.root, <span class="string">&#x27;car&#x27;</span>))))</span><br><span class="line">        image_dog = <span class="built_in">list</span>(<span class="built_in">sorted</span>(os.listdir(os.path.join(self.root, <span class="string">&#x27;dog&#x27;</span>))))</span><br><span class="line">        image_face = <span class="built_in">list</span>(<span class="built_in">sorted</span>(os.listdir(os.path.join(self.root, <span class="string">&#x27;face&#x27;</span>))))</span><br><span class="line">        image_snake = <span class="built_in">list</span>(<span class="built_in">sorted</span>(os.listdir(os.path.join(self.root, <span class="string">&#x27;snake&#x27;</span>))))</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#储存图片</span></span><br><span class="line">        car = np.zeros((<span class="number">4000</span>, <span class="number">256</span>, <span class="number">256</span>), dtype = np.uint8)</span><br><span class="line">        dog = np.zeros((<span class="number">4000</span>, <span class="number">256</span>, <span class="number">256</span>), dtype = np.uint8)</span><br><span class="line">        face = np.zeros((<span class="number">4000</span>, <span class="number">256</span>, <span class="number">256</span>), dtype = np.uint8)</span><br><span class="line">        snake = np.zeros((<span class="number">4000</span>, <span class="number">256</span>, <span class="number">256</span>), dtype = np.uint8)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#读取车、狗、人脸、蛇的图片，进行resize至256 * 256</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4000</span>) :</span><br><span class="line">            img = cv.imread(os.path.join(self.root, <span class="string">&#x27;car&#x27;</span>, image_car[i]), cv.IMREAD_GRAYSCALE)</span><br><span class="line">            img = cv.resize(img, (<span class="number">256</span>, <span class="number">256</span>), cv.INTER_CUBIC)</span><br><span class="line">            car[i] = img</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4000</span>) :</span><br><span class="line">            img = cv.imread(os.path.join(self.root, <span class="string">&#x27;dog&#x27;</span>, image_dog[i]), cv.IMREAD_GRAYSCALE)</span><br><span class="line">            img = cv.resize(img, (<span class="number">256</span>, <span class="number">256</span>), cv.INTER_CUBIC)</span><br><span class="line">            dog[i] = img    </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4000</span>) :</span><br><span class="line">            img = cv.imread(os.path.join(self.root, <span class="string">&#x27;face&#x27;</span>, image_face[i]), cv.IMREAD_GRAYSCALE)</span><br><span class="line">            img = cv.resize(img, (<span class="number">256</span>, <span class="number">256</span>), cv.INTER_CUBIC)</span><br><span class="line">            face[i] = img</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4000</span>) :</span><br><span class="line">            img = cv.imread(os.path.join(self.root, <span class="string">&#x27;snake&#x27;</span>, image_snake[i]), cv.IMREAD_GRAYSCALE)</span><br><span class="line">            img = cv.resize(img, (<span class="number">256</span>, <span class="number">256</span>), cv.INTER_CUBIC)</span><br><span class="line">            snake[i] = img</span><br><span class="line">        <span class="built_in">print</span>(car.shape, dog.shape, face.shape, snake.shape)</span><br><span class="line">        <span class="comment">#分割</span></span><br><span class="line">        train_data, train_target, test_data, test_target = self.data_segmentation(car, dog, face, snake)</span><br><span class="line">        <span class="keyword">return</span> train_data, train_target, test_data, test_target</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">micro_f1</span>(<span class="params">pred, target</span>) :</span><br><span class="line">    <span class="comment">#第一类</span></span><br><span class="line">    target1 = target.copy()</span><br><span class="line">    pred1 = pred.copy()</span><br><span class="line">    target1 = target1 == <span class="number">1</span></span><br><span class="line">    pred1 = pred1 == <span class="number">1</span></span><br><span class="line">    TP1 = np.<span class="built_in">sum</span>(target1[pred1 == <span class="number">1</span>] == <span class="number">1</span>)</span><br><span class="line">    FN1 = np.<span class="built_in">sum</span>(target1[pred1 == <span class="number">0</span>] == <span class="number">1</span>)</span><br><span class="line">    FP1 = np.<span class="built_in">sum</span>(target1[pred1 == <span class="number">1</span>] == <span class="number">0</span>)</span><br><span class="line">    TN1 = np.<span class="built_in">sum</span>(target1[pred1 == <span class="number">0</span>] == <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#第二类</span></span><br><span class="line">    target2 = target.copy()</span><br><span class="line">    pred2 = pred.copy()</span><br><span class="line">    target2 = target2 == <span class="number">2</span></span><br><span class="line">    pred2 = pred2 == <span class="number">2</span></span><br><span class="line">    TP2 = np.<span class="built_in">sum</span>(target2[pred2 == <span class="number">1</span>] == <span class="number">1</span>)</span><br><span class="line">    FN2 = np.<span class="built_in">sum</span>(target2[pred2 == <span class="number">0</span>] == <span class="number">1</span>)</span><br><span class="line">    FP2 = np.<span class="built_in">sum</span>(target2[pred2 == <span class="number">1</span>] == <span class="number">0</span>)</span><br><span class="line">    TN2 = np.<span class="built_in">sum</span>(target2[pred2 == <span class="number">0</span>] == <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#第三类</span></span><br><span class="line">    target3 = target.copy()</span><br><span class="line">    pred3 = pred.copy()</span><br><span class="line">    target3 = target3 == <span class="number">3</span></span><br><span class="line">    pred3 = pred3 == <span class="number">3</span></span><br><span class="line">    TP3 = np.<span class="built_in">sum</span>(target3[pred3 == <span class="number">1</span>] == <span class="number">1</span>)</span><br><span class="line">    FN3 = np.<span class="built_in">sum</span>(target3[pred3 == <span class="number">0</span>] == <span class="number">1</span>)</span><br><span class="line">    FP3 = np.<span class="built_in">sum</span>(target3[pred3 == <span class="number">1</span>] == <span class="number">0</span>)</span><br><span class="line">    TN3 = np.<span class="built_in">sum</span>(target3[pred3 == <span class="number">0</span>] == <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#第四类</span></span><br><span class="line">    target4 = target.copy()</span><br><span class="line">    pred4 = pred.copy()</span><br><span class="line">    target4 = target4 == <span class="number">4</span></span><br><span class="line">    pred4 = pred4 == <span class="number">4</span></span><br><span class="line">    TP4 = np.<span class="built_in">sum</span>(target4[pred4 == <span class="number">1</span>] == <span class="number">1</span>)</span><br><span class="line">    FN4 = np.<span class="built_in">sum</span>(target4[pred4 == <span class="number">0</span>] == <span class="number">1</span>)</span><br><span class="line">    FP4 = np.<span class="built_in">sum</span>(target4[pred4 == <span class="number">1</span>] == <span class="number">0</span>)</span><br><span class="line">    TN4 = np.<span class="built_in">sum</span>(target4[pred4 == <span class="number">0</span>] == <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    TP = TP1 + TP2 + TP3 + TP4</span><br><span class="line">    FN = FN1 + FN2 + FN3 + FN4</span><br><span class="line">    FP = FP1 + FP2 + FP3 + FP4</span><br><span class="line">    TN = TN1 + TN2 + TN3 + TN4</span><br><span class="line">    </span><br><span class="line">    precision = TP / (TP + FP)</span><br><span class="line">    recall = TP / (TP + FN)</span><br><span class="line">    f1 = <span class="number">2</span> * precision * recall / (precision + recall) </span><br><span class="line">    </span><br><span class="line">    confusion_matrix =np.array([[np.<span class="built_in">sum</span>(pred[target == <span class="number">1</span>] == <span class="number">1</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">1</span>] == <span class="number">2</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">1</span>] == <span class="number">3</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">1</span>] == <span class="number">4</span>)],</span><br><span class="line">                                [np.<span class="built_in">sum</span>(pred[target == <span class="number">2</span>] == <span class="number">1</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">2</span>] == <span class="number">2</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">2</span>] == <span class="number">3</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">2</span>] == <span class="number">4</span>)],</span><br><span class="line">                                [np.<span class="built_in">sum</span>(pred[target == <span class="number">3</span>] == <span class="number">1</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">3</span>] == <span class="number">2</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">3</span>] == <span class="number">3</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">3</span>] == <span class="number">4</span>)],</span><br><span class="line">                                [np.<span class="built_in">sum</span>(pred[target == <span class="number">4</span>] == <span class="number">1</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">4</span>] == <span class="number">2</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">4</span>] == <span class="number">3</span>), np.<span class="built_in">sum</span>(pred[target == <span class="number">4</span>] == <span class="number">4</span>)]])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> precision, recall, f1, TP1, TP2, TP3, TP4, confusion_matrix</span><br><span class="line"></span><br><span class="line">dataset = DataSet(root = <span class="string">&#x27;data&#x27;</span>, division = <span class="number">0.875</span>)</span><br><span class="line">train_data, train_target, test_data, test_target = dataset.datasets()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制混淆矩阵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_confusion_matrix</span>(<span class="params">cm, classes, title = <span class="string">&#x27;Confusion matrix&#x27;</span>, cmap = plt.cm.Blues</span>):</span><br><span class="line">    plt.imshow(cm, interpolation=<span class="string">&#x27;nearest&#x27;</span>, cmap = cmap)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.colorbar()</span><br><span class="line">    tick_marks = np.arange(<span class="built_in">len</span>(classes))</span><br><span class="line">    plt.xticks(tick_marks, classes)</span><br><span class="line">    plt.yticks(tick_marks, classes)</span><br><span class="line">    thresh = cm.<span class="built_in">max</span>() / <span class="number">2.</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(cm.shape[<span class="number">0</span>]) :</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cm.shape[<span class="number">1</span>]) :</span><br><span class="line">            plt.text(j, i, <span class="string">f&#x27;<span class="subst">&#123;cm[i][j]&#125;</span>&#x27;</span>, horizontalalignment=<span class="string">&quot;center&quot;</span>, color=<span class="string">&quot;white&quot;</span> <span class="keyword">if</span> cm[i][j] &gt; thresh <span class="keyword">else</span> <span class="string">&quot;black&quot;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;True label&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line"><span class="comment"># print(train_data.shape, train_target.shape, test_data.shape, test_target.shape)</span></span><br><span class="line"><span class="comment"># print(test_target, train_target)</span></span><br><span class="line"><span class="comment">#HoG特征获取</span></span><br><span class="line">train_feature = []</span><br><span class="line">test_feature = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(train_data)) :</span><br><span class="line">    hog = HoG(train_data[i], <span class="number">32</span>, <span class="number">9</span>)</span><br><span class="line">    temp_feature = hog.Block_Vector()</span><br><span class="line">    train_feature.append(temp_feature)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_data)) :</span><br><span class="line">    hog = HoG(test_data[i], <span class="number">32</span>, <span class="number">9</span>)</span><br><span class="line">    temp_feature = hog.Block_Vector()</span><br><span class="line">    test_feature.append(temp_feature)</span><br><span class="line"></span><br><span class="line">train_feature = np.array(train_feature)</span><br><span class="line">test_feature = np.array(test_feature)</span><br><span class="line"><span class="comment"># print(train_feature.shape, test_feature.shape)</span></span><br><span class="line"><span class="comment">#PCA降维</span></span><br><span class="line">pca = PCA(n_components = <span class="number">704</span>)</span><br><span class="line">pca.fit(train_feature)</span><br><span class="line">train_reduction = pca.transform(train_feature)</span><br><span class="line">test_reduction = pca.transform(test_feature)</span><br><span class="line"><span class="built_in">print</span>(train_reduction.shape)</span><br><span class="line"><span class="built_in">print</span>(test_reduction.shape)</span><br><span class="line"><span class="comment">#模型训练和预测</span></span><br><span class="line">clf = svm.SVC()</span><br><span class="line">clf.fit(train_reduction, train_target)</span><br><span class="line"><span class="built_in">print</span>(clf.score(test_reduction, test_target))</span><br><span class="line"><span class="built_in">print</span>(clf.score(train_reduction, train_target))</span><br><span class="line">pred = clf.predict(test_reduction)</span><br><span class="line">precision, recall, f1, TP1, TP2, TP3, TP4, confusion_matrix = micro_f1(pred, test_target)</span><br><span class="line"><span class="built_in">print</span>( precision, recall, f1, TP1, TP2, TP3, TP4, confusion_matrix)</span><br><span class="line"><span class="comment">#绘制混淆矩阵</span></span><br><span class="line">plot_confusion_matrix(cm = confusion_matrix, classes = [<span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;face&#x27;</span>, <span class="string">&#x27;snake&#x27;</span>])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>图像分类</tag>
        <tag>HOG</tag>
        <tag>特征提取</tag>
      </tags>
  </entry>
  <entry>
    <title>Adult 数据集分析及四种模型实现</title>
    <url>/2022/06/05/Adult-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%86%E6%9E%90%E5%8F%8A%E5%9B%9B%E7%A7%8D%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="一、数据集"><a href="#一、数据集" class="headerlink" title="一、数据集"></a>一、数据集</h1><h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><p>Adult数据集是一个经典的数据挖掘项目的的数据集，该数据从美国1994年人口普查数据库中抽取而来，因此也称作“人口普查收入”数据集，共包含48842条记录，年收入大于 50k 的占比23.93%年收入小于 50k 的占比76.07%，数据集已经划分为训练数据32561条和测试数据16281条。该数据集类变量为年收入是否超过 50k ，属性变量包括年龄、工种、学历、职业等14类重要信息，其中有8类属于类别离散型变量，另外6类属于数值连续型变量。该数据集是一个分类数据集，用来预测年收入是否超过50k。下载地址<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/">点这里</a>。<br><img src="https://img-blog.csdnimg.cn/f8c920dc998447a291c4f6636dedef53.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/f836e82e69cd4328a60298deab1d6b67.png" alt="在这里插入图片描述"></p>
<h2 id="数据集预处理及分析"><a href="#数据集预处理及分析" class="headerlink" title="数据集预处理及分析"></a>数据集预处理及分析</h2><p>因为是csv数据，所以主要采用pandas和numpy库来进行预处理，首先数据读取以及查看是否有缺失：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;adult.csv&#x27;</span>, header = <span class="literal">None</span>, names = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;fnlwgt&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>,  <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;capital-gain&#x27;</span>, <span class="string">&#x27;capital-loss&#x27;</span>, <span class="string">&#x27;hours-per-week&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>, <span class="string">&#x27;income&#x27;</span>])</span><br><span class="line">df.head()</span><br><span class="line">df.info()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/c01c6b52f812443e94e7cde5f41d2fcf.png" alt="在这里插入图片描述"><br>虽然上面查看数据是没有缺失值的，但其实是因为缺失值的是” ?”，而info()检测的是NaT或者Nan的缺失值。注意问号前面还有空格。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.apply(<span class="keyword">lambda</span> x : np.<span class="built_in">sum</span>(x == <span class="string">&quot; ?&quot;</span>))</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/2150770204c94f58a9806104e990b98f.png" alt="在这里插入图片描述"><br>分别是居民的工作类型workclass（离散型）缺1836、职业occupation（离散型）缺1843和国籍native-country（离散型)缺583。离散值一般填充众数，但是在此之前要先将缺失值转化成nan或者NaT。同时因为收入可以分为两种类型，则将&gt;50K的替换成1，&lt;=50K的替换成0。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.replace(<span class="string">&quot; ?&quot;</span>, pd.NaT, inplace = <span class="literal">True</span>)</span><br><span class="line">df.replace(<span class="string">&quot; &gt;50K&quot;</span>, <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">df.replace(<span class="string">&quot; &lt;=50K&quot;</span>, <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">trans = &#123;<span class="string">&#x27;workclass&#x27;</span> : df[<span class="string">&#x27;workclass&#x27;</span>].mode()[<span class="number">0</span>], <span class="string">&#x27;occupation&#x27;</span> : df[<span class="string">&#x27;occupation&#x27;</span>].mode()[<span class="number">0</span>], <span class="string">&#x27;native-country&#x27;</span> : df[<span class="string">&#x27;native-country&#x27;</span>].mode()[<span class="number">0</span>]&#125;</span><br><span class="line">df.fillna(trans, inplace = <span class="literal">True</span>)</span><br><span class="line">df.describe()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/ea9b9fcacbad4891b1a0a2027c344ac6.png" alt="在这里插入图片描述"><br>由上表可知，75%以上的人是没有资本收益和资本输出的，所以这两列是属于无关属性的，此外还包括序号列，应删除这三列。所以我们只需关注这三列之外的数据即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.drop(<span class="string">&#x27;fnlwgt&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">df.drop(<span class="string">&#x27;capital-gain&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">df.drop(<span class="string">&#x27;capital-loss&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/cf2d1072b2ad4d4ab88ce9eb8d06c96d.png" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.scatter(df[<span class="string">&quot;income&quot;</span>], df[<span class="string">&quot;age&quot;</span>])</span><br><span class="line">plt.grid(b = <span class="literal">True</span>, which = <span class="string">&quot;major&quot;</span>, axis = <span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Income distribution by age (1 is &gt;50K)&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/0206fafefe1543feb5a484bd6746363a.png" alt="在这里插入图片描述"><br>能看出对于中高年龄的人来说收入&gt;50K是比&lt;=50K的少。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&quot;workclass&quot;</span>].value_counts()</span><br><span class="line"></span><br><span class="line">income_0 = df[<span class="string">&quot;workclass&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[<span class="string">&quot;workclass&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&quot; &gt;50K&quot;</span> : income_1, <span class="string">&quot; &lt;=50K&quot;</span> : income_0&#125;)</span><br><span class="line">df1.plot(kind = <span class="string">&#x27;bar&#x27;</span>, stacked = <span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&quot;income distribution by Workclass&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;workclass&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;number of person&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/39f0c148721948ad873132c0f3fbf369.png" alt="在这里插入图片描述"><br>观察工作类型对年收入的影响。工作类别为Private的人在两种年收入中都是最多的，但是&gt;50K和&lt;=50K的比例最高的是Self-emp-inc。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df1 = df[<span class="string">&quot;hours-per-week&quot;</span>].groupby(df[<span class="string">&quot;workclass&quot;</span>]).agg([<span class="string">&#x27;mean&#x27;</span>,<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>])</span><br><span class="line">df1.sort_values(by = <span class="string">&#x27;mean&#x27;</span>, ascending = <span class="literal">False</span>)</span><br><span class="line">df1</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/d002e268383d4b6d8548777969aaeba1.png" alt="在这里插入图片描述"><br>用工作类别对每周工作时间进行分组，计算每组的均值，最大、小值，并且按均值进行排序。能看出工作类别是Federal-gov的人平均工作时间最长，但其的高收入占比并不是最高的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">income_0 = df[<span class="string">&quot;education&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[<span class="string">&quot;education&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&quot; &gt;50K&quot;</span> : income_1, <span class="string">&quot; &lt;=50K&quot;</span> : income_0&#125;)</span><br><span class="line">df1.plot(kind = <span class="string">&#x27;bar&#x27;</span>, stacked = <span class="literal">True</span>)</span><br><span class="line">plt.title(<span class="string">&quot;income distribution by Workclass&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;education&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;number of person&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/3e29faaf457b4a219b78bd23d824042b.png" alt="在这里插入图片描述"><br>统计受教育程度对年收入的影响，对于程度是Bachelors来说，两种收入的人数是比较接近的，收入比也是最大的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">income_0 = df[<span class="string">&quot;education-num&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>]</span><br><span class="line">income_1 = df[<span class="string">&quot;education-num&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>]</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&#x27; &gt;50K&#x27;</span> : income_1, <span class="string">&#x27; &lt;=50K&#x27;</span> : income_0&#125;)</span><br><span class="line">df1.plot(kind = <span class="string">&#x27;kde&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;education of income&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;education-num&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/e9b3bec32ed744faa009e8d4d8aa8b4f.png" alt="在这里插入图片描述"><br>统计受教育时间对收入的影响的概率密度图。大约在时间的中值的时段，收入&gt;50K的人是比&lt;=50K的概率要低一些，而在中值偏右的时段是相反的，在其余时段，两种收入大约是处于平衡的状态。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fig, ([[ax1, ax2, ax3], [ax4, ax5, ax6]]) = plt.subplots(2, 3, figsize=(15, 10))</span></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">231</span>) </span><br><span class="line">income_0 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; White&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; White&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&#x27; &gt;50K&#x27;</span> : income_1, <span class="string">&#x27; &lt;=50K&#x27;</span> : income_0&#125;)</span><br><span class="line">df1.plot(kind = <span class="string">&#x27;bar&#x27;</span>, ax = ax1)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;number of person&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;income of relationship by race_White&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">232</span>) </span><br><span class="line">income_0 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; Black&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; Black&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df2 = pd.DataFrame(&#123;<span class="string">&#x27; &gt;50K&#x27;</span> : income_1, <span class="string">&#x27; &lt;=50K&#x27;</span> : income_0&#125;)</span><br><span class="line">df2.plot(kind = <span class="string">&#x27;bar&#x27;</span>, ax = ax2)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;number of person&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;income of relationship by race_Black&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax3 = fig.add_subplot(<span class="number">233</span>) </span><br><span class="line">income_0 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; Asian-Pac-Islander&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; Asian-Pac-Islander&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df3 = pd.DataFrame(&#123;<span class="string">&#x27; &gt;50K&#x27;</span> : income_1, <span class="string">&#x27; &lt;=50K&#x27;</span> : income_0&#125;)</span><br><span class="line">df3.plot(kind = <span class="string">&#x27;bar&#x27;</span>, ax = ax3)</span><br><span class="line">ax3.set_ylabel(<span class="string">&#x27;number of person&#x27;</span>)</span><br><span class="line">ax3.set_title(<span class="string">&#x27;income of relationship by race_Asian-Pac-Islander&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax4 = fig.add_subplot(<span class="number">234</span>) </span><br><span class="line">income_0 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; Amer-Indian-Eskimo&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; Amer-Indian-Eskimo&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df4 = pd.DataFrame(&#123;<span class="string">&#x27; &gt;50K&#x27;</span> : income_1, <span class="string">&#x27; &lt;=50K&#x27;</span> : income_0&#125;)</span><br><span class="line">df4.plot(kind = <span class="string">&#x27;bar&#x27;</span>, ax = ax4)</span><br><span class="line">ax4.set_ylabel(<span class="string">&#x27;number of person&#x27;</span>)</span><br><span class="line">ax4.set_title(<span class="string">&#x27;income of relationship by race_Amer-Indian-Eskimo&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax5 = fig.add_subplot(<span class="number">235</span>) </span><br><span class="line">income_0 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; Other&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[df[<span class="string">&quot;race&quot;</span>] == <span class="string">&#x27; Other&#x27;</span>][<span class="string">&quot;relationship&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df5 = pd.DataFrame(&#123;<span class="string">&#x27; &gt;50K&#x27;</span> : income_1, <span class="string">&#x27; &lt;=50K&#x27;</span> : income_0&#125;)</span><br><span class="line">df5.plot(kind = <span class="string">&#x27;bar&#x27;</span>, ax = ax5)</span><br><span class="line">ax5.set_ylabel(<span class="string">&#x27;number of person&#x27;</span>)</span><br><span class="line">ax5.set_title(<span class="string">&#x27;income of relationship by race_Other&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/3a6aa0d93f3c48199bbf24d418d7ac9e.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/c685ffc9d0bf4dc68c4e5acd0be849f6.png" alt="在这里插入图片描述"><br>这里主要是做了不同种族扮演的社会角色的收入状况。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fig, ([[ax1, ax2, ax3], [ax4, ax5, ax6]]) = plt.subplots(2, 3, figsize=(10, 5))</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">121</span>) </span><br><span class="line">income_0 = df[df[<span class="string">&quot;sex&quot;</span>] == <span class="string">&#x27; Male&#x27;</span>][<span class="string">&quot;occupation&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[df[<span class="string">&quot;sex&quot;</span>] == <span class="string">&#x27; Male&#x27;</span>][<span class="string">&quot;occupation&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df1 = pd.DataFrame(&#123;<span class="string">&#x27; &gt;50K&#x27;</span> : income_1, <span class="string">&#x27; &lt;=50K&#x27;</span> : income_0&#125;)</span><br><span class="line">df1.plot(kind = <span class="string">&#x27;bar&#x27;</span>, ax = ax1)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;number of person&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;income of occupation by sex_Male&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">122</span>) </span><br><span class="line">income_0 = df[df[<span class="string">&quot;sex&quot;</span>] == <span class="string">&#x27; Female&#x27;</span>][<span class="string">&quot;occupation&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">0</span>].value_counts()</span><br><span class="line">income_1 = df[df[<span class="string">&quot;sex&quot;</span>] == <span class="string">&#x27; Female&#x27;</span>][<span class="string">&quot;occupation&quot;</span>][df[<span class="string">&quot;income&quot;</span>] == <span class="number">1</span>].value_counts()</span><br><span class="line">df2 = pd.DataFrame(&#123;<span class="string">&#x27; &gt;50K&#x27;</span> : income_1, <span class="string">&#x27; &lt;=50K&#x27;</span> : income_0&#125;)</span><br><span class="line">df2.plot(kind = <span class="string">&#x27;bar&#x27;</span>, ax = ax2)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;number of person&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;income of occupation by sex_Female&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/e6a6b90390384671b67b8b757f0ef48d.png" alt="在这里插入图片描述"><br>这里主要是做了不同性别的职业的收入状况。在男性中，职业为Exec-managerial的人中，收入&gt;50K的人要比&lt;=50K的人要多，而这种情况在女性中刚好相反。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_object_col = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> df[col].dtype.name == <span class="string">&#x27;object&#x27;</span>]</span><br><span class="line">df_int_col = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> df[col].dtype.name != <span class="string">&#x27;object&#x27;</span> <span class="keyword">and</span> col != <span class="string">&#x27;income&#x27;</span>]</span><br><span class="line">target = df[<span class="string">&quot;income&quot;</span>]</span><br><span class="line">dataset = pd.concat([df[df_int_col], pd.get_dummies(df[df_object_col])], axis = <span class="number">1</span>)</span><br><span class="line">dataset.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/d2d184c6574a456399f59b6c06b1c35b.png" alt="在这里插入图片描述"><br>先对数据类型进行统计，对非数值型的数据进行独热编码，再将两者进行拼接。最后将收入与其他数据分开分别作为标签和训练集或者测试集。</p>
<h1 id="二、四种模型对上述数据集进行预测"><a href="#二、四种模型对上述数据集进行预测" class="headerlink" title="二、四种模型对上述数据集进行预测"></a>二、四种模型对上述数据集进行预测</h1><h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p><em>导入相关包</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br></pre></td></tr></table></figure>
<p>数据预处理，要注意的是训练集和测试集进行独热编码之后可能形状不一样，所以要将他们进行配对；再者是因为我们要给缺失某列的数据进行增加全为零的列，奇怪的是当从DataFrame类型转到Numpy类型时全为零的列会全部变成nan，所以还要重新nan的列转成零。否则在预测的过程网络的输出会全部为nan。本次实验将训练集进行2 : 8的数据划分，2份作为验证集。且要对数据集进行归一化，效果会好很多。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_missing_columns</span>(<span class="params">d, columns</span>) :</span><br><span class="line">    missing_col = <span class="built_in">set</span>(columns) - <span class="built_in">set</span>(d.columns)</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> missing_col :</span><br><span class="line">        d[col] = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fix_columns</span>(<span class="params">d, columns</span>):  </span><br><span class="line">    add_missing_columns(d, columns)</span><br><span class="line">    <span class="keyword">assert</span>(<span class="built_in">set</span>(columns) - <span class="built_in">set</span>(d.columns) == <span class="built_in">set</span>())</span><br><span class="line">    d = d[columns]</span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_process</span>(<span class="params">df, model</span>) :</span><br><span class="line">    df.replace(<span class="string">&quot; ?&quot;</span>, pd.NaT, inplace = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> model == <span class="string">&#x27;train&#x27;</span> :</span><br><span class="line">        df.replace(<span class="string">&quot; &gt;50K&quot;</span>, <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        df.replace(<span class="string">&quot; &lt;=50K&quot;</span>, <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> model == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        df.replace(<span class="string">&quot; &gt;50K.&quot;</span>, <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        df.replace(<span class="string">&quot; &lt;=50K.&quot;</span>, <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">    trans = &#123;<span class="string">&#x27;workclass&#x27;</span> : df[<span class="string">&#x27;workclass&#x27;</span>].mode()[<span class="number">0</span>], <span class="string">&#x27;occupation&#x27;</span> : df[<span class="string">&#x27;occupation&#x27;</span>].mode()[<span class="number">0</span>], <span class="string">&#x27;native-country&#x27;</span> : df[<span class="string">&#x27;native-country&#x27;</span>].mode()[<span class="number">0</span>]&#125;</span><br><span class="line">    df.fillna(trans, inplace = <span class="literal">True</span>)</span><br><span class="line">    df.drop(<span class="string">&#x27;fnlwgt&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">    df.drop(<span class="string">&#x27;capital-gain&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">    df.drop(<span class="string">&#x27;capital-loss&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    df_object_col = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> df[col].dtype.name == <span class="string">&#x27;object&#x27;</span>]</span><br><span class="line">    df_int_col = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> df[col].dtype.name != <span class="string">&#x27;object&#x27;</span> <span class="keyword">and</span> col != <span class="string">&#x27;income&#x27;</span>]</span><br><span class="line">    target = df[<span class="string">&quot;income&quot;</span>]</span><br><span class="line">    dataset = pd.concat([df[df_int_col], pd.get_dummies(df[df_object_col])], axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> target, dataset</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Adult_data</span>(<span class="title class_ inherited__">Dataset</span>) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model</span>) :</span><br><span class="line">        <span class="built_in">super</span>(Adult_data, self).__init__()</span><br><span class="line">        self.model = model</span><br><span class="line">        </span><br><span class="line">        df_train = pd.read_csv(<span class="string">&#x27;adult.csv&#x27;</span>, header = <span class="literal">None</span>, names = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;fnlwgt&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>,  <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;capital-gain&#x27;</span>, <span class="string">&#x27;capital-loss&#x27;</span>, <span class="string">&#x27;hours-per-week&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>, <span class="string">&#x27;income&#x27;</span>])</span><br><span class="line">        df_test = pd.read_csv(<span class="string">&#x27;data.test&#x27;</span>, header = <span class="literal">None</span>, skiprows = <span class="number">1</span>, names = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;fnlwgt&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>,  <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;capital-gain&#x27;</span>, <span class="string">&#x27;capital-loss&#x27;</span>, <span class="string">&#x27;hours-per-week&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>, <span class="string">&#x27;income&#x27;</span>])</span><br><span class="line">        </span><br><span class="line">        train_target, train_dataset = data_process(df_train, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">        test_target, test_dataset = data_process(df_test, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="comment">#         进行独热编码对齐</span></span><br><span class="line">        test_dataset = fix_columns(test_dataset, train_dataset.columns)</span><br><span class="line"><span class="comment">#         print(df[&quot;income&quot;])</span></span><br><span class="line">        train_dataset = train_dataset.apply(<span class="keyword">lambda</span> x : (x - x.mean()) / x.std())</span><br><span class="line">        test_dataset = test_dataset.apply(<span class="keyword">lambda</span> x : (x - x.mean()) / x.std())</span><br><span class="line"><span class="comment">#         print(train_dataset[&#x27;native-country_ Holand-Netherlands&#x27;])</span></span><br><span class="line">        </span><br><span class="line">        train_target, test_target = np.array(train_target), np.array(test_target)</span><br><span class="line">        train_dataset, test_dataset = np.array(train_dataset, dtype = np.float32), np.array(test_dataset, dtype = np.float32)</span><br><span class="line">        <span class="keyword">if</span> model == <span class="string">&#x27;test&#x27;</span> :</span><br><span class="line">            isnan = np.isnan(test_dataset)</span><br><span class="line">            test_dataset[np.where(isnan)] = <span class="number">0.0</span></span><br><span class="line"><span class="comment">#             print(test_dataset[ : , 75])</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> model == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">            self.target = torch.tensor(test_target, dtype = torch.int64)</span><br><span class="line">            self.dataset = torch.FloatTensor(test_dataset)</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line"><span class="comment">#           前百分之八十的数据作为训练集，其余作为验证集</span></span><br><span class="line">            <span class="keyword">if</span> model == <span class="string">&#x27;train&#x27;</span> : </span><br><span class="line">                self.target = torch.tensor(train_target, dtype = torch.int64)[ : <span class="built_in">int</span>(<span class="built_in">len</span>(train_dataset) * <span class="number">0.8</span>)]</span><br><span class="line">                self.dataset = torch.FloatTensor(train_dataset)[ : <span class="built_in">int</span>(<span class="built_in">len</span>(train_target) * <span class="number">0.8</span>)]</span><br><span class="line">            <span class="keyword">else</span> :</span><br><span class="line">                self.target = torch.tensor(train_target, dtype = torch.int64)[<span class="built_in">int</span>(<span class="built_in">len</span>(train_target) * <span class="number">0.8</span>) : ] </span><br><span class="line">                self.dataset = torch.FloatTensor(train_dataset)[<span class="built_in">int</span>(<span class="built_in">len</span>(train_dataset) * <span class="number">0.8</span>) : ]</span><br><span class="line">        <span class="built_in">print</span>(self.dataset.shape, self.target.dtype)   </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>) :</span><br><span class="line">        <span class="keyword">return</span> self.dataset[item], self.target[item]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) :</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.dataset)</span><br><span class="line">    </span><br><span class="line">train_dataset = Adult_data(model = <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">val_dataset = Adult_data(model = <span class="string">&#x27;val&#x27;</span>)</span><br><span class="line">test_dataset = Adult_data(model = <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size = <span class="number">64</span>, shuffle = <span class="literal">True</span>, drop_last = <span class="literal">False</span>)</span><br><span class="line">val_loader = DataLoader(val_dataset, batch_size = <span class="number">64</span>, shuffle = <span class="literal">False</span>, drop_last = <span class="literal">False</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset, batch_size = <span class="number">64</span>, shuffle = <span class="literal">False</span>, drop_last = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>构建网络，因为是简单的二分类，这里使用了两层感知机网络，后面做对结果进行softmax归一化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Adult_Model</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) :</span><br><span class="line">        <span class="built_in">super</span>(Adult_Model, self).__init__()</span><br><span class="line">        self.net = nn.Sequential(nn.Linear(<span class="number">102</span>, <span class="number">64</span>), </span><br><span class="line">                                nn.ReLU(), </span><br><span class="line">                                nn.Linear(<span class="number">64</span>, <span class="number">32</span>), </span><br><span class="line">                                nn.ReLU(),</span><br><span class="line">                                nn.Linear(<span class="number">32</span>, <span class="number">2</span>)</span><br><span class="line">                                )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>) :</span><br><span class="line">        out = self.net(x) </span><br><span class="line"><span class="comment">#         print(out)</span></span><br><span class="line">        <span class="keyword">return</span> F.softmax(out)</span><br></pre></td></tr></table></figure>
<p>训练及验证，每经过一个epoch，就进行一次损失比较，当val_loss更小时，保存最好模型，直至迭代结束。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model = Adult_Model().to(device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr = <span class="number">0.001</span>, momentum = <span class="number">0.9</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">max_epoch = <span class="number">30</span></span><br><span class="line">classes = [<span class="string">&#x27; &lt;=50K&#x27;</span>, <span class="string">&#x27; &gt;50K&#x27;</span>]</span><br><span class="line">mse_loss = <span class="number">1000000</span></span><br><span class="line">os.makedirs(<span class="string">&#x27;MyModels&#x27;</span>, exist_ok = <span class="literal">True</span>)</span><br><span class="line">writer = SummaryWriter(log_dir = <span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(max_epoch) :</span><br><span class="line">    </span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line">    train_acc = <span class="number">0.0</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> x, label <span class="keyword">in</span> train_loader :</span><br><span class="line">        x, label = x.to(device), label.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        out = model(x)</span><br><span class="line">        loss = criterion(out, label)</span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">        loss.backward()</span><br><span class="line">        </span><br><span class="line">        _, pred = torch.<span class="built_in">max</span>(out, <span class="number">1</span>)</span><br><span class="line"><span class="comment">#         print(pred)</span></span><br><span class="line">        num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">        acc = num_correct / x.shape[<span class="number">0</span>]</span><br><span class="line">        train_acc += acc</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;epoch : <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>, train_loss : <span class="subst">&#123;train_loss / <span class="built_in">len</span>(train_loader.dataset)&#125;</span>, train_acc : <span class="subst">&#123;train_acc / <span class="built_in">len</span>(train_loader)&#125;</span>&#x27;</span>)</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, train_loss / <span class="built_in">len</span>(train_loader.dataset), epoch)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad() :</span><br><span class="line">        total_loss = []</span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">for</span> x, label <span class="keyword">in</span> val_loader :</span><br><span class="line">            x, label = x.to(device), label.to(device)</span><br><span class="line">            out = model(x)</span><br><span class="line">            loss = criterion(out, label)</span><br><span class="line">            total_loss.append(loss.item())</span><br><span class="line">        </span><br><span class="line">        val_loss = <span class="built_in">sum</span>(total_loss) / <span class="built_in">len</span>(total_loss)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> val_loss &lt; mse_loss :</span><br><span class="line">        mse_loss = val_loss </span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&#x27;MyModels/Deeplearning_Model.pth&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> model</span><br></pre></td></tr></table></figure>
<p>下载在训练过程保存的最好模型进行预测并保存结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_model = Adult_Model().to(device)</span><br><span class="line">ckpt = torch.load(<span class="string">&#x27;MyModels/Deeplearning_Model.pth&#x27;</span>, map_location=<span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">best_model.load_state_dict(ckpt)</span><br><span class="line"></span><br><span class="line">test_loss = <span class="number">0.0</span></span><br><span class="line">test_acc = <span class="number">0.0</span></span><br><span class="line">best_model.<span class="built_in">eval</span>()</span><br><span class="line">result = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x, label <span class="keyword">in</span> test_loader :</span><br><span class="line">    x, label = x.to(device), label.to(device)</span><br><span class="line">    </span><br><span class="line">    out = best_model(x)</span><br><span class="line">    loss = criterion(out, label)</span><br><span class="line">    test_loss += loss.item()</span><br><span class="line">    _, pred = torch.<span class="built_in">max</span>(out, dim = <span class="number">1</span>)</span><br><span class="line">    result.append(pred.detach())</span><br><span class="line">    num_correct = (pred == label).<span class="built_in">sum</span>().item()</span><br><span class="line">    acc = num_correct / x.shape[<span class="number">0</span>]</span><br><span class="line">    test_acc += acc</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;test_loss : <span class="subst">&#123;test_loss / <span class="built_in">len</span>(test_loader.dataset)&#125;</span>, test_acc : <span class="subst">&#123;test_acc / <span class="built_in">len</span>(test_loader)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">result = torch.cat(result, dim = <span class="number">0</span>).cpu().numpy()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;Predict/Deeplearing.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, newline = <span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> file :</span><br><span class="line">    writer = csv.writer(file)</span><br><span class="line">    writer.writerow([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;pred_result&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> i, pred <span class="keyword">in</span> <span class="built_in">enumerate</span>(result) :</span><br><span class="line">        writer.writerow([i, classes[pred]])</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/5f31fb9f77b649888e08068c28dd3185.png" alt="在这里插入图片描述"><br>正确率达到0.834还是蛮不错的。</p>
<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p>数据处理，跟深度学习的过程基本一致，只是返回值不一样而已。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier, export_graphviz</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_missing_columns</span>(<span class="params">d, columns</span>) :</span><br><span class="line">    missing_col = <span class="built_in">set</span>(columns) - <span class="built_in">set</span>(d.columns)</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> missing_col :</span><br><span class="line">        d[col] = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fix_columns</span>(<span class="params">d, columns</span>):  </span><br><span class="line">    add_missing_columns(d, columns)</span><br><span class="line">    <span class="keyword">assert</span>(<span class="built_in">set</span>(columns) - <span class="built_in">set</span>(d.columns) == <span class="built_in">set</span>())</span><br><span class="line">    d = d[columns]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_process</span>(<span class="params">df, model</span>) :</span><br><span class="line">    df.replace(<span class="string">&quot; ?&quot;</span>, pd.NaT, inplace = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> model == <span class="string">&#x27;train&#x27;</span> :</span><br><span class="line">        df.replace(<span class="string">&quot; &gt;50K&quot;</span>, <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        df.replace(<span class="string">&quot; &lt;=50K&quot;</span>, <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> model == <span class="string">&#x27;test&#x27;</span>:</span><br><span class="line">        df.replace(<span class="string">&quot; &gt;50K.&quot;</span>, <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">        df.replace(<span class="string">&quot; &lt;=50K.&quot;</span>, <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">    trans = &#123;<span class="string">&#x27;workclass&#x27;</span> : df[<span class="string">&#x27;workclass&#x27;</span>].mode()[<span class="number">0</span>], <span class="string">&#x27;occupation&#x27;</span> : df[<span class="string">&#x27;occupation&#x27;</span>].mode()[<span class="number">0</span>], <span class="string">&#x27;native-country&#x27;</span> : df[<span class="string">&#x27;native-country&#x27;</span>].mode()[<span class="number">0</span>]&#125;</span><br><span class="line">    df.fillna(trans, inplace = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    df.drop(<span class="string">&#x27;fnlwgt&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">    df.drop(<span class="string">&#x27;capital-gain&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line">    df.drop(<span class="string">&#x27;capital-loss&#x27;</span>, axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br><span class="line"><span class="comment">#         print(df)</span></span><br><span class="line"></span><br><span class="line">    df_object_col = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> df[col].dtype.name == <span class="string">&#x27;object&#x27;</span>]</span><br><span class="line">    df_int_col = [col <span class="keyword">for</span> col <span class="keyword">in</span> df.columns <span class="keyword">if</span> df[col].dtype.name != <span class="string">&#x27;object&#x27;</span> <span class="keyword">and</span> col != <span class="string">&#x27;income&#x27;</span>]</span><br><span class="line">    target = df[<span class="string">&quot;income&quot;</span>]</span><br><span class="line">    dataset = pd.concat([df[df_int_col], pd.get_dummies(df[df_object_col])], axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> target, dataset</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Adult_data</span>() :</span><br><span class="line"></span><br><span class="line">    df_train = pd.read_csv(<span class="string">&#x27;adult.csv&#x27;</span>, header = <span class="literal">None</span>, names = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;fnlwgt&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>,  <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;capital-gain&#x27;</span>, <span class="string">&#x27;capital-loss&#x27;</span>, <span class="string">&#x27;hours-per-week&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>, <span class="string">&#x27;income&#x27;</span>])</span><br><span class="line">    df_test = pd.read_csv(<span class="string">&#x27;data.test&#x27;</span>, header = <span class="literal">None</span>, skiprows = <span class="number">1</span>, names = [<span class="string">&#x27;age&#x27;</span>, <span class="string">&#x27;workclass&#x27;</span>, <span class="string">&#x27;fnlwgt&#x27;</span>, <span class="string">&#x27;education&#x27;</span>, <span class="string">&#x27;education-num&#x27;</span>, <span class="string">&#x27;marital-status&#x27;</span>, <span class="string">&#x27;occupation&#x27;</span>, <span class="string">&#x27;relationship&#x27;</span>,  <span class="string">&#x27;race&#x27;</span>, <span class="string">&#x27;sex&#x27;</span>, <span class="string">&#x27;capital-gain&#x27;</span>, <span class="string">&#x27;capital-loss&#x27;</span>, <span class="string">&#x27;hours-per-week&#x27;</span>, <span class="string">&#x27;native-country&#x27;</span>, <span class="string">&#x27;income&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    train_target, train_dataset = data_process(df_train, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">    test_target, test_dataset = data_process(df_test, <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line"><span class="comment">#         进行独热编码对齐</span></span><br><span class="line">    test_dataset = fix_columns(test_dataset, train_dataset.columns)</span><br><span class="line">    columns = train_dataset.columns</span><br><span class="line"><span class="comment">#         print(df[&quot;income&quot;])</span></span><br><span class="line"></span><br><span class="line">    train_target, test_target = np.array(train_target), np.array(test_target)</span><br><span class="line">    train_dataset, test_dataset = np.array(train_dataset), np.array(test_dataset)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> train_dataset, train_target, test_dataset, test_target, columns</span><br><span class="line"></span><br><span class="line">train_dataset, train_target, test_dataset, test_target, columns = Adult_data()</span><br><span class="line"><span class="built_in">print</span>(train_dataset.shape, test_dataset.shape, train_target.shape, test_target.shape)</span><br></pre></td></tr></table></figure>
<p>GridSearchCV 类可以用来对分类器的指定参数值进行详尽搜索，这里搜索最佳的决策树的深度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># params = &#123;&#x27;max_depth&#x27; : range(1, 20)&#125;</span></span><br><span class="line"><span class="comment"># best_clf = GridSearchCV(DecisionTreeClassifier(criterion = &#x27;entropy&#x27;, random_state = 20), param_grid = params)</span></span><br><span class="line"><span class="comment"># best_clf = best_clf.fit(train_dataset, train_target)</span></span><br><span class="line"><span class="comment"># print(best_clf.best_params_)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/ad5ae5d78b784f469b6716623cec87c4.png" alt="在这里插入图片描述"><br>用决策数进行分类，采用‘熵’作为决策基准，决策深度由上步骤得到8，分裂一个节点所需的样本数至少设为5，并保存预测结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># clf = DecisionTreeClassifier() score:0.7836742214851667</span></span><br><span class="line">classes = [<span class="string">&#x27; &lt;=50K&#x27;</span>, <span class="string">&#x27; &gt;50K&#x27;</span>]</span><br><span class="line">clf = DecisionTreeClassifier(criterion = <span class="string">&#x27;entropy&#x27;</span>, max_depth = <span class="number">8</span>, min_samples_split = <span class="number">5</span>)</span><br><span class="line">clf = clf.fit(train_dataset, train_target)</span><br><span class="line">pred = clf.predict(test_dataset)</span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line">score = clf.score(test_dataset, test_target)</span><br><span class="line"><span class="comment"># pred = clf.predict_proba(test_dataset)</span></span><br><span class="line"><span class="built_in">print</span>(score)</span><br><span class="line"><span class="comment"># print(np.argmax(pred, axis = 1))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;Predict/DecisionTree.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, newline = <span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> file :</span><br><span class="line">    writer = csv.writer(file)</span><br><span class="line">    writer.writerow([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;result_pred&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> i, result <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred) :</span><br><span class="line">        writer.writerow([i, classes[result]])</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/04f1e6373e304a5fa2adcdabeffa9f0e.png" alt="在这里插入图片描述"><br>结果有0.835跟深度学习差不多，可视化决策树结构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dot_data = export_graphviz(clf, out_file = <span class="literal">None</span>, feature_names = columns, class_names = classes, filled = <span class="literal">True</span>, rounded = <span class="literal">True</span>)</span><br><span class="line">graph = graphviz.Source(dot_data)</span><br><span class="line">graph</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/925caff0520045e28c02d84f58e66179.png" alt="在这里插入图片描述"></p>
<h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p>因数据处理方式与决策树相同，这里不再张贴，只粘贴模型部分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">classes = [<span class="string">&#x27; &lt;=50K&#x27;</span>, <span class="string">&#x27; &gt;50K&#x27;</span>]</span><br><span class="line">clf = svm.SVC(kernel = <span class="string">&#x27;linear&#x27;</span>)</span><br><span class="line">clf = clf.fit(train_dataset, train_target)</span><br><span class="line">pred = clf.predict(test_dataset)</span><br><span class="line">score = clf.score(test_dataset, test_target)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;Predict/SupportVectorMachine.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, newline = <span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> file :</span><br><span class="line">    writer = csv.writer(file)</span><br><span class="line">    writer.writerow([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;result_pred&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> i, result <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred) :</span><br><span class="line">        writer.writerow([i, classes[result]])</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/140e5b770d7440bd8e4202e0d3ca4b0a.png" alt="在这里插入图片描述"></p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">classes = [<span class="string">&#x27; &lt;=50K&#x27;</span>, <span class="string">&#x27; &gt;50K&#x27;</span>]</span><br><span class="line">rf = RandomForestClassifier(n_estimators = <span class="number">100</span>, random_state = <span class="number">0</span>)</span><br><span class="line">rf = rf.fit(train_dataset, train_target)</span><br><span class="line">score = rf.score(test_dataset, test_target)</span><br><span class="line"><span class="built_in">print</span>(score)</span><br><span class="line"></span><br><span class="line">pred = rf.predict(test_dataset)</span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;Predict/RandomForest.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, newline = <span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> file :</span><br><span class="line">    writer = csv.writer(file)</span><br><span class="line">    writer.writerow([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;result_pred&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> i, result <span class="keyword">in</span> <span class="built_in">enumerate</span>(pred) :</span><br><span class="line">        writer.writerow([i, classes[result]])</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/15755e762a0147079f488671b3569dee.png" alt="在这里插入图片描述"></p>
<h1 id="三、结果分析"><a href="#三、结果分析" class="headerlink" title="三、结果分析"></a>三、结果分析</h1><p>经过在Adult数据集的测试集的预测结果可知，深度学习模型、决策树、支持向量机和随机森林的正确率分别达到0.834、0.834、0.834和0.817，四种模型的正确率差不多。正确率并不是很高的原因可能有：<br>1、模型的鲁棒性不够。<br>2、数据集存在大量的离散类型数据，在经过独热编码之后，数据高度稀疏。<br>解决方法：<br>1、对模型再进行搜索性地调参，可以考虑增加模型复杂度，过程中需要注意过拟合。<br>2、不选择独热编码的方式对数据进行降维，可以考虑Embedding</p>
<blockquote>
<p>所有的代码都可以从我的 <a href="https://github.com/aishangcengloua/Data-Mining/tree/master/Adult_predicted">Github仓库</a> 获取，欢迎您的start</p>
</blockquote>
<p>最后，如果您对Adult数据集的处理和模型实现有收获的话，还要麻烦给点个赞，不甚感激。</p>
]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>数据处理</tag>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM 预测股票</title>
    <url>/2022/06/05/LSTM-%E9%A2%84%E6%B5%8B%E8%82%A1%E7%A5%A8/</url>
    <content><![CDATA[<p>﻿tushare是一个开源的金融数据源，目前维护的数据非常丰富，质量也很高，对于一般的分析已经足够，可以省去自己到处去爬数据。我这里下载沪深300指数数据进行预测每日的最高价</p>
<blockquote>
<p>首先使用pip install tushare安装tushare工具包 ，github地址为：<br><a href="https://github.com/aishangcengloua/MLData/blob/master/PyTorch/NLP/Forecast_stock/LSTM.ipynb">https://github.com/aishangcengloua/MLData/blob/master/PyTorch/NLP/Forecast_stock/LSTM.ipynb</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tushare <span class="keyword">as</span> ts</span><br><span class="line">cons = ts.get_apis()<span class="comment">#建立连接</span></span><br><span class="line">df = ts.bar(<span class="string">&#x27;000300&#x27;</span>, conn = cons, asset = <span class="string">&#x27;INDEX&#x27;</span>, start_date = <span class="string">&#x27;2010-01-01&#x27;</span>, end_date = <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">df.info()<span class="comment">#查看没有缺失值之后保存</span></span><br><span class="line">df.columns<span class="comment">#可知沪深300指数（000300）的信息包括交易日期，开盘价，收盘价，最高价，最低价，交易量，成交金额，涨跌幅。</span></span><br><span class="line"><span class="comment"># df.to_csv(&#x27;sh300.csv&#x27;)</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/f2d9f88f105e4c3286b86d871441eb60.png#pic_center" alt="在这里插入图片描述"></p>
<p>导入所需的包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim </span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<p>数据处理，这里我的思路是取[ ‘open’, ‘close’, ‘low’, ‘vol’, ‘amount’, ‘p_change’]六列作为模型的feature进行练，’high’列作为标签。此次我使用LSTM进行预测，所以要注意batch，TIME_STEP，input_size的划分，因为有六列feature，所以input_size为6；对于时间序列TIME_STEP，可以任意指定可以通过前n天的参数来预测今天的最高价。</p>
<p>比如：n = 3，X=[ [ ‘open1’, ‘close1’, ‘low1’, ‘vol1’, ‘amount1’, ‘p_change1’] , [ ‘open2’, ‘close2’, ‘low2’, ‘vol2’, ‘amount2’, ‘p_change2’]，   [ ‘open3’, ‘close3’, ‘low3’, ‘vol3’, ‘amount3’, ‘p_change3’] ]，Y=[ high4 ]。</p>
<p>我们要确保我们输入网络的的数据的维度是[batch，TIME_STEP，input_size]。其次是我将数据划分为8 ：2，2份作为预测数据。要注意的是，生成迭代数据的时候，batch_size 取值要大一些，否则训练时损失振幅会很大，导致预测效果不好。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">TIME_STEP = <span class="number">5</span><span class="comment">#指定序列长度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dataset</span>() :</span><br><span class="line">    df = pd.read_csv(<span class="string">&#x27;sh300.csv&#x27;</span>)</span><br><span class="line">    columns = df.columns</span><br><span class="line">    df_index = df[<span class="string">&#x27;datetime&#x27;</span>]<span class="comment">#获取日期，方便后面作图</span></span><br><span class="line">    df = df[[ <span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;close&#x27;</span>, <span class="string">&#x27;high&#x27;</span>, <span class="string">&#x27;low&#x27;</span>, <span class="string">&#x27;vol&#x27;</span>, <span class="string">&#x27;amount&#x27;</span>, <span class="string">&#x27;p_change&#x27;</span>]]</span><br><span class="line">    min_high, max_high = <span class="built_in">min</span>(df[<span class="string">&#x27;high&#x27;</span>]), <span class="built_in">max</span>(df[<span class="string">&#x27;high&#x27;</span>])<span class="comment">#保存标签的最大，最小值以便后续恢复真实值</span></span><br><span class="line">    df = df.apply(<span class="keyword">lambda</span> x : (x - <span class="built_in">min</span>(x)) / (<span class="built_in">max</span>(x) - <span class="built_in">min</span>(x)))<span class="comment">#将数据进行归一化</span></span><br><span class="line">    df1 = df[[ <span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;close&#x27;</span>, <span class="string">&#x27;low&#x27;</span>, <span class="string">&#x27;vol&#x27;</span>, <span class="string">&#x27;amount&#x27;</span>, <span class="string">&#x27;p_change&#x27;</span>]]</span><br><span class="line">    data = []</span><br><span class="line">    target = []</span><br><span class="line">    index = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(df.shape[<span class="number">0</span>] - TIME_STEP) :</span><br><span class="line">        data.append(df1.iloc[i : i + TIME_STEP].values)<span class="comment">#实现时间序列数据的提取</span></span><br><span class="line">        target.append(df[<span class="string">&#x27;high&#x27;</span>].iloc[i + TIME_STEP])<span class="comment">#保存今天的真实值，因为我们是用前n天来预测今天的最高值</span></span><br><span class="line">        index.append(df_index.iloc[i + TIME_STEP])</span><br><span class="line">    </span><br><span class="line">    target = torch.tensor(target, dtype = torch.float32)</span><br><span class="line">    data = torch.tensor(data, dtype = torch.float32)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> min_high, max_high, data, target, index</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Stock_dataset</span>(<span class="title class_ inherited__">Dataset</span>) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data, target, model = <span class="string">&#x27;train&#x27;</span></span>) :</span><br><span class="line">        <span class="built_in">super</span>(Stock_dataset, self).__init__()</span><br><span class="line">        self.model = model</span><br><span class="line">        <span class="keyword">if</span> model == <span class="string">&#x27;train&#x27;</span> :</span><br><span class="line">            self.data = data[ : <span class="built_in">int</span>(data.shape[<span class="number">0</span>] * <span class="number">0.8</span>)]</span><br><span class="line">            self.target = target[ : <span class="built_in">int</span>(target.shape[<span class="number">0</span>] * <span class="number">0.8</span>)]</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            self.data = data[<span class="built_in">int</span>(data.shape[<span class="number">0</span>] * <span class="number">0.8</span>) : ]</span><br><span class="line">            self.target = target[<span class="built_in">int</span>(target.shape[<span class="number">0</span>] * <span class="number">0.8</span>) : ]</span><br><span class="line">         </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>) :</span><br><span class="line">        <span class="keyword">return</span> self.data[item], self.target[item]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>) :</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line">    </span><br><span class="line">min_high, max_high, data, target, index = dataset()</span><br><span class="line"><span class="built_in">print</span>(target.shape, <span class="built_in">len</span>(index))</span><br><span class="line">train_data = Stock_dataset(data, target, model = <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">test_data = Stock_dataset(data, target, model = <span class="string">&#x27;test&#x27;</span>)</span><br><span class="line">test_index = index[<span class="built_in">int</span>(target.shape[<span class="number">0</span>] * <span class="number">0.8</span>) : ]</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_data, batch_size = <span class="number">64</span>, shuffle = <span class="literal">True</span>, drop_last = <span class="literal">False</span>)<span class="comment">#生成可迭代数据</span></span><br><span class="line">test_loader = DataLoader(test_data, batch_size = <span class="number">64</span>, shuffle = <span class="literal">False</span>, drop_last = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/5620c0833a484a4fb1499fc927f433b8.png" alt="在这里插入图片描述"></p>
<p>​    </p>
<p>构建网络，使用LSTM，后将LSTM网络的输出经过线性神经元进行输出。要注意的是LSTM输入和输出的隐含状态为（h， c），当将输出输入到linear网络时，只取最后一次TIME_STEP的输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LSTM</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, INPUT_SIZE, HIDDEN_SIZE</span>) :</span><br><span class="line">        <span class="built_in">super</span>(LSTM, self).__init__()</span><br><span class="line">        self.lstm = nn.LSTM(input_size = INPUT_SIZE, hidden_size = HIDDEN_SIZE, batch_first = <span class="literal">True</span>)</span><br><span class="line">        self.linear = nn.Linear(<span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>) :</span><br><span class="line">        lstm_out, (h, c) = self.lstm(x)</span><br><span class="line">        out = self.linear(lstm_out[ : , -<span class="number">1</span>, : ])<span class="comment">#降维，最后一次TIME_STEP的输出</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>设置超参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">TIME_STEP = <span class="number">5</span></span><br><span class="line">INPUT_SIZE = <span class="number">6</span></span><br><span class="line">HIDDEN_SIZE = <span class="number">64</span></span><br><span class="line">EPOCH = <span class="number">180</span></span><br><span class="line">model = LSTM(INPUT_SIZE = INPUT_SIZE, HIDDEN_SIZE = HIDDEN_SIZE).cuda()</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr = <span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<p>训练，用Tensorboard可视化，关于 Tensorboard 的使用<a href="https://blog.csdn.net/weixin_53598445/article/details/121301078">点这里</a>。model 的输出是一个矩阵，为了计算loss准确所以要对输出进行降维</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">writer = SummaryWriter(log_dir = <span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCH) :</span><br><span class="line">    model.train()</span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> x, label <span class="keyword">in</span> train_loader :</span><br><span class="line">        x, label = x.cuda(), label.cuda()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        out = model(x)</span><br><span class="line">        loss = criterion(torch.squeeze(out), label)<span class="comment">#降维</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"><span class="comment">#         train_loss += loss.item()</span></span><br><span class="line"><span class="comment">#     print(f&#x27;train_loss : &#123;train_loss / len(train_loader.dataset) : 0.4f&#125;&#x27;)</span></span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;sh300&#x27;</span>, loss, epoch)<span class="comment">#可视化</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/4b56fc5755a74737939144eaaa5fbaa4.PNG#pic_center" alt="在这里插入图片描述"></p>
<p>预测及可视化，在可视化中，为了更好的观察预测效果，我只选择了一百天进行可视化，且为了时间的有序，将它们进行逆序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">pred = []</span><br><span class="line">test_target = []</span><br><span class="line"><span class="keyword">for</span> x, label <span class="keyword">in</span> test_loader :</span><br><span class="line">    x, label = x.cuda(), label.cuda()</span><br><span class="line">    out = model(x)</span><br><span class="line"><span class="comment">#     print(out)</span></span><br><span class="line">    test_target.append(label.detach().cpu())</span><br><span class="line">    pred.append(out.detach().cpu())</span><br><span class="line">test_target = torch.cat(test_target, dim = <span class="number">0</span>).numpy().squeeze()<span class="comment">#将各个batch的输出进行拼接，转成数组再进行降维</span></span><br><span class="line">pred = torch.cat(pred, dim = <span class="number">0</span>).numpy().squeeze()</span><br><span class="line"></span><br><span class="line">test_target = test_target * (max_high - min_high) + min_high<span class="comment">#还原原始的数据</span></span><br><span class="line">pred = pred * (max_high - min_high) + min_high</span><br><span class="line">test_index = np.array(test_index)</span><br><span class="line">plt.plot(test_index[ : <span class="number">101</span>][ : : -<span class="number">1</span>], test_target[ : <span class="number">101</span>][ : : -<span class="number">1</span>], <span class="string">&#x27;r&#x27;</span>, label = <span class="string">&#x27;test_target&#x27;</span>)</span><br><span class="line">plt.plot(test_index[ : <span class="number">101</span>][ : : -<span class="number">1</span>], pred[ : <span class="number">101</span>][ : : -<span class="number">1</span>], <span class="string">&#x27;b&#x27;</span>, label = <span class="string">&#x27;prediction&#x27;</span>)</span><br><span class="line">plt.legend(loc = <span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.xticks(np.arange(<span class="number">0</span>,<span class="number">101</span>,<span class="number">25</span>), [test_index[<span class="number">100</span>], test_index[<span class="number">75</span>], test_index[<span class="number">50</span>], test_index[<span class="number">25</span>], test_index[<span class="number">0</span>]])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/7898c62257c64232a598b577ff4f3f74.png#pic_center" alt="在这里插入图片描述"></p>
<p>看上去效果是非常好的。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>PyTorch</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>详解 Tensorboard 及使用教程</title>
    <url>/2022/06/05/%E8%AF%A6%E8%A7%A3-Tensorboard-%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="一、什么是Tensorboard"><a href="#一、什么是Tensorboard" class="headerlink" title="一、什么是Tensorboard"></a>一、什么是Tensorboard</h1><p>Tensorboard原本是Google TensorFlow的可视化工具，可以用于记录训练数据、评估数据、网络结构、图像等，并且可以在web上展示，对于观察神经网络的过程非常有帮助。PyTorch也推出了自己的可视化工具，一个是<strong>tensorboardX</strong>包，一个是<strong>torch.utils.tensorboard</strong>，二者的使用相差不大，这里介绍后者</p>
<h2 id="二、配置Tensorboard"><a href="#二、配置Tensorboard" class="headerlink" title="二、配置Tensorboard"></a>二、配置Tensorboard</h2><h3 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h3><ul>
<li>操作系统：Windows</li>
<li>Python3</li>
<li>PyTorch &gt;= 1.0.0 &amp;&amp; torchvision &gt;= 0.2.1 &amp;&amp; tensorboard &gt;= 1.12.0 1</li>
</ul>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><strong>注：</strong> 虽说PyTorch中直接有tensorboard的包，但是有时用的时候还是会报错，所以安装TensorFlow之后torch.utils.tensorboard就可以直接使用且稳定，所以这里介绍安装TensorFlow的方法。</p>
<ul>
<li>pip环境(相对麻烦需要下载依赖项)</li>
</ul>
<blockquote>
<p>pip install tensorflow_gpu=2.5.0 -i <a href="https://pypi.mirrors.ustc.edu.cn/simple/">https://pypi.mirrors.ustc.edu.cn/simple/</a><br>pip install six numpy wheel<br>pip install keras_applications=1.0.6 —no-deps<br>pip install keras_preprocessing=1.0.5 —no-deps</p>
</blockquote>
<ul>
<li>conda环境安装</li>
</ul>
<blockquote>
<p>conda install —channel <a href="https://conda.anaconda.org/anaconda">https://conda.anaconda.org/anaconda</a> tensorflow=2.5.0</p>
</blockquote>
<h1 id="三、Tensorboard的使用"><a href="#三、Tensorboard的使用" class="headerlink" title="三、Tensorboard的使用"></a>三、Tensorboard的使用</h1><p>首先展示该包的使用的大致流程</p>
<blockquote>
<p><strong><em>1)导入tensorboard，实例化SummaryWriter类，指明记录日记路径等信息</em></strong><br>from torch.utils.tensorboard import SummaryWriter</p>
<h1 id="实例化SummaryWriter，并指明日志存放路径。在当前目录如果每月logs目录将自动创建"><a href="#实例化SummaryWriter，并指明日志存放路径。在当前目录如果每月logs目录将自动创建" class="headerlink" title="实例化SummaryWriter，并指明日志存放路径。在当前目录如果每月logs目录将自动创建"></a>实例化SummaryWriter，并指明日志存放路径。在当前目录如果每月logs目录将自动创建</h1><h1 id="如果不写log-dir，系统将会创建runs目录"><a href="#如果不写log-dir，系统将会创建runs目录" class="headerlink" title="如果不写log_dir，系统将会创建runs目录"></a>如果不写log_dir，系统将会创建runs目录</h1><p>writer = SummaryWriter(log_dir = ‘logs’)</p>
<h1 id="调用实例"><a href="#调用实例" class="headerlink" title="调用实例"></a>调用实例</h1><p>writer.add_xxx()</p>
<h1 id="关闭writer"><a href="#关闭writer" class="headerlink" title="关闭writer"></a>关闭writer</h1><p>writer.close()<br><strong><em>2）调用相应的API，接口一般格式为：</em></strong><br>add_xxx(tag_name, object, iteration-number)<br><strong><em>3)启动tensorboard，在命令行中输入</em></strong><br>tensorboard —logdir=r’加logs所在路径’<br><strong><em>4)复制网址在浏览器中打开</em></strong></p>
</blockquote>
<h2 id="使用各种add方法记录数据"><a href="#使用各种add方法记录数据" class="headerlink" title="使用各种add方法记录数据"></a>使用各种add方法记录数据</h2><h3 id="单条曲线-scalar"><a href="#单条曲线-scalar" class="headerlink" title="单条曲线(scalar)"></a>单条曲线(scalar)</h3><blockquote>
<p>add_scalar(tag, scalar_value, global_step=None, walltime=None)</p>
</blockquote>
<p><strong>参数：</strong></p>
<ul>
<li>tag ( string ) – 数据标识符</li>
<li>scalar_value ( float或string/blobname ) – 要保存的值</li>
<li>global_step ( int ) – 要记录的全局步长值</li>
<li>walltime ( float ) – 记录训练的时间，默认 walltime (time.time()) 秒</li>
<li>new_style ( boolean ) – 是使用新样式（张量字段）还是旧样式（simple_value 字段）。新样式可能会导致更快的数据加载。<br>例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>) :</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;y = 2x&#x27;</span>, x, <span class="number">2</span> * x)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>效果<br><img src="https://img-blog.csdnimg.cn/84389ad9f39d42b8acdb3d56afa737e3.png" alt="在这里插入图片描述"></p>
<h3 id="多条曲线-scalars"><a href="#多条曲线-scalars" class="headerlink" title="多条曲线(scalars)"></a>多条曲线(scalars)</h3><blockquote>
<p>add_scalars( main_tag , tag_scalar_dict , global_step = None , walltime = None)</p>
</blockquote>
<p><strong>参数</strong></p>
<ul>
<li>main_tag ( string ) – 标签的父名称</li>
<li>tag_scalar_dict ( dict ) – 存储标签和对应值的键值对</li>
<li>global_step ( int ) – 要记录的全局步长值</li>
<li>walltime ( float ) – 记录训练的时间，默认 walltime (time.time()) 秒<br>例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line">r = <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>) :</span><br><span class="line">    writer.add_scalars(<span class="string">&#x27;run_14h&#x27;</span>, &#123;<span class="string">&#x27;xsinx&#x27;</span> : x * np.sin(x / r), </span><br><span class="line">                                  <span class="string">&#x27;xcosx&#x27;</span> : x * np.cos(x / r), </span><br><span class="line">                                  <span class="string">&#x27;xtanx&#x27;</span> : x * np.tan(x / r)&#125;, x)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/0557d6357ab240f7abc4705bbc088b44.png" alt="在这里插入图片描述"></p>
<h3 id="直方图-histogram"><a href="#直方图-histogram" class="headerlink" title="直方图(histogram)"></a>直方图(histogram)</h3><blockquote>
<p>add_histogram( tag , values , global_step = None , bins = ‘tensorflow’ , walltime = None , max_bins = None )</p>
</blockquote>
<p><strong>参数：</strong></p>
<ul>
<li>tag ( string ) – 数据标识符</li>
<li>值（torch.Tensor、numpy.array或string/blobname）– 构建直方图的值</li>
<li>global_step ( int ) – 要记录的全局步长值</li>
<li>bins ( string ) – {‘tensorflow’,’auto’, ‘fd’, …} 之一。这决定了柱的制作方式。</li>
<li>walltime ( float ) – 记录训练的时间，默认 walltime (time.time()) 秒<br>例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>) :</span><br><span class="line">    x = np.random.randn(<span class="number">1000</span>)</span><br><span class="line">    writer.add_histogram(<span class="string">&#x27;distribution of gaussion&#x27;</span>, x, step)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/b7ac08406f24467b94161e9348432b45.png" alt="在这里插入图片描述"></p>
<h3 id="图片-image"><a href="#图片-image" class="headerlink" title="图片(image)"></a>图片(image)</h3><blockquote>
<p>add_image(tag, img_tensor, global_step=None, walltime=None, dataformats = ‘CHW’)</p>
</blockquote>
<p><strong>参数：</strong></p>
<ul>
<li>tag ( string ) – 数据标识符</li>
<li>img_tensor ( torch.Tensor , numpy.array , or string/blobname ) – 图像数据</li>
<li>global_step ( int ) – 要记录的全局步长值</li>
<li>walltime ( float ) – 记录训练的时间，默认 walltime (time.time()) 秒<br>例子：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">img = cv.imread(<span class="string">&#x27;zhou.jpg&#x27;</span>, cv.IMREAD_COLOR)<span class="comment">#输入图像要是3通道的，所以读取彩色图像</span></span><br><span class="line">img = cv.cvtColor(img, cv.COLOR_BGR2RGB)</span><br><span class="line">img = torch.tensor(img.transpose(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))<span class="comment">#cv读取为numpy图像为(H * W * C)，所以要进行轴转换</span></span><br><span class="line">writer.add_image(<span class="string">&#x27;zhou_ge&#x27;</span>, img, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/2fe87fea05814845867ee262fb405ded.png" alt="在这里插入图片描述"></p>
<h3 id="渲染-figure"><a href="#渲染-figure" class="headerlink" title="渲染(figure)"></a>渲染(figure)</h3><blockquote>
<p>add_figure( tag , figure , global_step = None , close = True , walltime = None )</p>
</blockquote>
<p><strong>参数：</strong></p>
<ul>
<li>tag ( string ) – 数据标识符</li>
<li>image( matplotlib.pyplot.figure ) – 图或图列表</li>
<li>global_step ( int ) – 要记录的全局步长值</li>
<li>close ( bool ) – 自动关闭图形的标志</li>
<li><p>walltime ( float ) – 记录训练的时间，默认 walltime (time.time()) 秒</p>
<p>例子：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">1000</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line">figure1 = plt.figure()</span><br><span class="line">plt.plot(x, y, <span class="string">&#x27;r-&#x27;</span>)</span><br><span class="line">writer.add_figure(<span class="string">&#x27;my_figure&#x27;</span>, figure1, <span class="number">0</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>效果:<br><img src="https://img-blog.csdnimg.cn/8c9769e21dce47efbe45e082ba787f6c.png" alt="在这里插入图片描述"></p>
<h3 id="网络-graph"><a href="#网络-graph" class="headerlink" title="网络(graph)"></a>网络(graph)</h3><blockquote>
<p>add_graph(model, input_to_model=None, verbose=False, use_strict_trace = True)</p>
</blockquote>
<p><strong>参数：</strong></p>
<ul>
<li>model( torch.nn.Module ) – 要绘制的模型。</li>
<li>input_to_model ( torch.Tensor or list of torch.Tensor ) – 要输入的变量或变量元组</li>
<li>verbose(bool）– 是否在控制台中打印图形结构。</li>
<li>use_strict_trace ( bool ) – 是否将关键字参数严格传递给 torch.jit.trace。当您希望跟踪器记录您的可变容器类型（列表、字典）时传递 False.</li>
</ul>
<p>例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter()</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLP</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.Net = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">784</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line"></span><br><span class="line">            nn.Linear(<span class="number">128</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="built_in">input</span> = <span class="built_in">input</span>.view(-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>)</span><br><span class="line">        <span class="keyword">return</span> self.Net(<span class="built_in">input</span>)</span><br><span class="line">model = MLP()</span><br><span class="line"><span class="built_in">input</span> = torch.FloatTensor(np.random.rand(<span class="number">32</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">writer.add_graph(model, <span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/8d4d7286049d4f67a2fd3e306817bf2e.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/f9b11c2ca66a4cdba573c6b1b9e1c4f4.png" alt="在这里插入图片描述"></p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><strong>嵌入：</strong></p>
<blockquote>
<p>add_embedding(mat, metadata=None, label_img=None, global_step = None, tag=’default’, metadata_header=None)</p>
</blockquote>
<p><strong>参数：</strong></p>
<ul>
<li>mat ( torch.Tensor or numpy.array ) – 一个矩阵，每一行都是数据点的特征向量</li>
<li>metadata ( list ) – 标签列表，每个元素都将转换为字符串</li>
<li>label_img ( torch.Tensor ) – 图像对应每个数据点</li>
<li>global_step ( int ) – 要记录的全局步长值</li>
<li>tag ( string ) – 嵌入的名称</li>
</ul>
<h1 id="三、结语"><a href="#三、结语" class="headerlink" title="三、结语"></a>三、结语</h1><p>以上是关于一些tensorboard可视化的操作，如果您有收获的话，就给👨一个三连。就此谢过！</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>在使用 tensorboard 时报错</title>
    <url>/2022/06/05/%E5%9C%A8%E4%BD%BF%E7%94%A8-tensorboard-%E6%97%B6%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<p>﻿昨天在使用 tensorboard 时， 输入命令之后，一直出现下面的错误</p>
<blockquote>
<p>tensorboard: error: invalid choice: ‘Recognizer\\logs’ (choose from ‘serve’, ‘dev’)</p>
</blockquote>
<p>开始还以为是代码问题，但发现不是，又去找官网和别人的经过，但是最多找到的是路径是否正确的问题，但是我确定我不是。然后突然发现路径中有空格，就怀疑可能是空格的问题，经手一改，然后就可以了(学艺不精)</p>
<p>注意检查 <strong>tensorboard —logdir=”路径”</strong>（注意要是双引号） 中的路径是否空格以及logs所在路径是否填写正确。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>Numpy 实现 K_means 算法</title>
    <url>/2022/06/05/Numpy-%E5%AE%9E%E7%8E%B0-K-means-%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>﻿<a href="https://github.com/aishangcengloua/Python/blob/master/Lab4/Lab4.dat">代码所需数据</a><br>聚类就是根据数据之间的相似度将数据集划分为多个类别或组，使类别内的数据相似度较大而类别间的数据相似度较小。如下图所示，左边是原始数据，右边是聚类之后的效果，不同的颜色代表不同的类别。<br><img src="https://img-blog.csdnimg.cn/798a5b8629b348c29c9b58c281d4d1cc.png" alt="在这里插入图片描述"></p>
<p>对于本次代码聚类步骤如下（聚类算法大体步骤，可根据需求进行修改）：</p>
<blockquote>
<p><strong><em>1</em></strong>.设置初始类别中心和类别数，初始化是要注意在题目所给数据的x、y的<strong>最小值和最大值</strong>进行。<br><strong><em>2</em></strong>.根据类别中心对全部数据进行类别划分：每个点分到离自己<strong>距离最小</strong>的那个类<br><strong><em>3</em></strong>.重新计算当前类别划分下每个类的中心：例如可以取每个类别里所有的点的平均值作为新的中心。如何求多个点的平均值？ 分别计算X坐标的平均值，y坐标的平均值，从而得到新的点。注意：类的中心可以不是真实的点，虚拟的点也不影响。<br><strong><em>4</em></strong>.在新的类别中心下继续进行类别划分;</p>
</blockquote>
<p>如果连续两次的类别划分结果不变则停止算法; 否则循环2～5。例如当类的中心不再变化时，跳出循环。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(<span class="string">&#x27;Lab4.dat&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calSSE</span>(<span class="params">X, cidx, ctrs</span>) :</span><br><span class="line">    SSE = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, ctr <span class="keyword">in</span> <span class="built_in">enumerate</span>(ctrs) :</span><br><span class="line">        SSE += np.<span class="built_in">sum</span>(np.square(X[np.where(cidx == i + <span class="number">1</span>)] - ctr))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> SSE / X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kmeans</span>(<span class="params">X, K</span>) :</span><br><span class="line">    center_point = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K) :</span><br><span class="line">        point_x = np.random.uniform(np.<span class="built_in">min</span>(X, axis = <span class="number">0</span>)[<span class="number">0</span>], np.<span class="built_in">max</span>(X, axis = <span class="number">0</span>)[<span class="number">0</span>])<span class="comment">#随机初始化簇心</span></span><br><span class="line">        point_y = np.random.uniform(np.<span class="built_in">min</span>(X, axis = <span class="number">0</span>)[<span class="number">1</span>], np.<span class="built_in">max</span>(X, axis = <span class="number">0</span>)[<span class="number">1</span>])</span><br><span class="line">        center_point.append([point_x, point_y])</span><br><span class="line">    center_point = np.array(center_point)</span><br><span class="line">    cluter = np.zeros(X.shape[<span class="number">0</span>]).astype(np.int32)<span class="comment">#建立簇类初始化为0</span></span><br><span class="line">    item = <span class="number">5</span></span><br><span class="line">    <span class="keyword">while</span> item &gt; <span class="number">0</span>:<span class="comment">#迭代</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">0</span>]) :<span class="comment">#计算每一组数据与每个簇心的欧氏距离，距离最小者记为此组数据为所标类别</span></span><br><span class="line">            distance = center_point</span><br><span class="line">            distance = np.<span class="built_in">sum</span>(np.square(distance - X[i]), axis = <span class="number">1</span>)<span class="comment">#注意x， y都计算所以要求和，注意求和维度</span></span><br><span class="line">            cluter[i] = np.argmin(distance) + <span class="number">1</span><span class="comment">#最小值的下标</span></span><br><span class="line">    </span><br><span class="line">        New_center_point = np.zeros((K, <span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K) :<span class="comment">#更新簇心，取每一簇类的平均值作为新簇心</span></span><br><span class="line">            New_center_point[i][<span class="number">0</span>] = np.mean(X[np.where(cluter == i + <span class="number">1</span>), <span class="number">0</span>])</span><br><span class="line">            New_center_point[i][<span class="number">1</span>] = np.mean(X[np.where(cluter == i + <span class="number">1</span>), <span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> (New_center_point - center_point &lt; <span class="number">1e-7</span>).<span class="built_in">all</span>() :<span class="comment">#当新簇心与之前的簇心近似相等时退出迭代</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        center_point = New_center_point</span><br><span class="line">        item -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> cluter, center_point<span class="comment">#返回每一组数据所对应的簇类和簇心</span></span><br><span class="line"></span><br><span class="line">SSE = []</span><br><span class="line">mark = [ <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;k&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;g&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.ion()</span><br><span class="line"><span class="keyword">for</span> K <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">7</span>) :</span><br><span class="line">    cidx, ctrs = kmeans(data, K)</span><br><span class="line">    ctrs_set.append(ctrs)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;K为<span class="subst">&#123;K&#125;</span>时的簇心 : \n <span class="subst">&#123;ctrs&#125;</span>&#x27;</span>)</span><br><span class="line">    SSE.append(calSSE(data, cidx, ctrs))<span class="comment">#手肘法求最好分类的K值</span></span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">3</span>, K - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K) :</span><br><span class="line">        plt.scatter(data[np.where(cidx == i + <span class="number">1</span>), <span class="number">0</span>], data[np.where(cidx == i + <span class="number">1</span>), <span class="number">1</span>], marker = <span class="string">&#x27;.&#x27;</span>, color = mark[i])<span class="comment">#作图</span></span><br><span class="line">    plt.scatter(ctrs[ : , <span class="number">0</span>], ctrs[ : , <span class="number">1</span>], marker = <span class="string">&#x27;*&#x27;</span>, color = <span class="string">&#x27;g&#x27;</span>)<span class="comment">#做出簇心</span></span><br><span class="line">    plt.title(<span class="string">f&#x27;K is <span class="subst">&#123;K&#125;</span>&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.xticks([]), plt.yticks([])</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">2</span>, <span class="number">7</span>)), SSE, <span class="string">&#x27;+--&#x27;</span>)</span><br><span class="line">plt.ioff()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/713872beed8f409ba91d8cfe5bba3e1a.png#pic_center" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/cc79c8e8a4cf4f5b9f7c4ed34e162344.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>聚类</tag>
        <tag>numpy</tag>
      </tags>
  </entry>
  <entry>
    <title>对含有奇异值和高斯噪声的数据进行处理</title>
    <url>/2022/06/05/%E5%AF%B9%E5%90%AB%E6%9C%89%E5%A5%87%E5%BC%82%E5%80%BC%E5%92%8C%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86/</url>
    <content><![CDATA[<p>﻿分别用平均滑动窗口、指数滑动窗口、SG滤波法对含有奇异值和高斯噪声的两列数据进行去奇异值和降噪，最终拟合曲线推测函数表达式。<a href="https://blog.csdn.net/hajlyx/article/details/100580316">去噪方法理论知识参考</a><br>对第一列数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> optimize</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> scio</span><br><span class="line">%matplotlib</span><br><span class="line"><span class="comment">#防止中文乱码</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.sans-serif&quot;</span>] = [<span class="string">&quot;Simhei&quot;</span>]</span><br><span class="line">plt.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line">data = scio.loadmat(<span class="string">&#x27;2 data_preprocess_practice.mat&#x27;</span>)</span><br><span class="line"></span><br><span class="line">yy3 = data[<span class="string">&quot;yy3&quot;</span>]</span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">20001</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment">#去除奇异值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Noise_reduction</span>(<span class="params">data_col</span>) :</span><br><span class="line">    lst = []</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="comment">#此处用的是3sigema的方法</span></span><br><span class="line">    <span class="keyword">while</span> i + <span class="number">12</span> &lt; <span class="number">20001</span> :</span><br><span class="line">        lst1 = data_col[i : i + <span class="number">12</span>]</span><br><span class="line">        mean = np.mean(lst1)</span><br><span class="line">        std = np.std(lst1)</span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> lst1 :</span><br><span class="line">            <span class="keyword">if</span> (value - mean) &gt;= -<span class="number">3</span> * std <span class="keyword">and</span> (value - mean) &lt;= <span class="number">3</span> * std :</span><br><span class="line">                lst.append(value)</span><br><span class="line">        i += <span class="number">12</span></span><br><span class="line">        lst1 = []</span><br><span class="line">    <span class="keyword">return</span> lst</span><br><span class="line"></span><br><span class="line"><span class="comment">#平均滑动去噪</span></span><br><span class="line"><span class="comment">#滑动平均法适用于，噪声的均值为0，真实值变化不大或线性变化的场景</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Average_sliding_denoising</span>(<span class="params">arr, window_size</span>) :</span><br><span class="line">    <span class="comment">#对数组进首尾扩展，以滑动窗口可以处理到首尾点，思想与图片滤波算子相似</span></span><br><span class="line">    New_arr = arr[ : ]</span><br><span class="line">    window_size = (window_size - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(window_size) :</span><br><span class="line">        arr.insert(step, <span class="built_in">sum</span>(arr[ : window_size]) / window_size)</span><br><span class="line">        arr.insert(<span class="built_in">len</span>(arr) - step, <span class="built_in">sum</span>(arr[<span class="built_in">len</span>(arr) - window_size : <span class="built_in">len</span>(arr)]) / window_size)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(window_size, <span class="built_in">len</span>(arr) - window_size) :</span><br><span class="line">        New_arr[i - window_size] = (<span class="built_in">sum</span>(arr[i - window_size : i + window_size + <span class="number">1</span>])) / (<span class="number">2</span> * window_size + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> New_arr</span><br><span class="line"></span><br><span class="line"><span class="comment">#指数平均滑动去噪</span></span><br><span class="line"><span class="comment">#当误差不受观测值大小影响的话，指数滑动平均比滑动平均好；当误差随观测值大小变化时，滑动平均比指数滑动平均更好。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Exponential_sliding_denoising</span>(<span class="params">arr, weight = <span class="number">0.01</span></span>) :</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(arr)) :</span><br><span class="line">        arr[i] = weight * arr[i] + (<span class="number">1</span> - weight) * arr[i - <span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"><span class="comment">#Savitzky-Golay平滑去噪</span></span><br><span class="line"><span class="comment">#SG滤波法对于数据的观测信息保持的更好，在一些注重数据变化的场合会比较适用。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_x</span>(<span class="params">size, rank</span>):</span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> * size + <span class="number">1</span>):</span><br><span class="line">        m = i - size</span><br><span class="line">        row = [m ** j <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(rank)]</span><br><span class="line">        x.append(row) </span><br><span class="line">    x = np.mat(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Savgol_Denosing</span>(<span class="params">arr, window_size, rank</span>) :</span><br><span class="line">    New_arr = arr[ : ]</span><br><span class="line">    m = (window_size - <span class="number">1</span>) // <span class="number">2</span></span><br><span class="line">    <span class="comment"># 处理边缘数据，用边缘值首尾增加m个首尾项</span></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(m) :</span><br><span class="line">        arr.insert(step, arr[<span class="number">0</span>])</span><br><span class="line">        arr.insert(<span class="built_in">len</span>(arr) - step, arr[<span class="built_in">len</span>(arr) - <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 创建X矩阵</span></span><br><span class="line">    X = create_x(m, rank)</span><br><span class="line">    <span class="comment"># 计算加权系数矩阵B</span></span><br><span class="line">    B = (X * (X.T * X).I) * X.T</span><br><span class="line">    <span class="comment">#只用更新第m个点，因此只需取B系数矩阵的第m行即可</span></span><br><span class="line">    A0 = B[m].T</span><br><span class="line">    <span class="comment"># 计算平滑修正后的值</span></span><br><span class="line">    narr = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(New_arr)):</span><br><span class="line">        y = [arr[i + j] <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(window_size)]</span><br><span class="line">        y1 = np.mat(y) * A0</span><br><span class="line">        y1 = <span class="built_in">float</span>(y1)</span><br><span class="line">        narr.append(y1)</span><br><span class="line">    <span class="keyword">return</span> narr</span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化不同去噪方法的效果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Mapping</span>(<span class="params">lst, arr, arr1, arr2</span>) :</span><br><span class="line">    x = np.array(<span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(arr), <span class="number">1</span>)))</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line">    fig.<span class="built_in">set</span>(alpha = <span class="number">0.2</span>)</span><br><span class="line">    plt.subplot2grid((<span class="number">1</span>,<span class="number">4</span>), (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">    plt.plot(x, arr, label = <span class="string">&#x27;Average_sliding_denoising&#x27;</span>)</span><br><span class="line">    plt.legend(loc = <span class="number">1</span>)</span><br><span class="line">    plt.subplot2grid((<span class="number">1</span>, <span class="number">4</span>), (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    plt.plot(x, arr1, <span class="string">&#x27;g-&#x27;</span>, label = <span class="string">&#x27;Exponential_sliding_denoising&#x27;</span>)</span><br><span class="line">    plt.legend(loc = <span class="number">1</span>)</span><br><span class="line">    plt.subplot2grid((<span class="number">1</span>, <span class="number">4</span>), (<span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line">    plt.plot(x, arr2, <span class="string">&#x27;r-&#x27;</span>, label = <span class="string">&#x27;Savgol_Denosing&#x27;</span>)</span><br><span class="line">    plt.legend(loc = <span class="number">1</span>)</span><br><span class="line">    plt.subplot2grid((<span class="number">1</span>, <span class="number">4</span>), (<span class="number">0</span>, <span class="number">3</span>))</span><br><span class="line">    plt.plot(x, lst, <span class="string">&#x27;b-&#x27;</span>, x, arr, <span class="string">&#x27;pink&#x27;</span>, x, arr1, <span class="string">&#x27;g&#x27;</span>, x, arr2, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    plt.legend([<span class="string">&#x27;Before Denoising&#x27;</span>, <span class="string">&#x27;Exponential_sliding_denoising&#x27;</span>, <span class="string">&#x27;Average_sliding_denoising&#x27;</span>, <span class="string">&#x27;Savgol_Denosing&#x27;</span>], loc = <span class="number">1</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#小结，单纯从可视化效果来看，指数平均化动的效果是最好的</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#数据重新拟合，推测函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Polynomial_fitting</span>(<span class="params">lst</span>) :</span><br><span class="line">    x1 = np.arange(<span class="number">0</span>, <span class="built_in">len</span>(lst), <span class="number">1</span>).astype(<span class="built_in">float</span>)</span><br><span class="line">    z1 = np.polyfit(x1, lst, <span class="number">11</span>)</span><br><span class="line"><span class="comment">#     print(np.poly1d(z1))</span></span><br><span class="line">    x_points = np.linspace(<span class="number">0</span>, <span class="number">19973</span>, <span class="number">19973</span>)</span><br><span class="line">    y_point = np.polyval(z1, x_points)</span><br><span class="line">    fig1 = plt.figure()</span><br><span class="line">    plt.plot(x1, lst, x_points, y_point, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    plt.legend([<span class="string">&#x27;Before fitting&#x27;</span>, <span class="string">&#x27;After fitting&#x27;</span>], loc = <span class="number">1</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_col1 = []</span><br><span class="line">data_col2 = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> yy3 :</span><br><span class="line">    data_col1.append(line[<span class="number">0</span>])</span><br><span class="line">    data_col2.append(line[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">data_col1 = np.array(data_col1)</span><br><span class="line">data_col2 = np.array(data_col2)</span><br><span class="line"></span><br><span class="line">lst1 = Noise_reduction(data_col1)</span><br><span class="line">lst1_A = Average_sliding_denoising(Noise_reduction(data_col1), <span class="number">61</span>)</span><br><span class="line">lst1_E = Exponential_sliding_denoising(Noise_reduction(data_col1))</span><br><span class="line">lst1_S = Savgol_Denosing(Noise_reduction(data_col1), <span class="number">59</span>, <span class="number">2</span>)</span><br><span class="line">Mapping(lst1, lst1_A, lst1_E, lst1_S)</span><br><span class="line">Polynomial_fitting1(lst1_A)</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/104514d8184f40f88c9bae68948c16f5.png" alt="在这里插入图片描述"></p>
<p>对第二列数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Polynomial_fitting2</span>(<span class="params">lst</span>) :</span><br><span class="line">    x1 = np.arange(<span class="number">0</span>, <span class="built_in">len</span>(lst), <span class="number">1</span>).astype(<span class="built_in">float</span>)</span><br><span class="line">    z1 = np.polyfit(x1, lst, <span class="number">50</span>)</span><br><span class="line">    x_points = np.linspace(<span class="number">0</span>, <span class="number">19973</span>, <span class="number">19973</span>)</span><br><span class="line">    y_point = np.polyval(z1, x_points)</span><br><span class="line">    fig1 = plt.figure()</span><br><span class="line">    plt.plot(x1, lst, x_points, y_point, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    plt.legend([<span class="string">&#x27;Before fitting&#x27;</span>, <span class="string">&#x27;After fitting&#x27;</span>], loc = <span class="number">1</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">lst2 = Noise_reduction(data_col2)</span><br><span class="line">lst2_A = Average_sliding_denoising(Noise_reduction(data_col2), <span class="number">61</span>)</span><br><span class="line">lst2_E = Exponential_sliding_denoising(Noise_reduction(data_col2))</span><br><span class="line">lst2_S = Savgol_Denosing(Noise_reduction(data_col2), <span class="number">59</span>, <span class="number">2</span>)</span><br><span class="line">Mapping(lst2, lst2_E, lst2_A, lst2_S)</span><br><span class="line">Polynomial_fitting2(lst2_A)</span><br></pre></td></tr></table></figure>
<p>效果：<br><img src="https://img-blog.csdnimg.cn/69f8d6d6d4c540d6b81e69278035a21d.png" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>数据挖掘</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据去噪</tag>
      </tags>
  </entry>
  <entry>
    <title>生成对抗网络（GAN）</title>
    <url>/2022/06/05/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%EF%BC%88GAN%EF%BC%89/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;在生成对抗网络(Generative Adversarial Network，简称 GAN)发明之前，变分自编码器(VAE)被认为是理论完备，实现简单，使用神经网络训练起来很稳定，生成的图片逼近度也较高，但是人眼还是可以很轻易地分辨出真实图片与机器生成的图片。但在2014年GAN被提出之后，在之后的几年里面里迅速发展，生成的图片越来越逼真。</p>
<h1 id="1-GAN"><a href="#1-GAN" class="headerlink" title="1    GAN"></a>1    GAN</h1><h2 id="1-1-相关介绍"><a href="#1-1-相关介绍" class="headerlink" title="1.1    相关介绍"></a>1.1    相关介绍</h2><p>&emsp;&emsp;GAN模型的核心思想就是博弈思想，是生成器(造假者)和判别器(鉴别者)之间的博弈，在提出GAN的原始论文中，作者举了货币制造的例子。即像一台验钞机和一台制造假币的机器之间的博弈，两者不断博弈，博弈的结果假币越来越像真币，直到验钞机无法识别一张货币是假币还是真币为止。</p>
<h2 id="1-2-原理"><a href="#1-2-原理" class="headerlink" title="1.2    原理"></a>1.2    原理</h2><h3 id="1-2-1-网络架构"><a href="#1-2-1-网络架构" class="headerlink" title="1.2.1    网络架构"></a>1.2.1    网络架构</h3><p>&emsp;&emsp;生成对抗网络包含了两个子网络：生成网络(Generator，简称 G)和判别网络(Discriminator，简称 D)，其中生成网络 G 负责学习样本的真实分布，判别网络 D 负责将生成网络采样的样本与真实样本区分开来。<br>&emsp;&emsp;<strong>生成网络G(𝒛)</strong> ：生成网络 G 和自编码器的 Decoder 功能类似，从先验分布$p_z$(∙)采样获得潜在空间点向量，经过网络生成图片样本$\bar{x}$~$𝑝_𝑔(x|z)$。<img src="https://img-blog.csdnimg.cn/f0a07617c2ce41ada27a39cfbcf0b1f6.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;生成器的网络($𝑝_𝑔(x|z)$)可以由深度神经网络来参数化，如：卷积网络和转置卷积网络。下图中从均匀分布$𝑝𝒛$(∙)中采样出隐藏变量$z$，经过多层转置卷积层网络参数化的$𝑝_𝑔(x|z)$分布中采样出样本$x_f$，从输入输出层面来看，生成器 G 的功能是将隐向量𝒛通过神经网络转换为样本向量$x_f$，下标𝑓代表假样本(Fake samples)。<img src="https://img-blog.csdnimg.cn/f74001c39bfa414ea921a2420f4f96f8.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;<strong>判别网络D(𝒙)</strong>：判别网络和普通的二分类网络功能类似，网络的输入数据集由采样自真实数据分布$p_𝑟$(∙)的样本$x_𝑟$ ~ $𝑝_𝑟$(∙)和采样自生成网络的假样本$x_𝑓$ ~ $𝑝_𝑔(x|z)$组成。判别网络输出为$x$属于真实样本的概率𝑃($x$为真|$x$)，我们把所有真实样本$x_r$的标签标注为真(1)，所有生成网络产生的样本，所有生成网络产生的样本$x_f$标注为假(0)，通过最小化判别网络 D 的预测值与标签之间的误差来优化判别网络参数。<img src="https://img-blog.csdnimg.cn/e986cb9be6344b68889460f74812b572.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-2-2-网络训练"><a href="#1-2-2-网络训练" class="headerlink" title="1.2.2    网络训练"></a>1.2.2    网络训练</h3><p>&emsp;&emsp;GAN 博弈学习的思想体现在在它的训练方式上，由于生成器 G 和判别器 D 的优化目标不一样，不能和之前的网络模型的训练一样，只采用一个损失函数。所以我们要分别对生成器和判别器进行训练。<br>&emsp;&emsp;<strong>判别网络D(𝒙)</strong>：它的目标是能够很好地分辨出真样本$x_r$与假样本$x_f$。则其损失函数既要考虑识别真图像能力，又要考虑识别假图像能力，而不能只考虑一方面，故判别器的损失函数为两者的和。因此 D 的分类问题是二分类问题，以图片生成来说，交叉熵损失函数定义为：<img src="https://img-blog.csdnimg.cn/73d5853d0a524cddb3e665e367b22d1d.png#pic_center" alt="在这里插入图片描述"><br>因此判别网络 D 的优化目标是：<br><img src="https://img-blog.csdnimg.cn/c0b19fec09f74f4890fae16f63799ac0.png#pic_center" alt="在这里插入图片描述"><br>将最小化转成最大化的问题并写成期望的形式：<br><img src="https://img-blog.csdnimg.cn/550fc7f16cf543a8b1f2c449fce08d90.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;具体代码如下：D表示判别器、G为生成器、real_labels、fake_labels分别表示真图像标签、假图像标签。images是真图像，z是从潜在空间随机采样的向量，通过生成器得到假图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义判断器对真图像的损失函数 </span></span><br><span class="line">outputs = D(images)</span><br><span class="line">d_loss_real = criterion(outputs, real_labels) </span><br><span class="line">real_score = outputs </span><br><span class="line"><span class="comment"># 定义判别器对假图像（即由潜在空间点生成的图像）的损失函数 </span></span><br><span class="line">z = torch.randn(batch_size, latent_size).to(device) </span><br><span class="line">fake_images = G(z) </span><br><span class="line">outputs = D(fake_images) </span><br><span class="line">d_loss_fake = criterion(outputs, fake_labels) </span><br><span class="line">fake_score = outputs </span><br><span class="line"><span class="comment"># 得到判别器总的损失函数 </span></span><br><span class="line">d_loss = d_loss_real + d_loss_fake</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<strong>生成网络G(𝒛)</strong> ：我们希望$x_f$ = 𝐺(𝒛)能够很好地骗过判别网络 D，假样本$x_f$在判别网络的输出越接近真实的标签越好。也就是说，在训练生成网络时，希望判别网络的输出𝐷(𝐺(𝒛))越逼近 1 越好，最小化𝐷(𝐺(𝒛))与 1 之间的交叉熵损失函数：<img src="https://img-blog.csdnimg.cn/9baccb14957b4738b4a1232a959761b7.png#pic_center" alt="在这里插入图片描述"><br>将最小化转成最大化的问题并写成期望的形式：<img src="https://img-blog.csdnimg.cn/0c4e02351e04459da5825f9d60edce2e.png#pic_center" alt="在这里插入图片描述"><br>等价成：<br><img src="https://img-blog.csdnimg.cn/9774d234ecff4d1e978ef7046ac875dc.png#pic_center" alt="在这里插入图片描述"><br>其中𝜙为生成网络 G 的参数集，可以利用梯度下降算法来优化参数𝜙。具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">z = torch.randn(batch_size, latent_size).to(device) </span><br><span class="line">fake_images = G(z) </span><br><span class="line">outputs = D(fake_images) </span><br><span class="line">g_loss = criterion(outputs, real_labels)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;通过对生成器和判别器的损失函数的求解，GAN的架构如下：<br><img src="https://img-blog.csdnimg.cn/46f8a03977c44c909c48c030a38e18ff.png#pic_center" alt="在这里插入图片描述"><br>算法流程为：<br><img src="https://img-blog.csdnimg.cn/73987cbfaf8c46d48437cabfe0d417bd.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="1-3-用GAN生成图像"><a href="#1-3-用GAN生成图像" class="headerlink" title="1.3    用GAN生成图像"></a>1.3    用GAN生成图像</h2><p>&emsp;&emsp;本次实验为了方便，我使用的是 MNIST 手写数字数据集，下面进行每部分的代码实现。</p>
<h3 id="1-3-1-判别器"><a href="#1-3-1-判别器" class="headerlink" title="1.3.1    判别器"></a>1.3.1    判别器</h3><p>&emsp;&emsp;定义判别器网络结构，这里使用LeakyReLU为激活函数，输出一个节点 并经过Sigmoid后输出，用于真假二分类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) :</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.D = nn.Sequential(nn.Linear(IMAGE_SIZE, HIDDEN_SIZE),</span><br><span class="line">                               nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">                               nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),</span><br><span class="line">                               nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">                               nn.Linear(HIDDEN_SIZE, <span class="number">1</span>),</span><br><span class="line">                               nn.Sigmoid())</span><br></pre></td></tr></table></figure>
<h3 id="1-3-2-生成器"><a href="#1-3-2-生成器" class="headerlink" title="1.3.2    生成器"></a>1.3.2    生成器</h3><p>&emsp;&emsp;生成器与AVE的生成器类似，不同的地方是输出为nn.tanh，使用nn.tanh 将使数据分布在[-1,1]之间。其输入是潜在空间的向量z，输出维度与真图像相同。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.G = nn.Sequential(nn.Linear(Z_SIZE, HIDDEN_SIZE),</span><br><span class="line">                               nn.ReLU(),</span><br><span class="line">                               nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),</span><br><span class="line">                               nn.ReLU(),</span><br><span class="line">                               nn.Linear(HIDDEN_SIZE, IMAGE_SIZE),</span><br><span class="line">                               nn.Tanh())</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z</span>) :</span><br><span class="line">        <span class="keyword">return</span> self.G(z)</span><br></pre></td></tr></table></figure>
<h3 id="1-3-3-训练模型"><a href="#1-3-3-训练模型" class="headerlink" title="1.3.3    训练模型"></a>1.3.3    训练模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(MAX_EPOCH) :</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(Dataloader) :</span><br><span class="line"></span><br><span class="line">        images = images.reshape(BATCH_SIZE, -<span class="number">1</span>).cuda()</span><br><span class="line">        <span class="comment">#真样本与生成样本的标签设置</span></span><br><span class="line">        real_labels = torch.ones(BATCH_SIZE, <span class="number">1</span>).cuda()</span><br><span class="line">        fake_labels = torch.zeros(BATCH_SIZE, <span class="number">1</span>).cuda()</span><br><span class="line">        <span class="comment">#训练判别器</span></span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line">        g_optimizer.zero_grad()</span><br><span class="line">        out = D(images)</span><br><span class="line">        real_score = out</span><br><span class="line">        d_loss_real = criterion(out, real_labels)</span><br><span class="line"></span><br><span class="line">        z = torch.randn(BATCH_SIZE, Z_SIZE).cuda()</span><br><span class="line">        fake_images = G(z)</span><br><span class="line">        out = D(fake_images)</span><br><span class="line">        fake_score = out</span><br><span class="line">        d_loss_fake = criterion(out, fake_labels)</span><br><span class="line"></span><br><span class="line">        d_loss = d_loss_fake + d_loss_real</span><br><span class="line"></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#训练生成器</span></span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line">        g_optimizer.zero_grad()</span><br><span class="line">        z = torch.randn(BATCH_SIZE, Z_SIZE).cuda()</span><br><span class="line">        fake_images = G(z)</span><br><span class="line">        out = D(fake_images)</span><br><span class="line">        g_loss = criterion(out, real_labels)</span><br><span class="line"></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        g_optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], d_loss: &#123;:.4f&#125;, g_loss: &#123;:.4f&#125;, D(x): &#123;:.2f&#125;, D(G(z)): &#123;:.2f&#125;&#x27;</span></span><br><span class="line">                  .<span class="built_in">format</span>(epoch, MAX_EPOCH, i + <span class="number">1</span>, <span class="built_in">len</span>(Dataloader), d_loss.item(), g_loss.item(),</span><br><span class="line">                          real_score.mean().item(), fake_score.mean().item()))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 保存真图片</span></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) == <span class="number">1</span>:</span><br><span class="line">            images = images.reshape(images.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">            save_image(denorm(images), os.path.join(sample_dir, <span class="string">&#x27;real_images.png&#x27;</span>))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 保存假图片</span></span><br><span class="line">        fake_images = fake_images.reshape(fake_images.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        save_image(denorm(fake_images), os.path.join(sample_dir, <span class="string">&#x27;fake_images-&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存模型</span></span><br><span class="line">    torch.save(G.state_dict(), <span class="string">&#x27;G.ckpt&#x27;</span>)</span><br><span class="line">    torch.save(D.state_dict(), <span class="string">&#x27;D.ckpt&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;效果，分别展示epoch为1、100、200时生成的图片，其中当epoch为200时噪声就已经很少了，但是对数字的分布结构并不能很好的描述出来。<br><img src="https://img-blog.csdnimg.cn/3790f4c34ea848deab7c737aca0c482b.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="2-GAN变种"><a href="#2-GAN变种" class="headerlink" title="2    GAN变种"></a>2    GAN变种</h1><h2 id="2-1-CGAN"><a href="#2-1-CGAN" class="headerlink" title="2.1    CGAN"></a>2.1    CGAN</h2><p>&emsp;&emsp;AVE和GAN都能基于潜在空间的随机向量z生成新图片，GAN生成的图 像比AVE的更清晰，质量更好些。不过它们生成的都是随机的，无法预先控制你要生成的哪类或哪个数。我们希望 生成某个数字，生成某个主题或类别的图像，实现按需生成的目的，这样的应用应该非常广泛。CGAN正是针对这类问题而提出的。</p>
<h3 id="2-1-1-原理"><a href="#2-1-1-原理" class="headerlink" title="2.1.1    原理"></a>2.1.1    原理</h3><p>&emsp;&emsp;在GAN这种完全无监督的方式加上一个标签或一点监督信息，使整个网络就可看成半监督模型。其基本架构与GAN类似，只要添加一个条件y即可，y就是加入的监督信息，比如说MNIST数据集可以提供某个数字的标签 信息，人脸生成可以提供性别、是否微笑、年龄等信息，带某个主题的图像 等标签信息。<br><img src="https://img-blog.csdnimg.cn/c5a1b78cb4ff4ca3a9cf7a02cee1a6b5.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;对生成器输入一个从潜在空间随机采样的一个向量z及一个条件y，生成 一个符合该条件的图像G(z/y)。对判别器来说，输入一张图像x和条件y，输 出该图像在该条件下的概率D(x/y)。</p>
<h3 id="2-1-2-PyTorch实现"><a href="#2-1-2-PyTorch实现" class="headerlink" title="2.1.2    PyTorch实现"></a>2.1.2    PyTorch实现</h3><p>&emsp;&emsp;CGAN实现采用的数据集依然是 MNIST 手写数字数据集，其实现过程与原始的GAN的相差不大，主要差异时是标注信息的添加。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> make_grid</span><br><span class="line"></span><br><span class="line"><span class="comment">#设置超参数</span></span><br><span class="line">MAX_EPOCH = <span class="number">50</span></span><br><span class="line">LR_RATE = <span class="number">0.0001</span></span><br><span class="line">BATCH_SIZE = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(log_dir = <span class="string">&#x27;logs&#x27;</span>)</span><br><span class="line">sample_dir = <span class="string">&#x27;samples_CGAN&#x27;</span></span><br><span class="line">os.makedirs(sample_dir, exist_ok = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">Dataset = datasets.MNIST(root = <span class="string">&#x27;data&#x27;</span>,</span><br><span class="line">                         download = <span class="literal">False</span>,</span><br><span class="line">                         train = <span class="literal">True</span>,</span><br><span class="line">                         transform = transforms.Compose([transforms.ToTensor(),</span><br><span class="line">                                                         transforms.Normalize([<span class="number">0.5</span>], [<span class="number">0.5</span>])]))</span><br><span class="line"></span><br><span class="line">Dataloader = DataLoader(Dataset, batch_size = BATCH_SIZE, shuffle = <span class="literal">True</span>, drop_last = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.embedding = nn.Embedding(<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        self.G = nn.Sequential(nn.Linear(<span class="number">110</span>, <span class="number">256</span>),</span><br><span class="line">                               nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">                               nn.Linear(<span class="number">256</span>, <span class="number">512</span>),</span><br><span class="line">                               nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">                               nn.Linear(<span class="number">512</span>, <span class="number">1024</span>),</span><br><span class="line">                               nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">                               nn.Linear(<span class="number">1024</span>, <span class="number">784</span>),</span><br><span class="line">                               nn.Tanh())</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z, labels</span>) :</span><br><span class="line">        y = self.embedding(labels)</span><br><span class="line">        x = torch.cat([z, y], dim = <span class="number">1</span>)</span><br><span class="line">        out = self.G(x)</span><br><span class="line">        <span class="keyword">return</span> out.view(z.size(<span class="number">0</span>), <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#判别器</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) :</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        self.embedding = nn.Embedding(<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">        self.D = nn.Sequential(nn.Linear(<span class="number">794</span>, <span class="number">1024</span>),</span><br><span class="line">                               nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">                               nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">                               nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">                               nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">                               nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">                               nn.Linear(<span class="number">512</span>, <span class="number">256</span>),</span><br><span class="line">                               nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">                               nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">                               nn.Linear(<span class="number">256</span>, <span class="number">1</span>),</span><br><span class="line">                               nn.Sigmoid())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, labels</span>):</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        y = self.embedding(labels)</span><br><span class="line">        x = torch.cat([x, y], dim = <span class="number">1</span>)</span><br><span class="line">        out = self.D(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment">#Clamp函数x限制在区间[min, max]内</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">denorm</span>(<span class="params">x</span>):</span><br><span class="line">    out = (x + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> out.clamp(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">D = Discriminator().cuda()</span><br><span class="line">G = Generator().cuda()</span><br><span class="line">d_optimizer = optim.Adam(D.parameters(), lr = LR_RATE)</span><br><span class="line">g_optimizer = optim.Adam(G.parameters(), lr = LR_RATE)</span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(MAX_EPOCH) :</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(Dataloader) :</span><br><span class="line">        step = epoch * <span class="built_in">len</span>(Dataloader) + i + <span class="number">1</span></span><br><span class="line">        images, labels = images.reshape(BATCH_SIZE, -<span class="number">1</span>).cuda(), labels.cuda()</span><br><span class="line">        real_labels = torch.ones(BATCH_SIZE, <span class="number">1</span>).cuda()</span><br><span class="line"></span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line">        g_optimizer.zero_grad()</span><br><span class="line">        out = D(images, labels)</span><br><span class="line">        real_score = out</span><br><span class="line">        d_loss_real = criterion(out, real_labels)</span><br><span class="line"></span><br><span class="line">        z = torch.randn(BATCH_SIZE, <span class="number">100</span>).cuda()</span><br><span class="line">        fake_labels = torch.randint(<span class="number">0</span>, <span class="number">10</span>, (BATCH_SIZE, )).cuda()</span><br><span class="line"></span><br><span class="line">        fake_images = G(z, fake_labels)</span><br><span class="line">        out = D(fake_images, fake_labels)</span><br><span class="line">        fake_score = out</span><br><span class="line">        d_loss_fake = criterion(out, torch.zeros(BATCH_SIZE, <span class="number">1</span>).cuda())</span><br><span class="line"></span><br><span class="line">        d_loss = d_loss_fake + d_loss_real</span><br><span class="line"></span><br><span class="line">        d_loss.backward()</span><br><span class="line">        d_optimizer.step()</span><br><span class="line"></span><br><span class="line">        d_optimizer.zero_grad()</span><br><span class="line">        g_optimizer.zero_grad()</span><br><span class="line">        z = torch.randn(BATCH_SIZE, <span class="number">100</span>).cuda()</span><br><span class="line">        fake_images = G(z, fake_labels)</span><br><span class="line">        out = D(fake_images, fake_labels)</span><br><span class="line">        g_loss = criterion(out, real_labels)</span><br><span class="line"></span><br><span class="line">        g_loss.backward()</span><br><span class="line">        g_optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch [&#123;&#125;/&#123;&#125;], Step [&#123;&#125;/&#123;&#125;], d_loss: &#123;:.4f&#125;, g_loss: &#123;:.4f&#125;, D(x): &#123;:.2f&#125;, D(G(z)): &#123;:.2f&#125;&#x27;</span></span><br><span class="line">                  .<span class="built_in">format</span>(epoch, MAX_EPOCH, i + <span class="number">1</span>, <span class="built_in">len</span>(Dataloader), d_loss.item(), g_loss.item(),</span><br><span class="line">                          real_score.mean().item(), fake_score.mean().item()))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存真图片</span></span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) == <span class="number">1</span>:</span><br><span class="line">            images = images.reshape(images.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">            save_image(denorm(images), os.path.join(sample_dir, <span class="string">&#x27;real_images.png&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存假图片</span></span><br><span class="line">        fake_images = fake_images.reshape(fake_images.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        save_image(denorm(fake_images), os.path.join(sample_dir, <span class="string">&#x27;fake_images-&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(epoch + <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 可视化损失值</span></span><br><span class="line">        writer.add_scalars(<span class="string">&#x27;scalars&#x27;</span>, &#123;<span class="string">&#x27;d_loss&#x27;</span>: d_loss.item(), <span class="string">&#x27;g_loss&#x27;</span>: g_loss.item()&#125;, step)</span><br><span class="line">    <span class="comment"># 保存模型</span></span><br><span class="line">    torch.save(G.state_dict(), <span class="string">&#x27;G.ckpt&#x27;</span>)</span><br><span class="line">    torch.save(D.state_dict(), <span class="string">&#x27;D.ckpt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#利用网格（10×10）的形式显示指定条件下生成的图像。</span></span><br><span class="line">z = torch.randn(<span class="number">100</span>, <span class="number">100</span>).cuda()</span><br><span class="line">labels = torch.LongTensor([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]).cuda()</span><br><span class="line">images = G(z, labels).unsqueeze(<span class="number">1</span>)</span><br><span class="line">grid = make_grid(images, nrow = <span class="number">10</span>, normalize = <span class="literal">True</span>)</span><br><span class="line">fig, ax = plt.subplots(figsize = (<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">ax.imshow(grid.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).detach().cpu().numpy(), cmap = <span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化指定单个数字条件下生成的数字</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_digit</span>(<span class="params">generator, digit</span>) :</span><br><span class="line">    z = torch.randn(<span class="number">1</span>, <span class="number">100</span>).cuda()</span><br><span class="line">    label = torch.LongTensor([digit]).cuda()</span><br><span class="line">    img = generator(z, label).detach().cpu()</span><br><span class="line">    img = <span class="number">0.5</span> * img + <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">return</span> transforms.ToPILImage()(img)</span><br><span class="line">generate_digit(G, <span class="number">8</span>)</span><br></pre></td></tr></table></figure>
<p>利用网格（10×10）的形式显示指定条件下生成的图像：<br><img src="https://img-blog.csdnimg.cn/e07f02b2a62c4121a3c9508964bf8645.png#pic_center" alt="在这里插入图片描述"><br>可视化指定单个数字条件下生成的数字：<br><img src="https://img-blog.csdnimg.cn/8e844bf24dda4184b3c7f68404dc2cc3.png#pic_center" alt="在这里插入图片描述"><br>可视化生成器和判别器损失值如下 ：<br><img src="https://img-blog.csdnimg.cn/9b041640e36b4c8d9adf7825ed0b09f1.png#pic_center" alt="在这里插入图片描述"><br>由上图可知，CGAN的训练过程不像一般神经网络的过程，它是判别 器和生成器互相竞争的过程，最后两者达成一个平衡。</p>
<h2 id="2-2-DCGAN"><a href="#2-2-DCGAN" class="headerlink" title="2.2    DCGAN"></a>2.2    DCGAN</h2><p>&emsp;&emsp;在前面中无论是原始的GAN还是CGAN我们建立的网络都是基于全连接网络构建的，这样的网络由于图片的维度较高，网络参数量巨大，不能很好地学习到图片地特征，导致训练效果不佳。DCGAN提出了使用转置卷积层实现的生成网络，普通卷积层来实现的判别网络，大大地降低了网络参数量，同时图片的生成效果也大幅提升，展现了 GAN 模型在图片生成效果上超越 VAE 模型的潜质。注：虽然使用卷积网络会大大降低参数量，但是所需要的样本数要更多一些。<br><img src="https://img-blog.csdnimg.cn/5e90c21b8b094029a3871a8d40e57433.png#pic_center" alt="加粗样式"></p>
<h2 id="2-3-CycleGAN"><a href="#2-3-CycleGAN" class="headerlink" title="2.3    CycleGAN"></a>2.3    CycleGAN</h2><p>CycleGAN 是一种无监督方式，主要用于图片风格相互转换的。CycleGAN 基本的思想是，如果由图片 A 转换到图片 B，再从图片 B 转换到A′，那么A′应该和 A 是同一张图片。因此除了设立标准的 GAN 损失项外，CycleGAN 还增设了循环一致性损失(Cycle Consistency Loss)，来保证A′尽可能与 A 逼近。<img src="https://img-blog.csdnimg.cn/4ec023cd50bc4123a2c2d3031746937b.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-4-WGAN"><a href="#2-4-WGAN" class="headerlink" title="2.4    WGAN"></a>2.4    WGAN</h2><p>&emsp;&emsp;GAN 的训练问题一直被诟病，很容易出现训练不收敛和模式崩塌的现象。WGAN 从理论层面分析了原始的 GAN 使用 JS 散度存在的缺陷，并提出了可以使用 Wasserstein 距 离来解决这个问题。在 WGAN-GP 中，作者提出了通过添加梯度惩罚项，从工程层面很好的实现了 WGAN 算法，并且实验性证实了 WGAN 训练稳定的优点。</p>
<h1 id="3-训练GAN的技巧"><a href="#3-训练GAN的技巧" class="headerlink" title="3    训练GAN的技巧"></a>3    训练GAN的技巧</h1><ul>
<li>批量加载和批规范化，有利于提升训练过程中博弈的稳定性。</li>
<li>使用tanh激活函数作为生成器最后一层，将图像数据规范在-1和1之间，一般不用sigmoid。</li>
<li>选用Leaky ReLU作为生成器和判别器的激活函数，有利于改善梯度的稀疏性，稀疏的梯度会妨碍GAN的训练。 </li>
<li>使用卷积层时，考虑卷积核的大小能被步幅整除，否则，可能导致生成的图像中存在棋盘状伪影。</li>
</ul>
<p>全部代码可以参考<a href="https://github.com/aishangcengloua/MLData/tree/master/PyTorch/GenerateNetwork">此处</a><br><strong>参考</strong></p>
<ul>
<li><strong>《Python深度学习基于PyTorch》</strong></li>
<li><strong>《TensorFlow深度学习》</strong></li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>PyTorch</tag>
        <tag>生成对抗网络</tag>
      </tags>
  </entry>
  <entry>
    <title>自编码器</title>
    <url>/2022/06/05/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;目前我们可以通过爬虫等方式获取海量的样本数据𝒙，如照片、语音、文本等，是相对容易的，但困难的是获取这些数据所对应的标签信息，例如机器翻译，除了收集源语言的对话文本外，还需要待翻译的目标语言文本数据。数据的标注工作目前主要还是依赖人的先验知识来完成。因此，面对海量的无标注数据，我们需要从中学习到数据的分布𝑃(𝒙)的算法，而无监督算法模型就是针对这类问题而发展的。特别地，如果算法把𝒙作为监督信号来学习，这类算法称为自监督学习，本博客介绍的自编码器就属于自监督学习范畴。</p>
<h1 id="1-自编码器"><a href="#1-自编码器" class="headerlink" title="1    自编码器"></a>1    自编码器</h1><h2 id="1-1-原理"><a href="#1-1-原理" class="headerlink" title="1.1    原理"></a>1.1    原理</h2><p>&emsp;&emsp;自编码器是通过对输入$x$进行编码后得到一个低维的向量$z$，然后根据 这个向量还原出输入$x$。通过对比$x$与$\bar{x}$的误差，再利用神经网络去训练使得误差逐渐减小，从而达到非监督学习的目的。结构如下图所示。<br><img src="https://img-blog.csdnimg.cn/ad29328da64c473bacd2b582ad6f817e.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;其中我们将数据𝒙本身作为监督信号来指导网络的训练，即希望神经网络能够学习到映射${𝑓_θ}$: $x$ → $x$，我们把网络𝑓𝜃切分为两个部分，前面的子网络尝试学习映射关系：$g_{θ1}$: $x$ → $z$，后面的子网络尝试学习映射关系：$h_{θ2}$：$z$ → $x$。我们把$g_{θ1}$看成一个数据编码(Encode)的过程，作用就是将输入$x$编码成低纬度的隐藏变量$z$，$h_{θ2}$看成一个数据解码(Dncode)的过程，作用是将隐藏变量$z$重塑成高纬度的$x$。编码器和解码器共同完成了输入数据$x$的编码和解码过程，我们把整个网路模型${𝑓_θ}$叫做自动编码器(Auto-Encoder)，如果网络含有多个隐藏层，则称为深度自编码器(Deep Auto-encoder)。<img src="https://img-blog.csdnimg.cn/32d703628a7344b88533bbc59f8d41d2.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;自编码器的编码器通过编码器压缩得到的隐藏变量$z$重塑$\bar{x}$，我们希望解码器的输出能够完美地或者近似恢复出原来的输入，即$x$约等于$\bar{x}$，则自编码器的损失函数可定义为</p>
<script type="math/tex; mode=display">
\begin{aligned}
&Minimize  ℒ = dist(x, \bar{x})\\
&\bar{x} = h_{θ2}(g_{θ1}(x))\\
\end{aligned}</script><p>&emsp;&emsp;其中$dist(x, \bar{x})$表示$x$与 $\bar{x}$ 的距离，常见的距离度量函数为欧氏距离(也即均方差):</p>
<script type="math/tex; mode=display">
\begin{aligned}
&ℒ = \sum_{i}(x - \bar{x})^2\\
\end{aligned}</script><h2 id="1-2-PyTorch实现图片重塑"><a href="#1-2-PyTorch实现图片重塑" class="headerlink" title="1.2    PyTorch实现图片重塑"></a>1.2    PyTorch实现图片重塑</h2><h3 id="1-2-1-Fashion-MNIST-数据集"><a href="#1-2-1-Fashion-MNIST-数据集" class="headerlink" title="1.2.1    Fashion MNIST 数据集"></a>1.2.1    Fashion MNIST 数据集</h3><p>&emsp;&emsp;Fashion MNIST 是一个定位在比 MNIST 图片识别问题稍复杂的数据集，它的设定与MNIST 几乎完全一样，包含了 10 类不同类型的衣服、鞋子、包等灰度图片，图片大小为28 × 28，共 70000 张图片，其中 60000 张用于训练集，10000 张用于测试集。Fashion MNIST 除了图片内容与 MNIST 不一样，其它设定都相同，大部分情况可以直接替换掉原来基于 MNIST 训练的算法代码，而不需要额外修改。由于 Fashion MNIST 图片识别相对于 MNIST 图片更难，因此可以用于测试稍复杂的算法性能。<br><img src="https://img-blog.csdnimg.cn/6d62bb75794546f2b72c93b2cdf5831d.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;在PyTorch中可以直接使用torchvision包进行在线下载。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset = datasets.FashionMNIST(root = <span class="string">&#x27;data2&#x27;</span>,</span><br><span class="line">                        train = <span class="literal">False</span>,</span><br><span class="line">                        download = <span class="literal">True</span>,</span><br><span class="line">                        transform = transforms.ToTensor())</span><br></pre></td></tr></table></figure>
<h3 id="1-2-2-网络结构"><a href="#1-2-2-网络结构" class="headerlink" title="1.2.2    网络结构"></a>1.2.2    网络结构</h3><p>&emsp;&emsp;我们利用编码器将输入图片$x ∈ 𝑅^{784}降维到较低维度的隐藏向量z∈ 𝑅^{20}$，并基于隐藏向量 利用解码器重建图片，自编码器模型如图所示，编码器由 3 层全连接层网络组成，输出节点数分别为 256、128、20，解码器同样由 3 层全连接网络组成，输出节点数分别为 128、256、784。<br><img src="https://img-blog.csdnimg.cn/05c32307ae444242a8bb8181aa18991b.png#" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AE</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(AE, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">128</span>, <span class="number">20</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">20</span>, <span class="number">128</span>)</span><br><span class="line">        self.relu3 = nn.ReLU()</span><br><span class="line">        self.fc5 = nn.Linear(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.relu4 = nn.ReLU()</span><br><span class="line">        self.fc6 = nn.Linear(<span class="number">256</span>, <span class="number">784</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Encoder</span>(<span class="params">self, x</span>):</span><br><span class="line">        h1 = self.relu1(self.fc1(x))</span><br><span class="line">        h2 = self.relu2(self.fc2(h1))</span><br><span class="line">        <span class="keyword">return</span> self.fc3(h2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Decoder</span>(<span class="params">self, z</span>):</span><br><span class="line">        h1 = self.relu3(self.fc4(z))</span><br><span class="line">        h2 = self.relu4(self.fc5(h1))</span><br><span class="line">        <span class="keyword">return</span> F.sigmoid(self.fc6(h2))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        z = self.Encoder(x)</span><br><span class="line">        <span class="comment"># print(z.shape)</span></span><br><span class="line">        x_reconst = self.Decoder(z)</span><br><span class="line">        <span class="keyword">return</span> x_reconst</span><br></pre></td></tr></table></figure>
<h3 id="1-2-3-训练"><a href="#1-2-3-训练" class="headerlink" title="1.2.3    训练"></a>1.2.3    训练</h3><p>&emsp;&emsp;自编码器的训练过程与分类器的基本一致，通过误差函数计算出重建向量$\bar{x} 与原始输入向量x$之间的距离。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(MAX_EPOCH) :</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> i, (x, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader) :</span><br><span class="line">        x = x.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        x = x.view(-<span class="number">1</span>, image_size)</span><br><span class="line">        x_reconst = model(x)</span><br><span class="line">        <span class="comment"># 重构损失，使用二元分类损失</span></span><br><span class="line">        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        reconst_loss.backward()</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure>
<h3 id="1-2-4-图片重塑"><a href="#1-2-4-图片重塑" class="headerlink" title="1.2.4    图片重塑"></a>1.2.4    图片重塑</h3><p>&emsp;&emsp;与分类问题不同的是，自编码器的模型性能一般不好量化评价，尽管ℒ值可以在一定程度上代表网络的学习效果，但我们最终希望获得还原度较高、样式较丰富的重建样本。对于图片来说，一般依赖于人工主观的评估。在这次实践中正确做法应是将数据集划分为训练集和测试集，用测试集来进行图片重塑对比，但我为了方便就直接使用训练集来进行重塑了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad() :</span><br><span class="line">    out = model(x)</span><br><span class="line">    <span class="comment">#将与原图与重塑图像进行拼接，奇数列为原图像，偶数列为重塑图像</span></span><br><span class="line">    x_concat = torch.cat([x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), out.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)], dim = <span class="number">3</span>)</span><br><span class="line">    save_image(x_concat, os.path.join(samples_dir, <span class="string">f&#x27;reconst-<span class="subst">&#123;epoch </span></span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/f062f51cf95c490781564ea4c4ec2ed3.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;重塑图像如上图，其中奇数列为原图像，偶数列为重塑图像。可以看到，第一个 Epoch 时，图片重建效果较差，图片非常模糊，逼真度较差；随着训练的进行，重建图片边缘越来越清晰，第 100 个 Epoch时，重建的图片效果已经比较接近真实图片。<br>全部代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">MAX_EPOCH = <span class="number">100</span></span><br><span class="line">lr_learning = <span class="number">0.001</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">image_size = <span class="number">784</span></span><br><span class="line">os.makedirs(<span class="string">&#x27;samples_AE&#x27;</span>, exist_ok = <span class="literal">True</span>)</span><br><span class="line">samples_dir = <span class="string">&#x27;samples_AE&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset = datasets.FashionMNIST(root = <span class="string">&#x27;data2&#x27;</span>,</span><br><span class="line">                        train = <span class="literal">False</span>,</span><br><span class="line">                        download = <span class="literal">True</span>,</span><br><span class="line">                        transform = transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">data_loader = DataLoader(dataset, shuffle = <span class="literal">True</span>, batch_size = batch_size, drop_last = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AE</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(AE, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">128</span>, <span class="number">20</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">20</span>, <span class="number">128</span>)</span><br><span class="line">        self.relu3 = nn.ReLU()</span><br><span class="line">        self.fc5 = nn.Linear(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.relu4 = nn.ReLU()</span><br><span class="line">        self.fc6 = nn.Linear(<span class="number">256</span>, <span class="number">784</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Encoder</span>(<span class="params">self, x</span>):</span><br><span class="line">        h1 = self.relu1(self.fc1(x))</span><br><span class="line">        h2 = self.relu2(self.fc2(h1))</span><br><span class="line">        <span class="keyword">return</span> self.fc3(h2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Decoder</span>(<span class="params">self, z</span>):</span><br><span class="line">        h1 = self.relu3(self.fc4(z))</span><br><span class="line">        h2 = self.relu4(self.fc5(h1))</span><br><span class="line">        <span class="keyword">return</span> F.sigmoid(self.fc6(h2))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        z = self.Encoder(x)</span><br><span class="line">        <span class="comment"># print(z.shape)</span></span><br><span class="line">        x_reconst = self.Decoder(z)</span><br><span class="line">        <span class="keyword">return</span> x_reconst</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model = AE().to(device)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr = lr_learning)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(MAX_EPOCH) :</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> i, (x, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader) :</span><br><span class="line">        x = x.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        x = x.view(-<span class="number">1</span>, image_size)</span><br><span class="line">        x_reconst = model(x)</span><br><span class="line">        <span class="comment"># 重构损失，使用二元分类损失</span></span><br><span class="line">        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        reconst_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad() :</span><br><span class="line">        out = model(x)</span><br><span class="line">        <span class="comment">#将与原图与重塑图像进行拼接，奇数列为原图像，偶数列为重塑图像</span></span><br><span class="line">        x_concat = torch.cat([x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), out.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)], dim = <span class="number">3</span>)</span><br><span class="line">        save_image(x_concat, os.path.join(samples_dir, <span class="string">f&#x27;reconst-<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.png&#x27;</span>))</span><br><span class="line"></span><br><span class="line">img1 = cv.imread(<span class="string">&#x27;samples_AE/reconst-1.png&#x27;</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">&#x27;samples_AE/reconst-50.png&#x27;</span>)</span><br><span class="line">img3 = cv.imread(<span class="string">&#x27;samples_AE/reconst-100.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line">images = [img1, img2, img3]</span><br><span class="line">xlabels = [<span class="string">&#x27;epoch : 1&#x27;</span>, <span class="string">&#x27;epoch : 50&#x27;</span>, <span class="string">&#x27;epoch : 100&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>) :</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(images[i], <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.title(xlabels[i])</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h1 id="2-自编码器变种"><a href="#2-自编码器变种" class="headerlink" title="2    自编码器变种"></a>2    自编码器变种</h1><h2 id="2-1-降噪自编码器-DAE"><a href="#2-1-降噪自编码器-DAE" class="headerlink" title="2.1    降噪自编码器(DAE)"></a>2.1    降噪自编码器(DAE)</h2><p>&emsp;&emsp;DAE是通过改变重构误差项来获得一个能学到有用信息的自编码器。对于传统的自编码器最小优化目标：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&θ^∗ = argmin _θ \quad\ dist(ℎθ2(𝑔θ1(x)), x)\\
\end{aligned}</script><p>&emsp;&emsp;对于这个函数如果模型被赋予过大的容量，损失函数仅仅使得 g ◦ f 学成一个恒等函数。也即网络会简单地复制输入，网络没有学习特征的能力。DAE给网络输入$x$添加采样自高斯分布的噪声$\alpha$：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&x^\prime = x + \alpha, \alpha∈𝒩(0, var)\\
\end{aligned}</script><p>则优化目标变成：</p>
<script type="math/tex; mode=display">
\begin{aligned}
&θ^∗ = argmin _θ \quad\ dist(ℎ_{θ2}(𝑔_{θ1}(x^\prime)), x)\\
\end{aligned}</script><p>&emsp;&emsp;其中$x^\prime$是被某种噪声损坏的$x$的副本。因此去噪自编码器必须撤消这些损坏，而不是简单地复制输入。<br><img src="https://img-blog.csdnimg.cn/d5fc0ade729346b794fec89c1219f75d.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-2-对抗自编码器-AAE"><a href="#2-2-对抗自编码器-AAE" class="headerlink" title="2.2    对抗自编码器(AAE)"></a>2.2    对抗自编码器(AAE)</h2><p>&emsp;&emsp;为了能够方便地从某个已知的先验分布中𝑝(𝒛)采样隐藏变量𝒛，方便利用𝑝(𝒛)来重建输 入，对抗自编码器利用额外的判别器网络(Discriminator，简称 D网络)来判定降维的隐藏变量𝒛是否采样自先验分布𝑝(𝒛)。判别器网络的输出为一个属于[0,1]区间的变量，表征隐藏向量是否采样自先验分布𝑝(𝒛)：所有采样自先验分布𝑝(𝒛)的𝒛标注为真，采样自编码器的条件概率𝑞(𝒛|𝒙)的𝒛标注为假。通过这种方式训练，除了可以重建样本，还可以约束条件概率分布𝑞(𝒛|𝒙)逼近先验分布𝑝(𝒛)。<br><img src="https://img-blog.csdnimg.cn/4f54d125906e4eae952b11f263763ac8.png" alt="在这里插入图片描述"></p>
<h2 id="2-3-变分自编码器-VAE"><a href="#2-3-变分自编码器-VAE" class="headerlink" title="2.3    变分自编码器(VAE)"></a>2.3    变分自编码器(VAE)</h2><h3 id="2-3-1-原理"><a href="#2-3-1-原理" class="headerlink" title="2.3.1    原理"></a>2.3.1    原理</h3><p>&emsp;&emsp;自编码器因不能随意产生合理的潜在变量，从而导致它无法产生新的内容。因为潜在变量$z$都是编码器从原始图片中产生的。为解决这一问题，研究人员对潜在空间$z$(潜在变量对应的空间)增加一些约束，使$z$满足正态分布，由此就出现了VAE模型，VAE对编码器添加约束，就是强迫它产生服从单位正态分布的潜在变量。正是这种约束，把VAE和自编码器区分开来。<br>&emsp;&emsp;从神经网络的角度来看，VAE 相对于自编码器模型，同样具有编码器和解码器两个子网络。解码器接受输入$x$，输出为隐变量$z$；解码器负责将隐变量$z$解码为重建的$x$。不同的是，VAE 模型对隐变量$z$的分布有显式地约束，希望隐变量$z$符合预设的先验分布P($z$)。因此，在损失函数的设计上，除了原有的重建误差项外，还添加了隐变量$z$分布的约束项。也即我们优化目标希望$z$的分布接近于正态分布。度量图像的相似度一般采用交叉熵(如nn.BCELoss)，度量两个分布 的相似度一般采用KL散度(Kullback-Leibler divergence)。这两个度量的和 构成了整个模型的损失函数。变分自编码器的结构如下：<br><img src="https://img-blog.csdnimg.cn/15df6f69a6084f62ac52c4db7dd35e23.png#pic_center" alt="在这里插入图片描述"><br>模块1：把输入样本$x$通过编码器输出两个m维向量(mu、log_var)，这两个向量是潜在空间(假设满足正态分布)的两个参数(相当于均值和方差)。<br>模块2：从标准正态分布N(0,I)中采样 一个ε。<br>模块3：使得$z$=mu+exp(log_var)*ε。<br>模块4：$z$通过解码器生成一个样本$\bar{x}$。</p>
<p>损失函数的具体代码如下，推导过程：<a href="https://arxiv.org/pdf/1606.05908.pdf">https://arxiv.org/pdf/1606.05908.pdf</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义重构损失函数及KL散度 </span></span><br><span class="line">reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=<span class="literal">False</span>)</span><br><span class="line">kl_div = - <span class="number">0.5</span> * torch.<span class="built_in">sum</span>(<span class="number">1</span> + log_var - mu.<span class="built_in">pow</span>(<span class="number">2</span>) - log_var.exp()) </span><br><span class="line"><span class="comment">#两者相加得总损失 loss= reconst_loss+ kl_div</span></span><br></pre></td></tr></table></figure>
<h3 id="2-3-2-VAE图片生成"><a href="#2-3-2-VAE图片生成" class="headerlink" title="2.3.2    VAE图片生成"></a>2.3.2    VAE图片生成</h3><p>&emsp;&emsp;此次我们基于 VAE 模型实战MNIST手写数字图片的重建与生成。输入为 MNIST手写数字图片向量，经过 3 个全连接层后得到隐向量𝐳的均值与方差，分别用两个输出节点数为 20 的全连接层表示，FC2 的 20 个输出节点表示 20 个特征分布的均值向量，FC3 的 20 个输出节点表示 20 个特征分布的取log后的方差向量。采样获得长度为 20 的隐向量𝐳，并通过 FC4 和 FC5 重建出样本图片。<br>&emsp;&emsp;VAE 作为生成模型，除了可以重建输入样本，还可以单独使用解码器生成样本。通过从先验分布𝑝(𝐳)中直接采样获得隐向量𝐳，经过解码后可以产生生成的样本。<br><img src="https://img-blog.csdnimg.cn/e8bb31276b44466e88709706a27a1301.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;此过程的实现与图片的重塑过程相差不大，主要差异在损失函数部分和潜在变量$z$的采样部分。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">MAX_EPOCH = <span class="number">100</span></span><br><span class="line">lr_learning = <span class="number">0.001</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">hidden_size = <span class="number">400</span></span><br><span class="line">z_size = <span class="number">20</span></span><br><span class="line">image_size = <span class="number">784</span></span><br><span class="line">os.makedirs(<span class="string">&#x27;samples&#x27;</span>, exist_ok = <span class="literal">True</span>)</span><br><span class="line">samples_dir = <span class="string">&#x27;samples&#x27;</span></span><br><span class="line"></span><br><span class="line">dataset=datasets.MNIST( root = <span class="string">&#x27;data&#x27;</span>,</span><br><span class="line">                        train = <span class="literal">False</span>,</span><br><span class="line">                        download = <span class="literal">True</span>,</span><br><span class="line">                        transform = transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">data_loader = DataLoader(dataset, shuffle = <span class="literal">True</span>, batch_size = batch_size, drop_last = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VAE</span>(nn.Module) :</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_size, hidden_size, z_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(VAE, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(image_size, hidden_size)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.fc2 = nn.Linear(hidden_size, z_size)</span><br><span class="line">        self.fc3 = nn.Linear(hidden_size, z_size)</span><br><span class="line">        self.fc4 = nn.Linear(z_size, hidden_size)</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line">        self.fc5 = nn.Linear(hidden_size, image_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Encoder</span>(<span class="params">self, x</span>):</span><br><span class="line">        h = self.relu1(self.fc1(x))</span><br><span class="line">        <span class="keyword">return</span> self.fc2(h), self.fc3(h)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Reparameterize</span>(<span class="params">self, mu, Log_var</span>):</span><br><span class="line">        std = torch.exp(Log_var / <span class="number">2</span>)</span><br><span class="line">        eps = torch.randn_like((std))</span><br><span class="line">        <span class="keyword">return</span> mu + eps * std</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Decoder</span>(<span class="params">self, z</span>):</span><br><span class="line">        h = self.relu2(self.fc4(z))</span><br><span class="line">        <span class="keyword">return</span> F.sigmoid(self.fc5(h))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mu, Log_var = self.Encoder(x)</span><br><span class="line">        z = self.Reparameterize(mu, Log_var)</span><br><span class="line">        x_reconst = self.Decoder(z)</span><br><span class="line">        <span class="keyword">return</span> x_reconst, mu, Log_var</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model = VAE(image_size, hidden_size, z_size).to(device)</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr = lr_learning)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(MAX_EPOCH) :</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> i, (x, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(data_loader) :</span><br><span class="line">        x = x.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        x = x.view(-<span class="number">1</span>, image_size)</span><br><span class="line">        x_reconst, mu, Log_var = model(x)</span><br><span class="line">        <span class="comment"># 计算重构损失和KL散度</span></span><br><span class="line">        <span class="comment"># 重构损失</span></span><br><span class="line">        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># KL散度</span></span><br><span class="line">        kl_div = - <span class="number">0.5</span> * torch.<span class="built_in">sum</span>(<span class="number">1</span> + Log_var - mu.<span class="built_in">pow</span>(<span class="number">2</span>) - Log_var.exp())</span><br><span class="line">        loss = reconst_loss + kl_div</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># if i % 10 == 0 :</span></span><br><span class="line">        <span class="comment">#     print(f&#x27;reconst_loss : &#123;reconst_loss : 0.3f&#125;, kl_div : &#123;kl_div : 0.3f&#125;&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad() :</span><br><span class="line">        <span class="comment">#图片生成</span></span><br><span class="line">        z = torch.randn(batch_size, z_size).to(device)</span><br><span class="line">        out = model.Decoder(z).view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">        save_image(out, os.path.join(samples_dir, <span class="string">f&#x27;sampled-<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.png&#x27;</span>))</span><br><span class="line">        <span class="comment">#图片重塑</span></span><br><span class="line">        out, _, _ = model(x)</span><br><span class="line">        <span class="built_in">print</span>(x.shape)</span><br><span class="line">        x_concat = torch.cat([x.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), out.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)], dim = <span class="number">3</span>)</span><br><span class="line">        save_image(x_concat, os.path.join(samples_dir, <span class="string">f&#x27;reconst-<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>.png&#x27;</span>))</span><br><span class="line"></span><br><span class="line">img1 = cv.imread(<span class="string">&#x27;samples/sampled-1.png&#x27;</span>)</span><br><span class="line">img2 = cv.imread(<span class="string">&#x27;samples/sampled-50.png&#x27;</span>)</span><br><span class="line">img3 = cv.imread(<span class="string">&#x27;samples/sampled-100.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line">img4 = cv.imread(<span class="string">&#x27;samples/reconst-1.png&#x27;</span>)</span><br><span class="line">img5 = cv.imread(<span class="string">&#x27;samples/reconst-50.png&#x27;</span>)</span><br><span class="line">img6 = cv.imread(<span class="string">&#x27;samples/reconst-100.png&#x27;</span>)</span><br><span class="line"></span><br><span class="line">images = [img1, img2, img3, img4, img5, img6]</span><br><span class="line">xlabels = [<span class="string">&#x27;images sample epoch : 1&#x27;</span>, <span class="string">&#x27;epoch : 50&#x27;</span>, <span class="string">&#x27;epoch : 100&#x27;</span>, <span class="string">&#x27;images reconst epoch : 1&#x27;</span>, <span class="string">&#x27;epoch : 50&#x27;</span>, <span class="string">&#x27;epoch : 100&#x27;</span>]</span><br><span class="line">plt.figure(figsize = (<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>) :</span><br><span class="line">    plt.subplot(<span class="number">2</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(images[i], <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.title(xlabels[i])</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;效果如下，其中重塑图片中奇数列是原图，偶数列为重塑图像。由潜在空间点$z$生成的图像随着epoch的增加是越来越清晰的。<br><img src="https://img-blog.csdnimg.cn/b51ea0edf97f445893d9fc98b50337bd.png#pic_center" alt="在这里插入图片描述"><br><strong>参考</strong><br>《TensorFlow深度学习》<br>《Python深度学习基于PyTorch》</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>PyTorch</tag>
        <tag>自编码器</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】Canny 算子边缘检测</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91Canny-%E7%AE%97%E5%AD%90%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<p>﻿Canny 算子和 Marr（LoG）边缘检测方法类似，也属于是先平滑后求导数的方法John Canny研究了最优边缘检测方法所需的特性，给出了评价边缘检测性能优劣的三个指标：</p>
<ul>
<li>好的信噪比，即将非边缘点判定为边缘点的概率要低，将边缘点判为非边缘点的概率要低；</li>
<li>高的定位性能，即检测出的边缘点要尽可能在实际边缘的中心；</li>
<li>对单一边缘仅有唯一响应，即单个边缘产生多个响应的概率要低，并且虚假响应边缘应该得到最大抑制。</li>
</ul>
<p>步骤：</p>
<ul>
<li>减少噪音：由于边缘检测易受图像中的噪声影响，因此第一步是使用5x5高斯滤波器去除图像中的噪声.<br><img src="https://img-blog.csdnimg.cn/e3024b07247346be98463b755d346e6f.png#pic_center" alt="在这里插入图片描述"></li>
<li>计算图像梯度：对平滑后的图像使用sobel算子在水平与竖直方向上计算一阶导数，得到图像梯度（Gx和Gy）。根据梯度图找到边界梯度和方向<br><img src="https://img-blog.csdnimg.cn/0e5f4cccb84949258fc09df97191bc55.png#pic_center" alt="在这里插入图片描述"><br>根据角度对幅值进行非极大值抑制：将模糊的边界变得清晰（sharp）</li>
<li>将其梯度方向近似为以下值中的一个（0,45,90,135,180,225,270,315）（即上下左右和45度方向）；</li>
<li>比较该像素点，和其梯度方向正负方向的像素点的梯度强度；</li>
<li>如果该像素点梯度强度最大则保留，否则抑制（删除，即置为0）。<br><img src="https://img-blog.csdnimg.cn/116fa846d23a4a39873025fc11b8e35a.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/35c89ab7be494532a47c1723b1edd970.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/93823c91a0e94d81bc20b71d4332a9fe.png#pic_center" alt="在这里插入图片描述"><br>edge = cv2.Canny(image, threshold1, threshold2) 必要参数：</li>
<li>第一个参数是需要处理的原图像，该图像必须为单通道的灰度图；</li>
<li>第二个参数是阈值1；</li>
<li>第三个参数是阈值2。</li>
</ul>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">img = cv.imread(<span class="string">&#x27;girl.png&#x27;</span>, cv.IMREAD_GRAYSCALE)</span><br><span class="line">gaussion = cv.GaussianBlur(img, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)</span><br><span class="line">canny = cv.Canny(gaussion, <span class="number">32</span>, <span class="number">80</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">fig.<span class="built_in">set</span>(alpha = <span class="number">0.2</span>)</span><br><span class="line">plt.subplot2grid((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">plt.imshow(img, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">plt.imshow(canny, <span class="string">&#x27;gray&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/cc8336aa6b2641f682b9c7f0c7f88af6.png#pic_center" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#实现在线手动调整threshold1和threshold2的值</span></span><br><span class="line">img = cv.imread(<span class="string">&#x27;girl.png&#x27;</span>, cv.IMREAD_GRAYSCALE)</span><br><span class="line">img = cv.resize(img, (img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">threshold1_min = <span class="number">0</span></span><br><span class="line">threshold1_max = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">threshold2_min = <span class="number">100</span></span><br><span class="line">threshold2_max = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">canny_threshold1</span>(<span class="params">x</span>) :</span><br><span class="line">    gaussion = cv.GaussianBlur(img, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)</span><br><span class="line">    canny = cv.Canny(gaussion, x, threshold2_min)</span><br><span class="line">    cv.imshow(<span class="string">&#x27;Canny&#x27;</span>, canny)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">canny_threshold2</span>(<span class="params">x</span>) :</span><br><span class="line">    gaussion = cv.GaussianBlur(img, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)</span><br><span class="line">    canny = cv.Canny(gaussion, threshold1_min, x)</span><br><span class="line">    cv.imshow(<span class="string">&#x27;Canny&#x27;</span>, canny)</span><br><span class="line"></span><br><span class="line">cv.namedWindow(<span class="string">&#x27;Canny&#x27;</span>, cv.WINDOW_NORMAL | cv.WINDOW_KEEPRATIO)</span><br><span class="line"><span class="comment">#创建可调整大小的窗口并在调整窗口大小时保持图像比例不变</span></span><br><span class="line">cv.createTrackbar(<span class="string">&#x27;threshold1&#x27;</span>, <span class="string">&#x27;Canny&#x27;</span>, threshold1_min, threshold1_max, canny_threshold1)</span><br><span class="line">cv.createTrackbar(<span class="string">&#x27;threshold2&#x27;</span>, <span class="string">&#x27;Canny&#x27;</span>, threshold2_min, threshold2_max, canny_threshold2)</span><br><span class="line"><span class="comment">#绑定滑动条和窗口， 且设置滑动条的值</span></span><br><span class="line"><span class="comment">#cv2.createTrackbar(“scale”, “display”, 0, 100, self.opencv_calibration_node.on_scale)</span></span><br><span class="line"><span class="comment"># 第一个参数表示滑动条的名称，</span></span><br><span class="line"><span class="comment"># 第二个表示绑定的窗口名字，</span></span><br><span class="line"><span class="comment"># 第三个和第四设置滑动条的范围，注意的是第三个参数即滑动条的最小值固定为一，调整只是为了从你设定的那个数开始而已</span></span><br><span class="line"><span class="comment"># 第五个参数是回调函数，每次滑动都会调用回调函数。</span></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/fa11d0a9a5d44610b948f469113c9c3c.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
        <tag>边缘检测</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】Marr 算子边缘检测</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91Marr-%E7%AE%97%E5%AD%90%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<p>﻿Marr算子: Laplacian of a Gaussian（LOG）</p>
<ul>
<li>Marr算子是在Laplacian算子的基础上实现的，它得益于对人的视觉机理的研究，有一定的生物学和生理学意义。</li>
<li>由于Laplacian算子对噪声比较敏感，为了减少噪声影响，提出了将高斯滤<br>波和拉普拉斯检测算子结合在一起进行边缘检测的方法：先对图像进行平滑，然后再用Laplacian算子检测边缘。</li>
<li>平滑函数应能反映不同远近的周围点对给定像素具有不同的平滑作用，因此，平滑函数采用正态分布的高斯函数，即：<br><img src="https://img-blog.csdnimg.cn/689572f9726448c3b82d02949431e800.png#pic_center" alt="在这里插入图片描述"><br>卷积操作具有结合律，因此我们先将高斯平滑滤波器与拉普拉斯滤波器进行卷积，然后利用得到的混合滤波器去对图片进行卷积以得到所需的结果。<br>两个优点：</li>
<li>由于高斯和拉普拉斯核通常都比图像小得多，所以这种方法通常只需要很少的算术运算。</li>
<li>LoG (‘ Laplacian of Gaussian’)内核的参数可以预先计算，因此在运行时只需要对图像执行一遍的卷积即可。<br><img src="https://img-blog.csdnimg.cn/bd40ed4914ef4ebaa5fd705721f23519.png#pic_center" alt="在这里插入图片描述">算法步骤如下：</li>
<li>滤波：首先对图像f(x,y)进行平滑滤波，其滤波函数根据人类视觉特性选为高斯函数，</li>
<li>增强：对平滑图像进行拉普拉斯运算，</li>
<li>检测：利用二阶导数算子过零点的性质，可确定图像中阶跃边缘的位置</li>
</ul>
<p>由于的平滑性质能减少噪声的影响，所以当边缘模糊或噪声较大时，利用检测过零点能提供较可靠的边缘位置。在该算子中，σ 的选择很重要， σ 小时边缘位置精度高，但边缘细节变化多； σ 大时平滑作用大，但细节损失大，边缘点定位精度低。应根据噪声水平和边缘点定位精度要求适当选取 σ。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Marr算子：Lalpacian of Gaussion(LOG)</span></span><br><span class="line"><span class="comment">#cv2.GuassianBlur(img, ksize,sigmaX,sigmaY),sigmaX和sigmaY表示x和y方向上的高斯核标准差</span></span><br><span class="line">gaussion = cv.GaussianBlur(img_clean, (<span class="number">3</span>, <span class="number">3</span>), <span class="number">0</span>)<span class="comment">#先用高斯滤波对图像进行平滑处理</span></span><br><span class="line">dst = cv.Laplacian(gaussion, cv.CV_16S, ksize = <span class="number">3</span>)<span class="comment">#再用拉普拉斯算子进行边缘检测，第二个参数CV_16s表示图像中的数据是16位无符号整数</span></span><br><span class="line">log = cv.convertScaleAbs(dst)  <span class="comment">#convertScaleAbs函数是一个位深转化函数，可将任意类型的数据转化为CV_8UC1</span></span><br><span class="line"><span class="comment">#                                 (0)CV_8UCV1表示8位无符号整数，且通道为一</span></span><br><span class="line"><span class="comment">#                                 (1). 对于src*alpha+beta的结果如果是负值且大于-255，则直接取绝对值；</span></span><br><span class="line"><span class="comment">#                                 (2). 对于src*alpha+beta的结果如果大于255，则取255；</span></span><br><span class="line"><span class="comment">#                                 (3). 对于src*alpha+beta的结果是负值，且小于-255，则取255；</span></span><br><span class="line"><span class="comment">#                                 (4). 对于src*alpha+beta的结果如果在0-255之间，则保持不变；</span></span><br><span class="line"> </span><br><span class="line">fig = plt.figure(figsize = (<span class="number">10</span>, <span class="number">5</span>))<span class="comment">#作图</span></span><br><span class="line">fig.<span class="built_in">set</span>(alpha = <span class="number">0.2</span>)</span><br><span class="line">plt.subplot2grid((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">plt.imshow(img_clean, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">plt.imshow(log, <span class="string">&#x27;gray&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/d81987e5dd434b8f929c74cd6c6849e0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
        <tag>边缘检测</tag>
      </tags>
  </entry>
  <entry>
    <title>【OpenCv】kirsch 算子边缘检测</title>
    <url>/2022/06/05/%E3%80%90OpenCv%E3%80%91kirsch-%E7%AE%97%E5%AD%90%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<p>﻿Kirsch算子是R.Kirsch提出来一种边缘检测算法，它采用8个模板对图像上的每一个像素点进行卷积求导数，这8个模板代表8个方向，对图像上的8个特定边缘方向作出最大响应，运算中取最大值作为图像的边缘输出。<br><img src="https://img-blog.csdnimg.cn/b9bf43ef7ce24050b03fd22c438d597b.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/b9951f6416954240a2cd2898d9e7b3be.png#pic_center" alt="在这里插入图片描述"><br>Kirsch算子特点<br>• 在计算边缘强度的同时可以得到边缘的方向<br>• 各方向间的夹角为45º</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">%matplotlib</span><br><span class="line"><span class="comment">#kirsch算子</span></span><br><span class="line"><span class="comment">#自定义卷积核，八个方向</span></span><br><span class="line">m1 = np.array([[<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>], [-<span class="number">3</span>,<span class="number">0</span>,-<span class="number">3</span>], [-<span class="number">3</span>,-<span class="number">3</span>,-<span class="number">3</span>]])</span><br><span class="line">m2 = np.array([[-<span class="number">3</span>, <span class="number">5</span>,<span class="number">5</span>], [-<span class="number">3</span>,<span class="number">0</span>,<span class="number">5</span>], [-<span class="number">3</span>,-<span class="number">3</span>,-<span class="number">3</span>]])</span><br><span class="line">m3 = np.array([[-<span class="number">3</span>,-<span class="number">3</span>,<span class="number">5</span>], [-<span class="number">3</span>,<span class="number">0</span>,<span class="number">5</span>], [-<span class="number">3</span>,-<span class="number">3</span>,<span class="number">5</span>]])</span><br><span class="line">m4 = np.array([[-<span class="number">3</span>,-<span class="number">3</span>,-<span class="number">3</span>], [-<span class="number">3</span>,<span class="number">0</span>,<span class="number">5</span>], [-<span class="number">3</span>,<span class="number">5</span>,<span class="number">5</span>]])</span><br><span class="line">m5 = np.array([[-<span class="number">3</span>, -<span class="number">3</span>, -<span class="number">3</span>], [-<span class="number">3</span>,<span class="number">0</span>,-<span class="number">3</span>], [<span class="number">5</span>,<span class="number">5</span>,<span class="number">5</span>]])</span><br><span class="line">m6 = np.array([[-<span class="number">3</span>, -<span class="number">3</span>, -<span class="number">3</span>], [<span class="number">5</span>,<span class="number">0</span>,-<span class="number">3</span>], [<span class="number">5</span>,<span class="number">5</span>,-<span class="number">3</span>]])</span><br><span class="line">m7 = np.array([[<span class="number">5</span>, -<span class="number">3</span>, -<span class="number">3</span>], [<span class="number">5</span>,<span class="number">0</span>,-<span class="number">3</span>], [<span class="number">5</span>,-<span class="number">3</span>,-<span class="number">3</span>]])</span><br><span class="line">m8 = np.array([[<span class="number">5</span>, <span class="number">5</span>, -<span class="number">3</span>], [<span class="number">5</span>,<span class="number">0</span>,-<span class="number">3</span>], [-<span class="number">3</span>,-<span class="number">3</span>,-<span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">filterlist = [m1, m2, m3, m4, m5, m6, m7, m8]<span class="comment">#将各个方向的卷积核放到一起便于统一操作</span></span><br><span class="line">filtered_list = np.zeros((<span class="number">8</span>, img_clean.shape[<span class="number">0</span>], img_clean.shape[<span class="number">1</span>]))<span class="comment">#建立三维数组，第0维表示各个方向卷积后的值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>) :</span><br><span class="line">    out = cv.filter2D(img_clean, cv.CV_16S, filterlist[k])<span class="comment">#自定义卷积，其实里面的步骤跟Sobel算子是差不多的</span></span><br><span class="line">    filtered_list[k] = out</span><br><span class="line"></span><br><span class="line">final = np.<span class="built_in">max</span>(filtered_list, axis = <span class="number">0</span>)<span class="comment">#取八个方向中的最大值，也就是取第0维的最大值作为图像该点，滤波之后的新的像素值</span></span><br><span class="line">final[ np.where(final &gt;= <span class="number">255</span>)] = <span class="number">255</span><span class="comment">#令像素值大于255的点等于255</span></span><br><span class="line">final[ np.where(final &lt; <span class="number">255</span>) ] = <span class="number">0</span><span class="comment">#令像素值小于255的点等于0</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize = (<span class="number">10</span>, <span class="number">5</span>))<span class="comment">#显示图像</span></span><br><span class="line">fig.<span class="built_in">set</span>(alpha = <span class="number">0.2</span>)</span><br><span class="line">plt.subplot2grid((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">plt.imshow(img_clean, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot2grid((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">plt.imshow(final, <span class="string">&#x27;gray&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/678a0bbfe3d94918bcf2eaefebe238a3.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>机器视觉</category>
      </categories>
      <tags>
        <tag>机器视觉</tag>
        <tag>边缘检测</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树练习</title>
    <url>/2022/06/05/%E5%86%B3%E7%AD%96%E6%A0%91%E7%BB%83%E4%B9%A0/</url>
    <content><![CDATA[<p>﻿数据预处理分析，最后面附有决策树算法的实现<br>原始数据：<br><a href="https://github.com/aishangcengloua/Data-Mining/blob/master/HomeWork1/Data.xlsx">原数据地址</a><br><img src="https://img-blog.csdnimg.cn/810c34d959d0490383d5dd87183a7659.png#pic_center" alt="在这里插入图片描述"><br>计算第一次决策如果<br>分别对在14天各个属性下是否进行施肥的统计情况且计算该属性的基尼指数，同一种属性不同表现的基尼指数表示为M，加权平均之后为节点的基尼指数，用N表示<br>天气：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding = utf-8</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">Base_file = pd.read_excel(<span class="string">&#x27;Data.xlsx&#x27;</span>)</span><br><span class="line">Base_file.head(<span class="number">15</span>)</span><br><span class="line"><span class="comment">#Base_file.head()</span></span><br><span class="line">Weather_Sunny = Base_file[Base_file[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;晴天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line"><span class="comment">#print(Weather_Sunny)[&#x27;否&#x27; &#x27;否&#x27; &#x27;否&#x27; &#x27;是&#x27; &#x27;是&#x27;]</span></span><br><span class="line">Weather_Rainy = Base_file[Base_file[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;雨天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Weather_Overcast = Base_file[Base_file[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;阴天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Weather_Overcast[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Weather_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Weather_Sunny[<span class="string">&#x27;是&#x27;</span>], Weather_Sunny[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Weather_Rainy[<span class="string">&#x27;是&#x27;</span>], Weather_Rainy[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Weather_Overcast[<span class="string">&#x27;是&#x27;</span>], Weather_Overcast[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index=[<span class="string">&#x27;晴天&#x27;</span>, <span class="string">&#x27;雨天&#x27;</span>, <span class="string">&#x27;阴天&#x27;</span>])</span><br><span class="line">Weather_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/ff10b766deb94b239cab9d021788cf01.png" alt="在这里插入图片描述"><br>晴天：M1 = 2 <em> 2/5 </em> (1 - 2/5) = 0.444444445<br>雨天：M2 = 2 <em> 3/5 </em> (1 - 3/5) = 0.48<br>阴天：M3 = 0<br>N1 = 5/14 <em> M1 + 5/14 </em> M2 = 0.343<br>温度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Hot = Base_file[Base_file[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;炎热&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cool = Base_file[Base_file[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;温&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cold = Base_file[Base_file[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;冷&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Temperature_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Hot[<span class="string">&#x27;是&#x27;</span>], Hot[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cool[<span class="string">&#x27;是&#x27;</span>], Cool[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cold[<span class="string">&#x27;是&#x27;</span>], Cold[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>])</span><br><span class="line">Temperature_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/f05b14015fcf4abaadc25035109cde0a.png" alt="在这里插入图片描述"><br>炎热：M1 = 2 <em> 2/4 </em> (1 - 2/4) = 0.5<br>温 ： M2 = 2 <em> 2/6 </em> (1 - 2/6) = 0.44444445<br>冷：  M3 = 2 <em> 3/4 </em> (1 - 3/4) = 0.375<br>N2 = 4/14 <em> M1 + 6/14 </em> M2 + 4/14 * M3 = 0.440</p>
<p>湿度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Humidity_high = Base_file[Base_file[<span class="string">&#x27;湿度&#x27;</span>] == <span class="string">&#x27;高&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Humidity_mid = Base_file[Base_file[<span class="string">&#x27;湿度&#x27;</span>] == <span class="string">&#x27;中&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Humidity_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Humidity_high[<span class="string">&#x27;是&#x27;</span>], Humidity_high[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Humidity_mid[<span class="string">&#x27;是&#x27;</span>], Humidity_mid[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;高&#x27;</span>, <span class="string">&#x27;中&#x27;</span>])</span><br><span class="line">Humidity_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/92fcd8995d9c4f0398eea4ab5f9e21f1.png" alt="在这里插入图片描述"><br>高：M1 = 2 <em> 3/4 </em> (1 - 3/4) = 0.375<br>中：M2 = 2 <em> 6/7 </em> (1 - 6/7) = 0.245<br>N3 = 1/2 <em> M1 + 1/2 </em> M2 = 0.310</p>
<p>风力：</p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Wind_strong = Base_file[Base_file[<span class="string">&#x27;风力&#x27;</span>] == <span class="string">&#x27;强风&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Wind_weak = Base_file[Base_file[<span class="string">&#x27;风力&#x27;</span>] == <span class="string">&#x27;弱风&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Wind_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Wind_strong[<span class="string">&#x27;是&#x27;</span>], Wind_strong[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Wind_weak[<span class="string">&#x27;是&#x27;</span>], Wind_weak[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>])</span><br><span class="line">Wind_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/af12704b2e4447faaa8e547b580d8ded.png" alt="在这里插入图片描述"><br>强风：M1 = 2 <em> 3/6 </em> (1 - 3/6) = 0.5<br>弱风：M2 = 2 <em> 6/8 </em> (1 - 6/8) = 0.375<br>N4 = 6/14 <em> M1 + 8/14 </em> M2 = 0.429<br>因为N2 &gt; N4 &gt; N1 &gt; N3，所以第一次决策应根据湿度来分类：<br><img src="https://img-blog.csdnimg.cn/548dfadd9a1048e79cc824aa8cffbf2f.png#pic_center" alt="在这里插入图片描述"><br>因为此次分类之后，然未出现叶子节点，所以需要分别对第二排的两个节点进行分类，过程与第一次决策类似，计算各个属性下是否进行施肥的统计情况且计算该属性的基尼指数<br>左右节点的数据分别如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Base_file = pd.read_excel(<span class="string">&#x27;Data.xlsx&#x27;</span>)</span><br><span class="line">Base_file.head(<span class="number">15</span>)</span><br><span class="line">Temperature_df_high = Base_file[Base_file[<span class="string">&#x27;湿度&#x27;</span>] == <span class="string">&#x27;高&#x27;</span>]</span><br><span class="line">Temperature_df_high.head(<span class="number">14</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/673df477a0364e0cb1838f047d1d0f50.png#pic_center" alt="在这里插入图片描述"></p>
<p>先对左边节点分析：<br>天气：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Weather_Sunny = Temperature_df_high[Temperature_df_high[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;晴天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Weather_Sunny[<span class="string">&#x27;是&#x27;</span>] = <span class="number">0</span></span><br><span class="line"><span class="comment">#print(Weather_Sunny)[&#x27;否&#x27; &#x27;否&#x27; &#x27;否&#x27; &#x27;是&#x27; &#x27;是&#x27;]</span></span><br><span class="line">Weather_Rainy = Temperature_df_high[Temperature_df_high[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;雨天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Weather_Overcast = Temperature_df_high[Temperature_df_high[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;阴天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Weather_Overcast[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Weather_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Weather_Sunny[<span class="string">&#x27;是&#x27;</span>], Weather_Sunny[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Weather_Rainy[<span class="string">&#x27;是&#x27;</span>], Weather_Rainy[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Weather_Overcast[<span class="string">&#x27;是&#x27;</span>], Weather_Overcast[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index=[<span class="string">&#x27;晴天&#x27;</span>, <span class="string">&#x27;雨天&#x27;</span>, <span class="string">&#x27;阴天&#x27;</span>])</span><br><span class="line">Weather_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/18ffcc15e36b4ad997ae445099cb48bf.png" alt="在这里插入图片描述"><br>晴天：M1 = 0<br>雨天：M2 = 0.5<br>阴天：M3 = 0<br>N1 = 2/7 * M2 = 0.143<br>温度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Hot = Temperature_df_high[Temperature_df_high[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;炎热&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cool = Temperature_df_high[Temperature_df_high[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;温&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cold = Temperature_df_high[Temperature_df_high[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;冷&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cold[<span class="string">&#x27;是&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cold[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Temperature_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Hot[<span class="string">&#x27;是&#x27;</span>], Hot[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cool[<span class="string">&#x27;是&#x27;</span>], Cool[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cold[<span class="string">&#x27;是&#x27;</span>], Cold[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>])</span><br><span class="line">Temperature_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/08ea7732db2b43aea8876d02fe17b5b0.png" alt="在这里插入图片描述"><br>炎热：M1 = 0.44444444445<br>温：  M2 = 0.5<br>冷：  M3 = 0<br>N2 = 3/7 <em> M1 + 4/7 </em> M3 = 0.476</p>
<p>风力：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Wind_strong = Temperature_df_high[Temperature_df_high[<span class="string">&#x27;风力&#x27;</span>] == <span class="string">&#x27;强风&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Wind_weak = Temperature_df_high[Temperature_df_high[<span class="string">&#x27;风力&#x27;</span>] == <span class="string">&#x27;弱风&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Wind_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Wind_strong[<span class="string">&#x27;是&#x27;</span>], Wind_strong[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Wind_weak[<span class="string">&#x27;是&#x27;</span>], Wind_weak[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>])</span><br><span class="line">Wind_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/4419fb6e26a24f6a8bcb0fd1ef0ffeb3.png" alt="在这里插入图片描述"><br>强风：M1 = 0.44444444445<br>弱风：M2 =0.5<br>N3 = 3/7 <em> M1 + 4/7 </em> M2 = 0.476</p>
<p>N1 &gt; N2 = N3<br>所以左边的节点来说应该根据天气情况来分类<br>对右边节点分析：<br>天气：</p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Weather_Sunny = Temperature_df_mid[Temperature_df_mid[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;晴天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Weather_Sunny[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Weather_Rainy = Temperature_df_mid[Temperature_df_mid[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;雨天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Weather_Overcast = Temperature_df_mid[Temperature_df_mid[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;阴天&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Weather_Overcast[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Weather_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Weather_Sunny[<span class="string">&#x27;是&#x27;</span>], Weather_Sunny[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Weather_Rainy[<span class="string">&#x27;是&#x27;</span>], Weather_Rainy[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Weather_Overcast[<span class="string">&#x27;是&#x27;</span>], Weather_Overcast[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index=[<span class="string">&#x27;晴天&#x27;</span>, <span class="string">&#x27;雨天&#x27;</span>, <span class="string">&#x27;阴天&#x27;</span>])</span><br><span class="line">Weather_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/48783b2c05b943d18eca303e936829dd.png" alt="在这里插入图片描述"><br>晴天：M1 = 0<br>雨天：M2 = 0.444444444445<br>阴天：M3 = 0<br>N1 = 3/7 * M2 = 0.190</p>
<p>温度：</p>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Hot = Temperature_df_mid[Temperature_df_mid[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;炎热&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Hot[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cool = Temperature_df_mid[Temperature_df_mid[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;温&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cool[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cold = Temperature_df_mid[Temperature_df_mid[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;冷&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line"></span><br><span class="line">Temperature_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Hot[<span class="string">&#x27;是&#x27;</span>], Hot[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cool[<span class="string">&#x27;是&#x27;</span>], Cool[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cold[<span class="string">&#x27;是&#x27;</span>], Cold[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>])</span><br><span class="line">Temperature_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/291ad482ad4d4717aef3403865a56133.png" alt="在这里插入图片描述"><br>炎热：M1 = 0<br>温：  M2 = 0<br>冷：  M3 = 2 <em> 3/4 </em> (1 - 3/4) = 0.375<br>N2 = 3/7 * M3 = 0.214</p>
<p>风力：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Wind_strong = Temperature_df_mid[Temperature_df_mid[<span class="string">&#x27;风力&#x27;</span>] == <span class="string">&#x27;强风&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Wind_weak = Temperature_df_mid[Temperature_df_mid[<span class="string">&#x27;风力&#x27;</span>] == <span class="string">&#x27;弱风&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Wind_weak[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Wind_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Wind_strong[<span class="string">&#x27;是&#x27;</span>], Wind_strong[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Wind_weak[<span class="string">&#x27;是&#x27;</span>], Wind_weak[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>])</span><br><span class="line">Wind_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/1554bd1f61ec4b1da67841305c95e111.png" alt="在这里插入图片描述"><br>强风：M1 = 2 <em> 2/3 </em> (1 - 2/3) = 0.44444445<br>弱风：M2 = 0<br>N3 = 3/7 * M2 = 0.190</p>
<p>N1 = N3 &gt; N2<br>这里可以有两种分类决策方法，这里选择使用天气属性对右边节点进行分类，结合对左边节点的分析，对第二层的分类如下：<br><img src="https://img-blog.csdnimg.cn/38a2759681c844159c960655f0178c43.png#pic_center" alt="在这里插入图片描述"><br>经过第二次分类之后，出现了叶子节点，只剩下两个节点需要继续分类，且只剩下温度和风力两个属性，下面是第二次分类之后的左右两个节点数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Weather_df_Rainy1 = Base_file[Base_file[<span class="string">&#x27;湿度&#x27;</span>] == <span class="string">&#x27;高&#x27;</span>][Base_file[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;雨天&#x27;</span>]</span><br><span class="line">Weather_df_Rainy1.head()</span><br><span class="line">Weather_df_Rainy2 = Base_file[Base_file[<span class="string">&#x27;湿度&#x27;</span>] == <span class="string">&#x27;中&#x27;</span>][Base_file[<span class="string">&#x27;天气&#x27;</span>] == <span class="string">&#x27;雨天&#x27;</span>]</span><br><span class="line">Weather_df_Rainy2.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/f4af06ecd7604f528bf833f5f17c9f96.png" alt="在这里插入图片描述"><br>对于左边节点：<br>温度：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Hot = Weather_df_Rainy1[Weather_df_Rainy1[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;炎热&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Hot[<span class="string">&#x27;是&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Hot[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cool = Weather_df_Rainy1[Weather_df_Rainy1[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;温&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cold = Weather_df_Rainy1[Weather_df_Rainy1[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;冷&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cold[<span class="string">&#x27;是&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cold[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">Temperature_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Hot[<span class="string">&#x27;是&#x27;</span>], Hot[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cool[<span class="string">&#x27;是&#x27;</span>], Cool[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cold[<span class="string">&#x27;是&#x27;</span>], Cold[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>])</span><br><span class="line">Temperature_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/e2205a76332e4092a40b97d5482a3620.png" alt="在这里插入图片描述"><br>炎热：M1 = 0<br>温：  M2 = 2 <em> 1/2 </em> (1 – 1/2) = 0.5<br>冷：  M3 = 0<br>N1 = M2 = 0.5</p>
<p>风力：</p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Hot = Weather_df_Rainy1[Weather_df_Rainy1[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;炎热&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Hot[<span class="string">&#x27;是&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Hot[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cool = Weather_df_Rainy1[Weather_df_Rainy1[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;温&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cold = Weather_df_Rainy1[Weather_df_Rainy1[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;冷&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cold[<span class="string">&#x27;是&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cold[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">Temperature_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Hot[<span class="string">&#x27;是&#x27;</span>], Hot[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cool[<span class="string">&#x27;是&#x27;</span>], Cool[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cold[<span class="string">&#x27;是&#x27;</span>], Cold[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>])</span><br><span class="line">Temperature_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/04908ef755dd418f97ec0442752a6e8f.png" alt="在这里插入图片描述"><br>强风：M1 = 0<br>弱风：M2 = 0<br>N2 = 0</p>
<p>N1 &gt; N2<br>所以左边的节点应用风力属性继续往后分类<br>对右边节点分析：<br>温度：</p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> Hot = Weather_df_Rainy2[Weather_df_Rainy2[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;炎热&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Hot[<span class="string">&#x27;是&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Hot[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cool = Weather_df_Rainy2[Weather_df_Rainy2[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;温&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Cool[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Cold = Weather_df_Rainy2[Weather_df_Rainy2[<span class="string">&#x27;温度&#x27;</span>] == <span class="string">&#x27;冷&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Temperature_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Hot[<span class="string">&#x27;是&#x27;</span>], Hot[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cool[<span class="string">&#x27;是&#x27;</span>], Cool[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Cold[<span class="string">&#x27;是&#x27;</span>], Cold[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>])</span><br><span class="line">Temperature_df.head()</span><br></pre></td></tr></table></figure>
<p> <img src="https://img-blog.csdnimg.cn/28bff67159c84a8ca00d84972e1ae892.png" alt="在这里插入图片描述"><br>炎热：M1 = 0<br>温：  M2 = 0<br>冷：  M3 = 2 <em> 1/2 </em> (1 – 1/2) = 0.5<br>N1 = M3 = 0.5</p>
<p>风力：</p>
 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"> Wind_strong = Weather_df_Rainy2[Weather_df_Rainy2[<span class="string">&#x27;风力&#x27;</span>] == <span class="string">&#x27;强风&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Wind_strong[<span class="string">&#x27;是&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Wind_weak = Weather_df_Rainy2[Weather_df_Rainy2[<span class="string">&#x27;风力&#x27;</span>] == <span class="string">&#x27;弱风&#x27;</span>][<span class="string">&#x27;是否施肥&#x27;</span>].value_counts()</span><br><span class="line">Wind_weak[<span class="string">&#x27;否&#x27;</span>] = <span class="number">0</span></span><br><span class="line">Wind_df = pd.DataFrame([</span><br><span class="line">    pd.Series([Wind_strong[<span class="string">&#x27;是&#x27;</span>], Wind_strong[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]),</span><br><span class="line">    pd.Series([Wind_weak[<span class="string">&#x27;是&#x27;</span>], Wind_weak[<span class="string">&#x27;否&#x27;</span>]], index = [<span class="string">&#x27;是&#x27;</span>, <span class="string">&#x27;否&#x27;</span>])</span><br><span class="line">], index = [<span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>])</span><br><span class="line">Wind_df.head()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/7c9143d8b31a42b6be9b72fc65a6f6ce.png" alt="在这里插入图片描述"><br>强风：M1 = 0<br>弱风：M2 = 0<br>N2 = 0</p>
<p>N1 &gt; N2<br>所以右边边的节点应用风力属性继续往后分类，决策图如下：<br><img src="https://img-blog.csdnimg.cn/dc5aea1458624abda02b14f7538c57b9.png#pic_center" alt="在这里插入图片描述"></p>
<p>可以看出第二次分类再经过风力的分类之后，此时决策树最后一排的节点全部变为了叶子节点，说明至此，分类完成。<br>算法实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#encoding = utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">CalcGiNiIndex</span>(<span class="params">DataSet</span>) :</span><br><span class="line">    Num_length = <span class="built_in">len</span>(DataSet)</span><br><span class="line">    labelcounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> DataSet :</span><br><span class="line">        currentlabel = feature[-<span class="number">1</span>]</span><br><span class="line">        <span class="comment">#用字典统计类别及其数目</span></span><br><span class="line">        <span class="keyword">if</span> currentlabel <span class="keyword">not</span> <span class="keyword">in</span> labelcounts.keys() :</span><br><span class="line">            labelcounts[currentlabel] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            labelcounts[currentlabel] += <span class="number">1</span></span><br><span class="line">    GiNi_index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelcounts.keys() :</span><br><span class="line">        <span class="comment">#二分类求基尼指数：GiNi = 2 * p * （1 - p）</span></span><br><span class="line">        GiNi_index = <span class="number">2</span> * (<span class="built_in">float</span>(labelcounts[key]) / Num_length) * (<span class="number">1</span> - <span class="built_in">float</span>(labelcounts[key]) / Num_length)</span><br><span class="line">    <span class="keyword">return</span> GiNi_index</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createDataSet</span>() :</span><br><span class="line">    DataSet = [[<span class="string">&#x27;晴天&#x27;</span>, <span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;高&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>, <span class="string">&#x27;否&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;晴天&#x27;</span>, <span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;高&#x27;</span>, <span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;否&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;阴天&#x27;</span>, <span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;高&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;雨天&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;高&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;雨天&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;雨天&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;否&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;阴天&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;晴天&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;高&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>, <span class="string">&#x27;否&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;晴天&#x27;</span>, <span class="string">&#x27;冷&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;雨天&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;晴天&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;阴天&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;高&#x27;</span>, <span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;阴天&#x27;</span>, <span class="string">&#x27;炎热&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;弱风&#x27;</span>, <span class="string">&#x27;是&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;雨天&#x27;</span>, <span class="string">&#x27;温&#x27;</span>, <span class="string">&#x27;高&#x27;</span>, <span class="string">&#x27;强风&#x27;</span>, <span class="string">&#x27;否&#x27;</span>]]</span><br><span class="line"><span class="comment">#     file = pd.read_excel(&#x27;Data.xlsx&#x27;)</span></span><br><span class="line"><span class="comment">#     DataSet = file.iloc[ : , 1 : ]</span></span><br><span class="line"><span class="comment">#     DataSet = np.array(DataSet)</span></span><br><span class="line">    labels = [<span class="string">&#x27;天气&#x27;</span>, <span class="string">&#x27;温度&#x27;</span>, <span class="string">&#x27;湿度&#x27;</span>, <span class="string">&#x27;风力&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> DataSet, labels</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">splitDataSet</span>(<span class="params">DataSet, axis, value</span>): </span><br><span class="line">    <span class="comment">#计算以某个特征分类后剩下的数据量。</span></span><br><span class="line">    <span class="comment">#axis表示第i个特征，value表示在改特征的情况下的具体表现，如天气特征有雨天。阴天等。</span></span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="comment">#创建一个新列表，准备提取数据</span></span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> DataSet :</span><br><span class="line">        <span class="comment">#剔除在数据集中需要被分类的特征的列行</span></span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value :</span><br><span class="line">            reducedFeatVec = featVec[ : axis]</span><br><span class="line">            reducedFeatVec.extend(featVec[axis + <span class="number">1</span> : ])</span><br><span class="line">            retDataSet.append(reducedFeatVec)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ChooseBestFeatureToSplit</span>(<span class="params">DataSet</span>) :</span><br><span class="line">    <span class="comment">#计算父亲节点的GiNi指数</span></span><br><span class="line">    FatherGiNi = CalcGiNiIndex(DataSet)</span><br><span class="line">    BestIoFoGain = <span class="number">0</span></span><br><span class="line">    BestFeature = -<span class="number">1</span></span><br><span class="line">    numFeature = <span class="built_in">len</span>(DataSet[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">    <span class="comment">#去掉最后一列</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numFeature) :</span><br><span class="line">        <span class="comment">#每个特征下的具体表现形式</span></span><br><span class="line">        featList = [example[i] <span class="keyword">for</span> example <span class="keyword">in</span> DataSet]</span><br><span class="line">        uniqueVals = <span class="built_in">set</span>(featList)<span class="comment">#去重复</span></span><br><span class="line">        newGiNi = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals :</span><br><span class="line">            <span class="comment">#计算每一种表现形式GiNi指数的权重和</span></span><br><span class="line">            subData = splitDataSet(DataSet, i, value)</span><br><span class="line">            prob = <span class="built_in">len</span>(subData) / <span class="built_in">float</span>(<span class="built_in">len</span>(DataSet))</span><br><span class="line">            newGiNi += prob * CalcGiNiIndex(subData)</span><br><span class="line">        infogain = FatherGiNi - newGiNi<span class="comment">#计算信息增益</span></span><br><span class="line">        <span class="keyword">if</span> infogain &gt; BestIoFoGain :</span><br><span class="line">            <span class="comment">#比较信息增益的大小，更新最佳分类的特征</span></span><br><span class="line">            BestIoFoGain = infogain</span><br><span class="line">            BestFeature = i</span><br><span class="line">    <span class="keyword">return</span> BestFeature</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">majorityCnt</span>(<span class="params">classList</span>):    <span class="comment">#按分类后类别数量排序，比如：最后分类为2yes1no，则判定为yes；</span></span><br><span class="line">    classCount=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys():</span><br><span class="line">            classCount[vote]=<span class="number">0</span></span><br><span class="line">        classCount[vote]+=<span class="number">1</span></span><br><span class="line">    <span class="comment">#字典逆序排序</span></span><br><span class="line">    sortedClassCount = <span class="built_in">sorted</span>(classCount.items(), key = <span class="keyword">lambda</span> x : x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">DataSet, labels</span>) :</span><br><span class="line">    ConditionList = [example[-<span class="number">1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> DataSet]</span><br><span class="line">    <span class="comment">#list.count(element) 方法用于统计某个元素在列表中出现的次数。</span></span><br><span class="line">    <span class="keyword">if</span> ConditionList.count(ConditionList[<span class="number">0</span>]) == <span class="built_in">len</span>(ConditionList) :<span class="comment">#yes or no</span></span><br><span class="line">        <span class="keyword">return</span> ConditionList[<span class="number">0</span>]</span><br><span class="line">    <span class="comment">#dataSet[0]取矩阵第一行，dataSet[0][0]取矩阵第一行第一列元素</span></span><br><span class="line">    <span class="comment">#递归终止条件2：使用完所有特征，则返回最后出现次数最多的那个标签</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>( DataSet[<span class="number">0</span>] ) == <span class="number">1</span>:   </span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    </span><br><span class="line">     <span class="comment">#以上两个终止条件都不满足，开始选择最优特征划分，已经有了一个方框，准备往方框中写入判断问题</span></span><br><span class="line">    BestFeature = ChooseBestFeatureToSplit(DataSet)</span><br><span class="line">    BestFeatLabel = labels[BestFeature]</span><br><span class="line">    mytree = &#123;BestFeatLabel : &#123;&#125;&#125;</span><br><span class="line">    <span class="comment">#用过了该特征，将该特征从所有特征列表中删除</span></span><br><span class="line">    <span class="keyword">del</span> (labels[BestFeature])</span><br><span class="line">    featValues = [example[BestFeature] <span class="keyword">for</span> example <span class="keyword">in</span> DataSet]</span><br><span class="line">    uniqueVals = <span class="built_in">set</span>(featValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        subLabels = labels[ : ]</span><br><span class="line">        splitdata = splitDataSet(DataSet, BestFeature, value)</span><br><span class="line">        <span class="comment">#递归</span></span><br><span class="line">        mytree[BestFeatLabel][value] = createTree(splitdata, subLabels)</span><br><span class="line">    <span class="keyword">return</span> mytree</span><br><span class="line"></span><br><span class="line">DataSet, labels = createDataSet()<span class="comment"># 创造示列数据</span></span><br><span class="line"><span class="built_in">print</span>(createTree(DataSet, labels))<span class="comment"># 输出决策树模型结果</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/4c4883247d234b14a0660cf8a75baf70.png" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>传统算法</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title>自监督学习</title>
    <url>/2022/06/05/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="1-Transformer"><a href="#1-Transformer" class="headerlink" title="1    Transformer"></a>1    Transformer</h1><p>Transformer是Sequence-toSequence（Seq2Seq）的一个模型，我们之前在作一些实验的时候，当我们输入一个Sequence时，我们的输出也会是一个Sequence，而输入和输出结果的长度是一样的，当我们不知道输出结果是有多长时，我们便要机器自己决定要输出多长，这就会用到Seq2Seq，特别是在语音辨识及机器翻译中。<br><img src="https://img-blog.csdnimg.cn/8420b887f89d4bfbbc3a69b3cabf76c7.png#pic_center" alt="在这里插入图片描述"><br>一般的Seq2Seq模型是由Encoder和Decoder组成，Encoder接受外界的输入，然后把输出的结果丢给Decoder，再由Decoder决定要输出的Sequence的大小<img src="https://img-blog.csdnimg.cn/0c7feb608f9d448081eed81a79aaff31.png#pic_center" alt="在这里插入图片描述"><br>Seq2seq最早在14年的时候就有了，那时是长的很眉清目秀，后面就变得一言难尽了<br><img src="https://img-blog.csdnimg.cn/2df919b70adc4d648668668bb89c45b8.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/6fd8e35d462b41578578a96462ed6cdc.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><p>Encoder要做的事情就是输入一排向量然后输出一排长度相同向量，这个用RNN或者CNN都能做得到，Encoder用的是self-attention（在我第四篇笔记中有记录到，欢迎大家指正）<img src="https://img-blog.csdnimg.cn/799b3825287f42f3bf6fbc985faf306d.png#pic_center" alt="在这里插入图片描述"><br>现在的Encoder会被分成很多个block，每一个block先做一个self-attention，接受一排向量的输入，考虑全部的资讯，然后输出一排向量，再把结果丢到全连接层再输出一排向量，这就是每一个block的输出，<img src="https://img-blog.csdnimg.cn/b7b21b5cc1414980aa9437ef22899360.png#pic_center" alt="在这里插入图片描述"><br>实际上原来的transformer中，block做的事情更加复杂，在经过self-attention得到一排向量之后，并不会直接丢给全连接层，而是将输入加进来得到新的向量，当成新的output，这种架构叫做residual connection，再将得到的新output做layer normalization（不需要考虑batch），layer normalization在同一个feature中计算不同维度的mean，standard，用公式x’i = （xi - mean）/ std归一化，得到要输入到全连接层的结果，<img src="https://img-blog.csdnimg.cn/683d780331e142f7a415edf6d24b9d63.png#pic_center" alt="在这里插入图片描述"><br>同样的，全连接层里面也有residual connection的架构和normalization，然后才得到一个block的输出</p>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>这里记录两种常用的Decoder</p>
<h3 id="Autoregressive（AT）"><a href="#Autoregressive（AT）" class="headerlink" title="Autoregressive（AT）"></a>Autoregressive（AT）</h3><p>语音辨识例子：<br>给Encoder吃入”机器学习“的一段语音，Encoder会输出四排向量；对于Decoder来说，他的输入就是encoder的输出，首先Decoder有一个代表开始的符号BEGIN，缩写是BOS<img src="https://img-blog.csdnimg.cn/715b8a0576d1412eaadd11ec7880deed.png#pic_center" alt="在这里插入图片描述"><br>Decoder接受的每一个输入都可以用One-hot-vector来表示，然后Decoder会吐出一排向量，大小是一个字典的长度，比如说做的是中文的语音辨识，中文大概有三四千常用字，所以Decoder吐出向量的长度是三四千。在Decoder中，结果还会经过softmax，最终会给每一个文字一个分数，分数最高的为所需结果<br><img src="https://img-blog.csdnimg.cn/1404668e0ef648f2b3007db4ac9dfc4c.png#pic_center" alt="在这里插入图片描述"><br>同样的，第一个的输出再作为第二次的输入，进行同样过程。<img src="https://img-blog.csdnimg.cn/ce101b78da504ed9b826fd5a90a678cb.png#pic_center" alt="在这里插入图片描述"><br>我们能够发现Decoder的输出会被当成下一次的输入，这也会导致一个问题，就是当Deocder在某一次的输出错误的话就可能会导致后面的结果全部错误。接下来看一下Decoder的内层结果<img src="https://img-blog.csdnimg.cn/9f95166088654f9e86bd18c9aa3bacca.png#pic_center" alt="在这里插入图片描述"><br>可以看出，Decoder除了中间部分和结果处的softmax之外，跟Encoder是差不多的。还有一个地方就是在Decoder里面self-attention变成了Masked self-attention，Masked其实是对self-attention的一个限制，就是让网络由可以考虑全部的资讯变成只能考虑左边的资讯<img src="https://img-blog.csdnimg.cn/1c3451b3285c4f30a74e92b7dc2f184c.png#pic_center" alt="在这里插入图片描述"><br>例如下面，在输出b2时，只用第二个query和第一、二个的key相乘，而不考虑key3和key4<br><img src="https://img-blog.csdnimg.cn/0977980c78be4cee969f63d12c61ddbd.png#pic_center" alt="在这里插入图片描述"><br>因为在Decoder中，输入不是一次性全部输入的，他是先有a1，再有a2，a3，a4，所以当你要输出b2时，是没有a3，a4的。开始的时候我们讲到Decoder是要有一个开始符号的，那类似的，Decoder也有结束的符号end<img src="https://img-blog.csdnimg.cn/175fce77a9314ab59d101724efa51106.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="Non-autoregressive（NAT）"><a href="#Non-autoregressive（NAT）" class="headerlink" title="Non-autoregressive（NAT）"></a>Non-autoregressive（NAT）</h3><p>对于NAT Decoder，他是一次性吃一整排的向量，然后直接生成一个 句子，就很直接，<img src="https://img-blog.csdnimg.cn/c49f93cf2db7409684fb4887c7a4dc90.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="Encoder和Decoder之间的桥梁"><a href="#Encoder和Decoder之间的桥梁" class="headerlink" title="Encoder和Decoder之间的桥梁"></a>Encoder和Decoder之间的桥梁</h2><p>Decoder通过产生一个query，到Encoder中抽取资讯，然后当作Decoder中的全连接层的输入，这个过程叫做Cross attention<br><img src="https://img-blog.csdnimg.cn/a29c634964fb4d99a10f88f51e34fd40.png#pic_center" alt="在这里插入图片描述"><br>Decoder的输入接下来的处理是一样的。</p>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>我们还是用语音辨识的例子，假如输入的是”机器学习“，每一个字用一个独热向量表示，但我们经过Decoder得到第一个输出，这个输出是一个概率分布，我们会用”机“对应的独热向量跟输出进行cross entropy的计算<img src="https://img-blog.csdnimg.cn/124fca4530af4c51af1a41c188054dd7.png#pic_center" alt="在这里插入图片描述"><br>每一个输出都有一个cross entropy，而我们就要使总cross entropy loss越小越好，但是要注意的是，我们还要输出end（结束）向量<img src="https://img-blog.csdnimg.cn/bb1ad953d6d34a37af836c9fd9bc3c6f.png#pic_center" alt="在这里插入图片描述"><br>可以观察到我们在训练的时候，Decoder的输入都是正确的，这个叫Teacher Forcing：using the ground truth as input。但我们在测试时看的是自己的输入，可能有时候的输出是错误的，比如说将“器”输出成“气”，就可能导致后面全部错，所以我们在训练过程中需要给model加一些错误的信息让他去训练<img src="https://img-blog.csdnimg.cn/a982959eed6d4ef1b9b81822e6cdf7f8.png#pic_center" alt="在这里插入图片描述"><br>这个叫做Scheduled Sampling。</p>
<h1 id="2-结语"><a href="#2-结语" class="headerlink" title="2    结语"></a>2    结语</h1><p>以上是我本人学习机器学习的学习笔记的第五篇，有错误的地方还望指出，共勉！</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>自监督学习</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>循环神经网络（二）</title>
    <url>/2022/06/05/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="1-RNN-的缺点"><a href="#1-RNN-的缺点" class="headerlink" title="1    RNN 的缺点"></a>1    RNN 的缺点</h1><p>&emsp;&emsp;我在<a href="https://blog.csdn.net/weixin_53598445/article/details/124615312">上一篇博客</a>中跟大家一步一步探索了 RNN 模型的网络结构，最后面也介绍了 RNN 的应用场景。但在实际应用中，标准 RNN 训练的优化算法面临一个很大的难题，就是长期依赖问题——由于网络结构的变深使得模型丧失了学习到先前信息的能力，通俗的说，标准的 RNN 虽然有了记忆，但很健忘，也即标准 RNN 只有短时记忆。循环神经网络在处理较长的句子时，往往只能够理解有限长度内的信 息，而对于位于较长范围类的有用信息往往不能够很好的利用起来。我们把这种现象叫做短时记忆。<br>&emsp;&emsp;针对标准 RNN 短时记忆的问题，最直接的想法就是延长这种短时记忆，使得 RNN 可以有效利用较大范围内的训练数据，从而提升性能。这时，一种基于 RNN 改进的新型网络模型——<strong>LSTM</strong> 该登场了。同时在上篇博客的最后面谈到了 RNN 的梯度消失问题，LSTM 模型可以有效地解决这个问题。</p>
<h1 id="2-LSTM"><a href="#2-LSTM" class="headerlink" title="2    LSTM"></a>2    LSTM</h1><p>&emsp;&emsp;1997 年，瑞士人工智能科学家 Jürgen Schmidhuber 提出了 <strong>长短时记忆网络</strong>(Long Short-Term Memory，简称 LSTM)。LSTM 相对于基础的 RNN 网络来说，记忆能力更强，更擅长处理较长的序列信号数据，LSTM 提出后，被广泛应用在序列预测、自然语言处理等任务中，几乎取代了基础的 RNN 模型。<br>&emsp;&emsp;首先回顾一下基础的 RNN 网络结构：<br><img src="https://img-blog.csdnimg.cn/6b26167dd50b4959a0454dcb9b6e4bda.png" alt="在这里插入图片描述"></p>
<p>上一个时间戳的状态向量 $\boldsymbol{h_{t-1}}$ 与当前时间戳的输入 $\boldsymbol{x_t}$ 经过线性变换后，通过激活函数 $\boldsymbol{tanh}$ 后得到新的状态向量 $\boldsymbol{h_{t}}$。相对于基础的 RNN，网络只有一个状态向量 $\boldsymbol{h_{t}}$，LSTM 新增了一个状态向量 $\boldsymbol{C_{t}}$，同时引入了 <strong>门控(Gate)机制</strong>，通过门控单元来控制信息的遗忘和刷新：<img src="https://img-blog.csdnimg.cn/9c06bb9b83374b9d86de18b5b36e763a.png" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;在 LSTM Cell 中，有两个状态向量 $\boldsymbol{c}$ 和 $\boldsymbol{h}$，其中  $\boldsymbol{c}$ 作为 LSTM 的内部状态向量，可以理解为 LSTM 的 <strong>内存状态向量 Memory</strong>，而  $\boldsymbol{h}$ 表示 LSTM 的输出向量。相对于基础的 RNN 来说，LSTM 把内部 Memory 和输出分开为两个变量，同时利用三个门控：<strong>输入门</strong>(Input Gate)、<strong>遗忘门</strong>(Forget Gate)和<strong>输出门</strong>(Output Gate)来控制内部信息的流动。<br>&emsp;&emsp;门控机制可以理解为控制数据流通量的一种手段，类比于水阀门：当水阀门全部打开时，水流畅通无阻地通过；当水阀门全部关闭时，水流完全被隔断。在 LSTM 中，阀门开和程度利用门控值向量 $\boldsymbol{g}$ 表示：</p>
<p><img src="https://img-blog.csdnimg.cn/9cd23d7ac7384dabb0b211023da816d8.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中通过 $\boldsymbol{\sigma(g)}$ 激活函数将门控值压缩到 $\boldsymbol{[0, 1]}$ 之间，当 $\boldsymbol{\sigma(g) = 0}$ 时，门控全部关闭，输出 $\boldsymbol{o = 0}$；当 $\boldsymbol{\sigma(g) = 1}$ 时，门控全部打开，输出 $\boldsymbol{o = x}$。通过门控机制可以较好地控制数据的流量程度。</p>
<hr>
<p><strong><font color=red>注</font></strong>：到此您可以阅读完 GUR 的原理之后再回来阅读 LSTM，因 GRU 结构较为简单。</p>
<hr>
<h2 id="2-1-遗忘门"><a href="#2-1-遗忘门" class="headerlink" title="2.1    遗忘门"></a>2.1    遗忘门</h2><p>&emsp;&emsp;遗忘门作用于 LSTM 状态向量 $\boldsymbol{c}$，用于控制上一个时间戳的记忆 $\boldsymbol{c_{t - 1}}$ 对当前时间戳的影响。</p>
<p><img src="https://img-blog.csdnimg.cn/2ee0d073b9a1440c94b350f5e7d4e00c.png#pic_center" alt="在这里插入图片描述"></p>
<p>遗忘门的控制变量 $\boldsymbol{g_f}$ 计算过程如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{g_f = \sigma(W_f[h_{t- 1};x_t]+b_f)}</script><p>其中 $\boldsymbol{W_f}$ 和 $\boldsymbol{b_f}$ 为遗忘门的参数张量，可由反向传播算法自动优化，$\boldsymbol{\sigma}$ 为激活函数，一般使用 <strong>Sigmoid</strong> 函数。当 $\boldsymbol{g_f = 1}$ 时，遗忘门全部打开，LSTM 接受上一个状态 $\boldsymbol{c_{t-1}}$ 的所有信息 ；当 $\boldsymbol{g_f = 0}$ 时，遗忘门关闭，LSTM 直接忽略 $\boldsymbol{c_{t-1}}$ 的所有信息输出为 0 的向量。这也是遗忘门的名字由来。经过遗忘门后，LSTM 的状态向量 $\boldsymbol{c_t}$ 变为 $\boldsymbol{g_fc_{t-1}}$。</p>
<h2 id="2-2-输入门"><a href="#2-2-输入门" class="headerlink" title="2.2    输入门"></a>2.2    输入门</h2><p>&emsp;&emsp;输入门用于控制 LSTM 对输入的接收程度。</p>
<p><img src="https://img-blog.csdnimg.cn/5c894335d30e4ec68c7be897d66a22fe.png#pic_center" alt="在这里插入图片描述"></p>
<p>首先通过对当前时间戳的输入 $\boldsymbol{x_t}$ 和上一个时间戳的输出 $\boldsymbol{h_{t - 1}}$ 做非线性变换得到新的输入向量  $\boldsymbol{\tilde{c_t}}$：</p>
<script type="math/tex; mode=display">
\boldsymbol{\tilde{c_t} = tanh(W_c[h_{t -1};x_t] +b_c)}</script><p>其中 $\boldsymbol{W_c}$ 和 $\boldsymbol{b_c}$ 为输入门的参数，需要通过反向传播算法自动优化，$\boldsymbol{tanh}$ 为激活函数，用于将输入标准化到 $\boldsymbol{[-1,1]}$ 区间。$\boldsymbol{\tilde{c_t}}$ 并不会全部刷新进入 LSTM 的 Memory，而是通过输入门控制接受输入的量。输入门的控制变量同样来自于输入 $\boldsymbol{x_t}$ 和输出 $\boldsymbol{h_{t - 1}}$：</p>
<script type="math/tex; mode=display">
 \boldsymbol{g_i  = \sigma(W_i[h_{t - 1};x_t]+b_i)}</script><p> 其中 $\boldsymbol{W_i}$ 和 $\boldsymbol{b_i}$ 为输入门的参数，可由反向传播算法自动优化，$\boldsymbol{\sigma}$ 为激活函数，一般使用 <strong>Sigmoid</strong> 函数。输入门控制变量 $\boldsymbol{g_i}$ 决定了 LSTM 对当前时间戳的新输入 $\boldsymbol{\tilde{c_t}}$ 的接受程度：当 $\boldsymbol{g_i = 0}$ 时，LSTM 不接受任何的新输入 $\boldsymbol{\tilde{c_t}}$；当 $\boldsymbol{g_i = 1}$ 时，LSTM 全部接受新输入 $\boldsymbol{\tilde{c_t}}$。经过输入门之后，待写入 Memory 的向量为 $\boldsymbol{g_i\tilde{c_t}}$。<br> &emsp;&emsp;在遗忘门和输入门的控制下，LSTM 有选择地读取了上一个时间戳的记忆 $\boldsymbol{c_t}$ 和当前时间戳的新输入 $\boldsymbol{\tilde{c_t}}$，状态向量 $\boldsymbol{c_t}$ 的刷新方式为：</p>
<script type="math/tex; mode=display">
\boldsymbol{c_t = g_i\tilde{c_t} + g_fc_{t-1}}</script><p>得到的新状态向量 $\boldsymbol{c_t}$ 即为当前时间戳的状态向量：<br><img src="https://img-blog.csdnimg.cn/ba7bb0ffcfea4cf2b9506c2215e19292.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-3-输出门"><a href="#2-3-输出门" class="headerlink" title="2.3    输出门"></a>2.3    输出门</h2><p>&emsp;&emsp;LSTM 的内部状态向量 $\boldsymbol{c_t}$ 并不会直接用于输出，这一点和基础的 RNN 不一样。标准的 RNN 网络的状态向量 $\boldsymbol{h_t}$ 既用于记忆，又用于输出，所以基础的 RNN 可以理解为状态向量 $\boldsymbol{c_t}$ 和输出向量 $\boldsymbol{h_t}$ 是同一个对象。</p>
<p><img src="https://img-blog.csdnimg.cn/5beb171ddbc049cdbf7f13e34a4e76a9.png#pic_center" alt="在这里插入图片描述"></p>
<p>在 LSTM 内部，状态向量并不会全部输出，而是在输出门的作用下有选择地输出。输出门的门控变量 $\boldsymbol{g_o}$： </p>
<script type="math/tex; mode=display">
 \boldsymbol{g_o= \sigma(W_o[h_{t - 1};x_t]+b_o)}</script><p> 其中 $\boldsymbol{W_o}$ 和 $\boldsymbol{b_o}$ 为输出门的参数，可由反向传播算法自动优化，$\boldsymbol{\sigma}$ 为激活函数，一般使用 <strong>Sigmoid</strong> 函数。当 $\boldsymbol{g_o = 0}$ 时输出关闭，LSTM 的内部记忆完全被隔断，无法用作输出，此时输出为 0 的向量；当 $\boldsymbol{g_o = 1}$ 时，输出完全打开，LSTM 的状态向量 $\boldsymbol{c_t}$ 全部用于输出。LSTM 的输出为：</p>
<script type="math/tex; mode=display">
\boldsymbol{h_t = g_o\cdot tanh(c_t)}</script><p>即内存向量 $\boldsymbol{c_t}$ 经过 <strong>tanh</strong> 激活函数后与输入门作用，得到 LSTM 的输出。由于 $\boldsymbol{ 𝒈_o ∈ [0,1]}$，$\boldsymbol{tanh(c_t) ∈ [-1,1]}$，因此 LSTM的输出 $\boldsymbol{h_t∈ [-1,1]}$。</p>
<h2 id="2-4-小结"><a href="#2-4-小结" class="headerlink" title="2.4    小结"></a>2.4    小结</h2><p>&emsp;&emsp;LSTM 虽然状态向量和门控数量较多，计算流程相对复杂。但是由于每个门控功能清晰明确，每个状态的作用也比较好理解。LSTM 的核心公式记录如下：</p>
<ul>
<li>遗忘门：$\boldsymbol{g_f = \sigma(W_f[h_{t- 1};x_t]+b_f)}$；</li>
<li>输入向量更新：$\boldsymbol{\tilde{c_t} = tanh(W_c[h_{t -1};x_t] +b_c)}$；</li>
<li>输入门： $\boldsymbol{g_i  = \sigma(W_i[h_{t - 1};x_t]+b_i)}$；</li>
<li>状态向量更新：$\boldsymbol{c_t = g_i\tilde{c_t} + g_fc_{t-1}}$；</li>
<li>输出门：$\boldsymbol{g_o= \sigma(W_o[h_{t - 1};x_t]+b_o)}$；</li>
<li>输出向量更新：$\boldsymbol{h_t = g_o\cdot tanh(c_t)}$。</li>
</ul>
<p>总的来说，可以总结三个门的输出值都是 $\boldsymbol{[0,1]}$ 之间，都是为了控制不同量的”多少”进入下一个 Cell。LSTM 有效地克服了传统 RNN 的一 些不足，比较好地解决了梯度消失、长期依赖等问题。不过，LSTM 也有一 些不足，如结构比较复杂、计算复杂度较高等问题。能否继续改进？</p>
<h1 id="3-GRU"><a href="#3-GRU" class="headerlink" title="3    GRU"></a>3    GRU</h1><p>&emsp;&emsp;针对 LSTM 的缺点，我们尝试简化 LSTM 内部的计算流程，特别是减少门控数量。研究发现，遗忘门是 LSTM 中最重要的门控，甚至发现只有遗忘门的简化版网络在多个基准数据集上面优于标准 LSTM 网络。其中，<strong>门控循环网络</strong>(Gated Recurrent Unit，简称 GRU)是应用最广泛的 RNN 变种之一，GRU 对 LSTM 做了很多简化，比 LSTM 少一个 Gate，因此，计算效率更高，占用内存也相对较少(这也是一件非常有意思的事情，GRU 比 LSTM 提出的更晚，却更简单，且效率更高)。在实际使用中，GRU 和 LSTM差异不大，因此，GRU最近变得越来越流行。GRU 对 LSTM 做了两个大改动：</p>
<ul>
<li>将内部状态向量与输出合并为一个状态：$\boldsymbol{h_t}$；</li>
<li>将输入门、遗忘门、输出门变为两个门：更新门(Update Gate)和重置门(Reset Gate)。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/f649cb4bb6b54d9f985d00b7bbdaf6f4.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="3-1-复位门"><a href="#3-1-复位门" class="headerlink" title="3.1    复位门"></a>3.1    复位门</h2><p>&emsp;&emsp;复位门用于控制上一个时间戳的状态 $\boldsymbol{h_{t - 1}}$ 进入 GRU 的量。</p>
<p><img src="https://img-blog.csdnimg.cn/3ea836757e7141239136e880957e18ce.png#pic_center" alt="在这里插入图片描述"></p>
<p>门控向量 $\boldsymbol{g_r}$ 由当前时间戳输入 $\boldsymbol{x_t}$ 和上一时间戳状态  $\boldsymbol{h_{t-1}}$ 变换得到，关系如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{g_r = \sigma(W_r[h_{t-1};x_t]+b_r)}</script><p>其中 $\boldsymbol{W_r}$ 和 $\boldsymbol{b_r}$ 为复位门的参数，可由反向传播算法自动优化，$\boldsymbol{\sigma}$ 为激活函数，一般使用 <strong>Sigmoid</strong> 函数。门口向量 $\boldsymbol{g_r}$ 只控制 $\boldsymbol{h_{t-1}}$ ，而不会控制输入  $\boldsymbol{x_t}$,也就是说，输入会全部进入状态向量中：</p>
<script type="math/tex; mode=display">
\boldsymbol{\tilde{h_t} = tanh(W_h[g_rh_{t-1};x_t]+b_h)}</script><p>当 $\boldsymbol{g_r = 0}$ 时，新输入 $\boldsymbol{\tilde{h_t}}$ 全部来自于输入 $\boldsymbol{x_t}$，不接受 $\boldsymbol{h_{t-1}}$，此时相当于复位 $\boldsymbol{h_{t-1}}$。当 $\boldsymbol{g_r \not = 1}$ 时， $\boldsymbol{h_{t-1}}$ 和输入 $\boldsymbol{x_t}$ 共同产生新输入 $\boldsymbol{\tilde{h_t}}$。</p>
<h2 id="3-2-更新门"><a href="#3-2-更新门" class="headerlink" title="3.2    更新门"></a>3.2    更新门</h2><p>&emsp;&emsp;更新门用控制上一时间戳状态 $\boldsymbol{h_{t-1}}$ 和新输入 $\boldsymbol{\tilde{h_t}}$ 对新状态向量 $\boldsymbol{h_{t}}$ 的影响程度。</p>
<p><img src="https://img-blog.csdnimg.cn/49308e38251b42589857985c754dcd42.png#pic_center" alt="在这里插入图片描述"></p>
<p>更新门控向量 $\boldsymbol{g_z}$ 计算如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{g_z = \sigma(W_z[h_{t-1};x_t] + b_z)}</script><p>其中 $\boldsymbol{W_z}$ 和 $\boldsymbol{b_z}$ 为更新门的参数，可由反向传播算法自动优化，$\boldsymbol{\sigma}$ 为激活函数，一般使用 <strong>Sigmoid</strong> 函数。$\boldsymbol{g_z}$ 用与控制新输入 $\boldsymbol{\tilde{h_t}}$ 信号， $\boldsymbol{1 - g_z}$ 用于控制状态 $\boldsymbol{h_{t-1}}$ 信号：</p>
<script type="math/tex; mode=display">
\boldsymbol{h_t = g_z\tilde{h_t} + (1-g_z)h_{t-1}}</script><p>可以看到，$\boldsymbol{\tilde{h_t}}$ 和 $\boldsymbol{h_{t-1}}$ 对 $\boldsymbol{h_{t}}$ 的更新量处于相互竞争、此消彼长的状态。当更新门 $\boldsymbol{g_z = 0}$ 时，$\boldsymbol{h_{t}}$ 全部来自上一时间戳状态 $\boldsymbol{h_{t-1}}$；当更新门 $\boldsymbol{g_z =1}$ 时，$\boldsymbol{h_{t}}$ 全部来自新输入 $\boldsymbol{\tilde{h_t}}$。</p>
<h2 id="3-3-小结"><a href="#3-3-小结" class="headerlink" title="3.3    小结"></a>3.3    小结</h2><p>&emsp;&emsp;GRU 的核心公式总结如下：</p>
<ul>
<li>复位门：$\boldsymbol{g_r = \sigma(W_r[h_{t-1};x_t]+b_r)}$；</li>
<li>输入向量更新：$\boldsymbol{\tilde{h_t} = tanh(W_h[g_rh_{t-1};x_t]+b_h)}$；</li>
<li>更新门：$\boldsymbol{g_z = \sigma(W_z[h_{t-1};x_t] + b_z)}$；</li>
<li>状态向量更新：$\boldsymbol{h_t = g_z\tilde{h_t} + (1-g_z)h_{t-1}}$。</li>
</ul>
<p>能够发现，GRU 和 LSTM 的门控制向量的计算方式都一样，只不过 GRU 比 LSTM 更加简洁一些，只要按照 Cell 里面的结构一步一步进行推理，也是不难的。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>循环神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>循环神经网络（一）</title>
    <url>/2022/06/05/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1    简介"></a>1    简介</h1><p>&emsp;&emsp;在本系列文章中，我有跟大家分享过神经网络中两种经典层：<strong>卷积层(CNN)</strong> 和 <strong>全连接层(FC)</strong>，这两种层的输入数据分别是：特征向量和图像(张量)，在具体实现时输入的多样本之间是相互独立的，无联系关系。而且，卷积神经网络利用数据的局部相关性和权值共享的思想大大减少了网络的参数量，非常适合于图片这种具有 <strong>空间(Spatial)</strong> 局部相关性的数据，但自然界的信号除了具有空间维度之外，还有一个 <strong>时间(Temporal)</strong> 维度。具有时间维度的数据(也称作序列数据)有以下特点：</p>
<ul>
<li>不同样本之间存在相互关联；</li>
<li>模型的输出不仅    取决于当前输入，也受历史输入的影响。</li>
</ul>
<p>因此卷积神经网络并不擅长处理此类数据，本博客要介绍的循环神经网络可以较好地解决此类问题。<br>&emsp;&emsp;常见的序列数据有：语言、音乐、视频、股票、文字、DNA等等。</p>
<h1 id="2-序列表示方法"><a href="#2-序列表示方法" class="headerlink" title="2    序列表示方法"></a>2    序列表示方法</h1><p>&emsp;&emsp;具有先后顺序的数据一般叫作 <strong>序列(Sequence)</strong>，比如随时间而变化的商品价格数据就是非常典型的序列。考虑某件商品 A 在 1 月到 6 月之间的价格变化趋势，我们记为一维向量：$\boldsymbol{[x_1,x_2,x_3,x_4,x_5,x_6]}$，shape 为 $\boldsymbol{[6]}$。如果要表示 $\boldsymbol{b}$ 件商品在 1 月到 6 月之间的价格变化趋势，可以记为 2 维张量：</p>
<script type="math/tex; mode=display">
\boldsymbol{\left[[x_1^{(1)},x_2^{(1)},\cdots,x_6^{(1)}],[x_1^{(2)},x_2^{(2)},\cdots,x_6^{(2)}],\cdots,[x_1^{(6)},x_2^{(6)},\cdots,x_6^{(6)}]\right]}</script><p>其中 $\boldsymbol{b}$ 表示商品的数量，张量 shape 为 $\boldsymbol{[b,6]}$。因此，表示一个序列信号只需要一个 shape 为 $\boldsymbol{[b,s]}$ 的张量，其中 $\boldsymbol{b}$ 为序列数量，$\boldsymbol{s}$ 为一个序列的长度。但是对于很多信号并不能直接用一个标量数值表示，比如每个时间戳产生长度为 $\boldsymbol{n}$ 的特征向量，则需要 shape 为 $\boldsymbol{[b,s,n]}$ 的张量才能表示。考虑更复杂的文本数据：句子。它在每个时间戳上面产生的单词是一个字符，并不是数值，不能直接用某个标量表示。</p>
<h2 id="2-1-独热表示"><a href="#2-1-独热表示" class="headerlink" title="2.1    独热表示"></a>2.1    独热表示</h2><p>&emsp;&emsp;对于一个含有 $\boldsymbol{n}$ 个单词的句子，单词的一种简单表示方法就是 <strong>One-hot</strong> 编码。以英文句子为例，假设只考虑最常用的 1 万个单词，那么每个单词就可以表示为某位为 1，其它位置为 0 且长度为 1 万的稀疏 <strong>One-hot</strong> 向量；对于中文句子，如果也只考虑最常用的 5000 个汉字，同样的方法，一个汉字可以用长度为 5000 的 <strong>One-hot</strong> 向量表示。如果只考虑 $\boldsymbol{n}$ 个地名单词，可以将每个地名编码为长度为 $\boldsymbol{n}$ 的 <strong>One-hot</strong> 向量。</p>
<p><img src="https://img-blog.csdnimg.cn/c8298b3c836e41d99407383c05ad684c.png#pic_center" alt="在这里插入图片描述"><br>&emsp;&emsp;文字编码为数值的过程叫作 <strong>Word Embedding</strong>。One-hot 的编码方式实现 <strong>Word Embedding</strong> 简单直观，编码过程不需要学习和训练。在神经网络中，一般使用 <strong>词袋模型(Bag of words)</strong> 先对单词编号，如 2 表示 “I”，3 表示 “me” 等，然后再对每个进行 <strong>One-hot</strong> 编码，最后将每个词向量拼接成矩阵或者张量。但 <strong>One-hot</strong> 编码有以下缺点：</p>
<ul>
<li>容易受维数灾难的困扰，尤其是将其用于深度学习算法时；</li>
<li>任何两个词都是孤立的，存在语义鸿沟词(任意两个词之间都是孤 立的，不能体现词和词之间的关系)。如：对于单词 “like”、“dislike”、“Rome”、“Paris” 来说，“like” 和 “dislike” 在语义角度就强相关，它们都表示喜欢的程度；“Rome” 和 “Paris” 同样也是强相关，他们都表示欧洲的两个地点。如果采用 One-hot 编码，得到的向量之间没有相关性。</li>
</ul>
<p>为了克服此不足，人们提出了另一种表示方法，即分布式表示。</p>
<h2 id="2-2-分布式表示"><a href="#2-2-分布式表示" class="headerlink" title="2.2    分布式表示"></a>2.2    分布式表示</h2><p>&emsp;&emsp;首先要介绍一种相似度衡量方式。在自然语言处理领域，有专门的一个研究方向在探索如何学习到单词的表示向量(Word Vector)，使得语义层面的相关性能够很好地通过 Word Vector 体现出来。一个衡量词向量之间相关度的方法就是 <strong>余弦相关度(Cosine similarity)</strong>：</p>
<script type="math/tex; mode=display">
\boldsymbol{similarity(a,b)≜ cos(\theta)=\frac{a\cdot b}{|a| \cdot |b|}}</script><p>其中 $\boldsymbol{a}$ 和 $\boldsymbol{b}$ 代表了两个词向量。</p>
<p><img src="https://img-blog.csdnimg.cn/badafe223d1c46cdaf5e0937929cc8cf.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;分布式表示最早由 Hinton 于 1986 年提出的，可以克服独热表示的缺点。 解决词汇与位置无关问题，可以通过计算向量之间的 <strong>距离(欧式距离、余弦距离等)</strong> 来体现词与词的相似性。其基本想法是直接用一个普通的向量表示 一个词，此向量为$\boldsymbol{[0.792,-0.177,-0.107,0.109,-0.542,…]}$，常见维度为 50 或 100。用这种方式表示的向量，“麦克” 和 “话筒” 的距离会远远小于“ 麦克” 和 “天气” 的距离。<br>&emsp;&emsp;词向量的分布式表示的优点是解决了词汇与位置无关问题，不足是学习过程相对复杂且受训练语料的影响很大。训练这种向量表示的方法较多，常 见的有 LSA、PLSA、LDA、Word2Vec等，其中 Word2Vec 是 Google 在 2013 年开源的一个词向量计算工具，同时也是一套生成词向量的算法方案。</p>
<h2 id="2-3-Embedding-层"><a href="#2-3-Embedding-层" class="headerlink" title="2.3    Embedding 层"></a>2.3    Embedding 层</h2><p>&emsp;&emsp;在神经网络中，单词的表示向量可以直接通过训练的方式得到，我们把单词的表示层叫作 Embedding 层。Embedding 层负责把单词编码为某个词向量 $\boldsymbol{v}$，它接受的是采用数字编码的单词编号$\boldsymbol{i}$， 也就是词袋模型编码后的结果。系统总单词数量记为$\boldsymbol{N_{vocab}}$，输出长度为 $\boldsymbol{n}$ 的向量 $\boldsymbol{v}$：</p>
<script type="math/tex; mode=display">
\boldsymbol{v = f_\theta(i|N_{vocab}, n)}</script><p>构建一个 shape 为 $\boldsymbol{[N_{vocab}, n]}$ 的查询表对象 $\boldsymbol{table}$，对于任意的单词编号 $\boldsymbol{i}$，只需要查询到对应位置上的向量并返回即可：</p>
<script type="math/tex; mode=display">
 \boldsymbol{v = table[i]}</script><p>在 <strong>PyTorch</strong> 中，有一个 <strong>nn.Embedding(vocab_size，n)</strong> 类，它是 Module 类的子类，这里它接受最重要的两个初始化参数：词汇量大小，每个词汇向量表示的向量维度。Embedding 类返回的是一个形状为 <strong>[每句词个数，词维度]</strong> 的矩阵。</p>
<h1 id="3-一个例子"><a href="#3-一个例子" class="headerlink" title="3    一个例子"></a>3    一个例子</h1><p>&emsp;&emsp;现在我们来考虑如何处理序列信号，以文本序列为例，考虑一个句子：</p>
<script type="math/tex; mode=display">
“I\ hate\ this\ boring\ movie”</script><p>通过 Embedding 层，可以将它转换为 shape 为 $\boldsymbol{[b,s,n]}$ 的张量，$\boldsymbol{b}$ 为句子数量，$\boldsymbol{s}$ 为句子长度，$\boldsymbol{n}$ 为词向量长度。上述句子可以表示为 shape 为$\boldsymbol{[1,5,10]}$ 的张量，其中 5 代表句子单词长度，10 表示词向量长度。<br>&emsp;&emsp;接下来以情感分类任务为例来逐步探索能够处理序列信号的网络模型。情感分类任务通过分析给出的文本序列，提炼出文本数据表达的整体语义特征，从而预测输入文本的情感类型：<strong>正面评价</strong> 或者 <strong>负面评价</strong>。从分类角度来看，情感分类问题就是一个简单的二分类问题，与图片分类不一样的是，由于输入是文本序 列，传统的卷积神经网络并不能取得很好的效果。</p>
<p><img src="https://img-blog.csdnimg.cn/037699a2f9624e7c861cb51effa6f09d.png#pic_center" alt="在这里插入图片描述"></p>
<h2 id="3-1-考虑全连接"><a href="#3-1-考虑全连接" class="headerlink" title="3.1    考虑全连接"></a>3.1    考虑全连接</h2><p>&emsp;&emsp;对于每个词向量，分别使用一个全连接层网络来提取语义特征：</p>
<script type="math/tex; mode=display">
\boldsymbol{o = \sigma(W_tx_t + b_t)}</script><p><img src="https://img-blog.csdnimg.cn/f7b6f2fe099f4dd987aa592fdac6bce7.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中，各个单词的词向量通过 $\boldsymbol{s}$ 个全连接层分类网络 1 提取每个单词的特征，所有单词的特征最后合并，并通过分类网络 2 输出序列的类别概率分布，对于长度为 $\boldsymbol{s}$ 的句子来说，至少需要 $\boldsymbol{s}$ 个全网络层。但这种网络结构的缺点是：</p>
<ul>
<li>网络参数量是巨大，内存占用和计算代价较高，同时由于每个序列的长度 $\boldsymbol{s}$ 并不相同，网络结构是动态变化的；</li>
<li>每个全连接层子网络 $\boldsymbol{W_i}$ 和 $\boldsymbol{b_i}$ 只能感受当前词向量的输入，并不能感知之前和之后的语境信息，导致句子整体语义的缺失，每个子网络只能根据自己的输入来提取高层特征。</li>
</ul>
<h2 id="3-2-考虑权重共享"><a href="#3-2-考虑权重共享" class="headerlink" title="3.2    考虑权重共享"></a>3.2    考虑权重共享</h2><p>&emsp;&emsp;针对全连接的第一个缺点，我们知道卷积神经网络之所以在处理局部相关数据时优于全连接网络，是因为它充分利用了权值共享的思想，大大减少了网络的参数量，使得网络训练起来更加高效。那在处理序列信号的问题上，我们可以借鉴权值共享的思想。</p>
<p><img src="https://img-blog.csdnimg.cn/d2e43e2f62e64cadaa1abaa7b26225a5.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中，将这 $\boldsymbol{s}$ 个网络层参数共享，这样其实相当于使用一个全连接网络来提取所有单词的特征信息。通过权值共享后，参数量大大减少，网络训练变得更加稳定高效。但是，这种网络结构并没有考虑序列之间的先后顺序，将词向量打乱次序仍然能获得相同的输出，无法获取有效的全局语义信息。</p>
<h2 id="3-3-考虑全局语义"><a href="#3-3-考虑全局语义" class="headerlink" title="3.3    考虑全局语义"></a>3.3    考虑全局语义</h2><p>&emsp;&emsp;针对全连接的第二个缺点，我们让网络能够提供一个单独的内存变量，每次提取词向量的特征并刷新内存变量，直至最后一个输入完成，此时的内存变量即存储了所有序列的语义特征，并且由于输入序列之间的先后顺序，使得内存变量内容与序列顺序紧密关联。</p>
<p><img src="https://img-blog.csdnimg.cn/6378facb85614b75953d5a4bee30d6fe.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中，将内存变量实现为一个状态张量 $\boldsymbol{h}$，除了原来的 $\boldsymbol{W_{xh}}$ 参数共享外，这里额外增加了一个 $\boldsymbol{W_{hh}}$ 参数，每个时间戳 $\boldsymbol{t}$ 上状态张量刷新为：</p>
<script type="math/tex; mode=display">
\boldsymbol{h_t = \sigma(W_{xh}x_t+W_{hh}h_{t-1}+b) }</script><p>其中状态张量 $\boldsymbol{h_0}$ 为初始的内存状态，可以初始化为全 0，$\boldsymbol{\sigma}$ 为激活函数，经过 $\boldsymbol{s}$ 个词向量的输入后得到网络最终的状态张量  $\boldsymbol{h_s}$，$\boldsymbol{h_s}$ 较好地代表了句子的全局语义信息，基于 $\boldsymbol{h_s}$ 通过某个全连接层分类器即可完成情感分类任务。</p>
<h2 id="3-4-循环神经网络"><a href="#3-4-循环神经网络" class="headerlink" title="3.4    循环神经网络"></a>3.4    循环神经网络</h2><p>&emsp;&emsp;经过上面的一步步分析探索，可以得到一种新型的网络结构，在每个时间戳 $\boldsymbol{t}$，网络层接受当前时间戳的输入 $\boldsymbol{x_t}$ 和上一个时间戳的网络状态向量 $\boldsymbol{h_{t-1}}$ ，经过：</p>
<script type="math/tex; mode=display">
 \boldsymbol{h_t = f_\theta(h_{t-1},x_t)}</script><p>变换后得到当前时间戳的新状态向量 $\boldsymbol{h_t}$，并写入内存状态中，其中$\boldsymbol{f_\theta}$ 代表了网络的运算逻辑，$\boldsymbol{\theta}$ 为网络参数集。如果在每个时间戳上，网络层均有输出产生 $\boldsymbol{o_t}$，$\boldsymbol{o_t = g_\gamma(h_t)}$，即将网络的状态向量变换后输出。</p>
<p><img src="https://img-blog.csdnimg.cn/5bda3b2b2b6044c6a6ac57c868471e96.png#pic_center" alt="在这里插入图片描述"></p>
<p>上述网络结构在时间戳上折叠，可简化成：</p>
<p><img src="https://img-blog.csdnimg.cn/e837b3cf7f3f4efc96ec4975583393a7.png#pic_center" alt="在这里插入图片描述"></p>
<p>网络循环接受序列的每个特征向量 $\boldsymbol{x_t}$，并刷新内部状态向量 $\boldsymbol{h_t}$，同时形成输出 $\boldsymbol{o_t}$。对于这种网络结构，我们把它叫做 <strong>循环神经网络(Recurrent Neural Network，简称 RNN)</strong>。<br>&emsp;&emsp;如果使用张量 $\boldsymbol{W_{xh}}$、$\boldsymbol{W_{hh}}$ 和偏置 $\boldsymbol{b}$ 来参数化 $\boldsymbol{f_\theta}$ 网络，并按照如下方式更新内存状态：</p>
<script type="math/tex; mode=display">
\boldsymbol{h_t = \sigma(W_{xh}x_t+W_{hh}h_{t-1}+b) }</script><p>我们把这种网络叫做基本的循环神经网络，如无特别说明，一般说的循环神经网络即指这种实现。在循环神经网络中，激活函数更多地采用 <strong>tanh</strong> 函数。并且可以选择不使用偏执 $\boldsymbol{b}$ 来进一步减少参数量。状态向量 $\boldsymbol{h_t}$ 可以直接用作输出，即 $\boldsymbol{o_t = h_t}$，也可以对 $\boldsymbol{h_t}$ 做一个简单的线性变换 $\boldsymbol{o_t = W_{ho}h_t}$ 后得到每个时间戳上的网络输出 $\boldsymbol{o_t}$。</p>
<h2 id="3-5-小结"><a href="#3-5-小结" class="headerlink" title="3.5    小结"></a>3.5    小结</h2><p>&emsp;&emsp;经过上面的推到，我们知道 RNN 是怎么来的的，内部的公式如何计算的。由上面再次总结 RNN 的核心公式如下：</p>
<ul>
<li>$\boldsymbol{z_t = W_{xh}x_t+W_{hh}h_{t-1}+b}$；</li>
<li>$\boldsymbol{h_t =  \sigma(z_t) }$；</li>
<li>$\boldsymbol{o_t = W_{ho}h_t}$，若是分类问题的话，还可以是 $\boldsymbol{o_t = softmax(h_t)}$。</li>
</ul>
<p>要注意的是 RNN 中的激活函数可以是 ReLU、sigmoid、tanh，不过一般来说使用 tanh 较多。</p>
<h1 id="4-RNN-类型"><a href="#4-RNN-类型" class="headerlink" title="4    RNN 类型"></a>4    RNN 类型</h1><p>&emsp;&emsp;循环神经网络适合于处理序列数据，序列长度一般不固定，比如我们在前面举的文本分类的是有多个输入，只有一个输出；在讲解 RNN 结构时每一个输入都有一个输出，因此，RNN 应用非常广泛。我们可以根据应用场景将 RNN 分成以下几种类型：<br><img src="https://img-blog.csdnimg.cn/44cb35900c0841ab97ff5d0cdb765fa0.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中每一个矩形是一个向量，箭头则表示函数(比如矩阵相乘)。 其中最下层为输入向量，最上层为输出向量，中间层表示 RNN 的状态。从左到右：</p>
<ul>
<li>没有使用 RNN 的 Vanilla 模型，从固定大小的输入得到固定大小输出(比如图像分类)；</li>
<li>序列输出(比如图片字幕，输入一张图片输出一段文字序列)；</li>
<li>序列输入(比如情感分析，输入一段文字，然后将它分类成积极或者消极情感，包括雷达和我们上面举的文本分类)；</li>
<li>序列输入和序列输出(比如机器翻译：一个 RNN 读取一条英文语 句，然后将它以法语形式输出)；</li>
<li>同步序列输入输出(比如视频分类，对视频中每一帧打标签)。</li>
</ul>
<p>此外，RNN 也可以堆叠几层，如下：</p>
<p><img src="https://img-blog.csdnimg.cn/c6336fc568c547a694b0bccb4b92bdd1.png#pic_center" alt="在这里插入图片描述"></p>
<p>计算公式跟一层 RNN 完全一样，只是输出上有些区别，这里不展开讲述。</p>
<h1 id="5-反向传播-只是探讨梯度问题"><a href="#5-反向传播-只是探讨梯度问题" class="headerlink" title="5    反向传播(只是探讨梯度问题)"></a>5    反向传播(只是探讨梯度问题)</h1><p>&emsp;&emsp;这篇博客就不跟大家探讨 RNN 的梯度传播了，只是探讨一下传播过程中的问题。RNN 跟别的网络结构一样，在反向传播中依然存在梯度爆炸和梯度消失的问题，主要的解决方法如下：</p>
<ul>
<li>梯度爆炸：进行 <strong>梯度裁剪(Gradient Clipping)</strong>，梯度裁剪与张量限幅非常类似，也是通过将梯度张量的数值或者范数限制在某个较小的区间内，从而将远大于 1 的梯度值减少，避免出现梯度爆炸。</li>
<li>梯度消失：对网络结构进行改进，即 <strong>GRU</strong> 和 <strong>LSTM</strong>，这两种 RNN 的变种也是我下一篇要介绍的网络结构。</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>循环神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络（三）</title>
    <url>/2022/06/05/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>&emsp;&emsp;卷积神经网络发展非常迅速，应用非常广阔，所以近几年的卷积神经网络得到了长足的发展，下图为卷积神经网络近几年发展的大致轨迹。</p>
<p><img src="https://img-blog.csdnimg.cn/ef0e1297e2104ce699fb786232ec8928.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;1998年LeCun提出了 <strong>LeNet</strong>，可谓是开山鼻祖，系统地提出了卷积层、 池化层、全连接层等概念。2012年Alex等提出 <strong>AlexNet</strong>，提出 一些训练深度网络的重要方法或技巧，如 Dropout、ReLu、GPU、数据增强方法等，随后各种各样的深度卷积神经网络模型相继被提出，其中比较有代表性的有 <strong>VGG</strong> 系列，<strong>GoogLeNet</strong> 系列，<strong>ResNet</strong> 系列，<strong>DenseNet</strong> 系列等，他们的网络层数整体趋势逐渐增多。以网络模型在 ILSVRC 挑战赛 ImageNet数据集上面的分类性能表现为例，如下图，在 AlexNet 出现之前的网络模型都是浅层的神经网络，<strong>Top-5</strong>（表示神经网络返回的前5个最大概率值代表的内容中有一个是正确的）错误率均在 25%以上，AlexNet 8 层的深层神经网络将 Top-5 错误率降低至 16.4%，性能提升巨大，后续的 VGG、GoogleNet 模型继续将错误率降低至 6.7%；ResNet 的出现首次将网络层数提升至 152 层，错误率也降低至 3.57%。<br><img src="https://img-blog.csdnimg.cn/cdf688521db043d18d72e0a6f063ecb8.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h1><p>&emsp;&emsp;LeNet 是Yann LeCun等人提出的卷积神经网络结构，用于解决手写数字识别的机器视觉任务。1989年。一般来说，LeNet 是指 LeNet-5，是一个简单的卷积神经网络。卷积神经网络是一种前馈神经网络，其人工神经元可以对覆盖范围内的一部分周围细胞做出反应，在大规模图像处理中表现良好。LeNet 作为早期卷积神经网络的代表，拥有卷积神经网络的基本单元，如卷积层、池化层和全连接层，为卷积神经网络的未来发展奠定了基础。<br>&emsp;&emsp;模型架构：LeNet-5 模型结构为 <strong>输入层-卷积层-池化层-卷积层-池化层-全连接层-全 连接层-输出</strong>，为串联模式。</p>
<p><img src="https://img-blog.csdnimg.cn/d372e7fcd6ce40adbcee7ada2e3251e7.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;模型特点：</p>
<ul>
<li>每个卷积层包括三个部分：卷积、池化和非线性激活函数；</li>
<li>使用卷积提取空间特征；</li>
<li>采用降采样的平均池化层；</li>
<li>使用 <strong>tanh</strong> 激活函数；</li>
<li>使用 <strong>MLP</strong> 作为最后一个分类器；</li>
<li>层间稀疏连接，降低计算复杂度。</li>
</ul>
<h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><p>&emsp;&emsp;2012 年，ILSVRC12 挑战赛 ImageNet 数据集分类任务的冠军 Alex Krizhevsky 提出了 8<br>层的深度神经网络模型 AlexNet。AlexNet 在 ImageNet 取得了 15.3% 的 Top-5 错误率，比第二名在错误率上降低了 10.9%。原始论文的主要结果是模型的深度对其高性能至关重要，这在计算上是昂贵的，但由于在训练过程中使用了图形处理单元(GPU) 而变得可行。<br>&emsp;&emsp;模型架构：接收输入为 <strong>224 × 224</strong> 大小的彩色图片数据，经过五个卷积层和三个全连接层后得到样本属于 <strong>1000</strong> 个类别的概率分布。为了降低特征图的维度，AlexNet 在第 1、2、5 个卷积层后添加了 <strong>Max Pooling</strong> 层，网络的参数量达到了 6000 万个。为了能够在当时的显卡设备 NVIDIA GTX 580(3GB 显存)上训练模型，Alex Krizhevsky 将卷积层、前 2 个全连接层等拆开在两块显卡上面分别训练，最后一层合并到一张显卡上面，进行反向传播更新。</p>
<p><img src="https://img-blog.csdnimg.cn/db67045e9c10452f914803ee8f9d4e3a.png#pic_center" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/de86dbe37b284a799a91dcc191f422b3.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;模型特点：</p>
<ul>
<li>由 5 层卷积和 3 层全连接组成，输入图像为 3 通道 224×224 大小，网络规 模远大于 LeNet；</li>
<li>采用了 <strong>ReLU</strong> 激活函数，过去的神经网络大多采用 <strong>Sigmoid</strong> 激活函数，计算相对复杂，容易出现梯度弥散现象。</li>
<li>引入 <strong>Dropout</strong> 层。<strong>Dropout</strong> 提高了模型的泛化能力，防止过拟合，提升模型的鲁棒性。</li>
<li>具备一些很好的训练技巧，包括数据增广、学习率策略、<strong>Weight Decay</strong> 等。</li>
</ul>
<h1 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h1><p>&emsp;&emsp;AlexNet 模型的优越性能启发了业界朝着更深层的网络模型方向研究。2014 年，ILSVRC14 挑战赛 ImageNet 分类任务的亚军牛津大学 VGG 实验室提出了 VGG11、VGG13、VGG16、VGG19 等一系列的网络模型，如下图。VGG可以看成是加深版本的AlexNet，都是 <strong>Conv Layer + FC layer</strong>，VGG16 在 ImageNet 取得了 7.4%的 Top-5 错误率，比 AlexNet 在错误率上降低了 7.9%。</p>
<p><img src="https://img-blog.csdnimg.cn/30942835ff1d4171ad52a34c2f3c6f0b.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;模型架构：以 VGG16 为例，它接受 <strong>224 × 224</strong> 大小的彩色图片数据，经过 2 个 <strong>Conv-Conv-Pooling</strong> 单元，和 3 个 <strong>Conv-Conv-Conv-Pooling</strong> 单元的堆叠，最后通过 3 层全连接层输出当前图片分别属于 1000 类别的概率分布。</p>
<p><img src="https://img-blog.csdnimg.cn/fd59378f38094452b40210e44f6090fb.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;模型特点：</p>
<ul>
<li>更深的网络结构：网络层数由 AlexNet 的 8 层增至 16 和 19 层，更深的网络意味着更强大的网络能力，也意味着需要更强大的计算力，不过后来硬件发展也很快，显卡运算力也在快速增长，以此助推深度学习的快速发展。</li>
<li>全部采用更小的 <strong>3 × 3</strong> 卷积核，相对于 AlexNet 中 <strong>7 × 7</strong> 的卷积核，参数量更少，计算代价更低。</li>
<li>采用更小的池化层 <strong>2 × 2</strong> 窗口和步长 $\boldsymbol{s = 2}$，而 AlexNet 中是步长 $\boldsymbol{𝑠 = 2、3 × 3}$ 的池化窗口。</li>
</ul>
<h1 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h1><p>&emsp;&emsp;在介绍 GoogleNet 之前，我们需要对卷积核进行讨论。再前面说过 VGG 模型使用的卷积核大小均是 <strong>3 × 3</strong>，参数量更少，计算代价更低，同时因为两个 <strong>3 × 3</strong> 卷积核的感受野相当于一个 <strong>5 × 5</strong> 卷积核，能捕获图像更多的细节信息，因此 <strong>3 × 3</strong> 卷积核在性能表现上更优越。因此业界开始探索卷积核最小的情况：<strong>1 × 1</strong> 卷积核。</p>
<p><img src="https://img-blog.csdnimg.cn/123e773fcfc34da79386e563a60b6175.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中，输入为 3 通道的 <strong>5 × 5</strong> 图片，与单个 <strong>1 × 1</strong> 的卷积核进行卷积运算，每个通道的数据与对应通道的卷积核运算，得到 3 个通道的中间矩阵，对应位置相加得到最终的输出张量。对于输入 <strong>shape</strong> 为 $\boldsymbol{[b, h,w,c_{in}]}$，<strong>1 × 1</strong> 卷积层的输出为 $\boldsymbol{[b, h,w,c_{out}]}$，其中 $\boldsymbol{c_{in}}$ 为输入数据的通道数，$\boldsymbol{c_{out}}$ 为输出数据的通道数，也是 <strong>1 × 1</strong> 卷积核的数量。 <strong>1 × 1</strong> 卷积核的一个特别之处在于，它可以不改变特征图的宽高，而只对通道数 $\boldsymbol{c}$ 进行变换。这起到了降维的作用，因此 <strong>1 × 1</strong> 卷积核可以帮助我们降低参数数量。<br>&emsp;&emsp;2014 年，ILSVRC14 挑战赛的冠军 Google 提出了大量采用 <strong>3 × 3</strong> 和<strong>1 × 1</strong> 卷积核的网络模型：GoogLeNet，网络层数达到了 22 层。虽然 GoogLeNet 的层数远大于 AlexNet，但是它的参数量却只有 AlexNet 的 $\boldsymbol{\frac{1}{12}}$，同时性能也远好于 AlexNet。在 ImageNet 数据集分类任务上，GoogLeNet 取得了 6.7%的 Top-5 错误率，比 VGG16 在错误率上降低了 0.7%。<br>&emsp;&emsp;模型架构：VGG 是增加网络的深度，但深度达到一个程度时，可能就成为瓶颈。 GoogLeNet 则从另一个维度来增加网络能力，每单元有许多层并行计算，让网络更宽了。GoogLeNet 网络通过大量堆叠 <strong>Inception</strong> 模块，形成了复杂的网络结构，如下图。</p>
<p><img src="https://img-blog.csdnimg.cn/d1021c4e19ea455185e943b1d157feaf.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中，<strong>Inception</strong> 模块的输入为 $\boldsymbol{X}$，通过 4 个子网络得到 4 个网络输出，在通道轴上面进行拼接合并，形成 <strong>Inception</strong> 模块的输出。这 4 个子网络为：</p>
<ul>
<li><strong>1 × 1</strong> 卷积层；</li>
<li><strong>1 × 1</strong> 卷积层，再通过一个 <strong>3 × 3</strong> 卷积层；</li>
<li><strong>1 × 1</strong> 卷积层，再通过一个 <strong>5 × 5</strong> 卷积层；</li>
<li><strong>3 × 3</strong> 最大池化层，再通过 <strong>1 × 1</strong> 卷积层。</li>
</ul>
<p>GoogLeNet 的网络结构如下图所示，其中红色框中的网络结构即为 <strong>Inception</strong> 模块的网络结构。</p>
<p><img src="https://img-blog.csdnimg.cn/4e8d066c01e14eff8dad7b5d83fed171.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;模型特点：</p>
<ul>
<li>引入 <strong>Inception</strong> 结构，这是一种网中网(Network In Network)的结构。通过网络的水平排布，可以用较浅的网络得到较好的模型能力，并进行多特征融合，同时更容易训练。使用了 <strong>1 × 1</strong> 卷积来先对特征通道进行降维，减少计算量。GoogLeNet 就是一个精心设计的性能良好的 <strong>Inception</strong> 网络(Inception v1)的 实例，即 GoogLeNet 是 <strong>Inception v1</strong> 网络的一种。</li>
<li>采用全局平均池化层。将后面的全连接层全部替换为简单的全局平均池化，在最后参数会变得更少。而在 AlexNet 中最后 3 层的全连接层参数差不多占总参数的 90%，使用大网络在宽度和深度上允许 GoogleNet 移除全连接层，但并不会影响到结果的精度。</li>
</ul>
<h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><p>&emsp;&emsp;AlexNet、VGG、GoogLeNet 等网络模型的出现将神经网络的发展带入了几十层的阶段，研究人员发现网络的层数越深，越有可能获得更好的泛化能力。但是当模型加深以后，网络变得越来越难训练，这主要是由于梯度弥散和梯度爆炸现象造成的。在较深层数的神经网络中，梯度信息由网络的末层逐层传向网络的首层时，传递的过程中会出现梯度接近于 0 或梯度值非常大的现象。网络层数越深，这种现象可能会越严重。对于深层神经网络的梯度弥散和梯度爆炸现象，我们可以想到浅层神经网络不容易出现这些梯度现象，那么可以尝试给深层神经网络添加一种回退到浅层神经网络的机制。当深层神经网络可以轻松地回退到浅层神经网络时，深层神经网络可以获得与浅层神经网络相当的模型性能，而不至于更糟糕。<br>&emsp;&emsp;2015 年，微软亚洲研究院何凯明等人发表了深度残差网络(Residual Neural Network，简称 ResNet)算法 [10]，并提出了 18 层、34 层、50 层、101层、152 层的 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 等模型。ResNet 在网络结构上做了一大创新，即采用残差网络结构，而不再是简单地堆积层数，ResNet 在卷积神经网络中提供了一个新思路。ResNet 在 ILSVRC 2015 挑战赛 ImageNet数据集上的分类、检测等任务上面均获得了最好性能。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>&emsp;&emsp;ResNet 通过在卷积层的输入和输出之间添加残差链接实现层数回退机制。</p>
<p><img src="https://img-blog.csdnimg.cn/ae2a26c169914e2db0b84dfdf01b84f5.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中，输入 $\boldsymbol{x}$ 通过两个卷积层，得到特征变换后的输出 $\boldsymbol{F(𝒙)}$，与输入 $\boldsymbol{x}$ 进行对应元素的相加运算，得到最终输出 $\boldsymbol{H(x)}$：</p>
<script type="math/tex; mode=display">
\boldsymbol{H(x) = F(x) + x}</script><p> $\boldsymbol{H(x)}$ 叫作残差模块(Residual Block，简称 ResBlock)，由于卷积神经网络需要学习映射 $\boldsymbol{F(x) = H(x) - x}$，故称为残差网络。为了能够满足输入 $\boldsymbol{x}$ 与卷积层的输出出 $\boldsymbol{F(𝒙)}$ 能够相加运算，需要输入 $\boldsymbol{x}$ 的 <strong>shape</strong> 与 $\boldsymbol{F(𝒙)}$ 的完全一致。当出现 <strong>shape</strong> 不一致时，一般通过在残差连接上添加额外的卷积运算环节将输入 $\boldsymbol{x}$ 变换到与 $\boldsymbol{F(𝒙)}$ 相同的 <strong>shape</strong>，如上图中 $\boldsymbol{dentity(𝒙)}$ 函数。因为再卷积过程中我们常常使用 <strong>Vaild卷积</strong>，因此 $\boldsymbol{dentity(𝒙)}$ 以<strong>1 × 1</strong>的卷积运算居多，主要用于调整输入的通道数。<br> &emsp;&emsp;模型架构：34 层的深度残差网络、34 层的普通深度网络以及 19 层的 VGG 网络结构如下图。可以看到，深度残差网络通过堆叠残差模块，达到了较深的网络层数，从而获得了训练稳定、性能优越的深层网络模型。</p>
<p> <img src="https://img-blog.csdnimg.cn/6fffa970f5cb4bc397eab122728c3184.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;模型特点：</p>
<ul>
<li>层数非常深，已经超过百层；</li>
<li>引入残差单元来解决退化问题。</li>
</ul>
<h1 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h1><p>&emsp;&emsp;DenseNet 将前面所有层的特征图信息通过 <strong>Skip Connection</strong> 与当前层输出进行聚合，与 ResNet 的对应位置相加方式不同，DenseNet 采用在通道轴 $\boldsymbol{c}$ 维度进行拼接操作，聚合特征信息。</p>
<p><img src="https://img-blog.csdnimg.cn/903767be083a4ecf9e2f7118040059ed.png#pic_center" alt="在这里插入图片描述"></p>
<p>上图中，输入 $\boldsymbol{X}$ 通过 $\boldsymbol{H_1}$ 卷积层得到输出 $\boldsymbol{X_1}$，$\boldsymbol{X_1}$ 与 $\boldsymbol{X}$ 在通道轴上进行拼接，得到聚合后的特征张量，送入 $\boldsymbol{H_2}$ 卷积层，得到输出 $\boldsymbol{X_2}$，同样的方法，$\boldsymbol{X_2}$ 与前面所有层的特征信息 $\boldsymbol{X_1}$ 与 $\boldsymbol{X}$ 进行聚合，再送入下一层。如此循环，直至最后一层的输出 $\boldsymbol{X_4}$ 和前面所有层的特征信息：$\boldsymbol{\{X_i\}_{i = 0, 1, 2 ,3}}$进行聚合得到模块的最终输出。<br>&emsp;&emsp;模型架构：DenseNet 通过堆叠多个 Dense Block 构成复杂的深层神经网络。</p>
<p><img src="https://img-blog.csdnimg.cn/982bee45930b4c818752a0fb98eb368d.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;模型特点：</p>
<ul>
<li>引入来稠密连接模块解决退化问题。</li>
</ul>
<p>不同版本的 DenseNet 的性能、DenseNet 与 ResNet 的性能比较，以及DenseNet 与 ResNet 训练曲线比较如下：<br><img src="https://img-blog.csdnimg.cn/88f8963b05a14dc19eb03bf1e6b1a517.png#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络（二）</title>
    <url>/2022/06/05/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="1-池化层"><a href="#1-池化层" class="headerlink" title="1    池化层"></a>1    池化层</h1><p>&emsp;&emsp;在上篇博客中，有跟大家分析过，在卷积层中没有 <strong>padding</strong> 的情况下，可以通过调节步长参数 $\boldsymbol{s}$ 实现特征图的高宽成倍缩小，从而降低了网络的参数量。但是在实际上我们通常使用 <strong>Same卷积</strong>，即输入和输出特征图的维度一样，这样一来将面临巨大的计算量挑战，而且容易产生过拟合的现象，因此我们需要一种专门的网络层可以实现尺寸缩减功能，它就是这里要介绍的 <strong>池化层</strong>(pooling layer)，通常，池化操作也被称作 <strong>下采样</strong>。<br>&emsp;&emsp;池化层同样基于局部相关性的思想，通过从局部相关的一组元素中进行采样或信息聚合，从而得到新的元素值。下面介绍两种池化方式：</p>
<ul>
<li>最大池化（Max Pooling）：选择 <strong>pooling</strong> 窗口中的最大值作为采样值；</li>
<li>均值池化（Mean Pooling）：将 <strong>pooling</strong> 窗口中的所有值相加取平均， 以平均值作为采样值。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/380e2764641f4fd3a00e461b67f04906.png#pic_center" alt="在这里插入图片描述"></p>
<p>不管采用什么样的池化函数，当输入作出少量平移时，池化能够帮助输入的表示近似 <strong>不变（invariant）</strong>，对于平移的不变性是指当我们对输入进行少量平移时，经过池化函数后的大多数输出并不会发生改变。池化操作就是图像的 <strong>resize</strong>，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。说明池化能够提升模型的尺度不变性、旋转不变性。<br>&emsp;&emsp;以 $\boldsymbol{5 × 5}$ 输入 $\boldsymbol{X}$ 的最大池化层为例，考虑池化窗口大小 $\boldsymbol{ k =2}$ ，步长 $\boldsymbol{s = 2}$ 的情况。</p>
<p><img src="https://img-blog.csdnimg.cn/4a74011efe814fa7935270648d7da830.png#pic_center" alt="在这里插入图片描述"></p>
<p>绿色虚线方框代表第一次池化窗口的位置，感受野元素集合为：</p>
<script type="math/tex; mode=display">
\boldsymbol{\{ 1, -1, -1,-2\}}</script><p>在最大池化采样的方法下，通过:</p>
<script type="math/tex; mode=display">\boldsymbol{x' = }
\boldsymbol{\ max(\{ 1, -1, -1,-2\}) = 1}</script><p>计算出当前位置的输出值为 1，并写入对应位置。若采用的是平均池化操作，则此时的输出值应为:</p>
<script type="math/tex; mode=display">\boldsymbol{x' = }
\boldsymbol{\ avg(\{ 1, -1, -1,-2\}) = -0.75}</script><p>计算完当前位置的池化窗口后，与卷积层的计算步骤类似，将池化窗口按着步长向右移动若干单位，到达上图中就是实现绿色窗口所在位置此时的输出为：</p>
<script type="math/tex; mode=display">\boldsymbol{x' = }
\boldsymbol{\ max(\{ -1, 0, -2,2\}) = 2}</script><p>同样的方法，逐渐移动感受野窗口至最右边，计算出输出 $\boldsymbol{x’ = }<br>\boldsymbol{\ max(\{ 2,0, 3,1\}) = 3}$ 此时窗口已经到达输入边缘，按照卷积层同样的方式，感受野窗口向下移动一个步长，并回到行首。</p>
<p><img src="https://img-blog.csdnimg.cn/a9a0ebacdf0e4afe9c5e0c74ea8ae18a.png#pic_center" alt="在这里插入图片描述"></p>
<p>循环往复，直至最下方、最右边，获得最大池化层的输出，长宽为 $\boldsymbol{4 × 4}$，小于输入 $\boldsymbol{X}$ 的高宽。</p>
<p><img src="https://img-blog.csdnimg.cn/1214352efa374c48b5a3b7ee041a02db.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;池化层没有需要学习的参数，计算简单，在 <strong>CNN</strong> 中可用来减小尺寸，提高运算速度及减小噪声影响，让各特征更具有健壮性。池化层比卷积层更简单，它没有卷积运算，只是在滤 波器算子滑动区域内取最大值或平均值。而池化的作用则体现在降采样：保留显著特征、降低特征维度，增大感受野。深度网络越往后面越能捕捉到物体的语义信息，这种语义信息是建立在较大的感受野基础上。<br>&emsp;&emsp;通过设计池化层感受野的高宽𝑘和步长 $\boldsymbol{s}$ 参数，可以实现各种降维运算。比如，一种常用的池化层设定是池化窗口大小 $\boldsymbol{k = 2}$，步长 $\boldsymbol{s = 2}$，这样可以实现输出只有输入高宽一半的目的。如下图中，池化窗口 $\boldsymbol{k = 3}$，步长 $\boldsymbol{s = 2}$，输入 $\boldsymbol{X}$ 高宽为 $\boldsymbol{5×5}$，输出 $\boldsymbol{O}$ 高宽只有 $\boldsymbol{2×2}$。</p>
<p><img src="https://img-blog.csdnimg.cn/e28168ec964a4af7a4aa4a31946ef60e.png#pic_center" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/1796eb7358864e6da9e533da5651bdd2.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="2-BatchNorm层"><a href="#2-BatchNorm层" class="headerlink" title="2    BatchNorm层"></a>2    BatchNorm层</h1><p>&emsp;&emsp;卷积神经网络的出现，网络参数量大大减低，使得几十层的深层网络成为可能。然而，在残差网络出现之前，网络的加深使得网络训练变得非常不稳定，甚至出现网络长时间不更新甚至不收敛的现象，同时网络对超参数比较敏感，超参数的微量扰动也会导致网络的训练轨迹完全改变。<br>&emsp;&emsp;2015 年，Google 研究人员 Sergey Ioffe 等提出了一种参数标准化(Normalize)的手段，并基于参数标准化设计了 <strong>Batch Nomalization</strong>（简写为 BatchNorm，或 BN）层 。BN 层的提出，使得网络的超参数的设定更加自由，比如更大的学习率、更随意的网络初始化等，同时网络的收敛速度更快，性能也更好。BN 层提出后便广泛地应用在各种深度网络模型上，卷积层、BN 层、ReLU 层、池化层一度成为网络模型的标配单元块，通过堆叠 <strong>Conv-BN-ReLU-Pooling</strong> 方式往往可以获得不错的模型性能。总结 <strong>BN</strong> 层的作用如下三点，在后面过程中会具体怎么实现中这些作用的。</p>
<ul>
<li>加快网络的训练和收敛的速度；</li>
<li>控制梯度爆炸防止梯度消失；</li>
<li>防止过拟合。</li>
<li>&emsp;&emsp;为什么需要对网络中的数据进行标准化操作？我们可以先来看看虑 <strong>Sigmoid</strong> 激活函数和它的梯度分布。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/9bb131337fc14d57966a05c710434b2d.png#pic_center" alt="在这里插入图片描述"><br>由上图知，<strong>Sigmoid</strong> 函数在 $\boldsymbol{𝑥 ∈ [−2 ,2]}$ 区间的导数值在 $\boldsymbol{[0.1,0.25]}$ 区间分布；$\boldsymbol{𝑥 &gt; 2}$ 或 $\boldsymbol{𝑥 &lt;-2}$ 时，<strong>Sigmoid</strong> 函数的导数变得很小，逼近于 0，在反向传播中从而容易出现梯度弥散现象。为了避免因为输入较大或者较小而导致 <strong>Sigmoid</strong> 函数出现梯度弥散现象。如假设网络中每层的学习梯度都小于最大值 $\boldsymbol{0.25}$，网络中有 $\boldsymbol{n}$ 层，因为链式求导的原因，第一层的梯度将会小于 $\boldsymbol{0.25}$ 的 $\boldsymbol{n}$ 次方，所以学习速率相对来说会变的很慢，而对于网络的最后一层只需要对自身求导一次，梯度就大，学习速率就会比较快，这就会造成在一个很深的网络中，浅层基本不学习，权值变化小，而后面几层网络一直学习，后面的网络基本可以表征整个网络，这样失去了深度的意义。因此将函数输入 $\boldsymbol{𝑥 }$ 标准化映射到 0 附近的一段较小区间将变得非常重要，上图中，通过标准化重映射后，值被映射在 0 附近，此处的导数值不至于过小，从而不容易出现梯度弥散现象。同时，假如激活层斜率均为最大值 $\boldsymbol{0.25}$，所有层的权值为 100，这样梯度就会指数增加，但是如果进行了归一化之后，权值就不会很大，梯度爆炸的情况就会减少。<br>&emsp;&emsp;再来分析以下只有 2 个输入节点的线性模型：$\boldsymbol{L = a= x_1w_1 + x_2w_2+b}$：</p>
<p><img src="https://img-blog.csdnimg.cn/cacb8e53f8234918ae1ea7de8ce5de9c.png#pic_center" alt="在这里插入图片描述"></p>
<p> 由于模型相对简单，可以绘制出 2 种 $\boldsymbol{x_1,x_2}$ 下的函数的损失等高线图：</p>
<p> <img src="https://img-blog.csdnimg.cn/6142e3ec2c9041cba9075a4de2319ef7.png#pic_center" alt="在这里插入图片描述"></p>
<p>其中，左边的损失等高线图是 $\boldsymbol{x_1∈[1,10],x_2∈[100,1000]}$ 时的某条优化轨迹线示意图，右边的损失等高线图是 $\boldsymbol{x_1∈[1,10],x_2∈[1,10]}$ 时的某条优化轨迹线示意图，图中的圆环中心即为全局极值点。当 $\boldsymbol{x_1,x_2}$ 输入分布相近时， $\boldsymbol{\frac{\partial L}{w_1},\frac{\partial L}{w_2}}$ 偏导数值相当，收敛更加快速，优化轨迹更理想如上图中的右图；当 $\boldsymbol{x_1,x_2}$ 输入分布差距较大时，比如 $\boldsymbol{x_1≪x_2}$，则$\boldsymbol{\frac{\partial L}{w_1}≪\frac{\partial L}{w_2}}$，损失函数等势线在$\boldsymbol{x_2}$ 轴更加陡峭，某条可能的优化轨迹如上图中的左图。<br>&emsp;&emsp;通过上述的 2 个例子，能够知道网络层输入 $\boldsymbol{x}$ 分布相近，并且分布在较小范围内时(如 0 附近)，更有利于函数的优化。我们可以通过数据标准化操作达到这个目的，通过数据标准化操作可以将数据 $\boldsymbol{x}$ 映射到 $\boldsymbol{\hat{x}}$：</p>
<script type="math/tex; mode=display">
\boldsymbol{\hat{x}}= \boldsymbol{\frac{x - \mu_r}{\sqrt{\sigma_r^2+\epsilon}}}</script><p>其中 $\boldsymbol{\mu_r、\sigma_r^2}$ 来自统计的所有数据的均值和方差， $\boldsymbol{\epsilon}$ 是为防止出现除 0 错误而设置的较小数，如 <strong>1e − 8</strong>。在基于 <strong>Batch</strong> 的训练阶段，考虑 <strong>Batch</strong> 内部的均值 $\boldsymbol{\mu_B}$ 和方差 $\boldsymbol{\sigma_B^2}$：</p>
<script type="math/tex; mode=display">
 \boldsymbol{\mu_B}  =  \boldsymbol{\frac{1}{m}\sum_{i = 1}^{m}x_i} \\
\boldsymbol{\sigma_B^2} = \boldsymbol{\frac{1}{m}\sum_{i = 1}^{m}(x_i - \mu_B)^2}</script><p>其中 <strong>m</strong> 为 <strong>Batch</strong> 样本数，而且因为每次网络都是随机取 <strong>Batch</strong>，这样就会使得整个网络不会朝这一个方向使劲学习。一定程度上避免了过拟合。。因此，在训练阶段，通过：</p>
<script type="math/tex; mode=display">
\boldsymbol{\hat{x}_{train}}= \boldsymbol{\frac{x_{train} - \mu_B}{\sqrt{\sigma_B^2+\epsilon}}}</script><p>标准化输入，并记录每个 <strong>Batch</strong> 的统计数据 $\boldsymbol{\mu_B、\sigma_B^2}$，用于统计真实的全局 $\boldsymbol{\mu_r、\sigma_r^2}$。在测试阶段，根据记录的每个 <strong>Batch</strong> 的 $\boldsymbol{\mu_B、\sigma_B^2}$ 估计出的所有训练数据的 $\boldsymbol{\mu_r、\sigma_r^2}$，依据：</p>
<script type="math/tex; mode=display">
\boldsymbol{\hat{x}_{test}}= \boldsymbol{\frac{x_{test} - \mu_r}{\sqrt{\sigma_r^2+\epsilon}}}</script><p>将每层的输入标准化。上述的标准化运算并没有引入额外的待优化变量，各个均值和方差均由统计得到，不需要参与梯度更新。但实际上，为了提高 <strong>BN</strong> 层的表达能力，<strong>BN</strong> 层作者引入了 <strong>“scale and shift”</strong> 技巧，将 $\boldsymbol{\hat{x}}$ 变量再次映射变换：</p>
<script type="math/tex; mode=display">
\boldsymbol{\tilde{x} = \hat{x} \cdot\gamma + \beta}</script><p>其中 $\boldsymbol{\gamma}$ 参数实现对标准化后的 $\boldsymbol{\hat{x}}$ 再次进行缩放，$\boldsymbol{\beta}$ 参数实现对标准化的 $\boldsymbol{\hat{x}}$ 进行平移，不同的是，$\boldsymbol{\gamma、\beta}$ 参数均由反向传播算法自动优化即学习参数，实现网络层“按需”缩放平移数据的分布的目的。综上，<strong>BN</strong> 层的流程如下：</p>
<p><img src="https://img-blog.csdnimg.cn/266261b51886466fb14fe20d4ff3d80c.png#pic_center" alt="在这里插入图片描述"></p>
<p>原文的算法流程如下：</p>
<p><img src="https://img-blog.csdnimg.cn/13b202795d7344d28cc5aed5c684c38a.png#pic_center" alt="在这里插入图片描述"></p>
<p>&emsp;&emsp;最后来分析一下 <strong>BN</strong> 层中的参数共享问题，我在上一篇博客中跟大家分享过，特征图的数量取决于卷积层中的卷积核个数。1 个卷积核产生 1 个 <strong>feature map</strong>，1 个 <strong>feature map</strong> 有 1 对 $\boldsymbol{\gamma}$ 和 $\boldsymbol{\beta}$ 参数，同一 <strong>Batch</strong> 同 <strong>channel</strong> 的 <strong>feature map</strong> 共享同一对 $\boldsymbol{\gamma}$ 和 $\boldsymbol{\beta}$ 参数，若卷积层有 $\boldsymbol{n}$ 个卷积核，则有 $\boldsymbol{n}$ 对 $\boldsymbol{\gamma}$ 和 $\boldsymbol{\beta}$ 参数。<br>&emsp;&emsp;至此，我跟大家介绍完了卷积神经网络的基础网络结构，分了两篇博客，分别讲了卷积层、池化层和 BN 层，在下一篇博客中我会跟大家介绍几种经典的 CNN 模型。期待您的访问！感恩！</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>卷积神经网络（一）</title>
    <url>/2022/06/05/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="1-简介"><a href="#1-简介" class="headerlink" title="1    简介"></a>1    简介</h1><p>&emsp;&emsp;<strong>卷积网络</strong>（convolutional network）(LeCun, 1989)，也叫做 <strong>卷积神经网络</strong>（convolutional neural network, CNN），是一种专门用来处理具有类似网格结构的数据的神经网络。例如时间序列数据（可以认为是在时间轴上有规律地采样形成的一维网格）和图像数据（可以看作是二维的像素网格）。卷积网络在诸多应用领域都表现优异。“卷积神经网络’’ 一词表明该网络使用了 <strong>卷积</strong>（convolution）这种数学运算。卷积是一种特殊的线性运算。卷积网络是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络。<br>&emsp;&emsp;卷积网络为什么会出现？得先看看更早时期提出的 <strong>全连接网络</strong>（Fully Connected Neural Network，FC）在处理类似图片数据时会出现的问题：</p>
<ul>
<li>参数过多；</li>
<li>破坏图像的空间分布和像素之间的距离关系；</li>
</ul>
<p>针对上述问题，图像的主要特点：</p>
<ul>
<li>图像的关键特征可能只是图像的一小部分；</li>
<li>相同的特征可能出现在不同位置；</li>
<li>对一张图像进行抽样，不改变预测目标。</li>
</ul>
<p><strong>CNN</strong> 正是针对图像的特点来解决 <strong>FC</strong> 的缺点的。卷积神经网络通常由一个或多个卷积层和顶端的全连通层（对应经典的神经网络）组成，同时也包括 <strong>关联权重</strong> 和 <strong>池化层</strong>（Pooling Layer）等。下图就是一个卷积神经网络架构。</p>
<p><img src="https://img-blog.csdnimg.cn/0f19278124b24dc8bf173254b12592a0.png" alt="在这里插入图片描述"><br>与其他深度学习结构相比，卷积神经网络在图像和语音识别方面能够给出更好的结果。这一模型也可以使用反向传播算法进行训练。相比其他深度、前馈神经网络，卷积神经网络可以用更少的参数，却获得更高的性能。卷积神经网络的一般结构包括卷积神经网络的常用层， 如卷积层、池化层、全连接层和输出层；有些还包括其他层，如正则化层、 高级层等。</p>
<h1 id="2-卷积层"><a href="#2-卷积层" class="headerlink" title="2    卷积层"></a>2    卷积层</h1><p>&emsp;&emsp;针对FC神经网络处理图片数据的两个缺点，CNN提出的解决方案是 <strong>权值共享</strong> 和 <strong>卷积操作</strong>。首先要先理解一个概念：<strong>感受野</strong>，感受野表示当前特征图的 <strong>每个像素</strong> 表示 <strong>原始图像</strong> 的哪部分，看图说话：</p>
<p><img src="https://img-blog.csdnimg.cn/d67ed130fab64b38873845e7e13a6114.png#pic_center" alt="在这里插入图片描述"></p>
<p>输入图像  $\boldsymbol{X}$，维度为  $\boldsymbol{5×5}$，<strong>Layer2</strong> 的输出特征维度是 $\boldsymbol{3×3}$，则其中的任一像素表征着  $\boldsymbol{X}$ 的 9 个像素即 <strong>Layer1</strong> 中的绿色部分，则 <strong>Layer2</strong> 的感受野为 3，<strong>Layer3</strong> 的输出特征维度是 $\boldsymbol{1×1}$，只有一个像素，表征着 <strong>Layer2</strong> 整张特征图，对应到  $\boldsymbol{X}$ 也是表征  $\boldsymbol{X}$ 的整幅特征图，因此 <strong>Layer3</strong> 的感受野是 5。总结成一个规律就是，特征图越小，其感受野越大。 </p>
<h2 id="2-1-权值共享"><a href="#2-1-权值共享" class="headerlink" title="2.1    权值共享"></a>2.1    权值共享</h2><p>&emsp;&emsp;由我们上面介绍的感受野的概念，网络层的每个输出节点（输出像素）仅与感受野区域内 $\boldsymbol{k × k}$ 个输入节点相连接，假如输出节点数为 $\boldsymbol{J}$，则当前层的参数量为 $\boldsymbol{k × k×J}$，相对于全连接层的 $\boldsymbol{I×J}$，$\boldsymbol{k}$ 一般取值较小，如 1、 3、5 等，$\boldsymbol{k×k}$ 远小于 $\boldsymbol{I}$，因此成功地将参数量减少了很多。<strong>注：</strong> 上述假设以及在后面的示例中只有一层卷积层，这是为了用感受野容易表示卷积图像位置，如果是多层卷积，则不能随便使用感受野这个名词。<br>&emsp;&emsp;通过权值共享的思想，对于每个输出节点 $\boldsymbol{o_j}$，均使用相同的权值矩阵 $\boldsymbol{W}$，那么无论输出节点的数量 $\boldsymbol{J}$ 是多少，网络层的参数量总是 $\boldsymbol{k × k}$。如下图所示，在计算左上角位置的输出像素时，使用权值矩阵 $\boldsymbol{W}$：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
w_{00} & w_{01} & w_{02} \\
 w_{10} & w_{11} & w_{12}\\
 w_{020} & w_{21} & w_{22}
\end{bmatrix}</script><p>与对应感受野内部的像素相乘累加，作为左上角像素的输出值；在计算右下方感受野区域时，共享权值参数 $\boldsymbol{W}$，即使用相同的权值参数 $\boldsymbol{W}$相乘累加，得到右下角像素的输出值，此时网络层的参数量只有 $\boldsymbol{3 × 3 = 9}$ 个，且与输入、输出节点数无关。</p>
<p><img src="https://img-blog.csdnimg.cn/295c94aed75b4daca2c7aebdcff2d248.png#pic_center" alt="在这里插入图片描述"><br>通过运用局部相关性和权值共享的思想，我们成功把全连接网络的参数量从 $\boldsymbol{I×J}$ 减少到  $\boldsymbol{𝑘 × 𝑘}$ (准确地说，是在单输入通道、单卷积核的条件下)。这种共享权值的“局部连接层”网络其实就是卷积神经网络。</p>
<h2 id="2-2-卷积操作"><a href="#2-2-卷积操作" class="headerlink" title="2.2    卷积操作"></a>2.2    卷积操作</h2><p>&emsp;&emsp;卷积层是卷积神经网络的核心层，而卷积（Convolution）又是卷积层的核心。对卷积直观的理解，就是两个函数的一种运算，这种运算就称为卷积运算。下图就是一个简单的二维空间卷积运算示例，虽然简单，但却包含了卷积的核心内容。</p>
<p><img src="https://img-blog.csdnimg.cn/090c5cd557af42a586f92eb8f5c4e774.png#pic_center" alt="在这里插入图片描述"><br>上图中，输入和卷积核都是张量，卷积运算就是用卷积分别乘以输入张量中的每个元素，然后输出一个代表每个输入信息的张量。其中卷积核 （kernel）又称权重过滤器，简称为过滤器（filter）。我们可以将输入、卷积 核推广到更高维空间上，输入由 $\boldsymbol{2×2}$ 矩阵，拓展为 $\boldsymbol{5×5}$ 矩阵，卷积核由一个标量拓展为一个 $\boldsymbol{3×3}$ 矩阵，卷积结果如下：</p>
<p><img src="https://img-blog.csdnimg.cn/69d40f9aa9764aae88c092127b785b7f.png#pic_center" alt="在这里插入图片描述"><br>用卷积核中每个元素，乘以对应输入矩阵中的对应元素，这点还是一 样，但输入张量为 $\boldsymbol{5×5}$ 矩阵，而卷积核为 $\boldsymbol{3×3}$ 矩阵，所以这里首先就要解决 一个如何对应的问题，这个问题解决了，这个推广也就完成了。把卷积核作为在输入矩阵上的一个移动窗口，对应关系就迎刃而解了。了解上述的卷积方式之后，下面开始介绍的卷积是单通道输入、单卷积核的情况，然后推广至多通道输入、单卷积核，最后讨论最常用，也是最复杂的多通道输入、多个卷积核的卷积层实现。动图如下：<br><img src="https://img-blog.csdnimg.cn/f6e87cd35b984715bac41a76f68578b3.gif#pic_center" alt="在这里插入图片描述"><br>从数学上来讲，深度学习里面所谓的卷积运算，其实它被称为 <strong>互相关</strong>（cross-correlation）运算：将图像矩阵中，从左到右，由上到下，取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，最后的结果组成一个矩阵，其中没有对核进行翻转。</p>
<h2 id="2-3-单通道输入和单卷积核"><a href="#2-3-单通道输入和单卷积核" class="headerlink" title="2.3    单通道输入和单卷积核"></a>2.3    单通道输入和单卷积核</h2><p>&emsp;&emsp;首先讨论单通道输入 $\boldsymbol{C_{in} = 1}$，如灰度图片只有灰度值一个通道，单个卷积核 $\boldsymbol{C_{out} = 1}$ 的情况（卷积核的个数决定卷积层的输出通道数）。以输入 $\boldsymbol{X}$ 为 $\boldsymbol{5×5}$ 的矩阵，卷积核为 $\boldsymbol{3×3}$ 的矩阵为例，如下图：</p>
<p><img src="https://img-blog.csdnimg.cn/ec9c330197fe4a93ac71a10041ce27f3.png#pic_center" alt="在这里插入图片描述"><br>计算过程如下：与卷积核同大小的感受野(输入 $\boldsymbol{X}$ 上方的绿色方框)首先移动至输入 $\boldsymbol{X}$ 最左上方，选中输入 $\boldsymbol{X}$ 上 $\boldsymbol{3×3}$ 的感受野元素，与卷积核(图片中间 $\boldsymbol{3×3}$ 方框)对应元素相乘：</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
1 & -1 & 0\\
-1 & -2 & 2\\
1 & 2 & -2 \\
\end{bmatrix}⨀
\begin{bmatrix}
-1 & 1 & 2\\
1 & -1 & 3\\
0 & -1 & -2 \\
\end{bmatrix}=
\begin{bmatrix}
-1 & -1 & 0\\
-1 & 2 & 6\\
0 & -2 & 4 \\
\end{bmatrix}</script><p>⨀ 符号表示哈达马积(Hadamard Product)，即矩阵的对应元素相乘。运算后得到 $\boldsymbol{3×3}$ 的矩阵，这 9 个数值全部相加：</p>
<script type="math/tex; mode=display">
− 1−1 + 0−1 + 2 +6 + 0− 2 + 4=7</script><p>得到标量 7，写入输出矩阵第一行、第一列的位置。完成第一个感受野区域的特征提取后，感受野窗口向右移动一个步长单位(Strides，记 为𝑠，默认为 1)，选中下图中绿色方框中的 9 个感受野元素，按照同样的计算方法，与卷积核对应元素相乘累加，得到输出 10，写入第一行、第二列位置。</p>
<p><img src="https://img-blog.csdnimg.cn/8c855c50c2b54b0a9fd64aa02c76dd07.png#pic_center" alt="在这里插入图片描述"><br>感受野窗口再次向右移动一个步长单位，选中下图中绿色方框中的元素，并与卷积核相乘累加，得到输出 3，并写入输出的第一行、第三列位置。</p>
<p><img src="https://img-blog.csdnimg.cn/86b6e06a014e421cacd6b9e94abcb36a.png#pic_center" alt="在这里插入图片描述"><br>此时感受野已经移动至输入 $\boldsymbol{X}$ 的有效像素的最右边，无法向右边继续移动(在不填充无效元素的情况下），因此感受野窗口向下移动一个步长单位(𝑠 = 1)，并回到当前行的行首位置，继续选中新的感受野元素区域，与卷积核运算得到输出-1。此时的感受野由于经过向下移动一个步长单位，因此输出值 -1 写入第二行、第一列位置。</p>
<p><img src="https://img-blog.csdnimg.cn/51bbf50f32194180b073f7850c3ae09d.png#pic_center" alt="在这里插入图片描述"><br>以此类推得到最终的结果：</p>
<p><img src="https://img-blog.csdnimg.cn/7c1985e4181b409db125e6d05012e8cb.png#pic_center" alt="在这里插入图片描述"><br>最终输出我们得到一个 $\boldsymbol{3×3}$ 的矩阵，比输入 $\boldsymbol{5×5}$ 略小，这是因为感受野不能超出元素边界的缘故，由此我们也能知道，在没有扩展输入图像的情况下卷积，输出图像的维度一定会变小，我们将这种卷积方式称作 <strong>Vaild卷积</strong>。可以观察到，卷积运算的输出矩阵大小由卷积核的大小 $\boldsymbol{k}$ ，输入 $\boldsymbol{X}$ 的高宽，移动步长 $\boldsymbol{s}$，是否填充等因素共同决定。</p>
<h2 id="2-4-多通道输入和单卷积核"><a href="#2-4-多通道输入和单卷积核" class="headerlink" title="2.4    多通道输入和单卷积核"></a>2.4    多通道输入和单卷积核</h2><p>&emsp;&emsp;多通道输入的卷积层更为常见，比如彩色的图片包含了 <strong>R/G/B</strong> 三个通道，每个通道上<br>面的像素值表示 <strong>R/G/B</strong> 色彩的强度。下面我们以 3 通道输入、单个卷积核为例，将单通道输入的卷积运算方法推广到多通道的情况。在多通道输入的情况下，卷积核的通道数需要和输入 $\boldsymbol{X}$ 的通道数量相匹配，卷积核的第𝑖个通道和 $\boldsymbol{X}$ 的第 $\boldsymbol{i}$ 个通道运算，得到第 $\boldsymbol{i}$ 个中间矩阵，此时可以视为单通道输入与单卷积核的情况，所有通道的中间矩阵对应元素再次相加，作为最终输出。</p>
<p><img src="https://img-blog.csdnimg.cn/0c3558365d93465ba921c1dbc0a4f675.png#pic_center" alt="在这里插入图片描述"><br>上图中：每行的最左边 $\boldsymbol{5×5}$ 的矩阵表示输入 $\boldsymbol{X}$ 的 <strong>1~3</strong> 通道，第 <strong>2</strong> 列的 $\boldsymbol{3×3}$ 矩阵分别表示卷积核的 <strong>1~3</strong> 通道，第 <strong>3</strong> 列的矩阵表示当前通道上运算结果的中间矩阵，最右边一个矩阵表示卷积层运算的最终输出。在初始状态，每个通道上面的感受野窗口同步落在对应通道上面的最左边、最上方位置，每个通道上感受野区域元素与卷积核对应通道上面的矩阵相乘累加，分别得到三个通道上面的输出 7、-11、-1 的中间变量，这些中间<br>变量相加得到输出-5，写入对应位置。<br>&emsp;&emsp;随后，感受野窗口同步在 $\boldsymbol{X}$ 的每个通道上向右移动 $\boldsymbol{s = 1}$ 个步长单位，此时感受野区域元素如下图所示，每个通道上面的感受野与卷积核对应通道上面的矩阵相乘累加，得到中间变量 10、20、20，全部相加得到输出 50，写入第一行、第二列元素位置。</p>
<p><img src="https://img-blog.csdnimg.cn/75d121f60ebf471ba5aa22a45738b09a.png#pic_center" alt="在这里插入图片描述"><br>以此方式同步移动感受野窗口，直至最右边、最下方位置，此时全部完成输入和卷积核的卷积运算，得到 $\boldsymbol{3×3}$ 的输出矩阵。</p>
<p><img src="https://img-blog.csdnimg.cn/e329b80f1ddd4148ba61e7ef0d39c237.png#pic_center" alt="在这里插入图片描述"><br>输入的每个通道处的感受野均与卷积核的对应通道相乘累加，得到与通道数量相等的中间变量，这些中间变量全部相加即得到当前位置的输出值。输入通道的通道数量决定了卷积核的通道数。一个卷积核只能得到一个输出矩阵，无论输入 $\boldsymbol{X}$ 的通道数量。</p>
<p><img src="https://img-blog.csdnimg.cn/189c48be4e384941977d6f405be730cd.png#pic_center" alt="在这里插入图片描述"><br>一般来说，一个卷积核只能完成某种逻辑的特征提取，当需要同时提取多种逻辑特征时，可以通过增加多个卷积核来得到多种特征，提高神经网络的表达能力，这就是多通道输入、多卷积核的情况。</p>
<h2 id="2-5-多通道输入和多卷积核"><a href="#2-5-多通道输入和多卷积核" class="headerlink" title="2.5    多通道输入和多卷积核"></a>2.5    多通道输入和多卷积核</h2><p>&emsp;&emsp;多通道输入、多卷积核是卷积神经网络中最为常见的形式，前面已经介绍了单卷积核的运算过程，每个卷积核和输入 $\boldsymbol{X}$ 做卷积运算，得到一个输出矩阵。当出现多卷积核时，第 $\boldsymbol{i}$  ( $\boldsymbol{ 𝑖 ∈ 𝑛 }$，𝑛为卷积核个数)个卷积核与输入 $\boldsymbol{X}$ 运算得到第𝑖个输出矩阵(也称为输出张量 $\boldsymbol{O}$ 的通道 $\boldsymbol{i}$），最后全部的输出矩阵在通道维度上进行拼接(Stack 操作，创建输出通道数的新维度)，产生输出张量 $\boldsymbol{O}$ ，$\boldsymbol{O}$ 包含了 $\boldsymbol{n}$ 个通道数。<br>&emsp;&emsp;以 <strong>3</strong> 通道输入、<strong>2</strong> 个卷积核的卷积层为例。第一个卷积核与输入 $\boldsymbol{X}$ 运算得到输出 $\boldsymbol{O}$ 的第一个通道，第二个卷积核与输入𝑿运算得到输出𝑶的第二个通道，输出的两个通道拼接在一起形成了最终输出 $\boldsymbol{O}$ 。每个卷积核的大小 $\boldsymbol{k}$ 、步长 $\boldsymbol{s}$ 、填充设定等都是统一设置，这样才能保证输出的每个通道大小一致，从而满足拼接的条件。</p>
<p><img src="https://img-blog.csdnimg.cn/ffb728e215374554af5454a835e1b13b.png#pic_center" alt="在这里插入图片描述"><br>在CNN中，通常我们会使用大小为奇数的卷积核，因为进行卷积操作时一般会以卷积核模块的一个位置为基准进行滑动，这个基准通常就是卷积核模块的中心。若卷积核为奇数，卷积锚点很好找，自然就是卷积模块中心，但如果卷积核是偶数，这时候就没有办法确定了，让谁是锚点似乎都不怎么好。</p>
<h2 id="2-6-步长"><a href="#2-6-步长" class="headerlink" title="2.6    步长"></a>2.6    步长</h2><p>&emsp;&emsp;步长就是卷积核或过滤器在左边窗口中每次移动的格数 （无论是自左向右移动，或自上向下移动），对于 2D 输入来说，分为沿 $\boldsymbol{x}$ (向右)方向和 $\boldsymbol{y}$ (向下)方向的移动长度。下图中，绿色实线代表的卷积核的位置是当前位置，绿色虚线代表是上一次卷积核所在位置，从上一次位置移动到当前位置的移动长度即是步长的定义。下图中感受野沿 $\boldsymbol{x}$ 方向的步长为 2，表达为步长 $\boldsymbol{s = 2}$。</p>
<p><img src="https://img-blog.csdnimg.cn/7ed94b8d22814d00878f9102b9f827ec.png#pic_center" alt="在这里插入图片描述"><br>当感受野移动至输入 $\boldsymbol{X}$ 右边的边界时，感受野向下移动一个步长 $\boldsymbol{s = 2}$，并回到行首。如下图，感受野向下移动 2 个单位，并回到行首位置，进行相乘累加运算。</p>
<p><img src="https://img-blog.csdnimg.cn/d22dfa54f52e4ec2b220e3ffc3e10361.png" alt="在这里插入图片描述"></p>
<p>循环往复移动，直至达到最下方、最右边边缘位置。然后得到 $\boldsymbol{2×2}$ 的矩阵。</p>
<p><img src="https://img-blog.csdnimg.cn/37e2c77c7f164f8bac2da94939681f64.png" alt="在这里插入图片描述"></p>
<p>可以看到，通过设定步长𝑠，可以有效地控制信息密度的提取。当步长设计的较小时，卷积核以较小幅度移动窗口，有利于提取到更多的特征信息，输出张量的尺寸也更大；当步长设计的较大时，卷积核以较大幅度移动窗口，有利于减少计算代价，过滤冗余信息，输出张量的尺寸也更小。<br>&emsp;&emsp;同时，在卷积核移动过程中，其值始终是不变的，都是卷积核的值。也可以说，卷积核的值在整个过程中都是共享的，所以又把卷积核的值称为共享变 量。卷积神经网络采用参数共享的方法大大降低了参数的数量。在下图中，卷积核如果继续往右移动2格，卷积核窗口部分将在输入矩 阵之外，这种情况该如何处理？具体处理方法就涉及下面的内容——填充（Padding）。</p>
<p><img src="https://img-blog.csdnimg.cn/7c993edb7281400285b2bb80f9204a4a.png" alt="在这里插入图片描述"></p>
<h2 id="2-7-填充"><a href="#2-7-填充" class="headerlink" title="2.7    填充"></a>2.7    填充</h2><p>&emsp;&emsp;在前面我们提过，如果不对图片进行拓展的话，经过卷积运算后的输出 $\boldsymbol{O}$ 的高宽会小于输入 $\boldsymbol{X}$ 的高宽；且当卷积核的步长过大时，卷积核可能会超过图片边界。在实际的网络模型设计时，我们通常希望输出 $\boldsymbol{O}$ 的高宽能够与输入 $\boldsymbol{X}$ 的高宽相同，从而方便网络参数的设计、残差连接等。为了让输出  $\boldsymbol{O}$ 的高宽能够与输入  $\boldsymbol{X}$  的相等，一般通过在原输入  $\boldsymbol{X}$  的高和宽维度上面进行填充(padding)若干无效元素操作，得到增大的输入 $\boldsymbol{X’}$ 。通过精心设计填充单元的数量，在 $\boldsymbol{X’}$ 上面进行卷积运算得到输出 $\boldsymbol{O}$ 的高宽可以和原输入  $\boldsymbol{X}$  相等。这种输入与输出的特征图维度一样的卷积方式，我们称作 <strong>Same卷积</strong>，不填充称作 <strong>Vaild卷积</strong>。<br>&emsp;&emsp;如下图，在高/行方向的上(Top)、下(Bottom)方向，宽/列方向的左(Left)、 右(Right)均可以进行不定数量的填充操作，填充的数值一般默认为 0，也可以填充自定义的数据。上、下方向各填充 1 行，左、右方向各填充 2 列，得到新的输入 $\boldsymbol{X’}$。</p>
<p><img src="https://img-blog.csdnimg.cn/23c1e632e73b4dab974fd86844bd333f.png" alt="在这里插入图片描述"></p>
<p>那么添加填充后的卷积层运算同样，仅仅是把参与运算的输入从  $\boldsymbol{X}$  换成了填充后得到的新张量  $\boldsymbol{X’}$ 。如下图，感受野的初始位置在填充后的  $\boldsymbol{X’}$  的左上方，完成相乘累加运算，得到输出 1，写入输出张量的对应位置。</p>
<p><img src="https://img-blog.csdnimg.cn/e0b0df7456de4ef9a332b5ea981101aa.png" alt="在这里插入图片描述"></p>
<p>循环往复，最终得到 $\boldsymbol{5 × 5}$ 的输出张量。</p>
<p><img src="https://img-blog.csdnimg.cn/eea96add1bf5496489c757891b148bc3.png" alt="在这里插入图片描述"></p>
<h2 id="2-8-卷积的计算公式"><a href="#2-8-卷积的计算公式" class="headerlink" title="2.8    卷积的计算公式"></a>2.8    卷积的计算公式</h2><p>&emsp;&emsp;经过上述对输入图像、卷积核、步长、填充、输出图像的分析，使用张量将它们表示如下：</p>
<ul>
<li>输入图片的尺寸：一般用  $\boldsymbol{n × n}$  表示输入的图像大小；</li>
<li>卷积核的大小：一般用  $\boldsymbol{f × f}$  表示卷积核的大小；</li>
<li>填充（padding）：一般用  $\boldsymbol{p}$  来表示填充大小；</li>
<li>步长(stride)：一般用  $\boldsymbol{s}$  来表示步长大小；</li>
<li>输出图片的尺寸：一般用  $\boldsymbol{o}$  来表示。</li>
</ul>
<p>如果已知 $\boldsymbol{n、f、s}$，则  $\boldsymbol{p = \frac{f - 1}{2}}$，$\boldsymbol{o = \lfloor \frac{n + 2p - f}{s} + 1\rfloor}$。最后再来分析以下卷积核在 <a href="##2.5多通道输入和多卷积核">2.5    多通道输入和多卷积核</a> 的末尾我分析过在实际中卷积核的大小 $\boldsymbol{f}$ 常常使用奇数是为了找到一个好锚点。实际上选择奇数的卷积核也更容易（padding）。当我们使用 <strong>Same卷积</strong> 时，这时候我们就需要用到 padding。但是如果  $\boldsymbol{f}$ 是偶数的话，  $\boldsymbol{p = \frac{f - 1}{2}}$就不是整数了。这意味着我们只需要在输入图像的一边或者两边进行填充。<br>&emsp;&emsp;(这里可选看)在 <strong>PyTorch</strong> 中，假设 <strong>Input</strong> 维度为  $\boldsymbol{(N,C_{in},H_{in}, W_{in})}$，<strong>Output</strong> 维度为  $\boldsymbol{(N,C_{out},H_{out}, W_{out})}$，两维度关系如下：</p>
<ul>
<li>$\boldsymbol{H_{out} = \frac{H_{in} + 2 × padding[0] - dilation[0] ×(kernel\_size[0] - 1) - 1}{stride[0]} + 1}$</li>
<li>$\boldsymbol{W_{out} = \frac{W_{in} + 2 × padding[1] - dilation[1] ×(kernel\_size[1] - 1) - 1}{stride[1]} + 1}$</li>
</ul>
<h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3    总结"></a>3    总结</h1><p>&emsp;&emsp;在本篇博客中，我跟大家分享了卷积神经网络中的基础结构——卷积层，并依次介绍了权值共享、卷积操作、卷积核，填充等内容。卷积神经网络的基础知识有很多，本篇博客介绍不完，剩下的我放到下一篇博客。期待您的访问！感恩！</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>深度学习</tag>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>前向传播</title>
    <url>/2022/06/05/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD/</url>
    <content><![CDATA[<h1 id="一、Learning-rate"><a href="#一、Learning-rate" class="headerlink" title="一、Learning rate"></a>一、Learning rate</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>顾名思义，就是要给每个参数不同的learning rate，上一篇笔记中，我们提到了在沿着Loss函数我们可能会陷入local minima等一些gradient为零从而导致参数无法更新，Loss也就不再下降。但事实是当Loss不再下降的时候，gradient不一定很小，如下图<img src="https://img-blog.csdnimg.cn/d01b9835e2264c7b9e81ed8e431e8824.png#pic_center" alt="在这里插入图片描述"><br>当Loss很小时，gradient仍有在某时候是很大的，我们可以想象下面这样的情形导致的<img src="https://img-blog.csdnimg.cn/f5c537eea08244889a835027671b8d14.png#pic_center" alt="在这里插入图片描述"><br>由图知道Loss不再下降并不是因为卡在local minima或者saddle point，而是因为此时的learning rate太大导致点更新的步伐过大使gradient在“山谷”两侧“反复横跳”导致Loss不再下降。再如下面这个例子：假设只有两个参数不断计算gradient来降低Loss<img src="https://img-blog.csdnimg.cn/9e68d8dd538a43ccb978343394cfb365.png#pic_center" alt="在这里插入图片描述"><br>我们的目的就是能够使黑点到达黄色点的地方，此时Loss最小，设黄色点为山谷最低端，两旁是山壁，前文有说到当Loss不再下降时可能是因为“反复横跳”：<img src="https://img-blog.csdnimg.cn/3026ef9a40be4970a47e20184b7e2458.png#pic_center" alt="在这里插入图片描述"><br>接下来可能就有一个疑问就是，为什么不把learning rate设低一点让黑点跨的步伐小一点进入中间地区呢？嗯，是个好疑问，我们把learning rate设为10e-7看看<img src="https://img-blog.csdnimg.cn/d30a77a1a71848ddb1e40d45d9149c34.png#pic_center" alt="在这里插入图片描述"><br>从图可以看出，虽然黑点不再反复横跳，但他仍然不能到达黄点，这是因为此时的Loss函数已经十分平缓，而learning rate又太小而导致他不能继续再往前，所以我们需要更加特殊的gradient descent</p>
<h2 id="1-1-不同的参数需要不同的learning-rate"><a href="#1-1-不同的参数需要不同的learning-rate" class="headerlink" title="1.1 不同的参数需要不同的learning rate"></a>1.1 不同的参数需要不同的learning rate</h2><p>当在某个地方的方向十分陡峭时我们就需要小的learning rate，反之需要大的learning rate<img src="https://img-blog.csdnimg.cn/ee5b846ca140495c89eb308077217486.png#pic_center" alt="在这里插入图片描述"><br>按照普通的gradient descent，我们更新参数的方法是这样的<img src="https://img-blog.csdnimg.cn/74f768cc249f499aa97ef276c10e4ec4.png#pic_center" alt="在这里插入图片描述"><br>而现在我们因为需要同时更新learning rate，所以将learning rate除以依赖于某个对应参数的未知参数δ<img src="https://img-blog.csdnimg.cn/2950f70ec1ba48ed8fd06236df08722c.png#pic_center" alt="在这里插入图片描述"><br>下面来计算δ的值</p>
<h3 id="1-1-1-Root-Mean-Square计算δ"><a href="#1-1-1-Root-Mean-Square计算δ" class="headerlink" title="1.1.1 Root Mean Square计算δ"></a>1.1.1 Root Mean Square计算δ</h3><p><img src="https://img-blog.csdnimg.cn/e44708fa01b64c6eab2d79fdff90bf0d.png#pic_center" alt="在这里插入图片描述"><br>依照刚刚的δ的计算方法，当在Loss函数曲线较平缓的地方的gradient较小，因为δ跟gradient是呈正比关系，则算出来的δ也小，则learning rate较大，那便可以跨的步伐更大使Loss变化大一点<img src="https://img-blog.csdnimg.cn/d20cf402a93c48cfa6861b99059dd2e2.png#pic_center" alt="在这里插入图片描述"><br>在较陡的地方则相反<img src="https://img-blog.csdnimg.cn/036bf3a6f06b4ce7887944c753e1fe4a.png#pic_center" alt="在这里插入图片描述"><br>但是的话上面的方法还是不够好的，从上面的图中gradient的值都是差不多，都是朝着一个方向呈单调性变化的，但是在现实实验中我们可能会遇到的gradient在一个方向变化的程度可以是很大的<img src="https://img-blog.csdnimg.cn/b7a114266f664c81a52dfd3139dc1469.png#pic_center" alt="在这里插入图片描述"><br>所以我们就需要能够动态改变learning rate的值</p>
<h3 id="1-1-2-RMSProp计算δ"><a href="#1-1-2-RMSProp计算δ" class="headerlink" title="1.1.2 RMSProp计算δ"></a>1.1.2 RMSProp计算δ</h3><p><img src="https://img-blog.csdnimg.cn/7f3d35962c424a00af9605f6b4f7b8c5.png#pic_center" alt="在这里插入图片描述"><br>δ的值取决于gradient的大小，当gradient比较大的时候说明loss很陡峭需要刹车，所以δ的值也会变大，使得learning rate变小，达到一个刹车的目的，否则反之<br><img src="https://img-blog.csdnimg.cn/df8ed34532034b039c27eda2e796004f.png#pic_center" alt="在这里插入图片描述"><br>我们结合RMSProp和Momentum就可以构成最常用的优化器：Adam</p>
<h2 id="1-2-检验结果"><a href="#1-2-检验结果" class="headerlink" title="1.2 检验结果"></a>1.2 检验结果</h2><p>没有动态调整learning rate<br><img src="https://img-blog.csdnimg.cn/158a6ed277ca46a68fb7946c78fe8180.png#pic_center" alt="在这里插入图片描述"><br>之所以 出现红色圆圈里的现象是因为，随着gradient在y轴方向积累了很多小的值，使得δ在y轴方向很小导致learning rate太大出现井喷现象，但不会永远做简谐运动，因为随着learning rate还在不断更新黑点又会重新回到中间，我们有一种方法可以解决这个问题，就是Learning Rate Scheduling<img src="https://img-blog.csdnimg.cn/84200e0269764827aada97b055868bec.png#pic_center" alt="在这里插入图片描述"><br>使随着时间的增加让learning rate变的小一些<img src="https://img-blog.csdnimg.cn/b3d8aef1a911433da070ddda757a4b78.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="二、Classification"><a href="#二、Classification" class="headerlink" title="二、Classification"></a>二、Classification</h1><p>在第一篇的笔记中有写过Regression的output是一个数值，Classification的output是一个类别，如果结合起来看，我们是否可以将Classification当作Regression去训练呢？<br>这期间要求我们做得变化是将类别变成one-hot vector（独热向量）：<br>Class 1 = [1 0 0]T<br>Class 2 = [0 1 0]T<br>Class 3 = [0 0 1]T<br>所以我们就能像做Regression一样得到三组数据<br><img src="https://img-blog.csdnimg.cn/88ce9b37a3d74ef5a2d8e9a06e9398aa.png#pic_center" alt="在这里插入图片描述"><br>最后将得到的y值经过softmax函数得到y’再计算与y^的距离<img src="https://img-blog.csdnimg.cn/843878427f184940a40d2e9337c2a743.png#pic_center" alt="在这里插入图片描述"><br>因为经过神经网络我们得到的y值可能是任何值，但是我们的target只有0和1，所以需要做normalization（归一化）将y值限制到0-1之间，softmax的工作就是这个，具体过程如下：<br><img src="https://img-blog.csdnimg.cn/20ffebbcfb72426590151b6691096fce.png#pic_center" alt="在这里插入图片描述"><br>当我们在做两个类别分类时，可以直接使用sigmoid函数，因为sigmoid函数的取值范围是在0-1之间。<br>对于Classification时我们常用的Loss函数是Cross-entropy，表达式为：Error = -∑y^i*lny’i，在pytorch中，Cross-entropy常常是与softmax结合在一起的。</p>
<h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><p>首先我们先来看两个参数w1、w2对Loss的影响：<br><img src="https://img-blog.csdnimg.cn/c0485ddfd05f430ebe212ec3ef195d32.png#pic_center" alt="在这里插入图片描述"><br>且对应的神经网络是十分简单的：<br><img src="https://img-blog.csdnimg.cn/920d7fb08e504d15a8ae92bbe04e7ad2.png#pic_center" alt="在这里插入图片描述"><br>x1改变一点后，最终L值会改变，但是由于x1的输入都很小时，其实对L的影响变不大。但是如果w2的输入很大，虽然w2只是改变一点点，最终也会对L造成很大影响<img src="https://img-blog.csdnimg.cn/e7d9ff9b971d477b8dfc48aa688d893f.png#pic_center" alt="在这里插入图片描述"><br>所以我们应该让不同维度的数值都有一个相同范围。<br>假设R笔数据分布是这样的<br><img src="https://img-blog.csdnimg.cn/428644aa65a24bf49e06a89e57264e2b.png#pic_center" alt="在这里插入图片描述"><br>我们先把同一维不同笔资料的mean计算出来，用那一维的数减去mean，再除以standard deviation（标准偏差）得到新的x’再放回原来位置，最终feature值都在0左右。考虑深度学习神经网络做normalization<br><img src="https://img-blog.csdnimg.cn/79230d73a6854f4eab4d0c1c1710c1e0.png#pic_center" alt="在这里插入图片描述"><br>开始时我们对input vector做了normalization之后得到z1，z2，z3，而他们又是后一层网络的输入，但是我们得到z值的时候他们的分布并不是分布在0和1之间的，这样会导致第二层训练起来比较困难。所以我们要对z做normalization，一样的步骤，计算mean，std：<br><img src="https://img-blog.csdnimg.cn/44a18541c94c4c13bc08443d391fa954.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/37d00de5708245989c58a6b02ede0642.png#pic_center" alt="在这里插入图片描述"><br>上面这一大部分我们可以看成一层网络，这一层网络时是十分复杂的，因为里面有多个input和output，假如我们一次性把全部的资料读进去的话，计算量十分大，所以我们要考虑每次只对一部分的资料normalization，这就是Batch Normalization。值得注意的是Batch要足够多才行，只有这样才能算出u和δ的值<br>上面都是训练过程，现在来看一下testing：<br>上面我们知道u和    δ只能从比较大的Batch算出来，但是testing时，我们的数据量是不一定能够达到所需Batch值，<img src="https://img-blog.csdnimg.cn/d8c92380d5164808b2760b8e4f94a3c9.png#pic_center" alt="在这里插入图片描述"><br>这里有一个解决方法是，在训练时会把我们每次normalization得到的u1，u2，u3……拿出来计算得到平均值：<br><img src="https://img-blog.csdnimg.cn/263bf80c401647f1becfa9084d788548.png#pic_center" alt="在这里插入图片描述"><br>所以我们在testing时就不用计算u和δ的值，直接拿平均值即可</p>
<h1 id="三、结语"><a href="#三、结语" class="headerlink" title="三、结语"></a>三、结语</h1><p>以上是我本人学习机器学习的学习笔记的第三篇，有错误的地方还望指出，共勉！</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习任务</title>
    <url>/2022/06/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1/</url>
    <content><![CDATA[<h1 id="一、机器学习任务攻略"><a href="#一、机器学习任务攻略" class="headerlink" title="一、机器学习任务攻略"></a>一、机器学习任务攻略</h1><h2 id="1-1-Framework-of-ML"><a href="#1-1-Framework-of-ML" class="headerlink" title="1.1 Framework of ML"></a>1.1 Framework of ML</h2><p>  神经网络一共包含三个模块：训练模块、验证模块、预测模块。其中训练和验证模块共用数据是Training data，但要注意的是要把Training data分成训练和验证数据。<br>训练步骤包括三个步骤：<br>  1、要先写出一个有未知参数的函数f（x），x为input，也叫做feature<br>  2、定义Loss函数，输入为一组参数，计算这组参数所造成的误差<br>  3、定义optimization，找到一组最为合适的参数θ*，使得Loss最小<br>预测部分是用训练好的θ对Testing data进行预测结果。</p>
<h2 id="1-2-提高结果的准确性"><a href="#1-2-提高结果的准确性" class="headerlink" title="1.2 提高结果的准确性"></a>1.2 提高结果的准确性</h2><p>检查training data的Loss</p>
<h3 id="1-2-1-Loss过大"><a href="#1-2-1-Loss过大" class="headerlink" title="1.2.1 Loss过大"></a>1.2.1 Loss过大</h3><p>显然在训练资料上效果并不是很好，这时要从两方面出发检查：<br>1.model bias的原因：<br>  model过于简单，导致在神经网络的函数集中没有可以让Loss变的足够小的函数，就像在海中捞针<br>  解决方法：重新设计model让其更加深，鲁棒性更强<br>  1.增加输入的feature，或者使用Deep Learning<br>  <img src="https://img-blog.csdnimg.cn/fe38e307c8cc4583b1429e2ddb50f121.png" alt="在这里插入图片描述"><br>  <img src="https://img-blog.csdnimg.cn/728166a8620e4c77871276b7949dcbff.png" alt="在这里插入图片描述"><br>2.optimization做的不好<br> 在训练过程中可能卡到一个局部最优点（local minima）的地方，虽然网络中存在一个最好的函数，但是你无法找到让Loss最小的一组参数θ*<br> <img src="https://img-blog.csdnimg.cn/d9d0bbbebada476fb6ed815b5c7ffbfd.png#pic_center" alt="在这里插入图片描述"><br> 如何区分是model bias还是optimization的问题<br> 当一个神经网络的层数比另外一个神经网络要大，但Loss值却更大，则是optimization的问题，因为越深的网络的鲁棒性会更大；此外则是model bias的问题<br> <img src="https://img-blog.csdnimg.cn/091969533b60468e8be93969563b29a1.png#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-2-2-Loss足够小，但testing-data的Loss过大"><a href="#1-2-2-Loss足够小，但testing-data的Loss过大" class="headerlink" title="1.2.2 Loss足够小，但testing data的Loss过大"></a>1.2.2 Loss足够小，但testing data的Loss过大</h3><p>这里也要从两方面分析<br>1.over fitting<br>举一个极端的例子：<br>我们的testing data为：<br><img src="https://img-blog.csdnimg.cn/ad56387e9fb2422d9a9b7098bed4722d.png" alt="在这里插入图片描述"><br>通过training找出这样一个函数：<br><img src="https://img-blog.csdnimg.cn/d3bd1ecf77024e53b21edc839516b1b7.png#pic_center" alt="在这里插入图片描述"><br>当能够在训练资料中找到x的话就输出yi，否则就随机输出一个值。基于此，这个函数在training过程中的Loss为0，但是在test过程中就什么也没干，所以在testing过程中的Loss会很大，这就是over fitting。<br>在真实的实验过程中，往往是因为model的鲁棒性太强，导致在training后得到的模型有很大的“自由区”而不能很好的拟合testing数据<br><img src="https://img-blog.csdnimg.cn/98f7bbfa3dd943bcad15edc36787c35d.png#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/e709d8efa02f4d139940caf0e27d6c28.png#pic_center" alt="在这里插入图片描述"><br>导致Loss过大<br>解决方法：<br>1.增加数据量（Data augmentation）<br><img src="https://img-blog.csdnimg.cn/bd247ec02e7642d2992d7cd19fe47027.png#pic_center" alt="在这里插入图片描述"></p>
<p>2.限制model的鲁棒性<br>根据training的数据设定函数，少一些参数<br><img src="https://img-blog.csdnimg.cn/3b8b0f61c2ee40dfb5f1518cd5a8d6b6.png#pic_center" alt="在这里插入图片描述"><br>但要注意的是不能给model太多的限制，否则会导致model bias的问题<br>综上，我们可以得出model的复杂程度和Loss的一个非线性关系<br><img src="https://img-blog.csdnimg.cn/1564b47d4edb4778914f5d7175bd3d73.png#pic_center" alt="在这里插入图片描述"><br>当model越来越复杂时，虽然Training loss越来越小，但是可能会出现over fitting的问题，导致预测结果不准<br>我们在前面说过，我们有三大模块，训练、验证和预测，且将training data随机分成训练数据和验证数据，当我们在每一个epoch训练后得到的θ参数和loss，我们要将θ进行验证，如果验证组得到的loss更小，说明这组参数是较优的，将此loss替换训练得到的loss，最终找到一组最优解</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dev_mse = dev(model, dev_data)</span><br><span class="line"><span class="keyword">if</span> dev_mse &lt; min_mse :</span><br><span class="line">   	min_mse = dev_mse</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dev</span>(<span class="params">model, dev_data</span>) :</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    total_loss = []</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, label <span class="keyword">in</span> dev_data :</span><br><span class="line">        output = model(<span class="built_in">input</span>)</span><br><span class="line">        total_loss.append(model.cal_loss(output, label))</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(total_loss) / <span class="built_in">len</span>(total_loss)</span><br></pre></td></tr></table></figure>
<p>此外我们还可以用N折交叉验证的方法进行分数据和找θ*<br><img src="https://img-blog.csdnimg.cn/56cceab802cc4d93b098313d7c53a29d.png#pic_center" alt="在这里插入图片描述"><br>2.认为影响，这种问题不能怪model，机器是死的，这种问题一般来说叫做mismatch</p>
<h1 id="二、局部最小值（local-minima）与鞍点（saddle-point）"><a href="#二、局部最小值（local-minima）与鞍点（saddle-point）" class="headerlink" title="二、局部最小值（local minima）与鞍点（saddle point）"></a>二、局部最小值（local minima）与鞍点（saddle point）</h1><p>当optimization失败时一般有两点原因：<br>1.loss值无法再小，此时已经找到了一组最优解θ*<br>2.gradient等于0<br><img src="https://img-blog.csdnimg.cn/cf025c9accf44c99bfb743418a7b9b5d.png#pic_center" alt="在这里插入图片描述">这里我们对gradient==0的情况进行分析，当gradient等于0时，这个点有三种情况：<br>处于local minima，此时loss处于局部最小，没办法走到其他地方<br><img src="https://img-blog.csdnimg.cn/98b70267da1a402d9d966eb5d878d41f.png#pic_center" alt="在这里插入图片描述"><br>值得注意的是，local minima也有好坏之分当minima处于尖端的时候，testing loss是十分大的，而在平缓区时，testing loss就没那么大<br><img src="https://img-blog.csdnimg.cn/f38512838eb842be82f213ad4557aabe.png#pic_center" alt="在这里插入图片描述"></p>
<p>处于saddle point，此时loss并不是局部最小值，有别的地方可以走，这样就有机会到达全局最小点<br><img src="https://img-blog.csdnimg.cn/056c72263b5a4d2bb8483b56a787b92a.png#pic_center" alt="在这里插入图片描述"><br>Saddle Point vs Local Minima<br>他们两者之间谁更加常见呢？<br>如果在从二维空间去看的话Saddle Point就可能被认为是Local Minima<br><img src="https://img-blog.csdnimg.cn/dfdd51cc86e743838559786628dcbf56.png#pic_center" alt="在这里插入图片描述"><br>反过来假如我们从更高维度去看的话Local Minima却是Saddle Point<br><img src="https://img-blog.csdnimg.cn/1c32aaf3bda34b058cd818e323cb639c.png#pic_center" alt="在这里插入图片描述"><br>也就是说假如我们在某个维度没路可走的时候，我们可以提高维度来使其变成Saddle Point从而有路可走。这就是现在为什么神经网络如此复杂、参数众多的重要原因</p>
<h1 id="三、Batch和momentum"><a href="#三、Batch和momentum" class="headerlink" title="三、Batch和momentum"></a>三、Batch和momentum</h1><h2 id="3-1-Batch"><a href="#3-1-Batch" class="headerlink" title="3.1 Batch"></a>3.1 Batch</h2><p>现在假如说有一笔N资料，我们可以把N笔资料一次性全部跑完再计算loss和更新一次参数θ，但是的话我们也可以将N笔资料分成许多个batch资料，我们每跑完一个batch资料就计算更新一次参数<br><img src="https://img-blog.csdnimg.cn/91949cf989944b53a2ce9d290e0a4d0c.png#pic_center" alt="在这里插入图片描述"><br>1 epoch等于把全部的batch都看一遍<br>为什么要用batch？<br>现在有20笔资料，我们分别看看用和不用batch的参数更新效果<br><img src="https://img-blog.csdnimg.cn/2941be02cc9e4db5ae7b0e54028b59a6.png#pic_center" alt="在这里插入图片描述"><br>可以看出没有用batch的model的蓄力时间比较长，但每走一步都比较稳；用了batch的model蓄力时间短，但每次走的时候方是十分乱的。但是如果考虑gpu的平行预算，没有用batch耗费的时间不一定比用了batch所花时间长。在MNIST机器学习任务（一共有六万笔资料）中：<br>跑每一个不同batch所用时间如下，（6000代表不用batch）<br><img src="https://img-blog.csdnimg.cn/0d9369eca1ad471389b3fd91dc1d1430.png#pic_center" alt="在这里插入图片描述"><br>我们再看跑完一个epoch和跑完一个batch所需时间对比：<br><img src="https://img-blog.csdnimg.cn/028e4aa0dd214a7298b60a30dcb8d0ad.png#pic_center" alt="在这里插入图片描述"><br>我们可以看出一个epoch大的batch花的时间反而是比较少的<br>但是与我们直觉不同的是，分了batch的任务最终预测的正确率是比没分batch是要高的<br><img src="https://img-blog.csdnimg.cn/3038616128e843e6bf6037f537bba320.png#pic_center" alt="在这里插入图片描述"><br>为什么分batch会带来更好的结果？<br>我们先来考虑Full batch的情况<br>我们沿着Loss函数来更新参数，当陷入一个local minima之后就停止更新参数<br><img src="https://img-blog.csdnimg.cn/575bfa93f08d475d8e346d92c3992239.png#pic_center" alt="在这里插入图片描述"><br>再考虑small batch时，当我们用θ1参数组来算gradient的时候，他的loss函数是L1当遇到gradient等于0时就卡住了，但不会停止更新函数，可以用下一个batch来train优化model<br><img src="https://img-blog.csdnimg.cn/924a99ef89964f72a4700479a13f88b4.png#pic_center" alt="在这里插入图片描述"><br>Small Batch VS Large Batch<br><img src="https://img-blog.csdnimg.cn/7f28ab5d30a54fb5858ddbc5cf5cd6fa.png#pic_center" alt="在这里插入图片描述"><br>正因他们有各自的优点，则Batch size变成一个hyper parameter（超参数）</p>
<h2 id="3-2-Momentum"><a href="#3-2-Momentum" class="headerlink" title="3.2 Momentum"></a>3.2 Momentum</h2><p>momentum是一门可能可以对抗local minima的技术。他的概念可以想象成物理世界中的惯性，我们可以想象，当一个小球沿着loss函数走，当走到local minima时因为他有惯性而不会在minima处停下<br><img src="https://img-blog.csdnimg.cn/4ec31491daeb49c6bb65ae02b0b072fa.png#pic_center" alt="在这里插入图片描述"><br>对于普通的gradient descent，假设开始在θ0的点，计算该点gradient为g(0)，沿着gradient的反方向移动到θ1 =   θ0 - ng(0) 然后计算g(1)…..<br><img src="https://img-blog.csdnimg.cn/4a865146cedb4ad9a1df22327b4f4207.png#pic_center" alt="在这里插入图片描述"><br>结合momentum的gradient descent<br>我们在更新gradient时不单单沿着gradient的反方向，还要加上前一步(momentum)的方向进行更新，类似于物理中的力的合成，计算过程如下图：<br><img src="https://img-blog.csdnimg.cn/2be951e89eed4036ac7c7ab29915a82f.png#pic_center" alt="在这里插入图片描述"><br>当我们走到local minima和和saddle point时虽然gradient==0，但是由于我们还有前一步的momentum所以还会继续走下去<br><img src="https://img-blog.csdnimg.cn/9419e31cc1414edbb95afd1a247d221b.png#pic_center" alt="在这里插入图片描述"></p>
<h1 id="四、结语"><a href="#四、结语" class="headerlink" title="四、结语"></a>四、结语</h1><p>以上是我机器学习学习笔记的第二篇，如有不对之处，还望指出，与君共勉。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习概述</title>
    <url>/2022/06/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="一、机器学习基本概念简介"><a href="#一、机器学习基本概念简介" class="headerlink" title="一、机器学习基本概念简介"></a>一、机器学习基本概念简介</h1><h2 id="1-1机器学习的定义"><a href="#1-1机器学习的定义" class="headerlink" title="1.1机器学习的定义"></a>1.1机器学习的定义</h2><p>我们所要求机器所能为我们做的事情均离不开两个最要的模块：输入和输出。比如对于无人驾驶来说，汽车必须根据路段信息来决定车辆的行驶，在此过程中，路段信息就是输入，车俩的行驶就是输出，但问题是他是怎么让输入变成输出的呢。而这就是机器学习所需要做的事情：寻找一个函数根据输入而输出合理的操作，表示为f（输入）—&gt; 输出，这也是机器学习的定义。</p>
<h2 id="1-2函数的分类"><a href="#1-2函数的分类" class="headerlink" title="1.2函数的分类"></a>1.2函数的分类</h2><p>在机器学习中我们知道其定义是找一个函数来根据输入做出合理的输出，在这里介绍两种常见函数：<br>1.Regression（回归函数）：其输出是一个数值。如我们需要预测未来的PM2.5的浓度，当天的PM2.5浓度、气温、臭氧的浓度为输入然后经过一个回归函数来预测明天的PM2.5浓度。<br><img src="https://img-blog.csdnimg.cn/9489ec10768842349149893e675bc924.PNG#pic_center" alt="在这里插入图片描述"><br>2.Classification（分类函数）：其输出为一个类别。如我们在收到邮件时，常常有些骚扰或者垃圾邮件，这些邮件便是输入，经过分类函数可以将这些归类到“垃圾邮件”类别之中<br><img src="https://img-blog.csdnimg.cn/5b0de484b4574e60be7847a10579f8d1.PNG#pic_center" alt="在这里插入图片描述"></p>
<h2 id="1-3如何寻找函数"><a href="#1-3如何寻找函数" class="headerlink" title="1.3如何寻找函数"></a>1.3如何寻找函数</h2><h3 id="1-3-1定义函数"><a href="#1-3-1定义函数" class="headerlink" title="1.3.1定义函数"></a>1.3.1定义函数</h3><p>根据之前视频播放资讯预测未来的播放量即其他比例<br><img src="https://img-blog.csdnimg.cn/65f158ba7833419cb252a913ca1b31c5.PNG#pic_center" alt="在这里插入图片描述"><br>函数的输入是前一天的资讯，输出是今天的播放量的预测值。我们可以把函数设成一次函数:<br>y = b +wx1 其中b我们称为偏置参数bias，w为权重参数weight。x1是前一天的播放量，是我们所知道的，称作feature，w和b是未知的，需要我们通过学习得到的，而这样的一个带有未知参数的函数我们称作Model（模型）</p>
<h3 id="1-3-2定义Loss函数"><a href="#1-3-2定义Loss函数" class="headerlink" title="1.3.2定义Loss函数"></a>1.3.2定义Loss函数</h3><p>Loss函数的输入是我们在1.31所定义函数的未知参数（parameters）即：L(b, w)，输出我们预测的数据更跟实际数据的差别。如：<br>令L=L(500, 1)，则y = b + wx1 -&gt; y = 500 + x1 假设有下面时间的播放量：<br><img src="https://img-blog.csdnimg.cn/af94ddc9002e41c996fe40936249bde8.PNG#pic_center" alt="在这里插入图片描述"><br>对于2017/1/2这一天，当b=500，w=1时，x1等于2017/1/1的播放量根据所设函数计算y=500+4800 = 5300，即我们预测01/02号这天的播放量是5300，但从开始的资讯中我们可知实际这天的实际播放量是4900，则en=abs（5300 - 4900）。同样的方法，我们都可以算出每一天的误差。则最终的Loss = 1/N ∑en，N表示有N份学习资料。我们也可以推出在不同b和w值下Loss是不一样的，而机器要做的就是寻找一组最合适的b，w值从而使Loss最小，提高预测的精确度</p>
<h3 id="1-3-3定义Optimization（优化函数）"><a href="#1-3-3定义Optimization（优化函数）" class="headerlink" title="1.3.3定义Optimization（优化函数）"></a>1.3.3定义Optimization（优化函数）</h3><p>在1.3.2中我们知道要寻找一组最合适的b，w值的过程就是不断优化未知函数的过程，而最常用的方法就是梯度下降法（Gradient Descent）</p>
<h4 id="1-3-3-1假设只有w需要优化时"><a href="#1-3-3-1假设只有w需要优化时" class="headerlink" title="1.3.3.1假设只有w需要优化时"></a>1.3.3.1假设只有w需要优化时</h4><p>w<em> = arg minLoss，假设Loss函数与w关系如下：<br><img src="https://img-blog.csdnimg.cn/aff76bb9336e4f9aaa97957a127fe402.PNG#pic_center" alt="在这里插入图片描述"><br>首先随机找一个w的初始值w0，计算在w0的L对w的微分∂L/∂w（w=w0）也就是斜率：<br><img src="https://img-blog.csdnimg.cn/1b64a43477f1485a842770f58a9642fa.PNG?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>从图中我们可以观察到此偏导是负的，所以在w0左边的虚线比较高，右边比较低，这样的话我们可以提高w的值来使Loss值减小（偏导如果是正的则相反），有：<br><img src="https://img-blog.csdnimg.cn/0027698ef8a1475d81f5d91cd2797179.PNG#pic_center" alt="在这里插入图片描述"><br>在图中又有了一个新的参数为η，我们称作学习率（Learing rate），η值越大，w值更新越快，越小则w值更新越慢。而η是需要我们在实验过程中手动设置的参数，我们将这一类参数叫做超参数（hyperparameters），由图我们也能得出w与Loss的微分关系：w1-w0=η</em>∂L/∂w（w=w0），以此方法训练数据得到Loss的最小值，此时gradient为0<br>同样，b的值也是以这种方法不断更新</p>
<h4 id="1-3-3-2将b，w的方向组合在一起时"><a href="#1-3-3-2将b，w的方向组合在一起时" class="headerlink" title="1.3.3.2将b，w的方向组合在一起时"></a>1.3.3.2将b，w的方向组合在一起时</h4><p>w<em>，b</em> = arg minLoss，可视化后：<br><img src="https://img-blog.csdnimg.cn/e32ed89a3b7c444c82360f61684c7b1d.PNG?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"><br>当w<em> = 0.97（接近1），b</em> = 100（一般设的比较小）Loss值达到最小480，因此我们拿出这组数据来预测一下;<br><img src="https://img-blog.csdnimg.cn/2bce80fcb60f452f93c8975b1f9493c1.PNG#pic_center" alt="在这里插入图片描述"><br>可以看出大致的方向是能够拟合的，但是预测的播放量的低估总是比实际的出现晚一两天，这可能出现的原因是我们在预测是只用前一天的数据就行预测，数据量太少，因此我们就要修改我们的Model。</p>
<h2 id="1-4函数的修改"><a href="#1-4函数的修改" class="headerlink" title="1.4函数的修改"></a>1.4函数的修改</h2><h3 id="1-4-1取多天的资讯进行训练"><a href="#1-4-1取多天的资讯进行训练" class="headerlink" title="1.4.1取多天的资讯进行训练"></a>1.4.1取多天的资讯进行训练</h3><p>考虑7天时，函数由y = b + wx1 变成y = b + ∑wjxj（j从1到7）每一天的播放量都乘上对应的w值，Loss值变化及对应的b，w值如下：<br><img src="https://img-blog.csdnimg.cn/4ade2987fd394efe911f7acab9c6aa40.PNG#pic_center" alt="在这里插入图片描述"><br>L表示训练数据上的损失，L‘表示预测未知数据的损失。随着参考天数的增加，Loss值实在减小，而表格中w有正由负，负表示前一天的播放量与我们预测的那天的播放量是成反比的，从函数的表达式我们也能得到这个结论，w为正则相反。<br>当我们继续考虑28天和56天时：<br><img src="https://img-blog.csdnimg.cn/34e259fe7ed3404a872b6e7d992ffd7c.PNG#pic_center" alt="在这里插入图片描述"><br>我们发现考虑天数对Loss值的影响已经变化不大，因此这应该是极限了。<br>而以上我们所设和修改后的函数模型称作线性模型（Linear Models）</p>
<h1 id="二、深度学习基本概念简介"><a href="#二、深度学习基本概念简介" class="headerlink" title="二、深度学习基本概念简介"></a>二、深度学习基本概念简介</h1><p>前言：Linear Models对我们解决应用场景问题来说太过于简单了，因为Linear Medols永远都只是一条直线，你可以通过修改w值来改变斜率和修改b来修改斜距，但是其永远是直线。<img src="https://img-blog.csdnimg.cn/002df87309e540aa8f12385a1e8dfbcc.PNG#pic_center" alt="在这里插入图片描述"><br>而我们需要的可能是一段斜率是正的，而一段是负的，此时线性模型就永远不能满足这一点，显然Linear Models有着许多的限制，而这种来自于Models的限制叫做Model Bias，注意不是我们上面所设函数中的b参数。因此，我们需要更加有弹性的函数来实现图中红色线段。</p>
<h2 id="2-1sigmoid函数定义"><a href="#2-1sigmoid函数定义" class="headerlink" title="2.1sigmoid函数定义"></a>2.1sigmoid函数定义</h2><p>上述的红色曲线可以由一个常数项加上一堆s型折线的和来实现<br><img src="https://img-blog.csdnimg.cn/76504b95a0b948a7bf189386c5fa4f1e.PNG#pic_center" alt="在这里插入图片描述"><br>从0，1，2，3蓝色曲线分别取与红色曲线相对应的部分即可构成红色曲线。依照这种方法，无论所求的曲线有多复杂，折点有多多，我们都可以用一个常数项加不同数的s性折线构成。而要写出s性折线的函数表达式并不是很容易，所以我们可以用一条光滑的曲线去逼近它，这个曲线函数就是sigmoi函数：<br><img src="https://img-blog.csdnimg.cn/46b187fd0c714980a6a23489ade209fb.PNG#pic_center" alt="在这里插入图片描述"><br>从sigmoid函数表达式中y = c<em>[1 / (1 + e-(b + wx1))]（注意表达式中的b是Models bias）看出当x1非常大是函数值会收敛到c的位置，当x1非常小时，函数值会收敛到0。sigmoid函数可写成y = c </em> sigmoid(b + wx1)</p>
<h2 id="2-2sigmoid函数如何逼近各种线段"><a href="#2-2sigmoid函数如何逼近各种线段" class="headerlink" title="2.2sigmoid函数如何逼近各种线段"></a>2.2sigmoid函数如何逼近各种线段</h2><p>1.改变w值可以改变sigmoid函数图像的斜率<br>2.改变b的值可以让sigmoid函数图像左右移动<br>3.修改c的值可以改变sigmoid函数图像的高度<br><img src="https://img-blog.csdnimg.cn/03b2d7840d4b486196814d3214cf30c1.PNG#pic_center" alt="在这里插入图片描述"></p>
<h2 id="2-3建立更加弹性的函数"><a href="#2-3建立更加弹性的函数" class="headerlink" title="2.3建立更加弹性的函数"></a>2.3建立更加弹性的函数</h2><h3 id="2-3-1更多的Model-Features"><a href="#2-3-1更多的Model-Features" class="headerlink" title="2.3.1更多的Model Features"></a>2.3.1更多的Model Features</h3><p>当我们用很多的sigmoid函数去形成一条复杂的函数图像时，每一个sigmoid函数中参数c，b，w都是不一样的。<br>当我们只用一天的数据去预测未来的播放量时，函数可变成<br><img src="https://img-blog.csdnimg.cn/27632afc2bc14869b3bbe0b553d5afbc.PNG#pic_center" alt="在这里插入图片描述"><br>其中i表示sigmoid函数的个数<br>当用多天数据时，函数可变成<br><img src="https://img-blog.csdnimg.cn/f5100617cf51465184fd30f6169bd1f7.PNG#pic_center" alt="在这里插入图片描述"><br>其中i代表sigmoid函数个数，j代表天数，xj表示第前j天的播放量</p>
<h3 id="2-3-2sigmoid函数的计算方式"><a href="#2-3-2sigmoid函数的计算方式" class="headerlink" title="2.3.2sigmoid函数的计算方式"></a>2.3.2sigmoid函数的计算方式</h3><p>当j：1，2，3；i：1，2，3时，计算图如下：<br><img src="https://img-blog.csdnimg.cn/1b40be5955784d94bd03e3334c4c334e.PNG#pic_center" alt="在这里插入图片描述"></p>
<p>其中x1，x2，x3表示该天的播放量，wij表示乘给xj的播放量的weight。把b1+w11x1+w12x2+w13x3相加送到第一个sigmoid函数中计算，第二、三个sigmoid函数也是这样计算。为了简化计算过程，我们可以用矩阵的方法来计算，令<br>r1=b1+w11x1+w12x2+w13x3<br>r2=b2+w21x1+w22x2+w23x3<br>r3=b3+w31x1+w32x2+w33x3<br><img src="https://img-blog.csdnimg.cn/8ecba25138e74a69b0ef9ee6bd8b0f12.PNG#pic_center" alt="在这里插入图片描述"><br>再令a=sigmoid（r）=1 / （1 + e-r），再乘每个sigmoid函数的c再相加有!<br><img src="https://img-blog.csdnimg.cn/8fd8aef351f74ef7a988e3de65a8428a.PNG#pic_center" alt="在这里插入图片描述"><br>如果将三个sigmoid函数的过程整合成矩阵计算的话，如下：<br><strong>r</strong> = <strong>b</strong> + <strong>wx</strong><br><strong>a</strong> = sigmoid（<strong>r</strong>）<br><strong>y</strong> = <strong>b</strong> + <strong>c</strong>T（<strong>c</strong>矩阵的转置）<strong>a</strong><br>即 <strong>y</strong> = <strong>b</strong> + <strong>c</strong>T sigmoid（<strong>b</strong> + <strong>wx</strong>）</p>
<h2 id="2-4新Loss"><a href="#2-4新Loss" class="headerlink" title="2.4新Loss"></a>2.4新Loss</h2><p>在<strong>y</strong> = <strong>b</strong> + <strong>c</strong>T sigmoid（<strong>b</strong> + <strong>wx</strong>）中，我们将所有矩阵的每一列或者每一行整合在一起得到一个大的矩阵<strong>θ</strong><br><img src="https://img-blog.csdnimg.cn/8e38edc5d096454f93346448395cbf52.PNG#pic_center" alt="在这里插入图片描述"></p>
<p>所以Loss函数每一组的参数可以用<strong>L</strong>(θ)来表示，计算方法跟只有w，b时是一样的，只不过现在可能是几百，几千个参数</p>
<h2 id="2-5新Optimization"><a href="#2-5新Optimization" class="headerlink" title="2.5新Optimization"></a>2.5新Optimization</h2><p>计算方法参数的更新方法跟只有w，b时是一样的<br><strong>θ*</strong> = arg minLoss   <strong>θ</strong> = [θ1 θ2 θ3…]T</p>
<h2 id="2-6batch与epoch"><a href="#2-6batch与epoch" class="headerlink" title="2.6batch与epoch"></a>2.6batch与epoch</h2><p>当我们有一笔N资料时，要去计算Loss时，我们可以将N笔资料分成M份，每一份有N/M笔资料，N/M笔资料就叫做一个batch，而我们可以先计算每一个batch的Loss’，然后更新参数<strong>θ</strong>，计算出gradient。当所有batch都看过一遍之后叫做epoch</p>
<h2 id="2-7ReLU（Rectified-Linear-Unit）函数"><a href="#2-7ReLU（Rectified-Linear-Unit）函数" class="headerlink" title="2.7ReLU（Rectified Linear Unit）函数"></a>2.7ReLU（Rectified Linear Unit）函数</h2><p>ReLU是现在深度学习最常用的激活函数，表达式为<br>y = b + ∑ci max(0, ∑wijxj)<br>可以看出ReLU是分段函数，当∑wijxj &gt; 0时，y = ∑wijxj，当∑wijxj &lt;= 0时，y = 0 图像为<br><img src="https://img-blog.csdnimg.cn/3a17d89f025143858c181a7628f8b49e.PNG#pic_center" alt="在这里插入图片描述"><br>且可以看出两个ReLU函数才能组成一个sigmoid函数<br><img src="https://img-blog.csdnimg.cn/8ba370b8b6a5400283cc69923033282d.png" alt="在这里插入图片描述"><br>它们都是激活函数，一般来说ReLU的拟合效果比sigmoid函数好，因此ReLU更加常用</p>
<h2 id="2-8多层网络及深度学习的定义"><a href="#2-8多层网络及深度学习的定义" class="headerlink" title="2.8多层网络及深度学习的定义"></a>2.8多层网络及深度学习的定义</h2><p>之前所有的讨论都是只经过一次激活函数，但是我们可以通过多层的激活函数进行预测结果，一层激活函数的输出可以作为下一层的输入，所以层与层之间的参数是不相同的<br><img src="https://img-blog.csdnimg.cn/990b0409cf6f4b30a20cd899bed23bc3.png" alt="在这里插入图片描述"><br>注意两个<strong>a</strong>向量是不同的<br>在预测我们一开始的视频播放量时，当经过一百层的ReLU函数后，Loss与预测和实际播放量的拟合程度如下图：<br><img src="https://img-blog.csdnimg.cn/0e781da4e8cd4c20bda10c4c463540ae.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/c979016206b8436a986642124bda9aed.png" alt="在这里插入图片描述"><br>在上面的许多层的ReLU或者sigmoid，被称作Neuron（神经元），很多的Neuron就叫做Neural Network，许多许多的隐藏层就叫做Deep，而这一套分析计算技术就叫做Deep Learning</p>
<h1 id="三、后话"><a href="#三、后话" class="headerlink" title="三、后话"></a>三、后话</h1><p>此系列文章是我学习深度学习的一些笔记，可能过程中有些错误，欢迎大家指正，不胜感激！与君共勉</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>pip 安装 tensorflow 可能出现的问题</title>
    <url>/2022/06/05/pip-%E5%AE%89%E8%A3%85-tensorflow-%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>﻿解决安装用pip tensorflow过程中的一些问题：<br>1.超时问题，使用镜像源下载</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install tensorflow -i https://pypi.mirrors.ustc.edu.cn/simple/</span><br></pre></td></tr></table></figure>
<p>2  TensorFlow 软件包依赖项出现冲突，要安装以下包</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip3 install six numpy wheel</span><br><span class="line">pip3 install keras_applications==<span class="number">1.0</span><span class="number">.6</span> --no-deps</span><br><span class="line">pip3 install keras_preprocessing==<span class="number">1.0</span><span class="number">.5</span> --no-deps</span><br></pre></td></tr></table></figure>
<p>3.出现管理员权限问题<br><img src="https://img-blog.csdnimg.cn/00dc61c6fa204f72821627baeafefb9d.PNG#pic_center" alt=""><br>pip install …加入—user为pip install —user …</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>pip 安装 tensorflow</title>
    <url>/2022/06/05/pip-%E5%AE%89%E8%A3%85-tensorflow/</url>
    <content><![CDATA[<p>﻿<strong>ModuleNotFoundError: No module named ‘tensorboard’</strong><br>解决方法：用pip安装两个包</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">pip install tb-nightly或者pip install tb-nightly-gpu</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install future</span><br></pre></td></tr></table></figure>
<p>但安装过程中可能会出现问题超时等问题</p>
<p>所以建议使用镜像下载，我这里用的是豆瓣镜像：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">pip install tf-nightly-gpu -i http:<span class="comment">//pypi.douban.com/simple --trusted-host pypi.douban.com</span></span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">pip install future -i http:<span class="comment">//pypi.douban.com/simple --trusted-host pypi.douban.com</span></span><br></pre></td></tr></table></figure>
<p>速度贼快（不过有一点是就算是很快也要等起码半小时左右，且一次装好几乎不可能，因为与他配件的其他包可能版本过高或者过低，祝你好运，嘻嘻。</p>
]]></content>
      <categories>
        <category>机器学习</category>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/06/03/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
</search>
